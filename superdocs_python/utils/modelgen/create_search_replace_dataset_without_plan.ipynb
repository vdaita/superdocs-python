{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brx import BRX, sftoq, uif\n",
    "from superdocs_python.utils.diff_utils import parse_diff\n",
    "from datasets import load_dataset, IterableDataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from superdocs_python.utils.model import create_model\n",
    "import tiktoken\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "\n",
    "# the prompt for generating is \"Suggest rewrites that...\"\n",
    "#\n",
    "# The output should first be a brief plan and then an execution based on the results\n",
    "#\n",
    "\n",
    "DELIM = \"-----\"\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "dataset = load_dataset(\"princeton-nlp/SWE-bench_oracle\", split=\"train\")\n",
    "dataset = dataset.to_iterable_dataset()\n",
    "brx_client = BRX(os.environ.get(\"BRX_ACCESS_TOKEN\"))\n",
    "model = create_model(os.environ.get(\"OPENAI_API_KEY\"), \"gpt-3.5-turbo\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_FORMATTING_INST = \"\"\"I need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n",
    "<patch>\n",
    "--- a/file.py\n",
    "+++ b/file.py\n",
    "@@ -1,27 +1,35 @@\n",
    " def euclidean(a, b):\n",
    "-    while b:\n",
    "-        a, b = b, a % b\n",
    "-    return a\n",
    "+    if b == 0:\n",
    "+        return a\n",
    "+    return euclidean(b, a % b)\n",
    " \n",
    " \n",
    " def bresenham(x0, y0, x1, y1):\n",
    "     points = []\n",
    "     dx = abs(x1 - x0)\n",
    "     dy = abs(y1 - y0)\n",
    "-    sx = 1 if x0 < x1 else -1\n",
    "-    sy = 1 if y0 < y1 else -1\n",
    "-    err = dx - dy\n",
    "+    x, y = x0, y0\n",
    "+    sx = -1 if x0 > x1 else 1\n",
    "+    sy = -1 if y0 > y1 else 1\n",
    " \n",
    "-    while True:\n",
    "-        points.append((x0, y0))\n",
    "-        if x0 == x1 and y0 == y1:\n",
    "-            break\n",
    "-        e2 = 2 * err\n",
    "-        if e2 > -dy:\n",
    "+    if dx > dy:\n",
    "+        err = dx / 2.0\n",
    "+        while x != x1:\n",
    "+            points.append((x, y))\n",
    "             err -= dy\n",
    "-            x0 += sx\n",
    "-        if e2 < dx:\n",
    "-            err += dx\n",
    "-            y0 += sy\n",
    "+            if err < 0:\n",
    "+                y += sy\n",
    "+                err += dx\n",
    "+            x += sx\n",
    "+    else:\n",
    "+        err = dy / 2.0\n",
    "+        while y != y1:\n",
    "+            points.append((x, y))\n",
    "+            err -= dx\n",
    "+            if err < 0:\n",
    "+                x += sx\n",
    "+                err += dy\n",
    "+            y += sy\n",
    " \n",
    "+    points.append((x, y))\n",
    "     return points\n",
    "</patch>\"\"\"\n",
    "SEARCH_REPLACE_INST = \"\"\"\n",
    "Please respond with a series of search-replace and new-file blocks. Here's an example:\n",
    "\n",
    "First, in order to add an import for sympy at the top of the program, we must copy over the first couple lines for context.\n",
    "\n",
    "<edit>\n",
    "<filepath>mathweb/flask/app.py</filepath>\n",
    "<search>\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "</search>\n",
    "<replace>\n",
    "import sympy\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "</replace>\n",
    "</edit>\n",
    "\n",
    "Second, let's remove the is_prime function completely.\n",
    "<edit>\n",
    "<filepath>mathweb/flask/app.py</filepath>\n",
    "<search>\n",
    "    def is_prime(x):\n",
    "        if x < 2:\n",
    "            return False\n",
    "        for i in range(2, int(math.sqrt(x)) + 1):\n",
    "            if x % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "</search>\n",
    "<replace>\n",
    "</replace>\n",
    "</edit>\n",
    "\n",
    "Third, let's rewrite nth_prime to use sympy.isprime() instead of is_prime. We need to copy over is_prime completely to be able to properly make the replacement.\n",
    "<edit>\n",
    "<filepath>mathweb/flask/app.py</filepath>\n",
    "<search>\n",
    "    @app.route('/prime/<int:n>')\n",
    "    def nth_prime(n):\n",
    "        count = 0\n",
    "        num = 1\n",
    "        while count < n:\n",
    "            num += 1\n",
    "            if is_prime(num):\n",
    "                count += 1\n",
    "        return str(num)\n",
    "</search>\n",
    "<replace>\n",
    "    @app.route('/prime/<int:n>')\n",
    "    def nth_prime(n):\n",
    "        count = 0\n",
    "        num = 1\n",
    "        while count < n:\n",
    "            num += 1\n",
    "            if sympy.isprime(num):\n",
    "                count += 1\n",
    "        return str(num)\n",
    "</replace>\n",
    "</edit>\n",
    "\n",
    "Here's a quick example of generating a new file:\n",
    "<newfile>\n",
    "<filepath>mathweb/custom_fibonacci.py</filepath>\n",
    "<content>\n",
    "def nth_fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        fib = [0, 1]\n",
    "        for i in range(2, n+1):\n",
    "            fib.append(fib[i-1] + fib[i-2])\n",
    "        return fib[n]\n",
    "</content>\n",
    "</newfile>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n",
      "<issue>\n",
      "`initialize` and `Statevector` don't play nicely\n",
      "<!-- ⚠️ If you do not respect this template, your issue will be closed -->\n",
      "<!-- ⚠️ Make sure to browse the opened and closed issues -->\n",
      "\n",
      "### Informations\n",
      "\n",
      "- **Qiskit Aer version**: 0.5.1\n",
      "- **Python version**: 3.7.3\n",
      "- **Operating system**: OSX\n",
      "\n",
      "### What is the current behavior?\n",
      "\n",
      "Using `initialize` in a circuit and then running with `Statevector` results in the error \"Cannot apply Instruction: reset\"\n",
      "\n",
      "### Steps to reproduce the problem\n",
      "\n",
      "```\n",
      "import qiskit as qk\n",
      "import qiskit.quantum_info as qi\n",
      "from numpy import sqrt\n",
      "\n",
      "n = 2\n",
      "\n",
      "ket0 = [1/sqrt(2),0,0,1/sqrt(2)]\n",
      "\n",
      "qc = qk.QuantumCircuit(n)\n",
      "qc.initialize(ket0,range(n))\n",
      "    \n",
      "ket_qi = qi.Statevector.from_instruction(qc)\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "</issue>\n",
      "<code>\n",
      "[start of README.md]\n",
      "1 # Qiskit Terra\n",
      "2 \n",
      "3 [![License](https://img.shields.io/github/license/Qiskit/qiskit-terra.svg?style=popout-square)](https://opensource.org/licenses/Apache-2.0)[![Build Status](https://img.shields.io/travis/com/Qiskit/qiskit-terra/master.svg?style=popout-square)](https://travis-ci.com/Qiskit/qiskit-terra)[![](https://img.shields.io/github/release/Qiskit/qiskit-terra.svg?style=popout-square)](https://github.com/Qiskit/qiskit-terra/releases)[![](https://img.shields.io/pypi/dm/qiskit-terra.svg?style=popout-square)](https://pypi.org/project/qiskit-terra/)[![Coverage Status](https://coveralls.io/repos/github/Qiskit/qiskit-terra/badge.svg?branch=master)](https://coveralls.io/github/Qiskit/qiskit-terra?branch=master)\n",
      "4 \n",
      "5 **Qiskit** is an open-source framework for working with noisy quantum computers at the level of pulses, circuits, and algorithms.\n",
      "6 \n",
      "7 Qiskit is made up of elements that work together to enable quantum computing. This element is **Terra** and is the foundation on which the rest of Qiskit is built.\n",
      "8 \n",
      "9 ## Installation\n",
      "10 \n",
      "11 We encourage installing Qiskit via the pip tool (a python package manager), which installs all Qiskit elements, including Terra.\n",
      "12 \n",
      "13 ```bash\n",
      "14 pip install qiskit\n",
      "15 ```\n",
      "16 \n",
      "17 PIP will handle all dependencies automatically and you will always install the latest (and well-tested) version.\n",
      "18 \n",
      "19 To install from source, follow the instructions in the [documentation](https://qiskit.org/documentation/contributing_to_qiskit.html#install-terra-from-source).\n",
      "20 \n",
      "21 ## Creating Your First Quantum Program in Qiskit Terra\n",
      "22 \n",
      "23 Now that Qiskit is installed, it's time to begin working with Terra.\n",
      "24 \n",
      "25 We are ready to try out a quantum circuit example, which is simulated locally using \n",
      "26 the Qiskit BasicAer element. This is a simple example that makes an entangled state.\n",
      "27 \n",
      "28 ```\n",
      "29 $ python\n",
      "30 ```\n",
      "31 \n",
      "32 ```python\n",
      "33 >>> from qiskit import *\n",
      "34 >>> qc = QuantumCircuit(2, 2)\n",
      "35 >>> qc.h(0)\n",
      "36 >>> qc.cx(0, 1)\n",
      "37 >>> qc.measure([0,1], [0,1])\n",
      "38 >>> backend_sim = BasicAer.get_backend('qasm_simulator')\n",
      "39 >>> result = backend_sim.run(assemble(qc)).result()\n",
      "40 >>> print(result.get_counts(qc))\n",
      "41 ```\n",
      "42 \n",
      "43 In this case, the output will be:\n",
      "44 \n",
      "45 ```python\n",
      "46 {'00': 513, '11': 511}\n",
      "47 ```\n",
      "48 \n",
      "49 A script is available [here](examples/python/ibmq/hello_quantum.py), where we also show how to\n",
      "50 run the same program on a real quantum computer via IBMQ.  \n",
      "51 \n",
      "52 ### Executing your code on a real quantum chip\n",
      "53 \n",
      "54 You can also use Qiskit to execute your code on a\n",
      "55 **real quantum chip**.\n",
      "56 In order to do so, you need to configure Qiskit for using the credentials in\n",
      "57 your IBM Q account:\n",
      "58 \n",
      "59 #### Configure your IBMQ credentials\n",
      "60 \n",
      "61 1. Create an _[IBM Q](https://quantum-computing.ibm.com) > Account_ if you haven't already done so.\n",
      "62 \n",
      "63 2. Get an API token from the IBM Q website under _My Account > API Token_ and the URL for the account.\n",
      "64 \n",
      "65 3. Take your token and url from step 2, here called `MY_API_TOKEN`, `MY_URL`, and run:\n",
      "66 \n",
      "67    ```python\n",
      "68    >>> from qiskit import IBMQ\n",
      "69    >>> IBMQ.save_account('MY_API_TOKEN', 'MY_URL')\n",
      "70     ```\n",
      "71 \n",
      "72 After calling `IBMQ.save_account()`, your credentials will be stored on disk.\n",
      "73 Once they are stored, at any point in the future you can load and use them\n",
      "74 in your program simply via:\n",
      "75 \n",
      "76 ```python\n",
      "77 >>> from qiskit import IBMQ\n",
      "78 >>> IBMQ.load_account()\n",
      "79 ```\n",
      "80 \n",
      "81 Those who do not want to save their credentials to disk should use instead:\n",
      "82 \n",
      "83 ```python\n",
      "84 >>> from qiskit import IBMQ\n",
      "85 >>> IBMQ.enable_account('MY_API_TOKEN')\n",
      "86 ``` \n",
      "87 \n",
      "88 and the token will only be active for the session. For examples using Terra with real \n",
      "89 devices we have provided a set of examples in **examples/python** and we suggest starting with [using_qiskit_terra_level_0.py](examples/python/using_qiskit_terra_level_0.py) and working up in \n",
      "90 the levels.\n",
      "91 \n",
      "92 ## Contribution Guidelines\n",
      "93 \n",
      "94 If you'd like to contribute to Qiskit Terra, please take a look at our\n",
      "95 [contribution guidelines](CONTRIBUTING.md). This project adheres to Qiskit's [code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code.\n",
      "96 \n",
      "97 We use [GitHub issues](https://github.com/Qiskit/qiskit-terra/issues) for tracking requests and bugs. Please\n",
      "98 [join the Qiskit Slack community](https://join.slack.com/t/qiskit/shared_invite/zt-e4sscbg2-p8NHTezPVkC3r8nV6BIUVw)\n",
      "99 and use our [Qiskit Slack channel](https://qiskit.slack.com) for discussion and simple questions.\n",
      "100 For questions that are more suited for a forum we use the Qiskit tag in the [Stack Exchange](https://quantumcomputing.stackexchange.com/questions/tagged/qiskit).\n",
      "101 \n",
      "102 ## Next Steps\n",
      "103 \n",
      "104 Now you're set up and ready to check out some of the other examples from our\n",
      "105 [Qiskit Tutorials](https://github.com/Qiskit/qiskit-tutorials) repository.\n",
      "106 \n",
      "107 ## Authors and Citation\n",
      "108 \n",
      "109 Qiskit Terra is the work of [many people](https://github.com/Qiskit/qiskit-terra/graphs/contributors) who contribute\n",
      "110 to the project at different levels. If you use Qiskit, please cite as per the included [BibTeX file](https://github.com/Qiskit/qiskit/blob/master/Qiskit.bib).\n",
      "111 \n",
      "112 ## Changelog and Release Notes\n",
      "113 \n",
      "114 The changelog for a particular release is dynamically generated and gets\n",
      "115 written to the release page on Github for each release. For example, you can\n",
      "116 find the page for the `0.9.0` release here:\n",
      "117 \n",
      "118 https://github.com/Qiskit/qiskit-terra/releases/tag/0.9.0\n",
      "119 \n",
      "120 The changelog for the current release can be found in the releases tab:\n",
      "121 ![](https://img.shields.io/github/release/Qiskit/qiskit-terra.svg?style=popout-square)\n",
      "122 The changelog provides a quick overview of noteable changes for a given\n",
      "123 release.\n",
      "124 \n",
      "125 Additionally, as part of each release detailed release notes are written to\n",
      "126 document in detail what has changed as part of a release. This includes any\n",
      "127 documentation on potential breaking changes on upgrade and new features.\n",
      "128 For example, You can find the release notes for the `0.9.0` release in the\n",
      "129 Qiskit documentation here:\n",
      "130 \n",
      "131 https://qiskit.org/documentation/release_notes.html#terra-0-9\n",
      "132 \n",
      "133 ## License\n",
      "134 \n",
      "135 [Apache License 2.0](LICENSE.txt)\n",
      "136 \n",
      "[end of README.md]\n",
      "[start of qiskit/quantum_info/states/densitymatrix.py]\n",
      "1 # -*- coding: utf-8 -*-\n",
      "2 \n",
      "3 # This code is part of Qiskit.\n",
      "4 #\n",
      "5 # (C) Copyright IBM 2017, 2019.\n",
      "6 #\n",
      "7 # This code is licensed under the Apache License, Version 2.0. You may\n",
      "8 # obtain a copy of this license in the LICENSE.txt file in the root directory\n",
      "9 # of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
      "10 #\n",
      "11 # Any modifications or derivative works of this code must retain this\n",
      "12 # copyright notice, and modified files need to carry a notice indicating\n",
      "13 # that they have been altered from the originals.\n",
      "14 \n",
      "15 \"\"\"\n",
      "16 DensityMatrix quantum state class.\n",
      "17 \"\"\"\n",
      "18 \n",
      "19 import warnings\n",
      "20 from numbers import Number\n",
      "21 import numpy as np\n",
      "22 \n",
      "23 from qiskit.circuit.quantumcircuit import QuantumCircuit\n",
      "24 from qiskit.circuit.instruction import Instruction\n",
      "25 from qiskit.exceptions import QiskitError\n",
      "26 from qiskit.quantum_info.states.quantum_state import QuantumState\n",
      "27 from qiskit.quantum_info.operators.operator import Operator\n",
      "28 from qiskit.quantum_info.operators.scalar_op import ScalarOp\n",
      "29 from qiskit.quantum_info.operators.predicates import is_hermitian_matrix\n",
      "30 from qiskit.quantum_info.operators.predicates import is_positive_semidefinite_matrix\n",
      "31 from qiskit.quantum_info.operators.channel.quantum_channel import QuantumChannel\n",
      "32 from qiskit.quantum_info.operators.channel.superop import SuperOp\n",
      "33 from qiskit.quantum_info.states.statevector import Statevector\n",
      "34 \n",
      "35 \n",
      "36 class DensityMatrix(QuantumState):\n",
      "37     \"\"\"DensityMatrix class\"\"\"\n",
      "38 \n",
      "39     def __init__(self, data, dims=None):\n",
      "40         \"\"\"Initialize a density matrix object.\n",
      "41 \n",
      "42         Args:\n",
      "43             data (matrix_like or vector_like): a density matrix or\n",
      "44                 statevector. If a vector the density matrix is constructed\n",
      "45                 as the projector of that vector.\n",
      "46             dims (int or tuple or list): Optional. The subsystem dimension\n",
      "47                     of the state (See additional information).\n",
      "48 \n",
      "49         Raises:\n",
      "50             QiskitError: if input data is not valid.\n",
      "51 \n",
      "52         Additional Information:\n",
      "53             The ``dims`` kwarg can be None, an integer, or an iterable of\n",
      "54             integers.\n",
      "55 \n",
      "56             * ``Iterable`` -- the subsystem dimensions are the values in the list\n",
      "57               with the total number of subsystems given by the length of the list.\n",
      "58 \n",
      "59             * ``Int`` or ``None`` -- the leading dimension of the input matrix\n",
      "60               specifies the total dimension of the density matrix. If it is a\n",
      "61               power of two the state will be initialized as an N-qubit state.\n",
      "62               If it is not a power of two the state will have a single\n",
      "63               d-dimensional subsystem.\n",
      "64         \"\"\"\n",
      "65         if isinstance(data, (list, np.ndarray)):\n",
      "66             # Finally we check if the input is a raw matrix in either a\n",
      "67             # python list or numpy array format.\n",
      "68             self._data = np.asarray(data, dtype=complex)\n",
      "69         elif hasattr(data, 'to_operator'):\n",
      "70             # If the data object has a 'to_operator' attribute this is given\n",
      "71             # higher preference than the 'to_matrix' method for initializing\n",
      "72             # an Operator object.\n",
      "73             op = data.to_operator()\n",
      "74             self._data = op.data\n",
      "75             if dims is None:\n",
      "76                 dims = op._output_dims\n",
      "77         elif hasattr(data, 'to_matrix'):\n",
      "78             # If no 'to_operator' attribute exists we next look for a\n",
      "79             # 'to_matrix' attribute to a matrix that will be cast into\n",
      "80             # a complex numpy matrix.\n",
      "81             self._data = np.asarray(data.to_matrix(), dtype=complex)\n",
      "82         else:\n",
      "83             raise QiskitError(\"Invalid input data format for DensityMatrix\")\n",
      "84         # Convert statevector into a density matrix\n",
      "85         ndim = self._data.ndim\n",
      "86         shape = self._data.shape\n",
      "87         if ndim == 2 and shape[0] == shape[1]:\n",
      "88             pass  # We good\n",
      "89         elif ndim == 1:\n",
      "90             self._data = np.outer(self._data, np.conj(self._data))\n",
      "91         elif ndim == 2 and shape[1] == 1:\n",
      "92             self._data = np.reshape(self._data, shape[0])\n",
      "93             shape = self._data.shape\n",
      "94         else:\n",
      "95             raise QiskitError(\n",
      "96                 \"Invalid DensityMatrix input: not a square matrix.\")\n",
      "97         super().__init__(self._automatic_dims(dims, shape[0]))\n",
      "98 \n",
      "99     def __eq__(self, other):\n",
      "100         return super().__eq__(other) and np.allclose(\n",
      "101             self._data, other._data, rtol=self.rtol, atol=self.atol)\n",
      "102 \n",
      "103     def __repr__(self):\n",
      "104         prefix = 'DensityMatrix('\n",
      "105         pad = len(prefix) * ' '\n",
      "106         return '{}{},\\n{}dims={})'.format(\n",
      "107             prefix, np.array2string(\n",
      "108                 self._data, separator=', ', prefix=prefix),\n",
      "109             pad, self._dims)\n",
      "110 \n",
      "111     @property\n",
      "112     def data(self):\n",
      "113         \"\"\"Return data.\"\"\"\n",
      "114         return self._data\n",
      "115 \n",
      "116     def is_valid(self, atol=None, rtol=None):\n",
      "117         \"\"\"Return True if trace 1 and positive semidefinite.\"\"\"\n",
      "118         if atol is None:\n",
      "119             atol = self.atol\n",
      "120         if rtol is None:\n",
      "121             rtol = self.rtol\n",
      "122         # Check trace == 1\n",
      "123         if not np.allclose(self.trace(), 1, rtol=rtol, atol=atol):\n",
      "124             return False\n",
      "125         # Check Hermitian\n",
      "126         if not is_hermitian_matrix(self.data, rtol=rtol, atol=atol):\n",
      "127             return False\n",
      "128         # Check positive semidefinite\n",
      "129         return is_positive_semidefinite_matrix(self.data, rtol=rtol, atol=atol)\n",
      "130 \n",
      "131     def to_operator(self):\n",
      "132         \"\"\"Convert to Operator\"\"\"\n",
      "133         dims = self.dims()\n",
      "134         return Operator(self.data, input_dims=dims, output_dims=dims)\n",
      "135 \n",
      "136     def conjugate(self):\n",
      "137         \"\"\"Return the conjugate of the density matrix.\"\"\"\n",
      "138         return DensityMatrix(np.conj(self.data), dims=self.dims())\n",
      "139 \n",
      "140     def trace(self):\n",
      "141         \"\"\"Return the trace of the density matrix.\"\"\"\n",
      "142         return np.trace(self.data)\n",
      "143 \n",
      "144     def purity(self):\n",
      "145         \"\"\"Return the purity of the quantum state.\"\"\"\n",
      "146         # For a valid statevector the purity is always 1, however if we simply\n",
      "147         # have an arbitrary vector (not correctly normalized) then the\n",
      "148         # purity is equivalent to the trace squared:\n",
      "149         # P(|psi>) = Tr[|psi><psi|psi><psi|] = |<psi|psi>|^2\n",
      "150         return np.trace(np.dot(self.data, self.data))\n",
      "151 \n",
      "152     def tensor(self, other):\n",
      "153         \"\"\"Return the tensor product state self ⊗ other.\n",
      "154 \n",
      "155         Args:\n",
      "156             other (DensityMatrix): a quantum state object.\n",
      "157 \n",
      "158         Returns:\n",
      "159             DensityMatrix: the tensor product operator self ⊗ other.\n",
      "160 \n",
      "161         Raises:\n",
      "162             QiskitError: if other is not a quantum state.\n",
      "163         \"\"\"\n",
      "164         if not isinstance(other, DensityMatrix):\n",
      "165             other = DensityMatrix(other)\n",
      "166         dims = other.dims() + self.dims()\n",
      "167         data = np.kron(self._data, other._data)\n",
      "168         return DensityMatrix(data, dims)\n",
      "169 \n",
      "170     def expand(self, other):\n",
      "171         \"\"\"Return the tensor product state other ⊗ self.\n",
      "172 \n",
      "173         Args:\n",
      "174             other (DensityMatrix): a quantum state object.\n",
      "175 \n",
      "176         Returns:\n",
      "177             DensityMatrix: the tensor product state other ⊗ self.\n",
      "178 \n",
      "179         Raises:\n",
      "180             QiskitError: if other is not a quantum state.\n",
      "181         \"\"\"\n",
      "182         if not isinstance(other, DensityMatrix):\n",
      "183             other = DensityMatrix(other)\n",
      "184         dims = self.dims() + other.dims()\n",
      "185         data = np.kron(other._data, self._data)\n",
      "186         return DensityMatrix(data, dims)\n",
      "187 \n",
      "188     def _add(self, other):\n",
      "189         \"\"\"Return the linear combination self + other.\n",
      "190 \n",
      "191         Args:\n",
      "192             other (DensityMatrix): a quantum state object.\n",
      "193 \n",
      "194         Returns:\n",
      "195             DensityMatrix: the linear combination self + other.\n",
      "196 \n",
      "197         Raises:\n",
      "198             QiskitError: if other is not a quantum state, or has\n",
      "199                          incompatible dimensions.\n",
      "200         \"\"\"\n",
      "201         if not isinstance(other, DensityMatrix):\n",
      "202             other = DensityMatrix(other)\n",
      "203         if self.dim != other.dim:\n",
      "204             raise QiskitError(\"other DensityMatrix has different dimensions.\")\n",
      "205         return DensityMatrix(self.data + other.data, self.dims())\n",
      "206 \n",
      "207     def _multiply(self, other):\n",
      "208         \"\"\"Return the scalar multiplied state other * self.\n",
      "209 \n",
      "210         Args:\n",
      "211             other (complex): a complex number.\n",
      "212 \n",
      "213         Returns:\n",
      "214             DensityMatrix: the scalar multiplied state other * self.\n",
      "215 \n",
      "216         Raises:\n",
      "217             QiskitError: if other is not a valid complex number.\n",
      "218         \"\"\"\n",
      "219         if not isinstance(other, Number):\n",
      "220             raise QiskitError(\"other is not a number\")\n",
      "221         return DensityMatrix(other * self.data, self.dims())\n",
      "222 \n",
      "223     def evolve(self, other, qargs=None):\n",
      "224         \"\"\"Evolve a quantum state by an operator.\n",
      "225 \n",
      "226         Args:\n",
      "227             other (Operator or QuantumChannel\n",
      "228                    or Instruction or Circuit): The operator to evolve by.\n",
      "229             qargs (list): a list of QuantumState subsystem positions to apply\n",
      "230                            the operator on.\n",
      "231 \n",
      "232         Returns:\n",
      "233             QuantumState: the output quantum state.\n",
      "234 \n",
      "235         Raises:\n",
      "236             QiskitError: if the operator dimension does not match the\n",
      "237                          specified QuantumState subsystem dimensions.\n",
      "238         \"\"\"\n",
      "239         if qargs is None:\n",
      "240             qargs = getattr(other, 'qargs', None)\n",
      "241 \n",
      "242         # Evolution by a circuit or instruction\n",
      "243         if isinstance(other, (QuantumCircuit, Instruction)):\n",
      "244             return self._evolve_instruction(other, qargs=qargs)\n",
      "245 \n",
      "246         # Evolution by a QuantumChannel\n",
      "247         if hasattr(other, 'to_quantumchannel'):\n",
      "248             return other.to_quantumchannel()._evolve(self, qargs=qargs)\n",
      "249         if isinstance(other, QuantumChannel):\n",
      "250             return other._evolve(self, qargs=qargs)\n",
      "251 \n",
      "252         # Unitary evolution by an Operator\n",
      "253         if not isinstance(other, Operator):\n",
      "254             other = Operator(other)\n",
      "255         return self._evolve_operator(other, qargs=qargs)\n",
      "256 \n",
      "257     def probabilities(self, qargs=None, decimals=None):\n",
      "258         \"\"\"Return the subsystem measurement probability vector.\n",
      "259 \n",
      "260         Measurement probabilities are with respect to measurement in the\n",
      "261         computation (diagonal) basis.\n",
      "262 \n",
      "263         Args:\n",
      "264             qargs (None or list): subsystems to return probabilities for,\n",
      "265                 if None return for all subsystems (Default: None).\n",
      "266             decimals (None or int): the number of decimal places to round\n",
      "267                 values. If None no rounding is done (Default: None).\n",
      "268 \n",
      "269         Returns:\n",
      "270             np.array: The Numpy vector array of probabilities.\n",
      "271 \n",
      "272         Examples:\n",
      "273 \n",
      "274             Consider a 2-qubit product state :math:`\\\\rho=\\\\rho_1\\\\otimes\\\\rho_0`\n",
      "275             with :math:`\\\\rho_1=|+\\\\rangle\\\\!\\\\langle+|`,\n",
      "276             :math:`\\\\rho_0=|0\\\\rangle\\\\!\\\\langle0|`.\n",
      "277 \n",
      "278             .. jupyter-execute::\n",
      "279 \n",
      "280                 from qiskit.quantum_info import DensityMatrix\n",
      "281 \n",
      "282                 rho = DensityMatrix.from_label('+0')\n",
      "283 \n",
      "284                 # Probabilities for measuring both qubits\n",
      "285                 probs = rho.probabilities()\n",
      "286                 print('probs: {}'.format(probs))\n",
      "287 \n",
      "288                 # Probabilities for measuring only qubit-0\n",
      "289                 probs_qubit_0 = rho.probabilities([0])\n",
      "290                 print('Qubit-0 probs: {}'.format(probs_qubit_0))\n",
      "291 \n",
      "292                 # Probabilities for measuring only qubit-1\n",
      "293                 probs_qubit_1 = rho.probabilities([1])\n",
      "294                 print('Qubit-1 probs: {}'.format(probs_qubit_1))\n",
      "295 \n",
      "296             We can also permute the order of qubits in the ``qargs`` list\n",
      "297             to change the qubit position in the probabilities output\n",
      "298 \n",
      "299             .. jupyter-execute::\n",
      "300 \n",
      "301                 from qiskit.quantum_info import DensityMatrix\n",
      "302 \n",
      "303                 rho = DensityMatrix.from_label('+0')\n",
      "304 \n",
      "305                 # Probabilities for measuring both qubits\n",
      "306                 probs = rho.probabilities([0, 1])\n",
      "307                 print('probs: {}'.format(probs))\n",
      "308 \n",
      "309                 # Probabilities for measuring both qubits\n",
      "310                 # but swapping qubits 0 and 1 in output\n",
      "311                 probs_swapped = rho.probabilities([1, 0])\n",
      "312                 print('Swapped probs: {}'.format(probs_swapped))\n",
      "313         \"\"\"\n",
      "314         probs = self._subsystem_probabilities(\n",
      "315             np.abs(self.data.diagonal()), self._dims, qargs=qargs)\n",
      "316         if decimals is not None:\n",
      "317             probs = probs.round(decimals=decimals)\n",
      "318         return probs\n",
      "319 \n",
      "320     def reset(self, qargs=None):\n",
      "321         \"\"\"Reset state or subsystems to the 0-state.\n",
      "322 \n",
      "323         Args:\n",
      "324             qargs (list or None): subsystems to reset, if None all\n",
      "325                                   subsystems will be reset to their 0-state\n",
      "326                                   (Default: None).\n",
      "327 \n",
      "328         Returns:\n",
      "329             DensityMatrix: the reset state.\n",
      "330 \n",
      "331         Additional Information:\n",
      "332             If all subsystems are reset this will return the ground state\n",
      "333             on all subsystems. If only a some subsystems are reset this\n",
      "334             function will perform evolution by the reset\n",
      "335             :class:`~qiskit.quantum_info.SuperOp` of the reset subsystems.\n",
      "336         \"\"\"\n",
      "337         if qargs is None:\n",
      "338             # Resetting all qubits does not require sampling or RNG\n",
      "339             state = np.zeros(2 * (self._dim, ), dtype=complex)\n",
      "340             state[0, 0] = 1\n",
      "341             return DensityMatrix(state, dims=self._dims)\n",
      "342 \n",
      "343         # Reset by evolving by reset SuperOp\n",
      "344         dims = self.dims(qargs)\n",
      "345         reset_superop = SuperOp(ScalarOp(dims, coeff=0))\n",
      "346         reset_superop.data[0] = Operator(ScalarOp(dims)).data.ravel()\n",
      "347         return self.evolve(reset_superop, qargs=qargs)\n",
      "348 \n",
      "349     @classmethod\n",
      "350     def from_label(cls, label):\n",
      "351         r\"\"\"Return a tensor product of Pauli X,Y,Z eigenstates.\n",
      "352 \n",
      "353         .. list-table:: Single-qubit state labels\n",
      "354            :header-rows: 1\n",
      "355 \n",
      "356            * - Label\n",
      "357              - Statevector\n",
      "358            * - ``\"0\"``\n",
      "359              - :math:`\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}`\n",
      "360            * - ``\"1\"``\n",
      "361              - :math:`\\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}`\n",
      "362            * - ``\"+\"``\n",
      "363              - :math:`\\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}`\n",
      "364            * - ``\"-\"``\n",
      "365              - :math:`\\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}`\n",
      "366            * - ``\"r\"``\n",
      "367              - :math:`\\frac{1}{2}\\begin{pmatrix} 1 & -i \\\\ i & 1 \\end{pmatrix}`\n",
      "368            * - ``\"l\"``\n",
      "369              - :math:`\\frac{1}{2}\\begin{pmatrix} 1 & i \\\\ -i & 1 \\end{pmatrix}`\n",
      "370 \n",
      "371         Args:\n",
      "372             label (string): a eigenstate string ket label (see table for\n",
      "373                             allowed values).\n",
      "374 \n",
      "375         Returns:\n",
      "376             Statevector: The N-qubit basis state density matrix.\n",
      "377 \n",
      "378         Raises:\n",
      "379             QiskitError: if the label contains invalid characters, or the length\n",
      "380                          of the label is larger than an explicitly specified num_qubits.\n",
      "381         \"\"\"\n",
      "382         return DensityMatrix(Statevector.from_label(label))\n",
      "383 \n",
      "384     @staticmethod\n",
      "385     def from_int(i, dims):\n",
      "386         \"\"\"Return a computational basis state density matrix.\n",
      "387 \n",
      "388         Args:\n",
      "389             i (int): the basis state element.\n",
      "390             dims (int or tuple or list): The subsystem dimensions of the statevector\n",
      "391                                          (See additional information).\n",
      "392 \n",
      "393         Returns:\n",
      "394             DensityMatrix: The computational basis state :math:`|i\\\\rangle\\\\!\\\\langle i|`.\n",
      "395 \n",
      "396         Additional Information:\n",
      "397             The ``dims`` kwarg can be an integer or an iterable of integers.\n",
      "398 \n",
      "399             * ``Iterable`` -- the subsystem dimensions are the values in the list\n",
      "400               with the total number of subsystems given by the length of the list.\n",
      "401 \n",
      "402             * ``Int`` -- the integer specifies the total dimension of the\n",
      "403               state. If it is a power of two the state will be initialized\n",
      "404               as an N-qubit state. If it is not a power of  two the state\n",
      "405               will have a single d-dimensional subsystem.\n",
      "406         \"\"\"\n",
      "407         size = np.product(dims)\n",
      "408         state = np.zeros((size, size), dtype=complex)\n",
      "409         state[i, i] = 1.0\n",
      "410         return DensityMatrix(state, dims=dims)\n",
      "411 \n",
      "412     @classmethod\n",
      "413     def from_instruction(cls, instruction):\n",
      "414         \"\"\"Return the output density matrix of an instruction.\n",
      "415 \n",
      "416         The statevector is initialized in the state :math:`|{0,\\\\ldots,0}\\\\rangle` of\n",
      "417         the same number of qubits as the input instruction or circuit, evolved\n",
      "418         by the input instruction, and the output statevector returned.\n",
      "419 \n",
      "420         Args:\n",
      "421             instruction (qiskit.circuit.Instruction or QuantumCircuit): instruction or circuit\n",
      "422 \n",
      "423         Returns:\n",
      "424             DensityMatrix: the final density matrix.\n",
      "425 \n",
      "426         Raises:\n",
      "427             QiskitError: if the instruction contains invalid instructions for\n",
      "428                          density matrix simulation.\n",
      "429         \"\"\"\n",
      "430         # Convert circuit to an instruction\n",
      "431         if isinstance(instruction, QuantumCircuit):\n",
      "432             instruction = instruction.to_instruction()\n",
      "433         # Initialize an the statevector in the all |0> state\n",
      "434         num_qubits = instruction.num_qubits\n",
      "435         init = np.zeros((2**num_qubits, 2**num_qubits), dtype=complex)\n",
      "436         init[0, 0] = 1\n",
      "437         vec = DensityMatrix(init, dims=num_qubits * (2, ))\n",
      "438         vec._append_instruction(instruction)\n",
      "439         return vec\n",
      "440 \n",
      "441     def to_dict(self, decimals=None):\n",
      "442         r\"\"\"Convert the density matrix to dictionary form.\n",
      "443 \n",
      "444         This dictionary representation uses a Ket-like notation where the\n",
      "445         dictionary keys are qudit strings for the subsystem basis vectors.\n",
      "446         If any subsystem has a dimension greater than 10 comma delimiters are\n",
      "447         inserted between integers so that subsystems can be distinguished.\n",
      "448 \n",
      "449         Args:\n",
      "450             decimals (None or int): the number of decimal places to round\n",
      "451                                     values. If None no rounding is done\n",
      "452                                     (Default: None).\n",
      "453 \n",
      "454         Returns:\n",
      "455             dict: the dictionary form of the DensityMatrix.\n",
      "456 \n",
      "457         Examples:\n",
      "458 \n",
      "459             The ket-form of a 2-qubit density matrix\n",
      "460             :math:`rho = |-\\rangle\\!\\langle -|\\otimes |0\\rangle\\!\\langle 0|`\n",
      "461 \n",
      "462             .. jupyter-execute::\n",
      "463 \n",
      "464                 from qiskit.quantum_info import DensityMatrix\n",
      "465 \n",
      "466                 rho = DensityMatrix.from_label('-0')\n",
      "467                 print(rho.to_dict())\n",
      "468 \n",
      "469             For non-qubit subsystems the integer range can go from 0 to 9. For\n",
      "470             example in a qutrit system\n",
      "471 \n",
      "472             .. jupyter-execute::\n",
      "473 \n",
      "474                 import numpy as np\n",
      "475                 from qiskit.quantum_info import DensityMatrix\n",
      "476 \n",
      "477                 mat = np.zeros((9, 9))\n",
      "478                 mat[0, 0] = 0.25\n",
      "479                 mat[3, 3] = 0.25\n",
      "480                 mat[6, 6] = 0.25\n",
      "481                 mat[-1, -1] = 0.25\n",
      "482                 rho = DensityMatrix(mat, dims=(3, 3))\n",
      "483                 print(rho.to_dict())\n",
      "484 \n",
      "485             For large subsystem dimensions delimeters are required. The\n",
      "486             following example is for a 20-dimensional system consisting of\n",
      "487             a qubit and 10-dimensional qudit.\n",
      "488 \n",
      "489             .. jupyter-execute::\n",
      "490 \n",
      "491                 import numpy as np\n",
      "492                 from qiskit.quantum_info import DensityMatrix\n",
      "493 \n",
      "494                 mat = np.zeros((2 * 10, 2 * 10))\n",
      "495                 mat[0, 0] = 0.5\n",
      "496                 mat[-1, -1] = 0.5\n",
      "497                 rho = DensityMatrix(mat, dims=(2, 10))\n",
      "498                 print(rho.to_dict())\n",
      "499         \"\"\"\n",
      "500         return self._matrix_to_dict(self.data,\n",
      "501                                     self._dims,\n",
      "502                                     decimals=decimals,\n",
      "503                                     string_labels=True)\n",
      "504 \n",
      "505     @property\n",
      "506     def _shape(self):\n",
      "507         \"\"\"Return the tensor shape of the matrix operator\"\"\"\n",
      "508         return 2 * tuple(reversed(self.dims()))\n",
      "509 \n",
      "510     def _evolve_operator(self, other, qargs=None):\n",
      "511         \"\"\"Evolve density matrix by an operator\"\"\"\n",
      "512         if qargs is None:\n",
      "513             # Evolution on full matrix\n",
      "514             if self._dim != other._input_dim:\n",
      "515                 raise QiskitError(\n",
      "516                     \"Operator input dimension is not equal to density matrix dimension.\"\n",
      "517                 )\n",
      "518             op_mat = other.data\n",
      "519             mat = np.dot(op_mat, self.data).dot(op_mat.T.conj())\n",
      "520             return DensityMatrix(mat, dims=other._output_dims)\n",
      "521         # Otherwise we are applying an operator only to subsystems\n",
      "522         # Check dimensions of subsystems match the operator\n",
      "523         if self.dims(qargs) != other.input_dims():\n",
      "524             raise QiskitError(\n",
      "525                 \"Operator input dimensions are not equal to statevector subsystem dimensions.\"\n",
      "526             )\n",
      "527         # Reshape statevector and operator\n",
      "528         tensor = np.reshape(self.data, self._shape)\n",
      "529         # Construct list of tensor indices of statevector to be contracted\n",
      "530         num_indices = len(self.dims())\n",
      "531         indices = [num_indices - 1 - qubit for qubit in qargs]\n",
      "532         # Left multiple by mat\n",
      "533         mat = np.reshape(other.data, other._shape)\n",
      "534         tensor = Operator._einsum_matmul(tensor, mat, indices)\n",
      "535         # Right multiply by mat ** dagger\n",
      "536         adj = other.adjoint()\n",
      "537         mat_adj = np.reshape(adj.data, adj._shape)\n",
      "538         tensor = Operator._einsum_matmul(tensor, mat_adj, indices, num_indices,\n",
      "539                                          True)\n",
      "540         # Replace evolved dimensions\n",
      "541         new_dims = list(self.dims())\n",
      "542         for i, qubit in enumerate(qargs):\n",
      "543             new_dims[qubit] = other._output_dims[i]\n",
      "544         new_dim = np.product(new_dims)\n",
      "545         return DensityMatrix(np.reshape(tensor, (new_dim, new_dim)),\n",
      "546                              dims=new_dims)\n",
      "547 \n",
      "548     def _append_instruction(self, other, qargs=None):\n",
      "549         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "550 \n",
      "551         # Try evolving by a matrix operator (unitary-like evolution)\n",
      "552         mat = Operator._instruction_to_matrix(other)\n",
      "553         if mat is not None:\n",
      "554             self._data = self._evolve_operator(Operator(mat), qargs=qargs).data\n",
      "555             return\n",
      "556         # Otherwise try evolving by a Superoperator\n",
      "557         chan = SuperOp._instruction_to_superop(other)\n",
      "558         if chan is not None:\n",
      "559             # Evolve current state by the superoperator\n",
      "560             self._data = chan._evolve(self, qargs=qargs).data\n",
      "561             return\n",
      "562         # If the instruction doesn't have a matrix defined we use its\n",
      "563         # circuit decomposition definition if it exists, otherwise we\n",
      "564         # cannot compose this gate and raise an error.\n",
      "565         if other.definition is None:\n",
      "566             raise QiskitError('Cannot apply Instruction: {}'.format(\n",
      "567                 other.name))\n",
      "568         for instr, qregs, cregs in other.definition:\n",
      "569             if cregs:\n",
      "570                 raise QiskitError(\n",
      "571                     'Cannot apply instruction with classical registers: {}'.\n",
      "572                     format(instr.name))\n",
      "573             # Get the integer position of the flat register\n",
      "574             if qargs is None:\n",
      "575                 new_qargs = [tup.index for tup in qregs]\n",
      "576             else:\n",
      "577                 new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "578             self._append_instruction(instr, qargs=new_qargs)\n",
      "579 \n",
      "580     def _evolve_instruction(self, obj, qargs=None):\n",
      "581         \"\"\"Return a new statevector by applying an instruction.\"\"\"\n",
      "582         if isinstance(obj, QuantumCircuit):\n",
      "583             obj = obj.to_instruction()\n",
      "584         vec = DensityMatrix(self.data, dims=self._dims)\n",
      "585         vec._append_instruction(obj, qargs=qargs)\n",
      "586         return vec\n",
      "587 \n",
      "588     def to_statevector(self, atol=None, rtol=None):\n",
      "589         \"\"\"Return a statevector from a pure density matrix.\n",
      "590 \n",
      "591         Args:\n",
      "592             atol (float): Absolute tolerance for checking operation validity.\n",
      "593             rtol (float): Relative tolerance for checking operation validity.\n",
      "594 \n",
      "595         Returns:\n",
      "596             Statevector: The pure density matrix's corresponding statevector.\n",
      "597                 Corresponds to the eigenvector of the only non-zero eigenvalue.\n",
      "598 \n",
      "599         Raises:\n",
      "600             QiskitError: if the state is not pure.\n",
      "601         \"\"\"\n",
      "602         if atol is None:\n",
      "603             atol = self.atol\n",
      "604         if rtol is None:\n",
      "605             rtol = self.rtol\n",
      "606 \n",
      "607         if not is_hermitian_matrix(self._data, atol=atol, rtol=rtol):\n",
      "608             raise QiskitError(\"Not a valid density matrix (non-hermitian).\")\n",
      "609 \n",
      "610         evals, evecs = np.linalg.eig(self._data)\n",
      "611 \n",
      "612         nonzero_evals = evals[abs(evals) > atol]\n",
      "613         if len(nonzero_evals) != 1 or not np.isclose(nonzero_evals[0], 1,\n",
      "614                                                      atol=atol, rtol=rtol):\n",
      "615             raise QiskitError(\"Density matrix is not a pure state\")\n",
      "616 \n",
      "617         psi = evecs[:, np.argmax(evals)]  # eigenvectors returned in columns.\n",
      "618         return Statevector(psi)\n",
      "619 \n",
      "620     def to_counts(self):\n",
      "621         \"\"\"Returns the density matrix as a counts dict of probabilities.\n",
      "622 \n",
      "623         DEPRECATED: use :meth:`probabilities_dict` instead.\n",
      "624 \n",
      "625         Returns:\n",
      "626             dict: Counts of probabilities.\n",
      "627         \"\"\"\n",
      "628         warnings.warn(\n",
      "629             'The `Statevector.to_counts` method is deprecated as of 0.13.0,'\n",
      "630             ' and will be removed no earlier than 3 months after that '\n",
      "631             'release date. You should use the `Statevector.probabilities_dict`'\n",
      "632             ' method instead.', DeprecationWarning, stacklevel=2)\n",
      "633         return self.probabilities_dict()\n",
      "634 \n",
      "[end of qiskit/quantum_info/states/densitymatrix.py]\n",
      "[start of qiskit/quantum_info/states/statevector.py]\n",
      "1 # -*- coding: utf-8 -*-\n",
      "2 \n",
      "3 # This code is part of Qiskit.\n",
      "4 #\n",
      "5 # (C) Copyright IBM 2017, 2019.\n",
      "6 #\n",
      "7 # This code is licensed under the Apache License, Version 2.0. You may\n",
      "8 # obtain a copy of this license in the LICENSE.txt file in the root directory\n",
      "9 # of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
      "10 #\n",
      "11 # Any modifications or derivative works of this code must retain this\n",
      "12 # copyright notice, and modified files need to carry a notice indicating\n",
      "13 # that they have been altered from the originals.\n",
      "14 \n",
      "15 \"\"\"\n",
      "16 Statevector quantum state class.\n",
      "17 \"\"\"\n",
      "18 \n",
      "19 import re\n",
      "20 import warnings\n",
      "21 from numbers import Number\n",
      "22 \n",
      "23 import numpy as np\n",
      "24 \n",
      "25 from qiskit.circuit.quantumcircuit import QuantumCircuit\n",
      "26 from qiskit.circuit.instruction import Instruction\n",
      "27 from qiskit.exceptions import QiskitError\n",
      "28 from qiskit.quantum_info.states.quantum_state import QuantumState\n",
      "29 from qiskit.quantum_info.operators.operator import Operator\n",
      "30 from qiskit.quantum_info.operators.predicates import matrix_equal\n",
      "31 \n",
      "32 \n",
      "33 class Statevector(QuantumState):\n",
      "34     \"\"\"Statevector class\"\"\"\n",
      "35 \n",
      "36     def __init__(self, data, dims=None):\n",
      "37         \"\"\"Initialize a statevector object.\n",
      "38 \n",
      "39         Args:\n",
      "40             data (vector_like): a complex statevector.\n",
      "41             dims (int or tuple or list): Optional. The subsystem dimension of\n",
      "42                                          the state (See additional information).\n",
      "43 \n",
      "44         Raises:\n",
      "45             QiskitError: if input data is not valid.\n",
      "46 \n",
      "47         Additional Information:\n",
      "48             The ``dims`` kwarg can be None, an integer, or an iterable of\n",
      "49             integers.\n",
      "50 \n",
      "51             * ``Iterable`` -- the subsystem dimensions are the values in the list\n",
      "52               with the total number of subsystems given by the length of the list.\n",
      "53 \n",
      "54             * ``Int`` or ``None`` -- the length of the input vector\n",
      "55               specifies the total dimension of the density matrix. If it is a\n",
      "56               power of two the state will be initialized as an N-qubit state.\n",
      "57               If it is not a power of two the state will have a single\n",
      "58               d-dimensional subsystem.\n",
      "59         \"\"\"\n",
      "60         if isinstance(data, (list, np.ndarray)):\n",
      "61             # Finally we check if the input is a raw vector in either a\n",
      "62             # python list or numpy array format.\n",
      "63             self._data = np.asarray(data, dtype=complex)\n",
      "64         elif isinstance(data, Statevector):\n",
      "65             self._data = data._data\n",
      "66             if dims is None:\n",
      "67                 dims = data._dims\n",
      "68         elif isinstance(data, Operator):\n",
      "69             # We allow conversion of column-vector operators to Statevectors\n",
      "70             input_dim, output_dim = data.dim\n",
      "71             if input_dim != 1:\n",
      "72                 raise QiskitError(\"Input Operator is not a column-vector.\")\n",
      "73             self._data = np.ravel(data.data)\n",
      "74         else:\n",
      "75             raise QiskitError(\"Invalid input data format for Statevector\")\n",
      "76         # Check that the input is a numpy vector or column-vector numpy\n",
      "77         # matrix. If it is a column-vector matrix reshape to a vector.\n",
      "78         ndim = self._data.ndim\n",
      "79         shape = self._data.shape\n",
      "80         if ndim != 1:\n",
      "81             if ndim == 2 and shape[1] == 1:\n",
      "82                 self._data = np.reshape(self._data, shape[0])\n",
      "83             elif ndim != 2 or shape[1] != 1:\n",
      "84                 raise QiskitError(\"Invalid input: not a vector or column-vector.\")\n",
      "85         super().__init__(self._automatic_dims(dims, shape[0]))\n",
      "86 \n",
      "87     def __eq__(self, other):\n",
      "88         return super().__eq__(other) and np.allclose(\n",
      "89             self._data, other._data, rtol=self.rtol, atol=self.atol)\n",
      "90 \n",
      "91     def __repr__(self):\n",
      "92         prefix = 'Statevector('\n",
      "93         pad = len(prefix) * ' '\n",
      "94         return '{}{},\\n{}dims={})'.format(\n",
      "95             prefix, np.array2string(\n",
      "96                 self.data, separator=', ', prefix=prefix),\n",
      "97             pad, self._dims)\n",
      "98 \n",
      "99     @property\n",
      "100     def data(self):\n",
      "101         \"\"\"Return data.\"\"\"\n",
      "102         return self._data\n",
      "103 \n",
      "104     def is_valid(self, atol=None, rtol=None):\n",
      "105         \"\"\"Return True if a Statevector has norm 1.\"\"\"\n",
      "106         if atol is None:\n",
      "107             atol = self.atol\n",
      "108         if rtol is None:\n",
      "109             rtol = self.rtol\n",
      "110         norm = np.linalg.norm(self.data)\n",
      "111         return np.allclose(norm, 1, rtol=rtol, atol=atol)\n",
      "112 \n",
      "113     def to_operator(self):\n",
      "114         \"\"\"Convert state to a rank-1 projector operator\"\"\"\n",
      "115         mat = np.outer(self.data, np.conj(self.data))\n",
      "116         return Operator(mat, input_dims=self.dims(), output_dims=self.dims())\n",
      "117 \n",
      "118     def conjugate(self):\n",
      "119         \"\"\"Return the conjugate of the operator.\"\"\"\n",
      "120         return Statevector(np.conj(self.data), dims=self.dims())\n",
      "121 \n",
      "122     def trace(self):\n",
      "123         \"\"\"Return the trace of the quantum state as a density matrix.\"\"\"\n",
      "124         return np.sum(np.abs(self.data) ** 2)\n",
      "125 \n",
      "126     def purity(self):\n",
      "127         \"\"\"Return the purity of the quantum state.\"\"\"\n",
      "128         # For a valid statevector the purity is always 1, however if we simply\n",
      "129         # have an arbitrary vector (not correctly normalized) then the\n",
      "130         # purity is equivalent to the trace squared:\n",
      "131         # P(|psi>) = Tr[|psi><psi|psi><psi|] = |<psi|psi>|^2\n",
      "132         return self.trace() ** 2\n",
      "133 \n",
      "134     def tensor(self, other):\n",
      "135         \"\"\"Return the tensor product state self ⊗ other.\n",
      "136 \n",
      "137         Args:\n",
      "138             other (Statevector): a quantum state object.\n",
      "139 \n",
      "140         Returns:\n",
      "141             Statevector: the tensor product operator self ⊗ other.\n",
      "142 \n",
      "143         Raises:\n",
      "144             QiskitError: if other is not a quantum state.\n",
      "145         \"\"\"\n",
      "146         if not isinstance(other, Statevector):\n",
      "147             other = Statevector(other)\n",
      "148         dims = other.dims() + self.dims()\n",
      "149         data = np.kron(self._data, other._data)\n",
      "150         return Statevector(data, dims)\n",
      "151 \n",
      "152     def expand(self, other):\n",
      "153         \"\"\"Return the tensor product state other ⊗ self.\n",
      "154 \n",
      "155         Args:\n",
      "156             other (Statevector): a quantum state object.\n",
      "157 \n",
      "158         Returns:\n",
      "159             Statevector: the tensor product state other ⊗ self.\n",
      "160 \n",
      "161         Raises:\n",
      "162             QiskitError: if other is not a quantum state.\n",
      "163         \"\"\"\n",
      "164         if not isinstance(other, Statevector):\n",
      "165             other = Statevector(other)\n",
      "166         dims = self.dims() + other.dims()\n",
      "167         data = np.kron(other._data, self._data)\n",
      "168         return Statevector(data, dims)\n",
      "169 \n",
      "170     def _add(self, other):\n",
      "171         \"\"\"Return the linear combination self + other.\n",
      "172 \n",
      "173         Args:\n",
      "174             other (Statevector): a quantum state object.\n",
      "175 \n",
      "176         Returns:\n",
      "177             Statevector: the linear combination self + other.\n",
      "178 \n",
      "179         Raises:\n",
      "180             QiskitError: if other is not a quantum state, or has\n",
      "181                          incompatible dimensions.\n",
      "182         \"\"\"\n",
      "183         if not isinstance(other, Statevector):\n",
      "184             other = Statevector(other)\n",
      "185         if self.dim != other.dim:\n",
      "186             raise QiskitError(\"other Statevector has different dimensions.\")\n",
      "187         return Statevector(self.data + other.data, self.dims())\n",
      "188 \n",
      "189     def _multiply(self, other):\n",
      "190         \"\"\"Return the scalar multiplied state self * other.\n",
      "191 \n",
      "192         Args:\n",
      "193             other (complex): a complex number.\n",
      "194 \n",
      "195         Returns:\n",
      "196             Statevector: the scalar multiplied state other * self.\n",
      "197 \n",
      "198         Raises:\n",
      "199             QiskitError: if other is not a valid complex number.\n",
      "200         \"\"\"\n",
      "201         if not isinstance(other, Number):\n",
      "202             raise QiskitError(\"other is not a number\")\n",
      "203         return Statevector(other * self.data, self.dims())\n",
      "204 \n",
      "205     def evolve(self, other, qargs=None):\n",
      "206         \"\"\"Evolve a quantum state by the operator.\n",
      "207 \n",
      "208         Args:\n",
      "209             other (Operator): The operator to evolve by.\n",
      "210             qargs (list): a list of Statevector subsystem positions to apply\n",
      "211                            the operator on.\n",
      "212 \n",
      "213         Returns:\n",
      "214             Statevector: the output quantum state.\n",
      "215 \n",
      "216         Raises:\n",
      "217             QiskitError: if the operator dimension does not match the\n",
      "218                          specified Statevector subsystem dimensions.\n",
      "219         \"\"\"\n",
      "220         if qargs is None:\n",
      "221             qargs = getattr(other, 'qargs', None)\n",
      "222 \n",
      "223         # Evolution by a circuit or instruction\n",
      "224         if isinstance(other, (QuantumCircuit, Instruction)):\n",
      "225             return self._evolve_instruction(other, qargs=qargs)\n",
      "226         # Evolution by an Operator\n",
      "227         if not isinstance(other, Operator):\n",
      "228             other = Operator(other)\n",
      "229         if qargs is None:\n",
      "230             # Evolution on full statevector\n",
      "231             if self._dim != other._input_dim:\n",
      "232                 raise QiskitError(\n",
      "233                     \"Operator input dimension is not equal to statevector dimension.\"\n",
      "234                 )\n",
      "235             return Statevector(np.dot(other.data, self.data), dims=other.output_dims())\n",
      "236         # Otherwise we are applying an operator only to subsystems\n",
      "237         # Check dimensions of subsystems match the operator\n",
      "238         if self.dims(qargs) != other.input_dims():\n",
      "239             raise QiskitError(\n",
      "240                 \"Operator input dimensions are not equal to statevector subsystem dimensions.\"\n",
      "241             )\n",
      "242         # Reshape statevector and operator\n",
      "243         tensor = np.reshape(self.data, self._shape)\n",
      "244         mat = np.reshape(other.data, other._shape)\n",
      "245         # Construct list of tensor indices of statevector to be contracted\n",
      "246         num_indices = len(self.dims())\n",
      "247         indices = [num_indices - 1 - qubit for qubit in qargs]\n",
      "248         tensor = Operator._einsum_matmul(tensor, mat, indices)\n",
      "249         new_dims = list(self.dims())\n",
      "250         for i, qubit in enumerate(qargs):\n",
      "251             new_dims[qubit] = other._output_dims[i]\n",
      "252         # Replace evolved dimensions\n",
      "253         return Statevector(np.reshape(tensor, np.product(new_dims)), dims=new_dims)\n",
      "254 \n",
      "255     def equiv(self, other, rtol=None, atol=None):\n",
      "256         \"\"\"Return True if statevectors are equivalent up to global phase.\n",
      "257 \n",
      "258         Args:\n",
      "259             other (Statevector): a statevector object.\n",
      "260             rtol (float): relative tolerance value for comparison.\n",
      "261             atol (float): absolute tolerance value for comparison.\n",
      "262 \n",
      "263         Returns:\n",
      "264             bool: True if statevectors are equivalent up to global phase.\n",
      "265         \"\"\"\n",
      "266         if not isinstance(other, Statevector):\n",
      "267             try:\n",
      "268                 other = Statevector(other)\n",
      "269             except QiskitError:\n",
      "270                 return False\n",
      "271         if self.dim != other.dim:\n",
      "272             return False\n",
      "273         if atol is None:\n",
      "274             atol = self.atol\n",
      "275         if rtol is None:\n",
      "276             rtol = self.rtol\n",
      "277         return matrix_equal(self.data, other.data, ignore_phase=True,\n",
      "278                             rtol=rtol, atol=atol)\n",
      "279 \n",
      "280     def probabilities(self, qargs=None, decimals=None):\n",
      "281         \"\"\"Return the subsystem measurement probability vector.\n",
      "282 \n",
      "283         Measurement probabilities are with respect to measurement in the\n",
      "284         computation (diagonal) basis.\n",
      "285 \n",
      "286         Args:\n",
      "287             qargs (None or list): subsystems to return probabilities for,\n",
      "288                 if None return for all subsystems (Default: None).\n",
      "289             decimals (None or int): the number of decimal places to round\n",
      "290                 values. If None no rounding is done (Default: None).\n",
      "291 \n",
      "292         Returns:\n",
      "293             np.array: The Numpy vector array of probabilities.\n",
      "294 \n",
      "295         Examples:\n",
      "296 \n",
      "297             Consider a 2-qubit product state\n",
      "298             :math:`|\\\\psi\\\\rangle=|+\\\\rangle\\\\otimes|0\\\\rangle`.\n",
      "299 \n",
      "300             .. jupyter-execute::\n",
      "301 \n",
      "302                 from qiskit.quantum_info import Statevector\n",
      "303 \n",
      "304                 psi = Statevector.from_label('+0')\n",
      "305 \n",
      "306                 # Probabilities for measuring both qubits\n",
      "307                 probs = psi.probabilities()\n",
      "308                 print('probs: {}'.format(probs))\n",
      "309 \n",
      "310                 # Probabilities for measuring only qubit-0\n",
      "311                 probs_qubit_0 = psi.probabilities([0])\n",
      "312                 print('Qubit-0 probs: {}'.format(probs_qubit_0))\n",
      "313 \n",
      "314                 # Probabilities for measuring only qubit-1\n",
      "315                 probs_qubit_1 = psi.probabilities([1])\n",
      "316                 print('Qubit-1 probs: {}'.format(probs_qubit_1))\n",
      "317 \n",
      "318             We can also permute the order of qubits in the ``qargs`` list\n",
      "319             to change the qubit position in the probabilities output\n",
      "320 \n",
      "321             .. jupyter-execute::\n",
      "322 \n",
      "323                 from qiskit.quantum_info import Statevector\n",
      "324 \n",
      "325                 psi = Statevector.from_label('+0')\n",
      "326 \n",
      "327                 # Probabilities for measuring both qubits\n",
      "328                 probs = psi.probabilities([0, 1])\n",
      "329                 print('probs: {}'.format(probs))\n",
      "330 \n",
      "331                 # Probabilities for measuring both qubits\n",
      "332                 # but swapping qubits 0 and 1 in output\n",
      "333                 probs_swapped = psi.probabilities([1, 0])\n",
      "334                 print('Swapped probs: {}'.format(probs_swapped))\n",
      "335         \"\"\"\n",
      "336         probs = self._subsystem_probabilities(\n",
      "337             np.abs(self.data) ** 2, self._dims, qargs=qargs)\n",
      "338         if decimals is not None:\n",
      "339             probs = probs.round(decimals=decimals)\n",
      "340         return probs\n",
      "341 \n",
      "342     def reset(self, qargs=None):\n",
      "343         \"\"\"Reset state or subsystems to the 0-state.\n",
      "344 \n",
      "345         Args:\n",
      "346             qargs (list or None): subsystems to reset, if None all\n",
      "347                                   subsystems will be reset to their 0-state\n",
      "348                                   (Default: None).\n",
      "349 \n",
      "350         Returns:\n",
      "351             Statevector: the reset state.\n",
      "352 \n",
      "353         Additional Information:\n",
      "354             If all subsystems are reset this will return the ground state\n",
      "355             on all subsystems. If only a some subsystems are reset this\n",
      "356             function will perform a measurement on those subsystems and\n",
      "357             evolve the subsystems so that the collapsed post-measurement\n",
      "358             states are rotated to the 0-state. The RNG seed for this\n",
      "359             sampling can be set using the :meth:`seed` method.\n",
      "360         \"\"\"\n",
      "361         if qargs is None:\n",
      "362             # Resetting all qubits does not require sampling or RNG\n",
      "363             state = np.zeros(self._dim, dtype=complex)\n",
      "364             state[0] = 1\n",
      "365             return Statevector(state, dims=self._dims)\n",
      "366 \n",
      "367         # Sample a single measurement outcome\n",
      "368         dims = self.dims(qargs)\n",
      "369         probs = self.probabilities(qargs)\n",
      "370         sample = self._rng.choice(len(probs), p=probs, size=1)\n",
      "371 \n",
      "372         # Convert to projector for state update\n",
      "373         proj = np.zeros(len(probs), dtype=complex)\n",
      "374         proj[sample] = 1 / np.sqrt(probs[sample])\n",
      "375 \n",
      "376         # Rotate outcome to 0\n",
      "377         reset = np.eye(len(probs))\n",
      "378         reset[0, 0] = 0\n",
      "379         reset[sample, sample] = 0\n",
      "380         reset[0, sample] = 1\n",
      "381 \n",
      "382         # compose with reset projection\n",
      "383         reset = np.dot(reset, np.diag(proj))\n",
      "384         return self.evolve(\n",
      "385             Operator(reset, input_dims=dims, output_dims=dims),\n",
      "386             qargs=qargs)\n",
      "387 \n",
      "388     def to_counts(self):\n",
      "389         \"\"\"Returns the statevector as a counts dict\n",
      "390         of probabilities.\n",
      "391 \n",
      "392         DEPRECATED: use :meth:`probabilities_dict` instead.\n",
      "393 \n",
      "394         Returns:\n",
      "395             dict: Counts of probabilities.\n",
      "396         \"\"\"\n",
      "397         warnings.warn(\n",
      "398             'The `Statevector.to_counts` method is deprecated as of 0.13.0,'\n",
      "399             ' and will be removed no earlier than 3 months after that '\n",
      "400             'release date. You should use the `Statevector.probabilities_dict`'\n",
      "401             ' method instead.', DeprecationWarning, stacklevel=2)\n",
      "402         return self.probabilities_dict()\n",
      "403 \n",
      "404     @classmethod\n",
      "405     def from_label(cls, label):\n",
      "406         \"\"\"Return a tensor product of Pauli X,Y,Z eigenstates.\n",
      "407 \n",
      "408         .. list-table:: Single-qubit state labels\n",
      "409            :header-rows: 1\n",
      "410 \n",
      "411            * - Label\n",
      "412              - Statevector\n",
      "413            * - ``\"0\"``\n",
      "414              - :math:`[1, 0]`\n",
      "415            * - ``\"1\"``\n",
      "416              - :math:`[0, 1]`\n",
      "417            * - ``\"+\"``\n",
      "418              - :math:`[1 / \\\\sqrt{2},  1 / \\\\sqrt{2}]`\n",
      "419            * - ``\"-\"``\n",
      "420              - :math:`[1 / \\\\sqrt{2},  -1 / \\\\sqrt{2}]`\n",
      "421            * - ``\"r\"``\n",
      "422              - :math:`[1 / \\\\sqrt{2},  i / \\\\sqrt{2}]`\n",
      "423            * - ``\"l\"``\n",
      "424              - :math:`[1 / \\\\sqrt{2},  -i / \\\\sqrt{2}]`\n",
      "425 \n",
      "426         Args:\n",
      "427             label (string): a eigenstate string ket label (see table for\n",
      "428                             allowed values).\n",
      "429 \n",
      "430         Returns:\n",
      "431             Statevector: The N-qubit basis state density matrix.\n",
      "432 \n",
      "433         Raises:\n",
      "434             QiskitError: if the label contains invalid characters, or the\n",
      "435                          length of the label is larger than an explicitly\n",
      "436                          specified num_qubits.\n",
      "437         \"\"\"\n",
      "438         # Check label is valid\n",
      "439         if re.match(r'^[01rl\\-+]+$', label) is None:\n",
      "440             raise QiskitError('Label contains invalid characters.')\n",
      "441         # We can prepare Z-eigenstates by converting the computational\n",
      "442         # basis bit-string to an integer and preparing that unit vector\n",
      "443         # However, for X-basis states, we will prepare a Z-eigenstate first\n",
      "444         # then apply Hadamard gates to rotate 0 and 1s to + and -.\n",
      "445         z_label = label\n",
      "446         xy_states = False\n",
      "447         if re.match('^[01]+$', label) is None:\n",
      "448             # We have X or Y eigenstates so replace +,r with 0 and\n",
      "449             # -,l with 1 and prepare the corresponding Z state\n",
      "450             xy_states = True\n",
      "451             z_label = z_label.replace('+', '0')\n",
      "452             z_label = z_label.replace('r', '0')\n",
      "453             z_label = z_label.replace('-', '1')\n",
      "454             z_label = z_label.replace('l', '1')\n",
      "455         # Initialize Z eigenstate vector\n",
      "456         num_qubits = len(label)\n",
      "457         data = np.zeros(1 << num_qubits, dtype=complex)\n",
      "458         pos = int(z_label, 2)\n",
      "459         data[pos] = 1\n",
      "460         state = Statevector(data)\n",
      "461         if xy_states:\n",
      "462             # Apply hadamards to all qubits in X eigenstates\n",
      "463             x_mat = np.array([[1, 1], [1, -1]], dtype=complex) / np.sqrt(2)\n",
      "464             # Apply S.H to qubits in Y eigenstates\n",
      "465             y_mat = np.dot(np.diag([1, 1j]), x_mat)\n",
      "466             for qubit, char in enumerate(reversed(label)):\n",
      "467                 if char in ['+', '-']:\n",
      "468                     state = state.evolve(x_mat, qargs=[qubit])\n",
      "469                 elif char in ['r', 'l']:\n",
      "470                     state = state.evolve(y_mat, qargs=[qubit])\n",
      "471         return state\n",
      "472 \n",
      "473     @staticmethod\n",
      "474     def from_int(i, dims):\n",
      "475         \"\"\"Return a computational basis statevector.\n",
      "476 \n",
      "477         Args:\n",
      "478             i (int): the basis state element.\n",
      "479             dims (int or tuple or list): The subsystem dimensions of the statevector\n",
      "480                                          (See additional information).\n",
      "481 \n",
      "482         Returns:\n",
      "483             Statevector: The computational basis state :math:`|i\\\\rangle`.\n",
      "484 \n",
      "485         Additional Information:\n",
      "486             The ``dims`` kwarg can be an integer or an iterable of integers.\n",
      "487 \n",
      "488             * ``Iterable`` -- the subsystem dimensions are the values in the list\n",
      "489               with the total number of subsystems given by the length of the list.\n",
      "490 \n",
      "491             * ``Int`` -- the integer specifies the total dimension of the\n",
      "492               state. If it is a power of two the state will be initialized\n",
      "493               as an N-qubit state. If it is not a power of  two the state\n",
      "494               will have a single d-dimensional subsystem.\n",
      "495         \"\"\"\n",
      "496         size = np.product(dims)\n",
      "497         state = np.zeros(size, dtype=complex)\n",
      "498         state[i] = 1.0\n",
      "499         return Statevector(state, dims=dims)\n",
      "500 \n",
      "501     @classmethod\n",
      "502     def from_instruction(cls, instruction):\n",
      "503         \"\"\"Return the output statevector of an instruction.\n",
      "504 \n",
      "505         The statevector is initialized in the state :math:`|{0,\\\\ldots,0}\\\\rangle` of the\n",
      "506         same number of qubits as the input instruction or circuit, evolved\n",
      "507         by the input instruction, and the output statevector returned.\n",
      "508 \n",
      "509         Args:\n",
      "510             instruction (qiskit.circuit.Instruction or QuantumCircuit): instruction or circuit\n",
      "511 \n",
      "512         Returns:\n",
      "513             Statevector: The final statevector.\n",
      "514 \n",
      "515         Raises:\n",
      "516             QiskitError: if the instruction contains invalid instructions for\n",
      "517                          the statevector simulation.\n",
      "518         \"\"\"\n",
      "519         # Convert circuit to an instruction\n",
      "520         if isinstance(instruction, QuantumCircuit):\n",
      "521             instruction = instruction.to_instruction()\n",
      "522         # Initialize an the statevector in the all |0> state\n",
      "523         init = np.zeros(2 ** instruction.num_qubits, dtype=complex)\n",
      "524         init[0] = 1.0\n",
      "525         vec = Statevector(init, dims=instruction.num_qubits * (2,))\n",
      "526         vec._append_instruction(instruction)\n",
      "527         return vec\n",
      "528 \n",
      "529     def to_dict(self, decimals=None):\n",
      "530         r\"\"\"Convert the statevector to dictionary form.\n",
      "531 \n",
      "532         This dictionary representation uses a Ket-like notation where the\n",
      "533         dictionary keys are qudit strings for the subsystem basis vectors.\n",
      "534         If any subsystem has a dimension greater than 10 comma delimiters are\n",
      "535         inserted between integers so that subsystems can be distinguished.\n",
      "536 \n",
      "537         Args:\n",
      "538             decimals (None or int): the number of decimal places to round\n",
      "539                                     values. If None no rounding is done\n",
      "540                                     (Default: None).\n",
      "541 \n",
      "542         Returns:\n",
      "543             dict: the dictionary form of the Statevector.\n",
      "544 \n",
      "545         Example:\n",
      "546 \n",
      "547             The ket-form of a 2-qubit statevector\n",
      "548             :math:`|\\psi\\rangle = |-\\rangle\\otimes |0\\rangle`\n",
      "549 \n",
      "550             .. jupyter-execute::\n",
      "551 \n",
      "552                 from qiskit.quantum_info import Statevector\n",
      "553 \n",
      "554                 psi = Statevector.from_label('-0')\n",
      "555                 print(psi.to_dict())\n",
      "556 \n",
      "557             For non-qubit subsystems the integer range can go from 0 to 9. For\n",
      "558             example in a qutrit system\n",
      "559 \n",
      "560             .. jupyter-execute::\n",
      "561 \n",
      "562                 import numpy as np\n",
      "563                 from qiskit.quantum_info import Statevector\n",
      "564 \n",
      "565                 vec = np.zeros(9)\n",
      "566                 vec[0] = 1 / np.sqrt(2)\n",
      "567                 vec[-1] = 1 / np.sqrt(2)\n",
      "568                 psi = Statevector(vec, dims=(3, 3))\n",
      "569                 print(psi.to_dict())\n",
      "570 \n",
      "571             For large subsystem dimensions delimeters are required. The\n",
      "572             following example is for a 20-dimensional system consisting of\n",
      "573             a qubit and 10-dimensional qudit.\n",
      "574 \n",
      "575             .. jupyter-execute::\n",
      "576 \n",
      "577                 import numpy as np\n",
      "578                 from qiskit.quantum_info import Statevector\n",
      "579 \n",
      "580                 vec = np.zeros(2 * 10)\n",
      "581                 vec[0] = 1 / np.sqrt(2)\n",
      "582                 vec[-1] = 1 / np.sqrt(2)\n",
      "583                 psi = Statevector(vec, dims=(2, 10))\n",
      "584                 print(psi.to_dict())\n",
      "585         \"\"\"\n",
      "586         return self._vector_to_dict(self.data,\n",
      "587                                     self._dims,\n",
      "588                                     decimals=decimals,\n",
      "589                                     string_labels=True)\n",
      "590 \n",
      "591     @property\n",
      "592     def _shape(self):\n",
      "593         \"\"\"Return the tensor shape of the matrix operator\"\"\"\n",
      "594         return tuple(reversed(self.dims()))\n",
      "595 \n",
      "596     def _append_instruction(self, obj, qargs=None):\n",
      "597         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "598         mat = Operator._instruction_to_matrix(obj)\n",
      "599         if mat is not None:\n",
      "600             # Perform the composition and inplace update the current state\n",
      "601             # of the operator\n",
      "602             state = self.evolve(mat, qargs=qargs)\n",
      "603             self._data = state.data\n",
      "604         else:\n",
      "605             # If the instruction doesn't have a matrix defined we use its\n",
      "606             # circuit decomposition definition if it exists, otherwise we\n",
      "607             # cannot compose this gate and raise an error.\n",
      "608             if obj.definition is None:\n",
      "609                 raise QiskitError('Cannot apply Instruction: {}'.format(obj.name))\n",
      "610             for instr, qregs, cregs in obj.definition:\n",
      "611                 if cregs:\n",
      "612                     raise QiskitError(\n",
      "613                         'Cannot apply instruction with classical registers: {}'.format(\n",
      "614                             instr.name))\n",
      "615                 # Get the integer position of the flat register\n",
      "616                 if qargs is None:\n",
      "617                     new_qargs = [tup.index for tup in qregs]\n",
      "618                 else:\n",
      "619                     new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "620                 self._append_instruction(instr, qargs=new_qargs)\n",
      "621 \n",
      "622     def _evolve_instruction(self, obj, qargs=None):\n",
      "623         \"\"\"Return a new statevector by applying an instruction.\"\"\"\n",
      "624         if isinstance(obj, QuantumCircuit):\n",
      "625             obj = obj.to_instruction()\n",
      "626         vec = Statevector(self.data, dims=self.dims())\n",
      "627         vec._append_instruction(obj, qargs=qargs)\n",
      "628         return vec\n",
      "629 \n",
      "[end of qiskit/quantum_info/states/statevector.py]\n",
      "</code>\n",
      "I need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n",
      "<patch>\n",
      "--- a/file.py\n",
      "+++ b/file.py\n",
      "@@ -1,27 +1,35 @@\n",
      " def euclidean(a, b):\n",
      "-    while b:\n",
      "-        a, b = b, a % b\n",
      "-    return a\n",
      "+    if b == 0:\n",
      "+        return a\n",
      "+    return euclidean(b, a % b)\n",
      " \n",
      " \n",
      " def bresenham(x0, y0, x1, y1):\n",
      "     points = []\n",
      "     dx = abs(x1 - x0)\n",
      "     dy = abs(y1 - y0)\n",
      "-    sx = 1 if x0 < x1 else -1\n",
      "-    sy = 1 if y0 < y1 else -1\n",
      "-    err = dx - dy\n",
      "+    x, y = x0, y0\n",
      "+    sx = -1 if x0 > x1 else 1\n",
      "+    sy = -1 if y0 > y1 else 1\n",
      " \n",
      "-    while True:\n",
      "-        points.append((x0, y0))\n",
      "-        if x0 == x1 and y0 == y1:\n",
      "-            break\n",
      "-        e2 = 2 * err\n",
      "-        if e2 > -dy:\n",
      "+    if dx > dy:\n",
      "+        err = dx / 2.0\n",
      "+        while x != x1:\n",
      "+            points.append((x, y))\n",
      "             err -= dy\n",
      "-            x0 += sx\n",
      "-        if e2 < dx:\n",
      "-            err += dx\n",
      "-            y0 += sy\n",
      "+            if err < 0:\n",
      "+                y += sy\n",
      "+                err += dx\n",
      "+            x += sx\n",
      "+    else:\n",
      "+        err = dy / 2.0\n",
      "+        while y != y1:\n",
      "+            points.append((x, y))\n",
      "+            err -= dx\n",
      "+            if err < 0:\n",
      "+                x += sx\n",
      "+                err += dy\n",
      "+            y += sy\n",
      " \n",
      "+    points.append((x, y))\n",
      "     return points\n",
      "</patch>\n",
      "\n",
      "\n",
      "True\n",
      "\n",
      "--- a/qiskit/quantum_info/states/densitymatrix.py\n",
      "+++ b/qiskit/quantum_info/states/densitymatrix.py\n",
      "@@ -547,12 +547,22 @@ def _evolve_operator(self, other, qargs=None):\n",
      " \n",
      "     def _append_instruction(self, other, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "+        from qiskit.circuit.reset import Reset\n",
      "+        from qiskit.circuit.barrier import Barrier\n",
      " \n",
      "         # Try evolving by a matrix operator (unitary-like evolution)\n",
      "         mat = Operator._instruction_to_matrix(other)\n",
      "         if mat is not None:\n",
      "             self._data = self._evolve_operator(Operator(mat), qargs=qargs).data\n",
      "             return\n",
      "+\n",
      "+        # Special instruction types\n",
      "+        if isinstance(other, Reset):\n",
      "+            self._data = self.reset(qargs)._data\n",
      "+            return\n",
      "+        if isinstance(other, Barrier):\n",
      "+            return\n",
      "+\n",
      "         # Otherwise try evolving by a Superoperator\n",
      "         chan = SuperOp._instruction_to_superop(other)\n",
      "         if chan is not None:\n",
      "--- a/qiskit/quantum_info/states/statevector.py\n",
      "+++ b/qiskit/quantum_info/states/statevector.py\n",
      "@@ -595,29 +595,40 @@ def _shape(self):\n",
      " \n",
      "     def _append_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "+        from qiskit.circuit.reset import Reset\n",
      "+        from qiskit.circuit.barrier import Barrier\n",
      "+\n",
      "         mat = Operator._instruction_to_matrix(obj)\n",
      "         if mat is not None:\n",
      "             # Perform the composition and inplace update the current state\n",
      "             # of the operator\n",
      "-            state = self.evolve(mat, qargs=qargs)\n",
      "-            self._data = state.data\n",
      "-        else:\n",
      "-            # If the instruction doesn't have a matrix defined we use its\n",
      "-            # circuit decomposition definition if it exists, otherwise we\n",
      "-            # cannot compose this gate and raise an error.\n",
      "-            if obj.definition is None:\n",
      "-                raise QiskitError('Cannot apply Instruction: {}'.format(obj.name))\n",
      "-            for instr, qregs, cregs in obj.definition:\n",
      "-                if cregs:\n",
      "-                    raise QiskitError(\n",
      "-                        'Cannot apply instruction with classical registers: {}'.format(\n",
      "-                            instr.name))\n",
      "-                # Get the integer position of the flat register\n",
      "-                if qargs is None:\n",
      "-                    new_qargs = [tup.index for tup in qregs]\n",
      "-                else:\n",
      "-                    new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "-                self._append_instruction(instr, qargs=new_qargs)\n",
      "+            self._data = self.evolve(mat, qargs=qargs).data\n",
      "+            return\n",
      "+\n",
      "+        # Special instruction types\n",
      "+        if isinstance(obj, Reset):\n",
      "+            self._data = self.reset(qargs)._data\n",
      "+            return\n",
      "+        if isinstance(obj, Barrier):\n",
      "+            return\n",
      "+\n",
      "+        # If the instruction doesn't have a matrix defined we use its\n",
      "+        # circuit decomposition definition if it exists, otherwise we\n",
      "+        # cannot compose this gate and raise an error.\n",
      "+        if obj.definition is None:\n",
      "+            raise QiskitError('Cannot apply Instruction: {}'.format(obj.name))\n",
      "+\n",
      "+        for instr, qregs, cregs in obj.definition:\n",
      "+            if cregs:\n",
      "+                raise QiskitError(\n",
      "+                    'Cannot apply instruction with classical registers: {}'.format(\n",
      "+                        instr.name))\n",
      "+            # Get the integer position of the flat register\n",
      "+            if qargs is None:\n",
      "+                new_qargs = [tup.index for tup in qregs]\n",
      "+            else:\n",
      "+                new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "+            self._append_instruction(instr, qargs=new_qargs)\n",
      " \n",
      "     def _evolve_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Return a new statevector by applying an instruction.\"\"\"\n",
      "\n",
      "\n",
      "LENGTH OF THE PARSED DIFF:  5\n",
      "FILEPATH\n",
      " b/qiskit/quantum_info/states/densitymatrix.py\n",
      "SEARCH\n",
      "\n",
      "REPLACE\n",
      "\n",
      "FILEPATH\n",
      " b/qiskit/quantum_info/states/densitymatrix.py\n",
      "SEARCH\n",
      " \n",
      "     def _append_instruction(self, other, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      " \n",
      "         # Try evolving by a matrix operator (unitary-like evolution)\n",
      "         mat = Operator._instruction_to_matrix(other)\n",
      "         if mat is not None:\n",
      "             self._data = self._evolve_operator(Operator(mat), qargs=qargs).data\n",
      "             return\n",
      "         # Otherwise try evolving by a Superoperator\n",
      "         chan = SuperOp._instruction_to_superop(other)\n",
      "         if chan is not None:\n",
      "\n",
      "REPLACE\n",
      " \n",
      "     def _append_instruction(self, other, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "         from qiskit.circuit.reset import Reset\n",
      "         from qiskit.circuit.barrier import Barrier\n",
      " \n",
      "         # Try evolving by a matrix operator (unitary-like evolution)\n",
      "         mat = Operator._instruction_to_matrix(other)\n",
      "         if mat is not None:\n",
      "             self._data = self._evolve_operator(Operator(mat), qargs=qargs).data\n",
      "             return\n",
      " \n",
      "         # Special instruction types\n",
      "         if isinstance(other, Reset):\n",
      "             self._data = self.reset(qargs)._data\n",
      "             return\n",
      "         if isinstance(other, Barrier):\n",
      "             return\n",
      " \n",
      "         # Otherwise try evolving by a Superoperator\n",
      "         chan = SuperOp._instruction_to_superop(other)\n",
      "         if chan is not None:\n",
      "\n",
      "FILEPATH\n",
      " b/qiskit/quantum_info/states/statevector.py\n",
      "SEARCH\n",
      "\n",
      "REPLACE\n",
      "\n",
      "FILEPATH\n",
      " b/qiskit/quantum_info/states/statevector.py\n",
      "SEARCH\n",
      " \n",
      "     def _append_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "         mat = Operator._instruction_to_matrix(obj)\n",
      "         if mat is not None:\n",
      "             # Perform the composition and inplace update the current state\n",
      "             # of the operator\n",
      "             state = self.evolve(mat, qargs=qargs)\n",
      "             self._data = state.data\n",
      "         else:\n",
      "             # If the instruction doesn't have a matrix defined we use its\n",
      "             # circuit decomposition definition if it exists, otherwise we\n",
      "             # cannot compose this gate and raise an error.\n",
      "             if obj.definition is None:\n",
      "                 raise QiskitError('Cannot apply Instruction: {}'.format(obj.name))\n",
      "             for instr, qregs, cregs in obj.definition:\n",
      "                 if cregs:\n",
      "                     raise QiskitError(\n",
      "                         'Cannot apply instruction with classical registers: {}'.format(\n",
      "                             instr.name))\n",
      "                 # Get the integer position of the flat register\n",
      "                 if qargs is None:\n",
      "                     new_qargs = [tup.index for tup in qregs]\n",
      "                 else:\n",
      "                     new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "                 self._append_instruction(instr, qargs=new_qargs)\n",
      " \n",
      "     def _evolve_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Return a new statevector by applying an instruction.\"\"\"\n",
      "\n",
      "\n",
      "REPLACE\n",
      " \n",
      "     def _append_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Update the current Statevector by applying an instruction.\"\"\"\n",
      "         from qiskit.circuit.reset import Reset\n",
      "         from qiskit.circuit.barrier import Barrier\n",
      " \n",
      "         mat = Operator._instruction_to_matrix(obj)\n",
      "         if mat is not None:\n",
      "             # Perform the composition and inplace update the current state\n",
      "             # of the operator\n",
      "             self._data = self.evolve(mat, qargs=qargs).data\n",
      "             return\n",
      " \n",
      "         # Special instruction types\n",
      "         if isinstance(obj, Reset):\n",
      "             self._data = self.reset(qargs)._data\n",
      "             return\n",
      "         if isinstance(obj, Barrier):\n",
      "             return\n",
      " \n",
      "         # If the instruction doesn't have a matrix defined we use its\n",
      "         # circuit decomposition definition if it exists, otherwise we\n",
      "         # cannot compose this gate and raise an error.\n",
      "         if obj.definition is None:\n",
      "             raise QiskitError('Cannot apply Instruction: {}'.format(obj.name))\n",
      " \n",
      "         for instr, qregs, cregs in obj.definition:\n",
      "             if cregs:\n",
      "                 raise QiskitError(\n",
      "                     'Cannot apply instruction with classical registers: {}'.format(\n",
      "                         instr.name))\n",
      "             # Get the integer position of the flat register\n",
      "             if qargs is None:\n",
      "                 new_qargs = [tup.index for tup in qregs]\n",
      "             else:\n",
      "                 new_qargs = [qargs[tup.index] for tup in qregs]\n",
      "             self._append_instruction(instr, qargs=new_qargs)\n",
      " \n",
      "     def _evolve_instruction(self, obj, qargs=None):\n",
      "         \"\"\"Return a new statevector by applying an instruction.\"\"\"\n",
      "\n",
      "\n",
      "FILEPATH\n",
      "\n",
      "SEARCH\n",
      "\n",
      "REPLACE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "first_inst = next(iter(dataset))['text']\n",
    "print(first_inst)\n",
    "print(PATCH_FORMATTING_INST in first_inst)\n",
    "\n",
    "test_patch = next(iter(dataset))['patch']\n",
    "test_patch = test_patch.replace(\"<patch>\", \"\").replace(\"</patch>\", \"\")\n",
    "test_patch = re.sub(r'^diff.*\\n?', '', test_patch, flags=re.MULTILINE)\n",
    "\n",
    "parsed_test_diff = parse_diff(test_patch)\n",
    "\n",
    "\n",
    "print(test_patch)\n",
    "print(\"LENGTH OF THE PARSED DIFF: \", len(parsed_test_diff))\n",
    "\n",
    "for block in parsed_test_diff:\n",
    "    print(\"FILEPATH\")\n",
    "    print(block.filepath)\n",
    "    print(\"SEARCH\")\n",
    "    print(block.search_block)\n",
    "    print(\"REPLACE\")\n",
    "    print(block.replace_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4465\n",
      "Token count is too large: Qiskit__qiskit-1295\n",
      "Token count is too large: docker__compose-6410\n",
      "Token count is too large: ytdl-org__youtube-dl-1591\n",
      "Token count is too large: numpy__numpy-13703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3 examples [00:00, 10.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27237\n",
      "Token count is too large: googleapis__google-cloud-python-3712\n",
      "Token count is too large: Qiskit__qiskit-6240\n",
      "Token count is too large: numpy__numpy-11280\n",
      "Token count is too large: numpy__numpy-21187\n",
      "Token count is too large: pandas-dev__pandas-26343\n",
      "Token count is too large: googleapis__google-cloud-python-8438\n",
      "Token count is too large: numpy__numpy-23700\n",
      "Token count is too large: mesonbuild__meson-11181\n",
      "Token count is too large: huggingface__transformers-15625\n",
      "Token count is too large: apache__airflow-33043\n",
      "Token count is too large: pantsbuild__pants-18947\n",
      "Token count is too large: googleapis__google-cloud-python-5020\n",
      "Token count is too large: numpy__numpy-7258\n",
      "Token count is too large: pandas-dev__pandas-19230\n",
      "Token count is too large: ray-project__ray-8231\n",
      "Token count is too large: huggingface__transformers-8016\n",
      "Token count is too large: mesonbuild__meson-3894\n",
      "Token count is too large: numpy__numpy-23600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 9 examples [00:00, 10.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-10300\n",
      "Token count is too large: pandas-dev__pandas-8134\n",
      "Token count is too large: docker__compose-5653\n",
      "Token count is too large: pandas-dev__pandas-19730\n",
      "Token count is too large: pandas-dev__pandas-19112\n",
      "Token count is too large: pandas-dev__pandas-28297\n",
      "Token count is too large: pypa__pip-4992\n",
      "There was an error processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 13 examples [00:01, 12.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21969\n",
      "Token count is too large: conan-io__conan-2916\n",
      "Token count is too large: google__jax-1388\n",
      "Token count is too large: pandas-dev__pandas-6122\n",
      "Token count is too large: apache__airflow-8230\n",
      "Token count is too large: pandas-dev__pandas-33857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 15 examples [00:01, 10.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5701\n",
      "Token count is too large: Qiskit__qiskit-1276\n",
      "Token count is too large: pandas-dev__pandas-37546\n",
      "Token count is too large: Qiskit__qiskit-9823\n",
      "Token count is too large: wagtail__wagtail-9922\n",
      "Token count is too large: pandas-dev__pandas-30494\n",
      "Token count is too large: PrefectHQ__prefect-312\n",
      "Token count is too large: pandas-dev__pandas-22804\n",
      "Token count is too large: docker__compose-6221\n",
      "Token count is too large: pandas-dev__pandas-10841\n",
      "Token count is too large: pandas-dev__pandas-23021\n",
      "Token count is too large: Qiskit__qiskit-5601\n",
      "Token count is too large: explosion__spaCy-3434\n",
      "Token count is too large: Lightning-AI__lightning-1748\n",
      "Token count is too large: ray-project__ray-8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 22 examples [00:01, 17.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6044\n",
      "Token count is too large: apache__airflow-22710\n",
      "Token count is too large: ytdl-org__youtube-dl-14833\n",
      "Token count is too large: pandas-dev__pandas-6937\n",
      "Token count is too large: apache__airflow-10864\n",
      "Token count is too large: mesonbuild__meson-5396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 26 examples [00:01, 17.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5713\n",
      "Token count is too large: Qiskit__qiskit-1856\n",
      "Token count is too large: pandas-dev__pandas-39217\n",
      "Token count is too large: pandas-dev__pandas-10108\n",
      "Token count is too large: pandas-dev__pandas-16295\n",
      "Token count is too large: Qiskit__qiskit-6001\n",
      "Token count is too large: pantsbuild__pants-16220\n",
      "Token count is too large: celery__celery-6629\n",
      "Token count is too large: celery__celery-6288\n",
      "Token count is too large: Lightning-AI__lightning-1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 30 examples [00:02, 16.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7456\n",
      "Token count is too large: mesonbuild__meson-327\n",
      "Token count is too large: huggingface__transformers-18803\n",
      "Token count is too large: mesonbuild__meson-2849\n",
      "Token count is too large: mesonbuild__meson-5553\n",
      "Token count is too large: pandas-dev__pandas-20098\n",
      "Token count is too large: pandas-dev__pandas-20891\n",
      "Token count is too large: apache__airflow-18228\n",
      "Token count is too large: googleapis__google-cloud-python-7441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 32 examples [00:02, 15.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-10679\n",
      "Token count is too large: Lightning-AI__lightning-2865\n",
      "Token count is too large: pandas-dev__pandas-26134\n",
      "Token count is too large: docker__compose-1939\n",
      "Token count is too large: pandas-dev__pandas-19889\n",
      "Token count is too large: ytdl-org__youtube-dl-21658\n",
      "Token count is too large: pandas-dev__pandas-22266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 43 examples [00:02, 22.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-5036\n",
      "Token count is too large: jupyterlab__jupyterlab-8486\n",
      "Token count is too large: numpy__numpy-7635\n",
      "Token count is too large: Lightning-AI__lightning-1667\n",
      "Token count is too large: docker__compose-3670\n",
      "Token count is too large: numpy__numpy-18339\n",
      "Token count is too large: huggingface__transformers-6648\n",
      "Token count is too large: conan-io__conan-4495\n",
      "Token count is too large: mesonbuild__meson-5073\n",
      "Token count is too large: pandas-dev__pandas-31262\n",
      "Token count is too large: pypa__pip-7489\n",
      "Token count is too large: mesonbuild__meson-2496\n",
      "Token count is too large: pantsbuild__pants-5971\n",
      "Token count is too large: Lightning-AI__lightning-1377\n",
      "Token count is too large: googleapis__google-cloud-python-6010\n",
      "Token count is too large: googleapis__google-cloud-python-2151\n",
      "Token count is too large: ipython__ipython-2232\n",
      "Token count is too large: pandas-dev__pandas-19401\n",
      "Token count is too large: googleapis__google-cloud-python-814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 49 examples [00:02, 25.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-2600\n",
      "Token count is too large: pantsbuild__pants-14169\n",
      "Token count is too large: pandas-dev__pandas-21507\n",
      "Token count is too large: pandas-dev__pandas-38142\n",
      "Token count is too large: pandas-dev__pandas-17751\n",
      "Token count is too large: Qiskit__qiskit-9040\n",
      "Token count is too large: googleapis__google-cloud-python-603\n",
      "Token count is too large: pandas-dev__pandas-7076\n",
      "Token count is too large: pandas-dev__pandas-7657\n",
      "Token count is too large: pandas-dev__pandas-25434\n",
      "Token count is too large: google__jax-509\n",
      "Token count is too large: Qiskit__qiskit-10622\n",
      "Token count is too large: pandas-dev__pandas-23402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 53 examples [00:02, 26.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-1172\n",
      "Token count is too large: googleapis__google-cloud-python-10015\n",
      "Token count is too large: docker__compose-2720\n",
      "Token count is too large: googleapis__google-cloud-python-4498\n",
      "Token count is too large: pandas-dev__pandas-27068\n",
      "Token count is too large: googleapis__google-cloud-python-2989\n",
      "Token count is too large: google__jax-2561\n",
      "Token count is too large: pandas-dev__pandas-23837\n",
      "Token count is too large: ipython__ipython-14014\n",
      "Token count is too large: numpy__numpy-3266\n",
      "Token count is too large: huggingface__transformers-21727\n",
      "Token count is too large: googleapis__google-cloud-python-276\n",
      "Token count is too large: pantsbuild__pants-5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 57 examples [00:03, 24.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31918\n",
      "Token count is too large: pypa__pip-6818\n",
      "Token count is too large: Qiskit__qiskit-1615\n",
      "Token count is too large: Qiskit__qiskit-8759\n",
      "Token count is too large: ipython__ipython-3683\n",
      "Token count is too large: Lightning-AI__lightning-2185\n",
      "Token count is too large: pandas-dev__pandas-6661\n",
      "Token count is too large: pandas-dev__pandas-5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 60 examples [00:03, 19.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17836\n",
      "Token count is too large: pandas-dev__pandas-3585\n",
      "Token count is too large: pandas-dev__pandas-30995\n",
      "Token count is too large: conda__conda-11666\n",
      "Token count is too large: docker__compose-4333\n",
      "Token count is too large: numpy__numpy-11219\n",
      "Token count is too large: pantsbuild__pants-12281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 63 examples [00:03, 15.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20735\n",
      "Token count is too large: conan-io__conan-9360\n",
      "Token count is too large: pandas-dev__pandas-19973\n",
      "Token count is too large: Lightning-AI__lightning-2842\n",
      "Token count is too large: Lightning-AI__lightning-1104\n",
      "Token count is too large: pandas-dev__pandas-22695\n",
      "Token count is too large: mesonbuild__meson-9369\n",
      "Token count is too large: pandas-dev__pandas-26298\n",
      "Token count is too large: conan-io__conan-9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 66 examples [00:03, 16.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9033\n",
      "Token count is too large: Lightning-AI__lightning-1797\n",
      "Token count is too large: Qiskit__qiskit-2978\n",
      "Token count is too large: docker__compose-2051\n",
      "Token count is too large: huggingface__transformers-15085\n",
      "Token count is too large: pandas-dev__pandas-38057\n",
      "Token count is too large: pandas-dev__pandas-25275\n",
      "Token count is too large: pandas-dev__pandas-11006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 68 examples [00:03, 16.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21216\n",
      "Token count is too large: pandas-dev__pandas-11957\n",
      "Token count is too large: apache__airflow-19418\n",
      "Token count is too large: google__jax-1972\n",
      "Token count is too large: pandas-dev__pandas-14344\n",
      "Token count is too large: pandas-dev__pandas-6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 73 examples [00:04, 18.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7485\n",
      "Token count is too large: numpy__numpy-3244\n",
      "Token count is too large: pandas-dev__pandas-14629\n",
      "Token count is too large: pandas-dev__pandas-25729\n",
      "Token count is too large: conda__conda-12378\n",
      "Token count is too large: pypa__pip-11502\n",
      "Token count is too large: pantsbuild__pants-4773\n",
      "Token count is too large: numpy__numpy-6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 75 examples [00:04, 13.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1373\n",
      "Token count is too large: pandas-dev__pandas-11079\n",
      "Token count is too large: pandas-dev__pandas-4313\n",
      "Token count is too large: pandas-dev__pandas-5849\n",
      "Token count is too large: pantsbuild__pants-4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 80 examples [00:04, 15.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-7115\n",
      "Token count is too large: googleapis__google-cloud-python-2390\n",
      "Token count is too large: Lightning-AI__lightning-1724\n",
      "Token count is too large: numpy__numpy-14345\n",
      "Token count is too large: Qiskit__qiskit-989\n",
      "Token count is too large: apache__airflow-19142\n",
      "Token count is too large: pandas-dev__pandas-4846\n",
      "Token count is too large: ipython__ipython-11650\n",
      "Token count is too large: pandas-dev__pandas-6553\n",
      "Token count is too large: pandas-dev__pandas-4267\n",
      "Token count is too large: pantsbuild__pants-5605\n",
      "Token count is too large: pantsbuild__pants-16808\n",
      "Token count is too large: huggingface__transformers-7456\n",
      "Token count is too large: numpy__numpy-11850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 82 examples [00:05, 11.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-18018\n",
      "Token count is too large: mesonbuild__meson-4354\n",
      "Token count is too large: mesonbuild__meson-11951\n",
      "Token count is too large: ipython__ipython-11330\n",
      "Token count is too large: numpy__numpy-20934\n",
      "Token count is too large: pandas-dev__pandas-23657\n",
      "Token count is too large: open-mmlab__mmdetection-6279\n",
      "Token count is too large: Qiskit__qiskit-943\n",
      "Token count is too large: pandas-dev__pandas-22037\n",
      "Token count is too large: pandas-dev__pandas-27083\n",
      "Token count is too large: conda__conda-2355\n",
      "Token count is too large: ray-project__ray-4469\n",
      "Token count is too large: apache__airflow-19193\n",
      "Token count is too large: Qiskit__qiskit-6675\n",
      "Token count is too large: gitpython-developers__GitPython-1224\n",
      "Token count is too large: pandas-dev__pandas-24547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 85 examples [00:05,  8.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33513\n",
      "Token count is too large: mesonbuild__meson-9295\n",
      "Token count is too large: conda__conda-3051\n",
      "Token count is too large: Lightning-AI__lightning-2565\n",
      "Token count is too large: pandas-dev__pandas-31679\n",
      "Token count is too large: conan-io__conan-4045\n",
      "Token count is too large: pypa__pip-10962\n",
      "Token count is too large: ipython__ipython-2820\n",
      "Token count is too large: Qiskit__qiskit-10284\n",
      "Token count is too large: jupyterlab__jupyterlab-5196\n",
      "Token count is too large: mesonbuild__meson-5571\n",
      "Token count is too large: scipy__scipy-4385\n",
      "Token count is too large: ray-project__ray-3731\n",
      "Token count is too large: pypa__pip-1311\n",
      "Token count is too large: docker__compose-7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 89 examples [00:05, 11.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16658\n",
      "Token count is too large: pandas-dev__pandas-31215\n",
      "Token count is too large: dagster-io__dagster-9792\n",
      "Token count is too large: pyca__cryptography-377\n",
      "Token count is too large: tiangolo__fastapi-1534\n",
      "Token count is too large: jupyterlab__jupyterlab-7055\n",
      "Token count is too large: pantsbuild__pants-7304\n",
      "Token count is too large: conan-io__conan-9230\n",
      "Token count is too large: apache__airflow-18224\n",
      "Token count is too large: docker__compose-2585\n",
      "Token count is too large: pandas-dev__pandas-22640\n",
      "Token count is too large: scipy__scipy-3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 92 examples [00:05, 12.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-20386\n",
      "Token count is too large: Qiskit__qiskit-7618\n",
      "Token count is too large: pandas-dev__pandas-26158\n",
      "Token count is too large: ytdl-org__youtube-dl-15112\n",
      "Token count is too large: numpy__numpy-20246\n",
      "Token count is too large: pandas-dev__pandas-19307\n",
      "Token count is too large: apache__airflow-17850\n",
      "Token count is too large: pandas-dev__pandas-35751\n",
      "Token count is too large: Qiskit__qiskit-6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 94 examples [00:06, 11.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6986\n",
      "Token count is too large: Qiskit__qiskit-2463\n",
      "Token count is too large: ray-project__ray-3793\n",
      "Token count is too large: pandas-dev__pandas-35966\n",
      "Token count is too large: ray-project__ray-836\n",
      "Token count is too large: celery__celery-5631\n",
      "Token count is too large: apache__airflow-9740\n",
      "Token count is too large: apache__airflow-16491\n",
      "Token count is too large: conan-io__conan-11123\n",
      "Token count is too large: PrefectHQ__prefect-793\n",
      "Token count is too large: pyca__cryptography-8617\n",
      "Token count is too large: apache__airflow-15112\n",
      "Token count is too large: mesonbuild__meson-7527\n",
      "Token count is too large: ytdl-org__youtube-dl-4389\n",
      "Token count is too large: numpy__numpy-14536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 99 examples [00:06, 12.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6438\n",
      "Token count is too large: ipython__ipython-3484\n",
      "Token count is too large: conan-io__conan-5864\n",
      "Token count is too large: docker__compose-1261\n",
      "Token count is too large: huggingface__transformers-7767\n",
      "There was an error processing\n",
      "Token count is too large: pandas-dev__pandas-18707\n",
      "Token count is too large: pandas-dev__pandas-24277\n",
      "Token count is too large: pandas-dev__pandas-37390\n",
      "Token count is too large: conda__conda-6436\n",
      "Token count is too large: scipy__scipy-4425\n",
      "Token count is too large: PrefectHQ__prefect-1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 106 examples [00:06, 18.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-7157\n",
      "Token count is too large: ray-project__ray-3661\n",
      "Token count is too large: mesonbuild__meson-779\n",
      "Token count is too large: pantsbuild__pants-16922\n",
      "Token count is too large: ipython__ipython-5924\n",
      "Token count is too large: numpy__numpy-13648\n",
      "Token count is too large: apache__airflow-21006\n",
      "Token count is too large: numpy__numpy-21566\n",
      "Token count is too large: pandas-dev__pandas-37787\n",
      "Token count is too large: huggingface__transformers-11962\n",
      "Token count is too large: Qiskit__qiskit-858\n",
      "Token count is too large: pandas-dev__pandas-22654\n",
      "Token count is too large: conda__conda-6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 112 examples [00:07, 16.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-18163\n",
      "Token count is too large: pandas-dev__pandas-36179\n",
      "Token count is too large: Lightning-AI__lightning-1488\n",
      "Token count is too large: PrefectHQ__prefect-177\n",
      "Token count is too large: PrefectHQ__prefect-2492\n",
      "Token count is too large: googleapis__google-cloud-python-6453\n",
      "Token count is too large: apache__airflow-12336\n",
      "Token count is too large: numpy__numpy-12358\n",
      "Token count is too large: pyca__cryptography-7034\n",
      "Token count is too large: google__jax-3328\n",
      "Token count is too large: conan-io__conan-8218\n",
      "Token count is too large: jupyterlab__jupyterlab-7361\n",
      "Token count is too large: numpy__numpy-10539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 118 examples [00:07, 21.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4470\n",
      "Token count is too large: wagtail__wagtail-7922\n",
      "Token count is too large: pandas-dev__pandas-16090\n",
      "Token count is too large: conan-io__conan-5583\n",
      "Token count is too large: pypa__pip-443\n",
      "Token count is too large: Qiskit__qiskit-5458\n",
      "Token count is too large: apache__airflow-17003\n",
      "Token count is too large: pandas-dev__pandas-25967\n",
      "Token count is too large: ytdl-org__youtube-dl-21077\n",
      "Token count is too large: Lightning-AI__lightning-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 123 examples [00:07, 22.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38021\n",
      "Token count is too large: mesonbuild__meson-7716\n",
      "Token count is too large: mesonbuild__meson-5523\n",
      "Token count is too large: conda__conda-5054\n",
      "Token count is too large: docker__compose-4213\n",
      "Token count is too large: pyca__cryptography-1398\n",
      "Token count is too large: pandas-dev__pandas-14428\n",
      "Token count is too large: gitpython-developers__GitPython-918\n",
      "Token count is too large: google__jax-3152\n",
      "Token count is too large: Qiskit__qiskit-5537\n",
      "Token count is too large: pandas-dev__pandas-11257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 130 examples [00:07, 22.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4616\n",
      "Token count is too large: google__jax-2712\n",
      "Token count is too large: pandas-dev__pandas-5375\n",
      "Token count is too large: wagtail__wagtail-1133\n",
      "Token count is too large: pypa__pip-2796\n",
      "Token count is too large: conan-io__conan-6048\n",
      "Token count is too large: pypa__pip-7285\n",
      "Token count is too large: conda__conda-9284\n",
      "Token count is too large: googleapis__google-cloud-python-3177\n",
      "Token count is too large: mesonbuild__meson-1443\n",
      "Token count is too large: wagtail__wagtail-1412\n",
      "Token count is too large: huggingface__transformers-500\n",
      "Token count is too large: conan-io__conan-4308\n",
      "Token count is too large: pandas-dev__pandas-21957\n",
      "Token count is too large: googleapis__google-cloud-python-11288\n",
      "Token count is too large: pandas-dev__pandas-17482\n",
      "Token count is too large: pantsbuild__pants-4661\n",
      "Token count is too large: pypa__pip-7095\n",
      "Token count is too large: Lightning-AI__lightning-782\n",
      "Token count is too large: pandas-dev__pandas-18876\n",
      "Token count is too large: ytdl-org__youtube-dl-18776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 135 examples [00:08, 14.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37639\n",
      "Token count is too large: conan-io__conan-7051\n",
      "Token count is too large: pandas-dev__pandas-36118\n",
      "Token count is too large: numpy__numpy-21027\n",
      "Token count is too large: pandas-dev__pandas-7375\n",
      "Token count is too large: ytdl-org__youtube-dl-30664\n",
      "Token count is too large: ray-project__ray-7111\n",
      "Token count is too large: numpy__numpy-3059\n",
      "Token count is too large: PrefectHQ__prefect-1510\n",
      "Token count is too large: numpy__numpy-7414\n",
      "Token count is too large: conan-io__conan-5786\n",
      "Token count is too large: pandas-dev__pandas-24759\n",
      "Token count is too large: pandas-dev__pandas-17632\n",
      "Token count is too large: huggingface__transformers-4385\n",
      "Token count is too large: conan-io__conan-2845\n",
      "Token count is too large: pandas-dev__pandas-23517\n",
      "Token count is too large: wagtail__wagtail-10355\n",
      "Token count is too large: pandas-dev__pandas-17465\n",
      "Token count is too large: mesonbuild__meson-8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 137 examples [00:08, 10.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36478\n",
      "Token count is too large: wagtail__wagtail-1606\n",
      "Token count is too large: numpy__numpy-24077\n",
      "Token count is too large: huggingface__transformers-17356\n",
      "Token count is too large: pandas-dev__pandas-7560\n",
      "Token count is too large: pantsbuild__pants-6619\n",
      "Token count is too large: pandas-dev__pandas-35590\n",
      "Token count is too large: huggingface__transformers-11620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 144 examples [00:09, 14.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-3404\n",
      "Token count is too large: pandas-dev__pandas-20992\n",
      "Token count is too large: huggingface__transformers-4450\n",
      "Token count is too large: pandas-dev__pandas-21523\n",
      "Token count is too large: pandas-dev__pandas-28289\n",
      "Token count is too large: pantsbuild__pants-13559\n",
      "Token count is too large: tiangolo__fastapi-1549\n",
      "Token count is too large: Qiskit__qiskit-6522\n",
      "Token count is too large: conda__conda-8289\n",
      "Token count is too large: pantsbuild__pants-16931\n",
      "Token count is too large: Qiskit__qiskit-4584\n",
      "Token count is too large: google__jax-374\n",
      "Token count is too large: numpy__numpy-22421\n",
      "Token count is too large: jupyterlab__jupyterlab-8806\n",
      "Token count is too large: google__jax-2257\n",
      "Token count is too large: apache__airflow-27323\n",
      "Token count is too large: ipython__ipython-7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 148 examples [00:09, 16.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19191\n",
      "Token count is too large: conan-io__conan-8355\n",
      "Token count is too large: Lightning-AI__lightning-278\n",
      "Token count is too large: pandas-dev__pandas-36452\n",
      "Token count is too large: huggingface__transformers-17318\n",
      "Token count is too large: pandas-dev__pandas-8183\n",
      "Token count is too large: pandas-dev__pandas-8966\n",
      "Token count is too large: ipython__ipython-4285\n",
      "Token count is too large: ray-project__ray-9227\n",
      "Token count is too large: pandas-dev__pandas-10609\n",
      "Token count is too large: conda__conda-7415\n",
      "Token count is too large: pandas-dev__pandas-8407\n",
      "Token count is too large: pandas-dev__pandas-38919\n",
      "Token count is too large: celery__celery-6774\n",
      "Token count is too large: mesonbuild__meson-3523\n",
      "Token count is too large: mesonbuild__meson-1483\n",
      "Token count is too large: huggingface__transformers-1966\n",
      "Token count is too large: pandas-dev__pandas-21259\n",
      "Token count is too large: conda__conda-2685\n",
      "Token count is too large: pandas-dev__pandas-17789\n",
      "Token count is too large: Qiskit__qiskit-8447\n",
      "Token count is too large: pandas-dev__pandas-20475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 156 examples [00:09, 17.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34594\n",
      "Token count is too large: ray-project__ray-5844\n",
      "Token count is too large: gitpython-developers__GitPython-1263\n",
      "Token count is too large: numpy__numpy-20446\n",
      "Token count is too large: Qiskit__qiskit-5074\n",
      "Token count is too large: pypa__pip-7643\n",
      "Token count is too large: googleapis__google-cloud-python-5890\n",
      "Token count is too large: pandas-dev__pandas-31278\n",
      "Token count is too large: googleapis__google-cloud-python-11461\n",
      "Token count is too large: mesonbuild__meson-1650\n",
      "Token count is too large: Qiskit__qiskit-1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 160 examples [00:10, 17.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-14108\n",
      "Token count is too large: huggingface__transformers-4773\n",
      "Token count is too large: huggingface__transformers-4916\n",
      "Token count is too large: pyca__cryptography-3658\n",
      "Token count is too large: pandas-dev__pandas-36139\n",
      "Token count is too large: conda__conda-6370\n",
      "Token count is too large: conda__conda-7515\n",
      "Token count is too large: pandas-dev__pandas-23755\n",
      "Token count is too large: docker__compose-1714\n",
      "Token count is too large: pypa__pip-5836\n",
      "Token count is too large: pandas-dev__pandas-22380\n",
      "Token count is too large: pypa__pip-1201\n",
      "Token count is too large: pandas-dev__pandas-4969\n",
      "Token count is too large: pandas-dev__pandas-26300\n",
      "Token count is too large: pandas-dev__pandas-4154\n",
      "Token count is too large: googleapis__google-cloud-python-2730\n",
      "Token count is too large: Qiskit__qiskit-8640\n",
      "Token count is too large: numpy__numpy-17748\n",
      "Token count is too large: googleapis__google-cloud-python-11326\n",
      "Token count is too large: pandas-dev__pandas-4184\n",
      "Token count is too large: pandas-dev__pandas-4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 166 examples [00:10, 18.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8434\n",
      "Token count is too large: numpy__numpy-13397\n",
      "Token count is too large: pandas-dev__pandas-36266\n",
      "Token count is too large: pandas-dev__pandas-34595\n",
      "Token count is too large: google__jax-1269\n",
      "Token count is too large: huggingface__transformers-15835\n",
      "Token count is too large: conan-io__conan-4714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 171 examples [00:10, 19.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-1932\n",
      "Token count is too large: DataDog__integrations-core-1019\n",
      "Token count is too large: numpy__numpy-317\n",
      "Token count is too large: pandas-dev__pandas-23963\n",
      "Token count is too large: Qiskit__qiskit-3069\n",
      "Token count is too large: docker__compose-1658\n",
      "Token count is too large: pandas-dev__pandas-31036\n",
      "Token count is too large: pandas-dev__pandas-17940\n",
      "Token count is too large: docker__compose-2142\n",
      "Token count is too large: pandas-dev__pandas-13761\n",
      "Token count is too large: explosion__spaCy-2478\n",
      "Token count is too large: wagtail__wagtail-1395\n",
      "Token count is too large: celery__celery-3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 178 examples [00:10, 23.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-1334\n",
      "Token count is too large: celery__celery-5297\n",
      "Token count is too large: conda__conda-5316\n",
      "Token count is too large: huggingface__transformers-9554\n",
      "Token count is too large: Qiskit__qiskit-2531\n",
      "Token count is too large: ipython__ipython-8620\n",
      "Token count is too large: pandas-dev__pandas-28945\n",
      "Token count is too large: pandas-dev__pandas-23524\n",
      "Token count is too large: pandas-dev__pandas-4585\n",
      "Token count is too large: conda__conda-7289\n",
      "Token count is too large: pypa__pip-5623\n",
      "Token count is too large: Qiskit__qiskit-2928\n",
      "Token count is too large: google__jax-337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 183 examples [00:11, 20.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-3196\n",
      "Token count is too large: mesonbuild__meson-52\n",
      "Token count is too large: ipython__ipython-2218\n",
      "Token count is too large: pandas-dev__pandas-31820\n",
      "Token count is too large: PrefectHQ__prefect-2832\n",
      "Token count is too large: pandas-dev__pandas-4459\n",
      "Token count is too large: google__jax-452\n",
      "Token count is too large: pandas-dev__pandas-15443\n",
      "Token count is too large: pandas-dev__pandas-5187\n",
      "Token count is too large: wagtail__wagtail-9194\n",
      "Token count is too large: pandas-dev__pandas-31071\n",
      "Token count is too large: pandas-dev__pandas-36691\n",
      "Token count is too large: pandas-dev__pandas-30638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 186 examples [00:11, 17.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27304\n",
      "Token count is too large: huggingface__transformers-18280\n",
      "Token count is too large: mesonbuild__meson-4666\n",
      "Token count is too large: pandas-dev__pandas-26078\n",
      "Token count is too large: googleapis__google-cloud-python-5594\n",
      "Token count is too large: pandas-dev__pandas-33250\n",
      "Token count is too large: Lightning-AI__lightning-2055\n",
      "Token count is too large: pandas-dev__pandas-27291\n",
      "Token count is too large: Lightning-AI__lightning-1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 191 examples [00:11, 19.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37180\n",
      "Token count is too large: pandas-dev__pandas-33291\n",
      "Token count is too large: docker__compose-3922\n",
      "Token count is too large: numpy__numpy-23392\n",
      "Token count is too large: pandas-dev__pandas-20702\n",
      "Token count is too large: pantsbuild__pants-6789\n",
      "Token count is too large: mesonbuild__meson-11063\n",
      "Token count is too large: mesonbuild__meson-1669\n",
      "Token count is too large: numpy__numpy-18146\n",
      "Token count is too large: Qiskit__qiskit-4808\n",
      "Token count is too large: pandas-dev__pandas-8278\n",
      "Token count is too large: huggingface__transformers-19481\n",
      "Token count is too large: ytdl-org__youtube-dl-718\n",
      "Token count is too large: pandas-dev__pandas-35588\n",
      "Token count is too large: pandas-dev__pandas-7966\n",
      "Token count is too large: pypa__pip-8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 197 examples [00:12, 17.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6838\n",
      "Token count is too large: conda__conda-12670\n",
      "Token count is too large: numpy__numpy-20182\n",
      "Token count is too large: mesonbuild__meson-7978\n",
      "Token count is too large: mesonbuild__meson-7475\n",
      "Token count is too large: google__jax-834\n",
      "Token count is too large: googleapis__google-cloud-python-5245\n",
      "Token count is too large: pandas-dev__pandas-6004\n",
      "Token count is too large: apache__airflow-20902\n",
      "Token count is too large: pandas-dev__pandas-5222\n",
      "Token count is too large: huggingface__transformers-12548\n",
      "Token count is too large: conan-io__conan-3239\n",
      "Token count is too large: numpy__numpy-4406\n",
      "Token count is too large: googleapis__google-cloud-python-576\n",
      "Token count is too large: wagtail__wagtail-10189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 200 examples [00:12, 14.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20681\n",
      "Token count is too large: Lightning-AI__lightning-3145\n",
      "Token count is too large: Qiskit__qiskit-3577\n",
      "Token count is too large: conan-io__conan-2933\n",
      "Token count is too large: numpy__numpy-16878\n",
      "Token count is too large: apache__airflow-18804\n",
      "Token count is too large: PrefectHQ__prefect-956\n",
      "Token count is too large: mesonbuild__meson-1024\n",
      "Token count is too large: huggingface__transformers-21398\n",
      "Token count is too large: pandas-dev__pandas-15185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 206 examples [00:12, 16.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6281\n",
      "Token count is too large: pandas-dev__pandas-11330\n",
      "Token count is too large: google__jax-741\n",
      "Token count is too large: pandas-dev__pandas-6954\n",
      "Token count is too large: huggingface__transformers-10027\n",
      "Token count is too large: Qiskit__qiskit-3668\n",
      "Token count is too large: ipython__ipython-5376\n",
      "Token count is too large: conan-io__conan-4656\n",
      "Token count is too large: jupyterlab__jupyterlab-7079\n",
      "Token count is too large: pandas-dev__pandas-22963\n",
      "Token count is too large: conan-io__conan-5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 209 examples [00:12, 18.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-3662\n",
      "Token count is too large: docker__compose-246\n",
      "Token count is too large: pandas-dev__pandas-16157\n",
      "Token count is too large: ipython__ipython-6536\n",
      "Token count is too large: pandas-dev__pandas-11937\n",
      "Token count is too large: mesonbuild__meson-7116\n",
      "Token count is too large: PrefectHQ__prefect-2599\n",
      "Token count is too large: scipy__scipy-3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 215 examples [00:12, 23.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-1925\n",
      "Token count is too large: docker__compose-2020\n",
      "Token count is too large: google__jax-443\n",
      "Token count is too large: pandas-dev__pandas-11146\n",
      "Token count is too large: Lightning-AI__lightning-2787\n",
      "Token count is too large: huggingface__transformers-24238\n",
      "Token count is too large: pandas-dev__pandas-7564\n",
      "Token count is too large: pandas-dev__pandas-30560\n",
      "Token count is too large: pandas-dev__pandas-39796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 218 examples [00:13, 17.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6184\n",
      "Token count is too large: pandas-dev__pandas-28970\n",
      "Token count is too large: ytdl-org__youtube-dl-7069\n",
      "Token count is too large: pandas-dev__pandas-5157\n",
      "Token count is too large: huggingface__transformers-22938\n",
      "Token count is too large: pandas-dev__pandas-7108\n",
      "Token count is too large: mesonbuild__meson-2630\n",
      "Token count is too large: huggingface__transformers-17294\n",
      "Token count is too large: mesonbuild__meson-8742\n",
      "Token count is too large: numpy__numpy-5500\n",
      "Token count is too large: conda__conda-4361\n",
      "Token count is too large: Lightning-AI__lightning-155\n",
      "Token count is too large: numpy__numpy-12265\n",
      "Token count is too large: wagtail__wagtail-964\n",
      "Token count is too large: huggingface__transformers-14636\n",
      "Token count is too large: pyca__cryptography-7697\n",
      "Token count is too large: apache__airflow-33673\n",
      "Token count is too large: pandas-dev__pandas-10188\n",
      "Token count is too large: pandas-dev__pandas-11371\n",
      "Token count is too large: PrefectHQ__prefect-2885\n",
      "Token count is too large: pandas-dev__pandas-5529\n",
      "Token count is too large: Qiskit__qiskit-8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 223 examples [00:13, 13.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11654\n",
      "Token count is too large: pandas-dev__pandas-6408\n",
      "Token count is too large: tensorflow__models-4554\n",
      "Token count is too large: pantsbuild__pants-11661\n",
      "Token count is too large: pandas-dev__pandas-15934\n",
      "Token count is too large: tiangolo__fastapi-918\n",
      "Token count is too large: mesonbuild__meson-7083\n",
      "Token count is too large: ipython__ipython-1332\n",
      "Token count is too large: pandas-dev__pandas-22479\n",
      "Token count is too large: pypa__pip-5664\n",
      "Token count is too large: huggingface__transformers-7054\n",
      "Token count is too large: PrefectHQ__prefect-1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 231 examples [00:14, 16.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13225\n",
      "Token count is too large: pandas-dev__pandas-27682\n",
      "Token count is too large: conan-io__conan-4546\n",
      "Token count is too large: tensorflow__models-7330\n",
      "Token count is too large: pandas-dev__pandas-4791\n",
      "Token count is too large: pandas-dev__pandas-38546\n",
      "Token count is too large: ipython__ipython-4270\n",
      "Token count is too large: Lightning-AI__lightning-3163\n",
      "Token count is too large: Qiskit__qiskit-6322\n",
      "Token count is too large: pantsbuild__pants-5040\n",
      "Token count is too large: Qiskit__qiskit-8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 235 examples [00:14, 18.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18629\n",
      "Token count is too large: Lightning-AI__lightning-409\n",
      "Token count is too large: docker__compose-6390\n",
      "Token count is too large: Qiskit__qiskit-7970\n",
      "Token count is too large: pantsbuild__pants-18940\n",
      "Token count is too large: huggingface__transformers-20064\n",
      "Token count is too large: pantsbuild__pants-16155\n",
      "Token count is too large: pandas-dev__pandas-27511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 238 examples [00:14, 17.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26419\n",
      "Token count is too large: ray-project__ray-9547\n",
      "Token count is too large: jupyterlab__jupyterlab-1954\n",
      "Token count is too large: pypa__pip-4047\n",
      "Token count is too large: docker__compose-6973\n",
      "Token count is too large: PrefectHQ__prefect-2546\n",
      "Token count is too large: pandas-dev__pandas-39726\n",
      "Token count is too large: conan-io__conan-6653\n",
      "Token count is too large: Qiskit__qiskit-4263\n",
      "Token count is too large: Lightning-AI__lightning-2986\n",
      "Token count is too large: huggingface__transformers-21752\n",
      "Token count is too large: Qiskit__qiskit-6199\n",
      "Token count is too large: ipython__ipython-2904\n",
      "Token count is too large: pypa__pip-9708\n",
      "Token count is too large: googleapis__google-cloud-python-11352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 244 examples [00:15, 14.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20844\n",
      "Token count is too large: Qiskit__qiskit-3211\n",
      "Token count is too large: pandas-dev__pandas-20632\n",
      "Token count is too large: conan-io__conan-6720\n",
      "Token count is too large: pandas-dev__pandas-36316\n",
      "Token count is too large: google__jax-1262\n",
      "Token count is too large: pandas-dev__pandas-20677\n",
      "Token count is too large: pandas-dev__pandas-7112\n",
      "Token count is too large: googleapis__google-cloud-python-771\n",
      "Token count is too large: pandas-dev__pandas-6516\n",
      "Token count is too large: pandas-dev__pandas-11796\n",
      "Token count is too large: googleapis__google-cloud-python-3051\n",
      "Token count is too large: pypa__pip-10202\n",
      "Token count is too large: pantsbuild__pants-18165\n",
      "There was an error processing\n",
      "Token count is too large: Lightning-AI__lightning-2960\n",
      "Token count is too large: ytdl-org__youtube-dl-18371\n",
      "Token count is too large: huggingface__transformers-19477\n",
      "Token count is too large: pandas-dev__pandas-17844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 246 examples [00:15, 10.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9546\n",
      "Token count is too large: docker__compose-4528\n",
      "Token count is too large: pandas-dev__pandas-39194\n",
      "Token count is too large: numpy__numpy-7152\n",
      "Token count is too large: pantsbuild__pants-10475\n",
      "Token count is too large: docker__compose-1931\n",
      "Token count is too large: PrefectHQ__prefect-2521\n",
      "Token count is too large: apache__airflow-8775\n",
      "Token count is too large: pandas-dev__pandas-21457\n",
      "Token count is too large: pypa__pip-8483\n",
      "Token count is too large: jupyterlab__jupyterlab-12844\n",
      "Token count is too large: apache__airflow-10317\n",
      "Token count is too large: numpy__numpy-5981\n",
      "Token count is too large: pandas-dev__pandas-34816\n",
      "Token count is too large: pandas-dev__pandas-32548\n",
      "Token count is too large: numpy__numpy-5713\n",
      "Token count is too large: googleapis__google-cloud-python-2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 250 examples [00:15, 10.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3216\n",
      "Token count is too large: numpy__numpy-21654\n",
      "Token count is too large: dagster-io__dagster-8858\n",
      "Token count is too large: googleapis__google-cloud-python-3130\n",
      "Token count is too large: pandas-dev__pandas-8676\n",
      "Token count is too large: pandas-dev__pandas-31729\n",
      "Token count is too large: pandas-dev__pandas-7852\n",
      "Token count is too large: googleapis__google-cloud-python-4199\n",
      "Token count is too large: ipython__ipython-4338\n",
      "Token count is too large: pandas-dev__pandas-18388\n",
      "Token count is too large: huggingface__transformers-8423\n",
      "Token count is too large: ytdl-org__youtube-dl-8372\n",
      "Token count is too large: pantsbuild__pants-10779\n",
      "Token count is too large: docker__compose-5541\n",
      "Token count is too large: conda__conda-6923\n",
      "Token count is too large: ipython__ipython-1502\n",
      "Token count is too large: huggingface__transformers-12359\n",
      "Token count is too large: googleapis__google-cloud-python-930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 254 examples [00:16, 11.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20046\n",
      "Token count is too large: google__jax-692\n",
      "Token count is too large: googleapis__google-cloud-python-3927\n",
      "Token count is too large: pantsbuild__pants-5959\n",
      "Token count is too large: Lightning-AI__lightning-933\n",
      "Token count is too large: pandas-dev__pandas-25667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 256 examples [00:16,  9.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-5686\n",
      "Token count is too large: Lightning-AI__lightning-1441\n",
      "Token count is too large: dagster-io__dagster-6818\n",
      "Token count is too large: huggingface__transformers-14408\n",
      "Token count is too large: Qiskit__qiskit-4017\n",
      "Token count is too large: Qiskit__qiskit-10008\n",
      "Token count is too large: pandas-dev__pandas-14540\n",
      "Token count is too large: docker__compose-6598\n",
      "Token count is too large: pandas-dev__pandas-38443\n",
      "Token count is too large: celery__celery-5154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 258 examples [00:16,  9.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33761\n",
      "Token count is too large: pandas-dev__pandas-21477\n",
      "Token count is too large: pandas-dev__pandas-21224\n",
      "Token count is too large: pantsbuild__pants-17716\n",
      "Token count is too large: docker__compose-2743\n",
      "Token count is too large: pandas-dev__pandas-38567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 262 examples [00:17, 10.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11653\n",
      "Token count is too large: Qiskit__qiskit-3526\n",
      "Token count is too large: Qiskit__qiskit-1278\n",
      "Token count is too large: docker__compose-4565\n",
      "Token count is too large: google__jax-3082\n",
      "Token count is too large: ray-project__ray-6915\n",
      "Token count is too large: Lightning-AI__lightning-3404\n",
      "Token count is too large: mesonbuild__meson-2109\n",
      "Token count is too large: huggingface__transformers-21071\n",
      "Token count is too large: celery__celery-4540\n",
      "Token count is too large: ray-project__ray-8302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 266 examples [00:17, 12.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-10741\n",
      "Token count is too large: pandas-dev__pandas-17822\n",
      "Token count is too large: celery__celery-6103\n",
      "Token count is too large: apache__airflow-15212\n",
      "Token count is too large: pypa__pip-8666\n",
      "Token count is too large: pandas-dev__pandas-5935\n",
      "Token count is too large: pypa__pip-1896\n",
      "Token count is too large: numpy__numpy-14129\n",
      "Token count is too large: mesonbuild__meson-2952\n",
      "Token count is too large: apache__airflow-11529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 271 examples [00:17, 14.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-9722\n",
      "Token count is too large: scipy__scipy-3679\n",
      "Token count is too large: conan-io__conan-133\n",
      "Token count is too large: pandas-dev__pandas-35999\n",
      "Token count is too large: pandas-dev__pandas-27700\n",
      "Token count is too large: googleapis__google-cloud-python-7753\n",
      "Token count is too large: ray-project__ray-5863\n",
      "Token count is too large: pantsbuild__pants-13998\n",
      "Token count is too large: pandas-dev__pandas-15964\n",
      "Token count is too large: googleapis__google-cloud-python-3787\n",
      "Token count is too large: huggingface__transformers-24049\n",
      "Token count is too large: docker__compose-5362\n",
      "Token count is too large: scipy__scipy-2659\n",
      "Token count is too large: huggingface__transformers-3041\n",
      "Token count is too large: pandas-dev__pandas-17628\n",
      "Token count is too large: conan-io__conan-4716\n",
      "Token count is too large: pandas-dev__pandas-10857\n",
      "Token count is too large: pandas-dev__pandas-9936\n",
      "Token count is too large: twisted__twisted-11589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 280 examples [00:17, 19.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3378\n",
      "Token count is too large: pypa__pip-8932\n",
      "Token count is too large: pypa__pip-6236\n",
      "Token count is too large: huggingface__transformers-15482\n",
      "Token count is too large: pyca__cryptography-5072\n",
      "Token count is too large: pandas-dev__pandas-31017\n",
      "Token count is too large: wagtail__wagtail-10501\n",
      "Token count is too large: pantsbuild__pants-16455\n",
      "Token count is too large: pandas-dev__pandas-19908\n",
      "Token count is too large: conda__conda-4651\n",
      "Token count is too large: docker__compose-2392\n",
      "Token count is too large: docker__compose-6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 283 examples [00:18, 17.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-2564\n",
      "Token count is too large: ray-project__ray-541\n",
      "Token count is too large: ytdl-org__youtube-dl-24883\n",
      "Token count is too large: pandas-dev__pandas-10055\n",
      "Token count is too large: Qiskit__qiskit-6027\n",
      "Token count is too large: pandas-dev__pandas-10305\n",
      "Token count is too large: huggingface__transformers-911\n",
      "Token count is too large: pandas-dev__pandas-16220\n",
      "Token count is too large: pandas-dev__pandas-5995\n",
      "Token count is too large: conda__conda-4776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 291 examples [00:18, 18.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24654\n",
      "Token count is too large: twisted__twisted-11825\n",
      "Token count is too large: pandas-dev__pandas-4765\n",
      "Token count is too large: pandas-dev__pandas-33480\n",
      "Token count is too large: huggingface__transformers-13478\n",
      "Token count is too large: pypa__pip-9198\n",
      "Token count is too large: Qiskit__qiskit-3087\n",
      "Token count is too large: googleapis__google-cloud-python-4381\n",
      "Token count is too large: pandas-dev__pandas-19441\n",
      "Token count is too large: pandas-dev__pandas-10110\n",
      "Token count is too large: pandas-dev__pandas-21406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 294 examples [00:19, 13.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1210\n",
      "Token count is too large: Qiskit__qiskit-6803\n",
      "Token count is too large: pandas-dev__pandas-17194\n",
      "Token count is too large: pandas-dev__pandas-24056\n",
      "Token count is too large: pandas-dev__pandas-7086\n",
      "Token count is too large: google__jax-3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 300 examples [00:19, 18.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34943\n",
      "Token count is too large: pantsbuild__pants-18262\n",
      "Token count is too large: pandas-dev__pandas-28151\n",
      "Token count is too large: pandas-dev__pandas-32055\n",
      "Token count is too large: pandas-dev__pandas-29431\n",
      "Token count is too large: googleapis__google-cloud-python-192\n",
      "Token count is too large: mesonbuild__meson-5387\n",
      "Token count is too large: huggingface__transformers-12558\n",
      "Token count is too large: pandas-dev__pandas-39008\n",
      "Token count is too large: ray-project__ray-7434\n",
      "Token count is too large: PrefectHQ__prefect-2409\n",
      "Token count is too large: ytdl-org__youtube-dl-5954\n",
      "Token count is too large: scipy__scipy-4881\n",
      "Token count is too large: huggingface__transformers-15702\n",
      "Token count is too large: pandas-dev__pandas-17469\n",
      "Token count is too large: pyca__cryptography-7532\n",
      "Token count is too large: huggingface__transformers-25239\n",
      "Token count is too large: huggingface__transformers-15527\n",
      "Token count is too large: docker__compose-3137\n",
      "Token count is too large: Lightning-AI__lightning-3319\n",
      "Token count is too large: conan-io__conan-2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 303 examples [00:19, 14.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17402\n",
      "Token count is too large: docker__compose-7965\n",
      "Token count is too large: pandas-dev__pandas-24754\n",
      "Token count is too large: conan-io__conan-4249\n",
      "Token count is too large: pandas-dev__pandas-3013\n",
      "Token count is too large: huggingface__transformers-24510\n",
      "Token count is too large: googleapis__google-cloud-python-5870\n",
      "Token count is too large: googleapis__google-cloud-python-10196\n",
      "Token count is too large: huggingface__transformers-17092\n",
      "Token count is too large: conda__conda-5314\n",
      "Token count is too large: PrefectHQ__prefect-1375\n",
      "Token count is too large: ipython__ipython-12150\n",
      "Token count is too large: pandas-dev__pandas-15535\n",
      "Token count is too large: google__jax-1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 312 examples [00:20, 14.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11323\n",
      "Token count is too large: pandas-dev__pandas-18412\n",
      "Token count is too large: pantsbuild__pants-15367\n",
      "Token count is too large: Qiskit__qiskit-5851\n",
      "Token count is too large: jupyterlab__jupyterlab-12852\n",
      "Token count is too large: mesonbuild__meson-5128\n",
      "Token count is too large: huggingface__transformers-19880\n",
      "Token count is too large: mesonbuild__meson-75\n",
      "Token count is too large: Qiskit__qiskit-5016\n",
      "Token count is too large: docker__compose-7071\n",
      "Token count is too large: pandas-dev__pandas-19675\n",
      "Token count is too large: conda__conda-6524\n",
      "Token count is too large: PrefectHQ__prefect-779\n",
      "Token count is too large: celery__celery-5773\n",
      "Token count is too large: pandas-dev__pandas-33540\n",
      "Token count is too large: pypa__pip-4051\n",
      "Token count is too large: pandas-dev__pandas-17897\n",
      "Token count is too large: pypa__pip-5773\n",
      "Token count is too large: Qiskit__qiskit-8937\n",
      "Token count is too large: pandas-dev__pandas-5802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 318 examples [00:20, 16.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9566\n",
      "Token count is too large: PrefectHQ__prefect-907\n",
      "Token count is too large: celery__celery-5942\n",
      "Token count is too large: ray-project__ray-10513\n",
      "Token count is too large: PrefectHQ__prefect-1005\n",
      "Token count is too large: mesonbuild__meson-5234\n",
      "Token count is too large: google__jax-1958\n",
      "Token count is too large: ipython__ipython-10561\n",
      "Token count is too large: conan-io__conan-3505\n",
      "Token count is too large: pandas-dev__pandas-37834\n",
      "Token count is too large: celery__celery-5997\n",
      "Token count is too large: pandas-dev__pandas-38536\n",
      "Token count is too large: pandas-dev__pandas-18645\n",
      "Token count is too large: pandas-dev__pandas-37263\n",
      "Token count is too large: Qiskit__qiskit-2265\n",
      "Token count is too large: pandas-dev__pandas-30377\n",
      "Token count is too large: pypa__pip-2291\n",
      "Token count is too large: pyca__cryptography-5594\n",
      "Token count is too large: ipython__ipython-9596\n",
      "Token count is too large: Qiskit__qiskit-5836\n",
      "Token count is too large: mesonbuild__meson-6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 323 examples [00:21, 12.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: gitpython-developers__GitPython-1124\n",
      "Token count is too large: pandas-dev__pandas-5564\n",
      "Token count is too large: conda__conda-7131\n",
      "Token count is too large: conan-io__conan-3182\n",
      "Token count is too large: conda__conda-5580\n",
      "Token count is too large: pandas-dev__pandas-6659\n",
      "Token count is too large: scipy__scipy-4415\n",
      "Token count is too large: pantsbuild__pants-4333\n",
      "Token count is too large: pandas-dev__pandas-22539\n",
      "Token count is too large: Qiskit__qiskit-3057\n",
      "Token count is too large: mesonbuild__meson-2819\n",
      "Token count is too large: mesonbuild__meson-6356\n",
      "Token count is too large: pandas-dev__pandas-22261\n",
      "Token count is too large: pandas-dev__pandas-8331\n",
      "Token count is too large: pandas-dev__pandas-23866\n",
      "Token count is too large: pandas-dev__pandas-3900\n",
      "Token count is too large: ipython__ipython-3744\n",
      "Token count is too large: pandas-dev__pandas-4417\n",
      "Token count is too large: ipython__ipython-11718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 328 examples [00:21, 11.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-17719\n",
      "Token count is too large: conan-io__conan-4131\n",
      "Token count is too large: pandas-dev__pandas-17971\n",
      "Token count is too large: huggingface__transformers-25427\n",
      "Token count is too large: Lightning-AI__lightning-1577\n",
      "Token count is too large: googleapis__google-cloud-python-6176\n",
      "Token count is too large: pypa__pip-10083\n",
      "Token count is too large: pyca__cryptography-7292\n",
      "Token count is too large: googleapis__google-cloud-python-2313\n",
      "Token count is too large: Qiskit__qiskit-8927\n",
      "Token count is too large: huggingface__transformers-17188\n",
      "Token count is too large: pandas-dev__pandas-4713\n",
      "Token count is too large: Qiskit__qiskit-10287\n",
      "Token count is too large: pandas-dev__pandas-18889\n",
      "Token count is too large: pandas-dev__pandas-32510\n",
      "Token count is too large: numpy__numpy-16835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 332 examples [00:21, 12.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8417\n",
      "Token count is too large: pantsbuild__pants-5535\n",
      "Token count is too large: pandas-dev__pandas-8003\n",
      "Token count is too large: pandas-dev__pandas-38560\n",
      "Token count is too large: pyca__cryptography-3609\n",
      "Token count is too large: pantsbuild__pants-17416\n",
      "Token count is too large: ytdl-org__youtube-dl-29810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 335 examples [00:22, 12.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11173\n",
      "Token count is too large: mesonbuild__meson-4259\n",
      "Token count is too large: pandas-dev__pandas-7322\n",
      "Token count is too large: pandas-dev__pandas-34976\n",
      "Token count is too large: Qiskit__qiskit-1915\n",
      "Token count is too large: numpy__numpy-10392\n",
      "Token count is too large: Qiskit__qiskit-2061\n",
      "Token count is too large: huggingface__transformers-14071\n",
      "Token count is too large: pandas-dev__pandas-36934\n",
      "Token count is too large: ytdl-org__youtube-dl-17097\n",
      "Token count is too large: googleapis__google-cloud-python-1787\n",
      "Token count is too large: pandas-dev__pandas-27631\n",
      "Token count is too large: huggingface__transformers-11075\n",
      "Token count is too large: huggingface__transformers-6686\n",
      "Token count is too large: huggingface__transformers-9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 339 examples [00:22,  9.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5439\n",
      "Token count is too large: mesonbuild__meson-9452\n",
      "Token count is too large: pandas-dev__pandas-38173\n",
      "Token count is too large: pandas-dev__pandas-5554\n",
      "Token count is too large: celery__celery-5373\n",
      "Token count is too large: ytdl-org__youtube-dl-21536\n",
      "Token count is too large: apache__airflow-19907\n",
      "Token count is too large: pyca__cryptography-6603\n",
      "Token count is too large: mesonbuild__meson-9162\n",
      "Token count is too large: Qiskit__qiskit-2573\n",
      "Token count is too large: huggingface__transformers-9038\n",
      "Token count is too large: apache__airflow-963\n",
      "Token count is too large: ray-project__ray-8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 341 examples [00:22,  9.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11168\n",
      "Token count is too large: pandas-dev__pandas-31053\n",
      "Token count is too large: huggingface__transformers-13939\n",
      "Token count is too large: apache__airflow-13073\n",
      "Token count is too large: celery__celery-4402\n",
      "Token count is too large: pandas-dev__pandas-30151\n",
      "Token count is too large: pandas-dev__pandas-34737\n",
      "Token count is too large: Qiskit__qiskit-5492\n",
      "Token count is too large: pantsbuild__pants-5521\n",
      "Token count is too large: numpy__numpy-10031\n",
      "Token count is too large: mesonbuild__meson-6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 345 examples [00:23, 11.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8275\n",
      "Token count is too large: docker__compose-4469\n",
      "Token count is too large: apache__airflow-18742\n",
      "Token count is too large: pandas-dev__pandas-14101\n",
      "Token count is too large: pandas-dev__pandas-25246\n",
      "Token count is too large: Qiskit__qiskit-3683\n",
      "Token count is too large: open-mmlab__mmdetection-9358\n",
      "There was an error processing\n",
      "Token count is too large: mesonbuild__meson-7108\n",
      "Token count is too large: celery__celery-5232\n",
      "Token count is too large: pandas-dev__pandas-37874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 348 examples [00:23, 11.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12803\n",
      "Token count is too large: conda__conda-6775\n",
      "Token count is too large: apache__airflow-1948\n",
      "Token count is too large: googleapis__google-cloud-python-352\n",
      "Token count is too large: ray-project__ray-6258\n",
      "Token count is too large: apache__airflow-27898\n",
      "Token count is too large: docker__compose-3980\n",
      "Token count is too large: huggingface__transformers-23897\n",
      "Token count is too large: pandas-dev__pandas-5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 352 examples [00:23, 14.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16126\n",
      "Token count is too large: googleapis__google-cloud-python-6577\n",
      "Token count is too large: huggingface__transformers-7075\n",
      "Token count is too large: numpy__numpy-9952\n",
      "Token count is too large: mesonbuild__meson-1516\n",
      "Token count is too large: mesonbuild__meson-7791\n",
      "Token count is too large: pandas-dev__pandas-16610\n",
      "Token count is too large: Lightning-AI__lightning-1353\n",
      "Token count is too large: numpy__numpy-13564\n",
      "Token count is too large: pandas-dev__pandas-5600\n",
      "Token count is too large: googleapis__google-cloud-python-9995\n",
      "Token count is too large: huggingface__transformers-7340\n",
      "Token count is too large: pantsbuild__pants-15408\n",
      "Token count is too large: numpy__numpy-21722\n",
      "Token count is too large: numpy__numpy-13218\n",
      "Token count is too large: docker__compose-4930\n",
      "Token count is too large: google__jax-1015\n",
      "Token count is too large: pandas-dev__pandas-27341\n",
      "Token count is too large: Qiskit__qiskit-1314\n",
      "Token count is too large: numpy__numpy-87\n",
      "Token count is too large: celery__celery-5910\n",
      "Token count is too large: scipy__scipy-4675\n",
      "Token count is too large: conan-io__conan-2404\n",
      "Token count is too large: pyca__cryptography-4736\n",
      "Token count is too large: conda__conda-5733\n",
      "Token count is too large: pandas-dev__pandas-4748\n",
      "Token count is too large: scipy__scipy-2773\n",
      "Token count is too large: Qiskit__qiskit-2088\n",
      "Token count is too large: ytdl-org__youtube-dl-31275\n",
      "Token count is too large: googleapis__google-cloud-python-3647\n",
      "Token count is too large: pandas-dev__pandas-12013\n",
      "Token count is too large: pandas-dev__pandas-18937\n",
      "Token count is too large: pandas-dev__pandas-20474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 354 examples [00:24,  8.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37568\n",
      "Token count is too large: pandas-dev__pandas-35078\n",
      "Token count is too large: googleapis__google-cloud-python-6633\n",
      "Token count is too large: apache__airflow-28008\n",
      "Token count is too large: huggingface__transformers-11248\n",
      "Token count is too large: PrefectHQ__prefect-1442\n",
      "Token count is too large: pandas-dev__pandas-28933\n",
      "Token count is too large: pypa__pip-2270\n",
      "Token count is too large: Qiskit__qiskit-9762\n",
      "Token count is too large: apache__airflow-21155\n",
      "Token count is too large: Qiskit__qiskit-948\n",
      "Token count is too large: pandas-dev__pandas-16563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 358 examples [00:24,  9.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20705\n",
      "Token count is too large: docker__compose-6535\n",
      "Token count is too large: ray-project__ray-7238\n",
      "Token count is too large: huggingface__transformers-21869\n",
      "Token count is too large: pandas-dev__pandas-38146\n",
      "Token count is too large: huggingface__transformers-5082\n",
      "Token count is too large: google__jax-179\n",
      "Token count is too large: pandas-dev__pandas-21261\n",
      "Token count is too large: pandas-dev__pandas-20893\n",
      "Token count is too large: pantsbuild__pants-12023\n",
      "Token count is too large: docker__compose-7294\n",
      "Token count is too large: pandas-dev__pandas-6380\n",
      "Token count is too large: pandas-dev__pandas-38426\n",
      "Token count is too large: numpy__numpy-5886\n",
      "Token count is too large: pandas-dev__pandas-20782\n",
      "Token count is too large: numpy__numpy-10588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 361 examples [00:24,  9.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23592\n",
      "Token count is too large: pandas-dev__pandas-18232\n",
      "Token count is too large: numpy__numpy-5455\n",
      "Token count is too large: googleapis__google-cloud-python-8980\n",
      "Token count is too large: numpy__numpy-3120\n",
      "Token count is too large: mesonbuild__meson-3322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 364 examples [00:25,  9.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17316\n",
      "Token count is too large: pypa__pip-1750\n",
      "Token count is too large: pandas-dev__pandas-3722\n",
      "Token count is too large: celery__celery-3903\n",
      "Token count is too large: pandas-dev__pandas-5417\n",
      "Token count is too large: pandas-dev__pandas-20404\n",
      "Token count is too large: conda__conda-5221\n",
      "Token count is too large: celery__celery-4545\n",
      "Token count is too large: huggingface__transformers-8633\n",
      "Token count is too large: pandas-dev__pandas-19054\n",
      "Token count is too large: ytdl-org__youtube-dl-353\n",
      "Token count is too large: pandas-dev__pandas-18269\n",
      "Token count is too large: huggingface__transformers-21008\n",
      "Token count is too large: apache__airflow-9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 368 examples [00:25,  9.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2216\n",
      "Token count is too large: numpy__numpy-11849\n",
      "Token count is too large: googleapis__google-cloud-python-6655\n",
      "Token count is too large: pandas-dev__pandas-16060\n",
      "Token count is too large: Qiskit__qiskit-2533\n",
      "Token count is too large: pandas-dev__pandas-37657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 371 examples [00:25,  9.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19239\n",
      "Token count is too large: apache__airflow-15843\n",
      "Token count is too large: pandas-dev__pandas-20510\n",
      "Token count is too large: PrefectHQ__prefect-2608\n",
      "Token count is too large: pantsbuild__pants-12392\n",
      "Token count is too large: pandas-dev__pandas-38293\n",
      "Token count is too large: Qiskit__qiskit-9316\n",
      "Token count is too large: huggingface__transformers-22440\n",
      "Token count is too large: twisted__twisted-11734\n",
      "Token count is too large: pandas-dev__pandas-19943\n",
      "Token count is too large: huggingface__transformers-22857\n",
      "Token count is too large: numpy__numpy-12257\n",
      "Token count is too large: pandas-dev__pandas-31477\n",
      "Token count is too large: pandas-dev__pandas-17343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 381 examples [00:26, 17.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6581\n",
      "Token count is too large: PrefectHQ__prefect-2570\n",
      "Token count is too large: pandas-dev__pandas-27921\n",
      "Token count is too large: PrefectHQ__prefect-382\n",
      "Token count is too large: jupyterlab__jupyterlab-9568\n",
      "Token count is too large: conda__conda-8053\n",
      "Token count is too large: PrefectHQ__prefect-1437\n",
      "Token count is too large: ytdl-org__youtube-dl-23199\n",
      "Token count is too large: conda__conda-10638\n",
      "Token count is too large: numpy__numpy-9332\n",
      "Token count is too large: googleapis__google-cloud-python-7444\n",
      "Token count is too large: wagtail__wagtail-139\n",
      "Token count is too large: Qiskit__qiskit-6020\n",
      "Token count is too large: scipy__scipy-3926\n",
      "Token count is too large: open-mmlab__mmdetection-7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 385 examples [00:26, 18.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29186\n",
      "Token count is too large: Qiskit__qiskit-7028\n",
      "Token count is too large: PrefectHQ__prefect-2354\n",
      "Token count is too large: ipython__ipython-3377\n",
      "Token count is too large: conan-io__conan-5319\n",
      "Token count is too large: huggingface__transformers-17629\n",
      "Token count is too large: mesonbuild__meson-6170\n",
      "Token count is too large: wagtail__wagtail-356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 389 examples [00:26, 17.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11337\n",
      "Token count is too large: pypa__pip-3088\n",
      "Token count is too large: pypa__pip-4666\n",
      "Token count is too large: pandas-dev__pandas-37118\n",
      "Token count is too large: pandas-dev__pandas-27826\n",
      "Token count is too large: jupyterlab__jupyterlab-14273\n",
      "Token count is too large: pandas-dev__pandas-18127\n",
      "Token count is too large: pandas-dev__pandas-6977\n",
      "Token count is too large: pandas-dev__pandas-24882\n",
      "Token count is too large: pypa__pip-6613\n",
      "Token count is too large: huggingface__transformers-9907\n",
      "Token count is too large: pandas-dev__pandas-37329\n",
      "Token count is too large: pandas-dev__pandas-5192\n",
      "Token count is too large: Qiskit__qiskit-1668\n",
      "Token count is too large: PrefectHQ__prefect-2491\n",
      "Token count is too large: pandas-dev__pandas-25863\n",
      "Token count is too large: apache__airflow-9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 392 examples [00:27, 12.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-3985\n",
      "Token count is too large: ytdl-org__youtube-dl-15728\n",
      "Token count is too large: PrefectHQ__prefect-3109\n",
      "Token count is too large: docker__compose-1711\n",
      "Token count is too large: pyca__cryptography-6515\n",
      "Token count is too large: pandas-dev__pandas-16557\n",
      "Token count is too large: conan-io__conan-8208\n",
      "Token count is too large: pandas-dev__pandas-16141\n",
      "Token count is too large: ipython__ipython-9884\n",
      "Token count is too large: pandas-dev__pandas-24309\n",
      "Token count is too large: twisted__twisted-11598\n",
      "Token count is too large: pandas-dev__pandas-38681\n",
      "Token count is too large: Qiskit__qiskit-5332\n",
      "Token count is too large: ray-project__ray-7982\n",
      "Token count is too large: pypa__pip-5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 396 examples [00:27, 14.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8075\n",
      "Token count is too large: explosion__spaCy-2985\n",
      "Token count is too large: Qiskit__qiskit-8590\n",
      "Token count is too large: conda__conda-11849\n",
      "Token count is too large: pandas-dev__pandas-25926\n",
      "Token count is too large: mesonbuild__meson-9603\n",
      "Token count is too large: numpy__numpy-14763\n",
      "Token count is too large: apache__airflow-454\n",
      "Token count is too large: pandas-dev__pandas-16092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 400 examples [00:27, 13.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6296\n",
      "Token count is too large: pandas-dev__pandas-15569\n",
      "Token count is too large: Qiskit__qiskit-781\n",
      "Token count is too large: jupyterlab__jupyterlab-3107\n",
      "Token count is too large: huggingface__transformers-24226\n",
      "Token count is too large: ytdl-org__youtube-dl-1811\n",
      "Token count is too large: Qiskit__qiskit-893\n",
      "Token count is too large: mesonbuild__meson-11667\n",
      "Token count is too large: huggingface__transformers-9233\n",
      "Token count is too large: pandas-dev__pandas-14645\n",
      "Token count is too large: huggingface__transformers-15567\n",
      "Token count is too large: pandas-dev__pandas-21580\n",
      "Token count is too large: Qiskit__qiskit-4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 404 examples [00:27, 12.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3683\n",
      "Token count is too large: googleapis__google-cloud-python-6285\n",
      "Token count is too large: mesonbuild__meson-5133\n",
      "Token count is too large: conan-io__conan-3290\n",
      "Token count is too large: googleapis__google-cloud-python-2623\n",
      "Token count is too large: pandas-dev__pandas-14864\n",
      "Token count is too large: pantsbuild__pants-6871\n",
      "Token count is too large: pandas-dev__pandas-28677\n",
      "Token count is too large: conan-io__conan-3804\n",
      "Token count is too large: apache__airflow-1230\n",
      "Token count is too large: ipython__ipython-2370\n",
      "Token count is too large: pandas-dev__pandas-3555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 408 examples [00:28, 15.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-8892\n",
      "Token count is too large: numpy__numpy-8774\n",
      "Token count is too large: ytdl-org__youtube-dl-13773\n",
      "Token count is too large: Lightning-AI__lightning-1632\n",
      "Token count is too large: mesonbuild__meson-351\n",
      "Token count is too large: numpy__numpy-5186\n",
      "Token count is too large: pandas-dev__pandas-4007\n",
      "Token count is too large: pandas-dev__pandas-20672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 415 examples [00:28, 21.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13720\n",
      "Token count is too large: huggingface__transformers-6293\n",
      "Token count is too large: googleapis__google-cloud-python-3626\n",
      "Token count is too large: ytdl-org__youtube-dl-14455\n",
      "Token count is too large: pandas-dev__pandas-36161\n",
      "Token count is too large: numpy__numpy-3097\n",
      "Token count is too large: pandas-dev__pandas-36771\n",
      "Token count is too large: ipython__ipython-6936\n",
      "Token count is too large: google__jax-733\n",
      "Token count is too large: ray-project__ray-5651\n",
      "Token count is too large: celery__celery-4696\n",
      "Token count is too large: conda__conda-12874\n",
      "Token count is too large: numpy__numpy-9469\n",
      "Token count is too large: pyca__cryptography-1651\n",
      "Token count is too large: pandas-dev__pandas-26014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 419 examples [00:28, 19.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22810\n",
      "Token count is too large: pantsbuild__pants-12197\n",
      "Token count is too large: mesonbuild__meson-3716\n",
      "Token count is too large: dagster-io__dagster-899\n",
      "Token count is too large: pandas-dev__pandas-35951\n",
      "Token count is too large: googleapis__google-cloud-python-6343\n",
      "Token count is too large: pandas-dev__pandas-36551\n",
      "Token count is too large: pandas-dev__pandas-22941\n",
      "Token count is too large: apache__airflow-27256\n",
      "Token count is too large: apache__airflow-24362\n",
      "Token count is too large: googleapis__google-cloud-python-10205\n",
      "Token count is too large: pantsbuild__pants-18150\n",
      "Token count is too large: googleapis__google-cloud-python-328\n",
      "Token count is too large: pandas-dev__pandas-14918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 423 examples [00:28, 16.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22854\n",
      "Token count is too large: pyca__cryptography-3132\n",
      "Token count is too large: huggingface__transformers-10727\n",
      "Token count is too large: google__jax-3176\n",
      "Token count is too large: gitpython-developers__GitPython-677\n",
      "Token count is too large: pantsbuild__pants-5211\n",
      "Token count is too large: pandas-dev__pandas-20067\n",
      "Token count is too large: pandas-dev__pandas-4909\n",
      "Token count is too large: jupyterlab__jupyterlab-6585\n",
      "Token count is too large: pandas-dev__pandas-31416\n",
      "Token count is too large: pantsbuild__pants-19120\n",
      "Token count is too large: pandas-dev__pandas-4970\n",
      "Token count is too large: numpy__numpy-22324\n",
      "Token count is too large: pandas-dev__pandas-17253\n",
      "Token count is too large: conan-io__conan-2468\n",
      "Token count is too large: Qiskit__qiskit-91\n",
      "Token count is too large: Lightning-AI__lightning-2962\n",
      "Token count is too large: PrefectHQ__prefect-2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 431 examples [00:29, 19.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11988\n",
      "Token count is too large: pyca__cryptography-3328\n",
      "Token count is too large: apache__airflow-12595\n",
      "Token count is too large: numpy__numpy-23949\n",
      "Token count is too large: google__jax-2828\n",
      "Token count is too large: pandas-dev__pandas-4983\n",
      "Token count is too large: ipython__ipython-7326\n",
      "Token count is too large: googleapis__google-cloud-python-11567\n",
      "Token count is too large: conda__conda-5239\n",
      "Token count is too large: conan-io__conan-3021\n",
      "Token count is too large: conan-io__conan-11666\n",
      "Token count is too large: gitpython-developers__GitPython-1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 439 examples [00:29, 21.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-16206\n",
      "Token count is too large: huggingface__transformers-3955\n",
      "Token count is too large: huggingface__transformers-16139\n",
      "Token count is too large: pypa__pip-2629\n",
      "Token count is too large: gitpython-developers__GitPython-744\n",
      "Token count is too large: pypa__pip-9467\n",
      "Token count is too large: pandas-dev__pandas-36649\n",
      "Token count is too large: conan-io__conan-7695\n",
      "Token count is too large: pandas-dev__pandas-21223\n",
      "Token count is too large: huggingface__transformers-11566\n",
      "Token count is too large: Qiskit__qiskit-7887\n",
      "Token count is too large: Qiskit__qiskit-5135\n",
      "Token count is too large: PrefectHQ__prefect-751\n",
      "Token count is too large: wagtail__wagtail-10051\n",
      "Token count is too large: pantsbuild__pants-18463\n",
      "Token count is too large: pandas-dev__pandas-35519\n",
      "Token count is too large: Qiskit__qiskit-8671\n",
      "Token count is too large: pandas-dev__pandas-28606\n",
      "Token count is too large: pandas-dev__pandas-36458\n",
      "Token count is too large: Lightning-AI__lightning-837\n",
      "Token count is too large: Qiskit__qiskit-5270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 449 examples [00:29, 23.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4945\n",
      "Token count is too large: pandas-dev__pandas-33337\n",
      "Token count is too large: pandas-dev__pandas-37502\n",
      "Token count is too large: pandas-dev__pandas-39074\n",
      "Token count is too large: pantsbuild__pants-4399\n",
      "Token count is too large: conan-io__conan-2920\n",
      "Token count is too large: ipython__ipython-1019\n",
      "Token count is too large: ray-project__ray-1783\n",
      "Token count is too large: pandas-dev__pandas-38499\n",
      "Token count is too large: mesonbuild__meson-5687\n",
      "Token count is too large: ytdl-org__youtube-dl-3691\n",
      "Token count is too large: apache__airflow-12069\n",
      "Token count is too large: Qiskit__qiskit-1229\n",
      "Token count is too large: pandas-dev__pandas-13397\n",
      "Token count is too large: pandas-dev__pandas-30485\n",
      "Token count is too large: apache__airflow-33231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 455 examples [00:30, 25.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6922\n",
      "Token count is too large: conda__conda-5328\n",
      "Token count is too large: numpy__numpy-17974\n",
      "Token count is too large: ytdl-org__youtube-dl-30506\n",
      "Token count is too large: Lightning-AI__lightning-2831\n",
      "Token count is too large: dagster-io__dagster-6588\n",
      "Token count is too large: pandas-dev__pandas-4590\n",
      "Token count is too large: celery__celery-6583\n",
      "Token count is too large: conda__conda-7512\n",
      "Token count is too large: pandas-dev__pandas-7356\n",
      "Token count is too large: pandas-dev__pandas-33134\n",
      "Token count is too large: Qiskit__qiskit-4173\n",
      "Token count is too large: numpy__numpy-3322\n",
      "Token count is too large: googleapis__google-cloud-python-9873\n",
      "Token count is too large: ipython__ipython-6717\n",
      "Token count is too large: ray-project__ray-10775\n",
      "Token count is too large: apache__airflow-27808\n",
      "Token count is too large: pypa__pip-6691\n",
      "Token count is too large: pandas-dev__pandas-7789\n",
      "Token count is too large: docker__compose-5405\n",
      "Token count is too large: pandas-dev__pandas-37204\n",
      "Token count is too large: Qiskit__qiskit-6482\n",
      "Token count is too large: pandas-dev__pandas-34407\n",
      "Token count is too large: ytdl-org__youtube-dl-30329\n",
      "Token count is too large: pandas-dev__pandas-19539\n",
      "Token count is too large: numpy__numpy-22803\n",
      "Token count is too large: conan-io__conan-3177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 464 examples [00:30, 23.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-4789\n",
      "Token count is too large: numpy__numpy-23787\n",
      "Token count is too large: numpy__numpy-12408\n",
      "Token count is too large: mesonbuild__meson-10887\n",
      "Token count is too large: Lightning-AI__lightning-1097\n",
      "Token count is too large: pandas-dev__pandas-25918\n",
      "Token count is too large: pypa__pip-2853\n",
      "Token count is too large: pantsbuild__pants-18861\n",
      "Token count is too large: Qiskit__qiskit-6870\n",
      "Token count is too large: pandas-dev__pandas-14232\n",
      "Token count is too large: celery__celery-5527\n",
      "Token count is too large: ytdl-org__youtube-dl-31152\n",
      "Token count is too large: apache__airflow-9330\n",
      "Token count is too large: Qiskit__qiskit-1101\n",
      "Token count is too large: conan-io__conan-2486\n",
      "Token count is too large: pantsbuild__pants-9416\n",
      "Token count is too large: mesonbuild__meson-10503\n",
      "Token count is too large: wagtail__wagtail-7063\n",
      "Token count is too large: huggingface__transformers-21049\n",
      "Token count is too large: conda__conda-4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 467 examples [00:30, 16.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25102\n",
      "Token count is too large: mesonbuild__meson-5407\n",
      "Token count is too large: pyca__cryptography-2112\n",
      "Token count is too large: conda__conda-7310\n",
      "Token count is too large: ipython__ipython-10699\n",
      "Token count is too large: pandas-dev__pandas-24725\n",
      "Token count is too large: Lightning-AI__lightning-1568\n",
      "Token count is too large: pypa__pip-10495\n",
      "Token count is too large: ray-project__ray-8225\n",
      "Token count is too large: conan-io__conan-7183\n",
      "Token count is too large: ipython__ipython-2278\n",
      "Token count is too large: ray-project__ray-10715\n",
      "Token count is too large: Qiskit__qiskit-4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 471 examples [00:31, 19.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29469\n",
      "Token count is too large: pandas-dev__pandas-17755\n",
      "Token count is too large: pandas-dev__pandas-6158\n",
      "Token count is too large: docker__compose-4292\n",
      "Token count is too large: conan-io__conan-8985\n",
      "Token count is too large: pandas-dev__pandas-5097\n",
      "Token count is too large: pandas-dev__pandas-23439\n",
      "Token count is too large: mesonbuild__meson-8134\n",
      "Token count is too large: conda__conda-6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 474 examples [00:31, 16.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-10800\n",
      "Token count is too large: huggingface__transformers-16661\n",
      "Token count is too large: pandas-dev__pandas-11641\n",
      "Token count is too large: scipy__scipy-402\n",
      "Token count is too large: huggingface__transformers-9427\n",
      "Token count is too large: huggingface__transformers-16668\n",
      "Token count is too large: pandas-dev__pandas-35769\n",
      "Token count is too large: huggingface__transformers-11207\n",
      "Token count is too large: huggingface__transformers-15951\n",
      "Token count is too large: ipython__ipython-10539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 476 examples [00:31, 15.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21318\n",
      "Token count is too large: pandas-dev__pandas-37030\n",
      "Token count is too large: pantsbuild__pants-19123\n",
      "Token count is too large: pandas-dev__pandas-23650\n",
      "Token count is too large: dagster-io__dagster-14886\n",
      "Token count is too large: Lightning-AI__lightning-2819\n",
      "Token count is too large: huggingface__transformers-8989\n",
      "Token count is too large: Qiskit__qiskit-2835\n",
      "Token count is too large: pandas-dev__pandas-30202\n",
      "Token count is too large: pandas-dev__pandas-33247\n",
      "Token count is too large: numpy__numpy-23061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 490 examples [00:31, 26.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-2550\n",
      "Token count is too large: pandas-dev__pandas-19890\n",
      "Token count is too large: huggingface__transformers-8397\n",
      "Token count is too large: pandas-dev__pandas-17887\n",
      "Token count is too large: ytdl-org__youtube-dl-18217\n",
      "Token count is too large: googleapis__google-cloud-python-323\n",
      "Token count is too large: pandas-dev__pandas-9896\n",
      "Token count is too large: pandas-dev__pandas-21584\n",
      "Token count is too large: Qiskit__qiskit-3566\n",
      "Token count is too large: Qiskit__qiskit-10007\n",
      "Token count is too large: ytdl-org__youtube-dl-5556\n",
      "Token count is too large: celery__celery-6264\n",
      "Token count is too large: pandas-dev__pandas-35492\n",
      "Token count is too large: Qiskit__qiskit-9617\n",
      "Token count is too large: Qiskit__qiskit-2507\n",
      "Token count is too large: pantsbuild__pants-17360\n",
      "Token count is too large: conan-io__conan-4239\n",
      "Token count is too large: numpy__numpy-22991\n",
      "Token count is too large: pandas-dev__pandas-8982\n",
      "Token count is too large: pandas-dev__pandas-37073\n",
      "Token count is too large: pandas-dev__pandas-29113\n",
      "Token count is too large: huggingface__transformers-15795\n",
      "Token count is too large: ipython__ipython-6587\n",
      "Token count is too large: pandas-dev__pandas-23238\n",
      "Token count is too large: Qiskit__qiskit-7036\n",
      "Token count is too large: huggingface__transformers-7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 497 examples [00:32, 21.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37469\n",
      "Token count is too large: pandas-dev__pandas-26707\n",
      "Token count is too large: google__jax-1704\n",
      "Token count is too large: huggingface__transformers-17203\n",
      "Token count is too large: Lightning-AI__lightning-575\n",
      "Token count is too large: ipython__ipython-6866\n",
      "Token count is too large: docker__compose-5309\n",
      "Token count is too large: ipython__ipython-14055\n",
      "Token count is too large: pandas-dev__pandas-4394\n",
      "Token count is too large: apache__airflow-19985\n",
      "Token count is too large: conda__conda-12016\n",
      "Token count is too large: google__jax-1057\n",
      "Token count is too large: huggingface__transformers-7680\n",
      "Token count is too large: ipython__ipython-9097\n",
      "Token count is too large: ray-project__ray-9561\n",
      "Token count is too large: Qiskit__qiskit-6831\n",
      "Token count is too large: pandas-dev__pandas-24538\n",
      "Token count is too large: pantsbuild__pants-13541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:32, 15.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20424\n",
      "Token count is too large: pypa__pip-4493\n",
      "Token count is too large: pyca__cryptography-3236\n",
      "Token count is too large: pandas-dev__pandas-7587\n",
      "Token count is too large: Qiskit__qiskit-2045\n",
      "Token count is too large: pandas-dev__pandas-21674\n",
      "Token count is too large: pandas-dev__pandas-33645\n",
      "Token count is too large: pandas-dev__pandas-32734\n",
      "Token count is too large: ipython__ipython-10841\n",
      "Token count is too large: pandas-dev__pandas-20691\n",
      "Token count is too large: pypa__pip-1874\n",
      "Token count is too large: pandas-dev__pandas-22277\n",
      "Token count is too large: pandas-dev__pandas-20780\n",
      "Token count is too large: googleapis__google-cloud-python-4851\n",
      "Token count is too large: pandas-dev__pandas-18507\n",
      "Token count is too large: wagtail__wagtail-3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 503 examples [00:33, 11.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24947\n",
      "Token count is too large: pandas-dev__pandas-31088\n",
      "Token count is too large: pandas-dev__pandas-8492\n",
      "Token count is too large: ray-project__ray-10368\n",
      "Token count is too large: conan-io__conan-8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 507 examples [00:33, 12.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21623\n",
      "Token count is too large: pandas-dev__pandas-16504\n",
      "Token count is too large: pypa__pip-2445\n",
      "Token count is too large: pandas-dev__pandas-21361\n",
      "Token count is too large: docker__compose-2830\n",
      "Token count is too large: googleapis__google-cloud-python-9332\n",
      "Token count is too large: pypa__pip-6331\n",
      "Token count is too large: Qiskit__qiskit-6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 509 examples [00:33, 12.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20522\n",
      "Token count is too large: pandas-dev__pandas-17006\n",
      "Token count is too large: pandas-dev__pandas-39604\n",
      "Token count is too large: pantsbuild__pants-10789\n",
      "Token count is too large: conda__conda-6494\n",
      "Token count is too large: numpy__numpy-4565\n",
      "Token count is too large: numpy__numpy-4372\n",
      "Token count is too large: pandas-dev__pandas-27801\n",
      "Token count is too large: Lightning-AI__lightning-749\n",
      "Token count is too large: pandas-dev__pandas-27367\n",
      "Token count is too large: numpy__numpy-6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 511 examples [00:33, 11.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-3439\n",
      "Token count is too large: numpy__numpy-22436\n",
      "Token count is too large: conan-io__conan-4346\n",
      "Token count is too large: pandas-dev__pandas-23044\n",
      "Token count is too large: Qiskit__qiskit-9089\n",
      "Token count is too large: pyca__cryptography-2957\n",
      "Token count is too large: google__jax-1268\n",
      "Token count is too large: ipython__ipython-10263\n",
      "Token count is too large: ytdl-org__youtube-dl-3855\n",
      "Token count is too large: mesonbuild__meson-7757\n",
      "Token count is too large: pandas-dev__pandas-30335\n",
      "Token count is too large: conda__conda-11304\n",
      "Token count is too large: numpy__numpy-16675\n",
      "Token count is too large: pantsbuild__pants-12782\n",
      "Token count is too large: ytdl-org__youtube-dl-24968\n",
      "Token count is too large: pandas-dev__pandas-29888\n",
      "Token count is too large: wagtail__wagtail-1070\n",
      "Token count is too large: Lightning-AI__lightning-2528\n",
      "Token count is too large: numpy__numpy-5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 518 examples [00:34, 13.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28128\n",
      "Token count is too large: ipython__ipython-6945\n",
      "Token count is too large: conda__conda-7476\n",
      "Token count is too large: pandas-dev__pandas-14650\n",
      "Token count is too large: docker__compose-411\n",
      "Token count is too large: google__jax-2626\n",
      "Token count is too large: pandas-dev__pandas-39253\n",
      "Token count is too large: pandas-dev__pandas-7440\n",
      "Token count is too large: pandas-dev__pandas-23353\n",
      "Token count is too large: googleapis__google-cloud-python-6086\n",
      "Token count is too large: pandas-dev__pandas-37461\n",
      "Token count is too large: pandas-dev__pandas-6363\n",
      "Token count is too large: pandas-dev__pandas-13765\n",
      "Token count is too large: pandas-dev__pandas-21558\n",
      "Token count is too large: pypa__pip-11663\n",
      "Token count is too large: Qiskit__qiskit-6242\n",
      "Token count is too large: pantsbuild__pants-15098\n",
      "Token count is too large: open-mmlab__mmdetection-2921\n",
      "Token count is too large: pandas-dev__pandas-23855\n",
      "Token count is too large: Qiskit__qiskit-7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 522 examples [00:34, 13.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14697\n",
      "Token count is too large: numpy__numpy-3191\n",
      "Token count is too large: pandas-dev__pandas-19250\n",
      "Token count is too large: huggingface__transformers-9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 525 examples [00:34, 12.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6889\n",
      "Token count is too large: huggingface__transformers-13800\n",
      "Token count is too large: pandas-dev__pandas-16244\n",
      "Token count is too large: conan-io__conan-2581\n",
      "Token count is too large: pandas-dev__pandas-34137\n",
      "Token count is too large: pypa__pip-612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 527 examples [00:35,  7.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24856\n",
      "Token count is too large: huggingface__transformers-9626\n",
      "Token count is too large: google__jax-586\n",
      "Token count is too large: Qiskit__qiskit-1977\n",
      "Token count is too large: pypa__pip-6339\n",
      "Token count is too large: numpy__numpy-10030\n",
      "Token count is too large: pypa__pip-8026\n",
      "Token count is too large: apache__airflow-20172\n",
      "Token count is too large: pandas-dev__pandas-9134\n",
      "Token count is too large: googleapis__google-cloud-python-8472\n",
      "Token count is too large: googleapis__google-cloud-python-11205\n",
      "Token count is too large: pantsbuild__pants-12398\n",
      "Token count is too large: ytdl-org__youtube-dl-9597\n",
      "Token count is too large: Qiskit__qiskit-4335\n",
      "Token count is too large: mesonbuild__meson-10617\n",
      "Token count is too large: Qiskit__qiskit-9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 530 examples [00:35,  8.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13510\n",
      "Token count is too large: conda__conda-6588\n",
      "Token count is too large: mesonbuild__meson-4719\n",
      "Token count is too large: apache__airflow-8944\n",
      "Token count is too large: pandas-dev__pandas-22359\n",
      "Token count is too large: pandas-dev__pandas-11286\n",
      "Token count is too large: conda__conda-7049\n",
      "Token count is too large: mesonbuild__meson-4826\n",
      "Token count is too large: google__jax-870\n",
      "Token count is too large: ytdl-org__youtube-dl-17076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 534 examples [00:36, 10.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11325\n",
      "Token count is too large: Qiskit__qiskit-8197\n",
      "Token count is too large: pandas-dev__pandas-24105\n",
      "Token count is too large: pandas-dev__pandas-38504\n",
      "Token count is too large: numpy__numpy-3121\n",
      "Token count is too large: conan-io__conan-4556\n",
      "Token count is too large: pyca__cryptography-2739\n",
      "Token count is too large: Qiskit__qiskit-575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 542 examples [00:36, 16.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6690\n",
      "Token count is too large: pandas-dev__pandas-5753\n",
      "Token count is too large: huggingface__transformers-15017\n",
      "Token count is too large: Qiskit__qiskit-2084\n",
      "Token count is too large: Qiskit__qiskit-2939\n",
      "Token count is too large: pandas-dev__pandas-24450\n",
      "Token count is too large: pandas-dev__pandas-23433\n",
      "Token count is too large: ytdl-org__youtube-dl-30366\n",
      "Token count is too large: pandas-dev__pandas-36971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 547 examples [00:36, 18.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9321\n",
      "Token count is too large: dagster-io__dagster-4833\n",
      "Token count is too large: docker__compose-3299\n",
      "Token count is too large: Qiskit__qiskit-5257\n",
      "Token count is too large: pandas-dev__pandas-37406\n",
      "Token count is too large: Qiskit__qiskit-2880\n",
      "Token count is too large: docker__compose-6100\n",
      "Token count is too large: conda__conda-7826\n",
      "Token count is too large: ipython__ipython-1870\n",
      "Token count is too large: pandas-dev__pandas-17640\n",
      "Token count is too large: mesonbuild__meson-7254\n",
      "Token count is too large: Qiskit__qiskit-3319\n",
      "Token count is too large: pandas-dev__pandas-30960\n",
      "Token count is too large: twisted__twisted-649\n",
      "Token count is too large: numpy__numpy-20759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 551 examples [00:36, 20.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17656\n",
      "Token count is too large: pandas-dev__pandas-25247\n",
      "Token count is too large: pandas-dev__pandas-14105\n",
      "Token count is too large: pandas-dev__pandas-9701\n",
      "Token count is too large: conan-io__conan-290\n",
      "Token count is too large: conda__conda-2950\n",
      "Token count is too large: numpy__numpy-11200\n",
      "Token count is too large: pandas-dev__pandas-37864\n",
      "Token count is too large: docker__compose-4541\n",
      "Token count is too large: ytdl-org__youtube-dl-1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 554 examples [00:37, 15.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-1008\n",
      "Token count is too large: pandas-dev__pandas-3864\n",
      "Token count is too large: numpy__numpy-17053\n",
      "Token count is too large: pandas-dev__pandas-25419\n",
      "Token count is too large: conda__conda-5190\n",
      "Token count is too large: pantsbuild__pants-10052\n",
      "Token count is too large: pandas-dev__pandas-4768\n",
      "Token count is too large: googleapis__google-cloud-python-8666\n",
      "Token count is too large: huggingface__transformers-14894\n",
      "Token count is too large: pandas-dev__pandas-37958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 557 examples [00:37, 17.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6822\n",
      "Token count is too large: numpy__numpy-7654\n",
      "Token count is too large: docker__compose-4730\n",
      "Token count is too large: JohnSnowLabs__spark-nlp-13873\n",
      "Token count is too large: huggingface__transformers-19531\n",
      "Token count is too large: pantsbuild__pants-16183\n",
      "Token count is too large: pandas-dev__pandas-34863\n",
      "Token count is too large: celery__celery-5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 561 examples [00:37, 17.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6038\n",
      "Token count is too large: jupyterlab__jupyterlab-6372\n",
      "Token count is too large: Qiskit__qiskit-6730\n",
      "Token count is too large: pandas-dev__pandas-5772\n",
      "Token count is too large: pandas-dev__pandas-37009\n",
      "Token count is too large: Qiskit__qiskit-7484\n",
      "Token count is too large: googleapis__google-cloud-python-1804\n",
      "Token count is too large: apache__airflow-32397\n",
      "Token count is too large: pandas-dev__pandas-3618\n",
      "Token count is too large: ipython__ipython-3555\n",
      "Token count is too large: Qiskit__qiskit-3513\n",
      "Token count is too large: ipython__ipython-13534\n",
      "Token count is too large: conan-io__conan-12353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 569 examples [00:37, 22.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38379\n",
      "Token count is too large: Qiskit__qiskit-4893\n",
      "Token count is too large: celery__celery-5486\n",
      "Token count is too large: pandas-dev__pandas-35776\n",
      "Token count is too large: googleapis__google-cloud-python-1843\n",
      "Token count is too large: docker__compose-4861\n",
      "Token count is too large: pandas-dev__pandas-14977\n",
      "Token count is too large: ipython__ipython-4960\n",
      "Token count is too large: wagtail__wagtail-5479\n",
      "Token count is too large: pandas-dev__pandas-37564\n",
      "Token count is too large: numpy__numpy-6596\n",
      "Token count is too large: huggingface__transformers-20630\n",
      "Token count is too large: Qiskit__qiskit-7584\n",
      "Token count is too large: celery__celery-4403\n",
      "Token count is too large: googleapis__google-cloud-python-373\n",
      "Token count is too large: huggingface__transformers-9726\n",
      "Token count is too large: docker__compose-5277\n",
      "Token count is too large: mesonbuild__meson-4746\n",
      "Token count is too large: pandas-dev__pandas-37367\n",
      "Token count is too large: numpy__numpy-10032\n",
      "Token count is too large: conan-io__conan-6871\n",
      "Token count is too large: google__jax-875\n",
      "Token count is too large: huggingface__transformers-16778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 576 examples [00:38, 18.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23004\n",
      "Token count is too large: pantsbuild__pants-18218\n",
      "Token count is too large: numpy__numpy-22372\n",
      "Token count is too large: mesonbuild__meson-11050\n",
      "Token count is too large: Qiskit__qiskit-4166\n",
      "Token count is too large: huggingface__transformers-18419\n",
      "Token count is too large: numpy__numpy-5999\n",
      "Token count is too large: numpy__numpy-3049\n",
      "Token count is too large: google__jax-3098\n",
      "Token count is too large: Qiskit__qiskit-7411\n",
      "Token count is too large: scipy__scipy-3309\n",
      "Token count is too large: pypa__pip-5405\n",
      "Token count is too large: mesonbuild__meson-9615\n",
      "Token count is too large: pandas-dev__pandas-27101\n",
      "Token count is too large: ytdl-org__youtube-dl-12085\n",
      "Token count is too large: PrefectHQ__prefect-1226\n",
      "Token count is too large: dagster-io__dagster-1029\n",
      "Token count is too large: conan-io__conan-4767\n",
      "Token count is too large: open-mmlab__mmdetection-8136\n",
      "Token count is too large: googleapis__google-cloud-python-1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 579 examples [00:38, 14.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-14780\n",
      "Token count is too large: pandas-dev__pandas-22030\n",
      "Token count is too large: pandas-dev__pandas-21092\n",
      "Token count is too large: numpy__numpy-21015\n",
      "Token count is too large: pandas-dev__pandas-29567\n",
      "Token count is too large: pandas-dev__pandas-14330\n",
      "Token count is too large: ipython__ipython-13778\n",
      "Token count is too large: Qiskit__qiskit-1860\n",
      "Token count is too large: pandas-dev__pandas-30743\n",
      "Token count is too large: apache__airflow-8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 581 examples [00:38, 12.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11466\n",
      "Token count is too large: pandas-dev__pandas-21879\n",
      "Token count is too large: pantsbuild__pants-6594\n",
      "Token count is too large: google__jax-1524\n",
      "Token count is too large: pandas-dev__pandas-9629\n",
      "Token count is too large: pandas-dev__pandas-15515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 586 examples [00:39, 13.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3122\n",
      "Token count is too large: googleapis__google-cloud-python-788\n",
      "Token count is too large: huggingface__transformers-22190\n",
      "Token count is too large: Qiskit__qiskit-760\n",
      "Token count is too large: dagster-io__dagster-8618\n",
      "Token count is too large: pandas-dev__pandas-30495\n",
      "Token count is too large: numpy__numpy-10603\n",
      "Token count is too large: googleapis__google-cloud-python-11320\n",
      "Token count is too large: docker__compose-8644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 591 examples [00:39, 17.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: PrefectHQ__prefect-624\n",
      "Token count is too large: conan-io__conan-7610\n",
      "Token count is too large: pandas-dev__pandas-20681\n",
      "Token count is too large: Qiskit__qiskit-7765\n",
      "Token count is too large: pandas-dev__pandas-13592\n",
      "Token count is too large: pandas-dev__pandas-23432\n",
      "Token count is too large: numpy__numpy-6730\n",
      "Token count is too large: ytdl-org__youtube-dl-888\n",
      "Token count is too large: docker__compose-5833\n",
      "Token count is too large: pandas-dev__pandas-18829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 598 examples [00:39, 21.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4714\n",
      "Token count is too large: huggingface__transformers-19725\n",
      "Token count is too large: pandas-dev__pandas-26947\n",
      "Token count is too large: googleapis__google-cloud-python-10021\n",
      "Token count is too large: conda__conda-8925\n",
      "Token count is too large: mesonbuild__meson-1028\n",
      "Token count is too large: mesonbuild__meson-5011\n",
      "Token count is too large: pandas-dev__pandas-35585\n",
      "Token count is too large: conda__conda-7499\n",
      "Token count is too large: pypa__pip-299\n",
      "Token count is too large: pyca__cryptography-6744\n",
      "Token count is too large: Qiskit__qiskit-6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 602 examples [00:39, 22.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12367\n",
      "Token count is too large: pandas-dev__pandas-9699\n",
      "Token count is too large: numpy__numpy-2747\n",
      "Token count is too large: ipython__ipython-9647\n",
      "Token count is too large: pandas-dev__pandas-18805\n",
      "Token count is too large: pandas-dev__pandas-26839\n",
      "Token count is too large: pandas-dev__pandas-18685\n",
      "Token count is too large: jupyterlab__jupyterlab-13589\n",
      "Token count is too large: pypa__pip-5515\n",
      "Token count is too large: pandas-dev__pandas-14749\n",
      "Token count is too large: ipython__ipython-13411\n",
      "Token count is too large: pypa__pip-2133\n",
      "Token count is too large: conan-io__conan-8468\n",
      "Token count is too large: Qiskit__qiskit-3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 606 examples [00:39, 18.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-2926\n",
      "Token count is too large: conda__conda-6442\n",
      "Token count is too large: open-mmlab__mmdetection-3528\n",
      "Token count is too large: pandas-dev__pandas-18100\n",
      "Token count is too large: mesonbuild__meson-9106\n",
      "Token count is too large: pandas-dev__pandas-35688\n",
      "Token count is too large: wagtail__wagtail-426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 612 examples [00:40, 21.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23718\n",
      "Token count is too large: ytdl-org__youtube-dl-11901\n",
      "Token count is too large: mesonbuild__meson-1183\n",
      "Token count is too large: mesonbuild__meson-1091\n",
      "Token count is too large: pandas-dev__pandas-16663\n",
      "Token count is too large: pandas-dev__pandas-19635\n",
      "Token count is too large: pandas-dev__pandas-4614\n",
      "Token count is too large: pandas-dev__pandas-8126\n",
      "Token count is too large: pandas-dev__pandas-26004\n",
      "Token count is too large: pandas-dev__pandas-26795\n",
      "Token count is too large: docker__compose-2350\n",
      "Token count is too large: docker__compose-588\n",
      "Token count is too large: pandas-dev__pandas-6530\n",
      "Token count is too large: mesonbuild__meson-11826\n",
      "Token count is too large: pandas-dev__pandas-7009\n",
      "Token count is too large: conan-io__conan-4251\n",
      "Token count is too large: dagster-io__dagster-1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 615 examples [00:40, 13.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21870\n",
      "Token count is too large: google__jax-3320\n",
      "Token count is too large: pandas-dev__pandas-26404\n",
      "Token count is too large: numpy__numpy-7297\n",
      "Token count is too large: numpy__numpy-24526\n",
      "Token count is too large: open-mmlab__mmdetection-7797\n",
      "Token count is too large: pandas-dev__pandas-7532\n",
      "Token count is too large: pypa__pip-2451\n",
      "Token count is too large: celery__celery-6765\n",
      "Token count is too large: ray-project__ray-1693\n",
      "Token count is too large: pantsbuild__pants-5952\n",
      "Token count is too large: pandas-dev__pandas-22357\n",
      "Token count is too large: pandas-dev__pandas-11426\n",
      "Token count is too large: ipython__ipython-10496\n",
      "Token count is too large: pandas-dev__pandas-25280\n",
      "Token count is too large: pandas-dev__pandas-24500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 618 examples [00:40, 14.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7533\n",
      "Token count is too large: googleapis__google-cloud-python-6651\n",
      "Token count is too large: pandas-dev__pandas-27702\n",
      "Token count is too large: PrefectHQ__prefect-1556\n",
      "Token count is too large: pandas-dev__pandas-5960\n",
      "Token count is too large: pandas-dev__pandas-5604\n",
      "Token count is too large: pandas-dev__pandas-19884\n",
      "Token count is too large: mesonbuild__meson-10790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 627 examples [00:41, 21.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-1388\n",
      "Token count is too large: huggingface__transformers-12953\n",
      "Token count is too large: pandas-dev__pandas-32389\n",
      "Token count is too large: google__jax-236\n",
      "Token count is too large: pandas-dev__pandas-24275\n",
      "Token count is too large: googleapis__google-cloud-python-6110\n",
      "Token count is too large: pandas-dev__pandas-35111\n",
      "Token count is too large: apache__airflow-24676\n",
      "Token count is too large: Lightning-AI__lightning-2510\n",
      "Token count is too large: pandas-dev__pandas-26297\n",
      "Token count is too large: Qiskit__qiskit-7671\n",
      "Token count is too large: conan-io__conan-5260\n",
      "Token count is too large: mesonbuild__meson-6412\n",
      "Token count is too large: pandas-dev__pandas-22696\n",
      "Token count is too large: pandas-dev__pandas-30434\n",
      "Token count is too large: pandas-dev__pandas-6614\n",
      "Token count is too large: pandas-dev__pandas-7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 632 examples [00:41, 14.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-7185\n",
      "Token count is too large: huggingface__transformers-19648\n",
      "Token count is too large: mesonbuild__meson-5568\n",
      "Token count is too large: pandas-dev__pandas-23692\n",
      "Token count is too large: pandas-dev__pandas-24188\n",
      "Token count is too large: pandas-dev__pandas-22170\n",
      "Token count is too large: pandas-dev__pandas-22207\n",
      "Token count is too large: mesonbuild__meson-6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 637 examples [00:42, 10.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-6833\n",
      "Token count is too large: pandas-dev__pandas-11997\n",
      "Token count is too large: google__jax-2220\n",
      "Token count is too large: pantsbuild__pants-7504\n",
      "Token count is too large: celery__celery-5345\n",
      "Token count is too large: pandas-dev__pandas-4716\n",
      "Token count is too large: pandas-dev__pandas-27006\n",
      "Token count is too large: Lightning-AI__lightning-2289\n",
      "Token count is too large: conda__conda-8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 641 examples [00:42, 11.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7953\n",
      "Token count is too large: mesonbuild__meson-5577\n",
      "Token count is too large: Qiskit__qiskit-7350\n",
      "Token count is too large: celery__celery-5114\n",
      "Token count is too large: numpy__numpy-5358\n",
      "Token count is too large: huggingface__transformers-22649\n",
      "Token count is too large: conan-io__conan-8490\n",
      "Token count is too large: mesonbuild__meson-8974\n",
      "Token count is too large: googleapis__google-cloud-python-5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 643 examples [00:42, 10.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10638\n",
      "Token count is too large: pandas-dev__pandas-21867\n",
      "Token count is too large: wagtail__wagtail-5694\n",
      "Token count is too large: Qiskit__qiskit-9002\n",
      "Token count is too large: mesonbuild__meson-5942\n",
      "Token count is too large: pantsbuild__pants-7447\n",
      "Token count is too large: Qiskit__qiskit-8335\n",
      "Token count is too large: Lightning-AI__lightning-1824\n",
      "Token count is too large: pandas-dev__pandas-18674\n",
      "Token count is too large: pandas-dev__pandas-28907\n",
      "Token count is too large: pandas-dev__pandas-35360\n",
      "Token count is too large: pandas-dev__pandas-38803\n",
      "Token count is too large: google__jax-2788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 648 examples [00:43, 12.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-5938\n",
      "Token count is too large: pantsbuild__pants-19004\n",
      "Token count is too large: huggingface__transformers-10551\n",
      "Token count is too large: pandas-dev__pandas-5948\n",
      "Token count is too large: pandas-dev__pandas-7458\n",
      "Token count is too large: pandas-dev__pandas-10069\n",
      "Token count is too large: google__jax-1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 651 examples [00:43, 13.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2213\n",
      "Token count is too large: pandas-dev__pandas-36843\n",
      "Token count is too large: apache__airflow-18979\n",
      "Token count is too large: PrefectHQ__prefect-2507\n",
      "Token count is too large: pandas-dev__pandas-16586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 653 examples [00:43, 11.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4419\n",
      "Token count is too large: conda__conda-6555\n",
      "Token count is too large: google__jax-661\n",
      "Token count is too large: pandas-dev__pandas-36694\n",
      "Token count is too large: pandas-dev__pandas-5429\n",
      "Token count is too large: docker__compose-1702\n",
      "Token count is too large: numpy__numpy-13435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 655 examples [00:43, 10.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25585\n",
      "Token count is too large: Qiskit__qiskit-2052\n",
      "Token count is too large: Qiskit__qiskit-4141\n",
      "Token count is too large: mesonbuild__meson-9017\n",
      "Token count is too large: pypa__pip-1882\n",
      "Token count is too large: google__jax-3334\n",
      "Token count is too large: pyca__cryptography-4822\n",
      "Token count is too large: pandas-dev__pandas-23422\n",
      "Token count is too large: pandas-dev__pandas-25743\n",
      "Token count is too large: Lightning-AI__lightning-2723\n",
      "Token count is too large: wagtail__wagtail-562\n",
      "Token count is too large: conda__conda-10086\n",
      "Token count is too large: pandas-dev__pandas-15142\n",
      "Token count is too large: ipython__ipython-2432\n",
      "Token count is too large: pandas-dev__pandas-10490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 661 examples [00:44, 13.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-8861\n",
      "Token count is too large: pandas-dev__pandas-36647\n",
      "Token count is too large: google__jax-2414\n",
      "Token count is too large: ipython__ipython-5522\n",
      "Token count is too large: pandas-dev__pandas-10953\n",
      "Token count is too large: pypa__pip-9320\n",
      "Token count is too large: conda__conda-6189\n",
      "Token count is too large: huggingface__transformers-10517\n",
      "Token count is too large: open-mmlab__mmdetection-5486\n",
      "Token count is too large: pandas-dev__pandas-7386\n",
      "Token count is too large: apache__airflow-25856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 664 examples [00:44, 12.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21929\n",
      "Token count is too large: PrefectHQ__prefect-3007\n",
      "Token count is too large: Qiskit__qiskit-8576\n",
      "Token count is too large: huggingface__transformers-15928\n",
      "Token count is too large: huggingface__transformers-24101\n",
      "Token count is too large: open-mmlab__mmdetection-2626\n",
      "Token count is too large: pantsbuild__pants-19302\n",
      "Token count is too large: pandas-dev__pandas-31667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 667 examples [00:44, 12.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11104\n",
      "Token count is too large: pandas-dev__pandas-25953\n",
      "Token count is too large: pandas-dev__pandas-34338\n",
      "Token count is too large: pandas-dev__pandas-14668\n",
      "Token count is too large: pandas-dev__pandas-4881\n",
      "Token count is too large: googleapis__google-cloud-python-3758\n",
      "Token count is too large: Qiskit__qiskit-3354\n",
      "Token count is too large: pandas-dev__pandas-31388\n",
      "Token count is too large: Qiskit__qiskit-5223\n",
      "Token count is too large: conda__conda-7146\n",
      "Token count is too large: pandas-dev__pandas-25556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 670 examples [00:45, 11.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-20762\n",
      "Token count is too large: pandas-dev__pandas-36800\n",
      "Token count is too large: mesonbuild__meson-3556\n",
      "Token count is too large: Lightning-AI__lightning-2047\n",
      "Token count is too large: Qiskit__qiskit-530\n",
      "Token count is too large: ipython__ipython-2007\n",
      "Token count is too large: open-mmlab__mmdetection-2349\n",
      "Token count is too large: huggingface__transformers-13686\n",
      "Token count is too large: ytdl-org__youtube-dl-386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 677 examples [00:45, 15.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-5312\n",
      "Token count is too large: google__jax-3003\n",
      "Token count is too large: pandas-dev__pandas-4406\n",
      "Token count is too large: dagster-io__dagster-4615\n",
      "Token count is too large: open-mmlab__mmdetection-9319\n",
      "Token count is too large: conan-io__conan-3554\n",
      "Token count is too large: pandas-dev__pandas-34293\n",
      "Token count is too large: huggingface__transformers-3103\n",
      "Token count is too large: huggingface__transformers-8852\n",
      "Token count is too large: google__jax-3235\n",
      "Token count is too large: mesonbuild__meson-10709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 683 examples [00:45, 19.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7580\n",
      "Token count is too large: pandas-dev__pandas-26810\n",
      "Token count is too large: pandas-dev__pandas-13585\n",
      "Token count is too large: conda__conda-3457\n",
      "Token count is too large: pandas-dev__pandas-39407\n",
      "Token count is too large: huggingface__transformers-10531\n",
      "Token count is too large: Qiskit__qiskit-8571\n",
      "Token count is too large: numpy__numpy-7211\n",
      "Token count is too large: pandas-dev__pandas-38621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 688 examples [00:45, 20.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19074\n",
      "Token count is too large: pandas-dev__pandas-29836\n",
      "Token count is too large: pandas-dev__pandas-30305\n",
      "Token count is too large: google__jax-231\n",
      "Token count is too large: pandas-dev__pandas-34408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 695 examples [00:46, 23.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23367\n",
      "Token count is too large: pandas-dev__pandas-16233\n",
      "Token count is too large: conda__conda-2715\n",
      "Token count is too large: huggingface__transformers-9105\n",
      "Token count is too large: huggingface__transformers-7542\n",
      "Token count is too large: pandas-dev__pandas-26891\n",
      "Token count is too large: pantsbuild__pants-12022\n",
      "Token count is too large: DataDog__integrations-core-11210\n",
      "Token count is too large: scipy__scipy-4162\n",
      "Token count is too large: huggingface__transformers-11061\n",
      "Token count is too large: pandas-dev__pandas-34377\n",
      "Token count is too large: ytdl-org__youtube-dl-30340\n",
      "Token count is too large: apache__airflow-13745\n",
      "Token count is too large: Lightning-AI__lightning-439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 699 examples [00:46, 20.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9574\n",
      "Token count is too large: pandas-dev__pandas-24503\n",
      "Token count is too large: wagtail__wagtail-1978\n",
      "Token count is too large: DataDog__integrations-core-727\n",
      "Token count is too large: apache__airflow-23134\n",
      "Token count is too large: numpy__numpy-17446\n",
      "Token count is too large: dagster-io__dagster-9138\n",
      "Token count is too large: googleapis__google-cloud-python-3425\n",
      "Token count is too large: apache__airflow-25524\n",
      "Token count is too large: wagtail__wagtail-9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 702 examples [00:46, 21.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22969\n",
      "Token count is too large: googleapis__google-cloud-python-11329\n",
      "Token count is too large: ipython__ipython-4314\n",
      "Token count is too large: pantsbuild__pants-4500\n",
      "Token count is too large: pandas-dev__pandas-35427\n",
      "Token count is too large: mesonbuild__meson-7979\n",
      "Token count is too large: Qiskit__qiskit-8830\n",
      "Token count is too large: ipython__ipython-910\n",
      "Token count is too large: numpy__numpy-8236\n",
      "Token count is too large: pandas-dev__pandas-21570\n",
      "Token count is too large: pandas-dev__pandas-30285\n",
      "Token count is too large: mesonbuild__meson-1279\n",
      "Token count is too large: apache__airflow-19307\n",
      "Token count is too large: pypa__pip-5370\n",
      "Token count is too large: pandas-dev__pandas-22697\n",
      "Token count is too large: pandas-dev__pandas-37707\n",
      "Token count is too large: numpy__numpy-7260\n",
      "Token count is too large: pandas-dev__pandas-23221\n",
      "Token count is too large: docker__compose-1990\n",
      "Token count is too large: conda__conda-2772\n",
      "Token count is too large: conan-io__conan-6027\n",
      "Token count is too large: PrefectHQ__prefect-3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 709 examples [00:47, 15.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-6600\n",
      "Token count is too large: Lightning-AI__lightning-1018\n",
      "Token count is too large: wagtail__wagtail-1682\n",
      "Token count is too large: conan-io__conan-2679\n",
      "Token count is too large: pandas-dev__pandas-7285\n",
      "Token count is too large: pandas-dev__pandas-20356\n",
      "Token count is too large: pandas-dev__pandas-35686\n",
      "Token count is too large: huggingface__transformers-18618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 726 examples [00:47, 25.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21698\n",
      "Token count is too large: Qiskit__qiskit-6550\n",
      "Token count is too large: pandas-dev__pandas-15581\n",
      "Token count is too large: Qiskit__qiskit-3575\n",
      "Token count is too large: gitpython-developers__GitPython-479\n",
      "Token count is too large: conan-io__conan-3059\n",
      "Token count is too large: Qiskit__qiskit-1975\n",
      "Token count is too large: dagster-io__dagster-8406\n",
      "Token count is too large: pandas-dev__pandas-36552\n",
      "Token count is too large: ipython__ipython-5592\n",
      "Token count is too large: conan-io__conan-4359\n",
      "Token count is too large: pandas-dev__pandas-20345\n",
      "Token count is too large: conan-io__conan-4644\n",
      "Token count is too large: mesonbuild__meson-1338\n",
      "Token count is too large: googleapis__google-cloud-python-487\n",
      "Token count is too large: pypa__pip-2542\n",
      "Token count is too large: pandas-dev__pandas-8631\n",
      "Token count is too large: pantsbuild__pants-6912\n",
      "Token count is too large: pandas-dev__pandas-22365\n",
      "Token count is too large: pandas-dev__pandas-18163\n",
      "Token count is too large: numpy__numpy-9054\n",
      "Token count is too large: pandas-dev__pandas-21822\n",
      "Token count is too large: Qiskit__qiskit-3585\n",
      "Token count is too large: pypa__pip-4835\n",
      "Token count is too large: Lightning-AI__lightning-856\n",
      "Token count is too large: pandas-dev__pandas-16708\n",
      "Token count is too large: Qiskit__qiskit-3581\n",
      "Token count is too large: pandas-dev__pandas-32733\n",
      "Token count is too large: scipy__scipy-2740\n",
      "Token count is too large: pandas-dev__pandas-1073\n",
      "Token count is too large: huggingface__transformers-21834\n",
      "Token count is too large: pandas-dev__pandas-19773\n",
      "Token count is too large: pandas-dev__pandas-27992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 730 examples [00:47, 16.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-7282\n",
      "Token count is too large: apache__airflow-22123\n",
      "Token count is too large: pandas-dev__pandas-28233\n",
      "Token count is too large: numpy__numpy-23911\n",
      "Token count is too large: Qiskit__qiskit-1737\n",
      "Token count is too large: pandas-dev__pandas-18116\n",
      "Token count is too large: mesonbuild__meson-3289\n",
      "Token count is too large: pantsbuild__pants-11872\n",
      "Token count is too large: pyca__cryptography-7038\n",
      "Token count is too large: pandas-dev__pandas-7404\n",
      "Token count is too large: pandas-dev__pandas-29922\n",
      "Token count is too large: Qiskit__qiskit-5688\n",
      "Token count is too large: pandas-dev__pandas-4492\n",
      "Token count is too large: pandas-dev__pandas-22862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 737 examples [00:48, 14.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-16985\n",
      "Token count is too large: ipython__ipython-12144\n",
      "Token count is too large: numpy__numpy-12679\n",
      "Token count is too large: ipython__ipython-4789\n",
      "Token count is too large: scipy__scipy-287\n",
      "Token count is too large: apache__airflow-19668\n",
      "Token count is too large: googleapis__google-cloud-python-5372\n",
      "Token count is too large: pandas-dev__pandas-25602\n",
      "Token count is too large: pandas-dev__pandas-23847\n",
      "Token count is too large: pandas-dev__pandas-5354\n",
      "Token count is too large: googleapis__google-cloud-python-2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 741 examples [00:48, 17.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9613\n",
      "Token count is too large: numpy__numpy-18354\n",
      "Token count is too large: pandas-dev__pandas-8743\n",
      "Token count is too large: huggingface__transformers-9151\n",
      "Token count is too large: huggingface__transformers-18714\n",
      "Token count is too large: Qiskit__qiskit-8666\n",
      "Token count is too large: numpy__numpy-24299\n",
      "Token count is too large: twisted__twisted-11711\n",
      "Token count is too large: ray-project__ray-7324\n",
      "Token count is too large: wagtail__wagtail-9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 745 examples [00:48, 17.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-10511\n",
      "Token count is too large: pandas-dev__pandas-27871\n",
      "Token count is too large: pandas-dev__pandas-9036\n",
      "Token count is too large: Qiskit__qiskit-9441\n",
      "Token count is too large: numpy__numpy-16855\n",
      "Token count is too large: pandas-dev__pandas-35280\n",
      "Token count is too large: ipython__ipython-13868\n",
      "Token count is too large: mesonbuild__meson-3721\n",
      "Token count is too large: google__jax-1756\n",
      "Token count is too large: pandas-dev__pandas-28908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 750 examples [00:49, 19.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6213\n",
      "Token count is too large: pandas-dev__pandas-39014\n",
      "Token count is too large: pandas-dev__pandas-26463\n",
      "Token count is too large: Qiskit__qiskit-8444\n",
      "Token count is too large: Qiskit__qiskit-10410\n",
      "Token count is too large: pantsbuild__pants-17093\n",
      "Token count is too large: Qiskit__qiskit-6325\n",
      "Token count is too large: apache__airflow-16108\n",
      "Token count is too large: pandas-dev__pandas-17857\n",
      "Token count is too large: docker__compose-6134\n",
      "Token count is too large: numpy__numpy-21634\n",
      "Token count is too large: mesonbuild__meson-9608\n",
      "Token count is too large: pandas-dev__pandas-3972\n",
      "Token count is too large: google__jax-107\n",
      "Token count is too large: pandas-dev__pandas-37495\n",
      "Token count is too large: pandas-dev__pandas-21214\n",
      "Token count is too large: pantsbuild__pants-14448\n",
      "Token count is too large: Lightning-AI__lightning-2846\n",
      "Token count is too large: pandas-dev__pandas-21027\n",
      "Token count is too large: conda__conda-6313\n",
      "Token count is too large: tiangolo__fastapi-1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 754 examples [00:49, 16.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5492\n",
      "Token count is too large: pandas-dev__pandas-18091\n",
      "Token count is too large: pandas-dev__pandas-8122\n",
      "Token count is too large: pandas-dev__pandas-21935\n",
      "Token count is too large: googleapis__google-cloud-python-289\n",
      "Token count is too large: numpy__numpy-11843\n",
      "Token count is too large: mesonbuild__meson-10580\n",
      "Token count is too large: pandas-dev__pandas-30501\n",
      "Token count is too large: numpy__numpy-23310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 757 examples [00:49, 12.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10557\n",
      "Token count is too large: google__jax-745\n",
      "Token count is too large: ray-project__ray-833\n",
      "Token count is too large: pandas-dev__pandas-6347\n",
      "Token count is too large: ipython__ipython-4832\n",
      "Token count is too large: Qiskit__qiskit-5546\n",
      "Token count is too large: ytdl-org__youtube-dl-14358\n",
      "There was an error processing\n",
      "Token count is too large: Lightning-AI__lightning-1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 759 examples [00:50, 11.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9344\n",
      "Token count is too large: pypa__pip-5148\n",
      "Token count is too large: pandas-dev__pandas-36311\n",
      "Token count is too large: pandas-dev__pandas-16460\n",
      "Token count is too large: explosion__spaCy-2880\n",
      "Token count is too large: pandas-dev__pandas-25092\n",
      "Token count is too large: mesonbuild__meson-7460\n",
      "Token count is too large: pypa__pip-4656\n",
      "Token count is too large: pandas-dev__pandas-25983\n",
      "Token count is too large: apache__airflow-19886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 767 examples [00:50, 19.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-485\n",
      "Token count is too large: docker__compose-7199\n",
      "Token count is too large: numpy__numpy-4872\n",
      "Token count is too large: docker__compose-23\n",
      "Token count is too large: pandas-dev__pandas-8049\n",
      "Token count is too large: Qiskit__qiskit-8021\n",
      "Token count is too large: Qiskit__qiskit-2169\n",
      "Token count is too large: pandas-dev__pandas-19737\n",
      "Token count is too large: ytdl-org__youtube-dl-4598\n",
      "Token count is too large: conan-io__conan-13450\n",
      "Token count is too large: numpy__numpy-11086\n",
      "Token count is too large: googleapis__google-cloud-python-4040\n",
      "Token count is too large: google__jax-685\n",
      "Token count is too large: pantsbuild__pants-5011\n",
      "Token count is too large: conan-io__conan-5898\n",
      "Token count is too large: ytdl-org__youtube-dl-1239\n",
      "Token count is too large: twisted__twisted-11818\n",
      "Token count is too large: conda__conda-6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 771 examples [00:50, 18.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11846\n",
      "Token count is too large: docker__compose-5558\n",
      "Token count is too large: pandas-dev__pandas-18618\n",
      "Token count is too large: pandas-dev__pandas-10469\n",
      "Token count is too large: huggingface__transformers-21207\n",
      "Token count is too large: pypa__pip-3485\n",
      "Token count is too large: dagster-io__dagster-15406\n",
      "Token count is too large: dagster-io__dagster-15384\n",
      "Token count is too large: explosion__spaCy-3253\n",
      "Token count is too large: pandas-dev__pandas-17355\n",
      "Token count is too large: celery__celery-3779\n",
      "Token count is too large: pandas-dev__pandas-30295\n",
      "Token count is too large: Lightning-AI__lightning-310\n",
      "Token count is too large: Qiskit__qiskit-4931\n",
      "Token count is too large: google__jax-1872\n",
      "Token count is too large: conda__conda-6724\n",
      "Token count is too large: Qiskit__qiskit-4326\n",
      "Token count is too large: pandas-dev__pandas-18020\n",
      "Token count is too large: conan-io__conan-4805\n",
      "Token count is too large: pypa__pip-1787\n",
      "Token count is too large: huggingface__transformers-7537\n",
      "Token count is too large: mesonbuild__meson-2046\n",
      "Token count is too large: pandas-dev__pandas-28018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 775 examples [00:51, 13.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36937\n",
      "Token count is too large: pandas-dev__pandas-15924\n",
      "Token count is too large: wagtail__wagtail-10421\n",
      "Token count is too large: pypa__pip-9189\n",
      "Token count is too large: google__jax-257\n",
      "Token count is too large: pandas-dev__pandas-7892\n",
      "Token count is too large: twisted__twisted-1141\n",
      "Token count is too large: celery__celery-4908\n",
      "Token count is too large: pandas-dev__pandas-21238\n",
      "Token count is too large: wagtail__wagtail-9217\n",
      "Token count is too large: apache__airflow-12890\n",
      "Token count is too large: conda__conda-3521\n",
      "Token count is too large: mesonbuild__meson-4657\n",
      "Token count is too large: ray-project__ray-1245\n",
      "Token count is too large: open-mmlab__mmdetection-6104\n",
      "Token count is too large: google__jax-860\n",
      "Token count is too large: googleapis__google-cloud-python-1976\n",
      "Token count is too large: DataDog__integrations-core-1731\n",
      "Token count is too large: conda__conda-4190\n",
      "Token count is too large: huggingface__transformers-17496\n",
      "Token count is too large: pantsbuild__pants-11721\n",
      "Token count is too large: pandas-dev__pandas-24504\n",
      "Token count is too large: apache__airflow-24499\n",
      "Token count is too large: pandas-dev__pandas-23674\n",
      "Token count is too large: PrefectHQ__prefect-2092\n",
      "Token count is too large: pandas-dev__pandas-36413\n",
      "Token count is too large: pandas-dev__pandas-11343\n",
      "Token count is too large: pandas-dev__pandas-24412\n",
      "Token count is too large: numpy__numpy-8160\n",
      "Token count is too large: numpy__numpy-7667\n",
      "Token count is too large: Qiskit__qiskit-395\n",
      "Token count is too large: pantsbuild__pants-16611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 782 examples [00:51, 12.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-7891\n",
      "Token count is too large: pantsbuild__pants-7145\n",
      "Token count is too large: google__jax-2807\n",
      "Token count is too large: pandas-dev__pandas-28336\n",
      "Token count is too large: pandas-dev__pandas-3887\n",
      "Token count is too large: open-mmlab__mmdetection-5884\n",
      "Token count is too large: pypa__pip-8166\n",
      "Token count is too large: docker__compose-1960\n",
      "Token count is too large: ipython__ipython-9182\n",
      "Token count is too large: gitpython-developers__GitPython-755\n",
      "Token count is too large: conan-io__conan-6395\n",
      "Token count is too large: ipython__ipython-1081\n",
      "Token count is too large: ipython__ipython-4209\n",
      "Token count is too large: mesonbuild__meson-9244\n",
      "Token count is too large: Qiskit__qiskit-4818\n",
      "Token count is too large: pandas-dev__pandas-22149\n",
      "Token count is too large: pandas-dev__pandas-16324\n",
      "Token count is too large: pandas-dev__pandas-33644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 784 examples [00:52, 10.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11331\n",
      "Token count is too large: huggingface__transformers-8239\n",
      "Token count is too large: ytdl-org__youtube-dl-5641\n",
      "Token count is too large: pantsbuild__pants-16423\n",
      "Token count is too large: pyca__cryptography-3899\n",
      "Token count is too large: ipython__ipython-13619\n",
      "Token count is too large: numpy__numpy-5307\n",
      "Token count is too large: mesonbuild__meson-6419\n",
      "Token count is too large: apache__airflow-15822\n",
      "Token count is too large: mesonbuild__meson-9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 786 examples [00:52,  9.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29452\n",
      "Token count is too large: mesonbuild__meson-1953\n",
      "Token count is too large: pantsbuild__pants-5089\n",
      "Token count is too large: pypa__pip-6709\n",
      "Token count is too large: numpy__numpy-6488\n",
      "Token count is too large: huggingface__transformers-12963\n",
      "Token count is too large: Qiskit__qiskit-7140\n",
      "Token count is too large: googleapis__google-cloud-python-11169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 788 examples [00:52,  8.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-4497\n",
      "Token count is too large: pandas-dev__pandas-21254\n",
      "Token count is too large: google__jax-197\n",
      "Token count is too large: pantsbuild__pants-18406\n",
      "Token count is too large: conan-io__conan-5971\n",
      "Token count is too large: pandas-dev__pandas-39358\n",
      "Token count is too large: apache__airflow-19481\n",
      "Token count is too large: mesonbuild__meson-2883\n",
      "Token count is too large: google__jax-1106\n",
      "Token count is too large: pyca__cryptography-5295\n",
      "Token count is too large: pypa__pip-12188\n",
      "Token count is too large: jupyterlab__jupyterlab-8950\n",
      "Token count is too large: google__jax-755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 796 examples [00:53, 12.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-3612\n",
      "Token count is too large: conda__conda-6895\n",
      "Token count is too large: ray-project__ray-4775\n",
      "Token count is too large: pandas-dev__pandas-5447\n",
      "Token count is too large: conan-io__conan-3050\n",
      "Token count is too large: google__jax-807\n",
      "Token count is too large: pandas-dev__pandas-39022\n",
      "Token count is too large: apache__airflow-25196\n",
      "Token count is too large: Qiskit__qiskit-4713\n",
      "Token count is too large: pandas-dev__pandas-18831\n",
      "Token count is too large: pandas-dev__pandas-7631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 800 examples [00:53, 15.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-7622\n",
      "Token count is too large: Lightning-AI__lightning-2665\n",
      "Token count is too large: mesonbuild__meson-11982\n",
      "Token count is too large: pandas-dev__pandas-11087\n",
      "Token count is too large: pantsbuild__pants-15403\n",
      "Token count is too large: pandas-dev__pandas-16826\n",
      "Token count is too large: pandas-dev__pandas-23062\n",
      "Token count is too large: PrefectHQ__prefect-2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 802 examples [00:53, 13.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-28693\n",
      "Token count is too large: pandas-dev__pandas-15984\n",
      "Token count is too large: pandas-dev__pandas-39260\n",
      "Token count is too large: ipython__ipython-7853\n",
      "Token count is too large: mesonbuild__meson-5069\n",
      "Token count is too large: numpy__numpy-10558\n",
      "Token count is too large: pandas-dev__pandas-4388\n",
      "Token count is too large: pandas-dev__pandas-6875\n",
      "Token count is too large: mesonbuild__meson-7470\n",
      "Token count is too large: numpy__numpy-23932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 807 examples [00:53, 15.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22024\n",
      "Token count is too large: apache__airflow-364\n",
      "Token count is too large: pandas-dev__pandas-6639\n",
      "Token count is too large: huggingface__transformers-25267\n",
      "Token count is too large: pandas-dev__pandas-17846\n",
      "Token count is too large: pandas-dev__pandas-7971\n",
      "Token count is too large: numpy__numpy-18911\n",
      "Token count is too large: pandas-dev__pandas-22075\n",
      "Token count is too large: Qiskit__qiskit-6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 809 examples [00:54, 10.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-13385\n",
      "Token count is too large: mesonbuild__meson-9631\n",
      "Token count is too large: numpy__numpy-6500\n",
      "Token count is too large: pypa__pip-9822\n",
      "Token count is too large: pandas-dev__pandas-23769\n",
      "Token count is too large: celery__celery-5737\n",
      "Token count is too large: pandas-dev__pandas-37034\n",
      "Token count is too large: mesonbuild__meson-1692\n",
      "Token count is too large: conda__conda-6352\n",
      "Token count is too large: huggingface__transformers-11382\n",
      "Token count is too large: pandas-dev__pandas-10723\n",
      "Token count is too large: pandas-dev__pandas-37776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 815 examples [00:54, 13.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4823\n",
      "Token count is too large: pandas-dev__pandas-30270\n",
      "Token count is too large: conan-io__conan-5837\n",
      "Token count is too large: pyca__cryptography-2071\n",
      "Token count is too large: googleapis__google-cloud-python-2490\n",
      "Token count is too large: pandas-dev__pandas-21799\n",
      "Token count is too large: Qiskit__qiskit-3493\n",
      "Token count is too large: apache__airflow-19148\n",
      "Token count is too large: googleapis__google-cloud-python-6632\n",
      "Token count is too large: pandas-dev__pandas-6879\n",
      "Token count is too large: celery__celery-5613\n",
      "Token count is too large: numpy__numpy-21201\n",
      "Token count is too large: pandas-dev__pandas-27221\n",
      "Token count is too large: docker__compose-393\n",
      "Token count is too large: pyca__cryptography-6246\n",
      "Token count is too large: Qiskit__qiskit-8199\n",
      "Token count is too large: pantsbuild__pants-16186\n",
      "Token count is too large: ipython__ipython-4890\n",
      "Token count is too large: pandas-dev__pandas-30329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 821 examples [00:55, 12.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35736\n",
      "Token count is too large: wagtail__wagtail-4397\n",
      "Token count is too large: numpy__numpy-14310\n",
      "Token count is too large: pandas-dev__pandas-17960\n",
      "Token count is too large: conda__conda-7135\n",
      "Token count is too large: Qiskit__qiskit-2070\n",
      "Token count is too large: pandas-dev__pandas-17738\n",
      "Token count is too large: pandas-dev__pandas-39702\n",
      "Token count is too large: jupyterlab__jupyterlab-5400\n",
      "Token count is too large: pandas-dev__pandas-38982\n",
      "Token count is too large: pandas-dev__pandas-35441\n",
      "Token count is too large: conan-io__conan-3634\n",
      "Token count is too large: docker__compose-3991\n",
      "Token count is too large: Qiskit__qiskit-3888\n",
      "Token count is too large: pypa__pip-6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 823 examples [00:55, 11.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30588\n",
      "Token count is too large: pandas-dev__pandas-2224\n",
      "Token count is too large: pandas-dev__pandas-17023\n",
      "Token count is too large: pandas-dev__pandas-21917\n",
      "Token count is too large: huggingface__transformers-6717\n",
      "Token count is too large: pandas-dev__pandas-19650\n",
      "Token count is too large: google__jax-77\n",
      "Token count is too large: pandas-dev__pandas-22104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 825 examples [00:55, 11.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6042\n",
      "Token count is too large: pandas-dev__pandas-30903\n",
      "Token count is too large: mesonbuild__meson-2852\n",
      "Token count is too large: pandas-dev__pandas-9222\n",
      "Token count is too large: numpy__numpy-15928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 827 examples [00:55, 11.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29470\n",
      "Token count is too large: pypa__pip-4393\n",
      "Token count is too large: pypa__pip-6909\n",
      "Token count is too large: pandas-dev__pandas-29955\n",
      "Token count is too large: numpy__numpy-7675\n",
      "Token count is too large: numpy__numpy-23881\n",
      "Token count is too large: pandas-dev__pandas-26054\n",
      "Token count is too large: pantsbuild__pants-4648\n",
      "Token count is too large: pandas-dev__pandas-3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 829 examples [00:56,  8.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-3174\n",
      "Token count is too large: pypa__pip-5215\n",
      "Token count is too large: huggingface__transformers-18545\n",
      "Token count is too large: pandas-dev__pandas-10199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 833 examples [00:56, 12.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15941\n",
      "Token count is too large: pandas-dev__pandas-4658\n",
      "Token count is too large: conda__conda-9385\n",
      "Token count is too large: googleapis__google-cloud-python-11333\n",
      "Token count is too large: numpy__numpy-21855\n",
      "Token count is too large: numpy__numpy-19893\n",
      "Token count is too large: docker__compose-4761\n",
      "Token count is too large: pandas-dev__pandas-19224\n",
      "Token count is too large: huggingface__transformers-25226\n",
      "Token count is too large: huggingface__transformers-1057\n",
      "Token count is too large: pandas-dev__pandas-10212\n",
      "Token count is too large: numpy__numpy-12831\n",
      "Token count is too large: Qiskit__qiskit-9612\n",
      "Token count is too large: google__jax-754\n",
      "Token count is too large: mesonbuild__meson-5990\n",
      "Token count is too large: celery__celery-4448\n",
      "Token count is too large: mesonbuild__meson-8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 839 examples [00:56, 13.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2781\n",
      "Token count is too large: ray-project__ray-5270\n",
      "Token count is too large: ytdl-org__youtube-dl-1563\n",
      "Token count is too large: conan-io__conan-6138\n",
      "Token count is too large: mesonbuild__meson-1150\n",
      "Token count is too large: PrefectHQ__prefect-192\n",
      "Token count is too large: pandas-dev__pandas-20043\n",
      "Token count is too large: apache__airflow-20121\n",
      "Token count is too large: celery__celery-6330\n",
      "Token count is too large: pandas-dev__pandas-31114\n",
      "Token count is too large: google__jax-1698\n",
      "Token count is too large: scipy__scipy-4302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 842 examples [00:56, 15.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-7299\n",
      "Token count is too large: pandas-dev__pandas-17730\n",
      "Token count is too large: pandas-dev__pandas-26402\n",
      "Token count is too large: Qiskit__qiskit-6109\n",
      "Token count is too large: numpy__numpy-24468\n",
      "Token count is too large: pandas-dev__pandas-24815\n",
      "Token count is too large: pypa__pip-9442\n",
      "Token count is too large: googleapis__google-cloud-python-8837\n",
      "Token count is too large: pypa__pip-8594\n",
      "Token count is too large: ipython__ipython-2855\n",
      "Token count is too large: pandas-dev__pandas-4841\n",
      "Token count is too large: apache__airflow-30608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 846 examples [00:57, 14.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6175\n",
      "Token count is too large: wagtail__wagtail-4136\n",
      "Token count is too large: pandas-dev__pandas-25124\n",
      "Token count is too large: huggingface__transformers-12063\n",
      "Token count is too large: huggingface__transformers-9820\n",
      "Token count is too large: pypa__pip-8343\n",
      "Token count is too large: pantsbuild__pants-18112\n",
      "Token count is too large: ytdl-org__youtube-dl-12512\n",
      "Token count is too large: pypa__pip-6810\n",
      "Token count is too large: numpy__numpy-10946\n",
      "Token count is too large: conan-io__conan-7600\n",
      "Token count is too large: googleapis__google-cloud-python-4257\n",
      "Token count is too large: huggingface__transformers-3143\n",
      "Token count is too large: pantsbuild__pants-18622\n",
      "Token count is too large: huggingface__transformers-4751\n",
      "Token count is too large: pandas-dev__pandas-5978\n",
      "Token count is too large: huggingface__transformers-18044\n",
      "Token count is too large: pandas-dev__pandas-37152\n",
      "Token count is too large: celery__celery-4173\n",
      "Token count is too large: mesonbuild__meson-11986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 850 examples [00:57, 11.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25049\n",
      "Token count is too large: ray-project__ray-10979\n",
      "Token count is too large: Qiskit__qiskit-4223\n",
      "Token count is too large: Lightning-AI__lightning-2594\n",
      "Token count is too large: pantsbuild__pants-16935\n",
      "Token count is too large: pandas-dev__pandas-3736\n",
      "Token count is too large: pandas-dev__pandas-31773\n",
      "Token count is too large: numpy__numpy-21712\n",
      "Token count is too large: huggingface__transformers-18402\n",
      "Token count is too large: Lightning-AI__lightning-52\n",
      "Token count is too large: apache__airflow-11487\n",
      "Token count is too large: conan-io__conan-5112\n",
      "Token count is too large: pandas-dev__pandas-19145\n",
      "Token count is too large: open-mmlab__mmdetection-7147\n",
      "Token count is too large: pandas-dev__pandas-23463\n",
      "Token count is too large: conda__conda-3685\n",
      "Token count is too large: apache__airflow-18772\n",
      "Token count is too large: ray-project__ray-7752\n",
      "Token count is too large: wagtail__wagtail-33\n",
      "Token count is too large: google__jax-1390\n",
      "Token count is too large: huggingface__transformers-17182\n",
      "Token count is too large: pandas-dev__pandas-24096\n",
      "Token count is too large: ray-project__ray-10078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 856 examples [00:57, 13.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: scipy__scipy-5392\n",
      "Token count is too large: docker__compose-5472\n",
      "Token count is too large: pypa__pip-2205\n",
      "Token count is too large: Qiskit__qiskit-4322\n",
      "Token count is too large: Lightning-AI__lightning-3261\n",
      "Token count is too large: pandas-dev__pandas-7720\n",
      "Token count is too large: huggingface__transformers-13179\n",
      "Token count is too large: apache__airflow-30641\n",
      "Token count is too large: apache__airflow-25673\n",
      "Token count is too large: pandas-dev__pandas-15538\n",
      "Token count is too large: googleapis__google-cloud-python-783\n",
      "Token count is too large: Qiskit__qiskit-1718\n",
      "Token count is too large: pantsbuild__pants-10764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 858 examples [00:58, 11.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4206\n",
      "Token count is too large: googleapis__google-cloud-python-5295\n",
      "Token count is too large: googleapis__google-cloud-python-8436\n",
      "Token count is too large: ipython__ipython-7389\n",
      "Token count is too large: Qiskit__qiskit-2997\n",
      "Token count is too large: Qiskit__qiskit-5946\n",
      "Token count is too large: googleapis__google-cloud-python-6935\n",
      "Token count is too large: apache__airflow-9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 860 examples [00:58, 13.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9283\n",
      "Token count is too large: pandas-dev__pandas-26071\n",
      "Token count is too large: pandas-dev__pandas-16465\n",
      "Token count is too large: Lightning-AI__lightning-2335\n",
      "Token count is too large: wagtail__wagtail-9920\n",
      "Token count is too large: google__jax-484\n",
      "Token count is too large: pandas-dev__pandas-38579\n",
      "Token count is too large: pandas-dev__pandas-21590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 867 examples [00:58, 15.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-17732\n",
      "Token count is too large: mesonbuild__meson-4300\n",
      "Token count is too large: pandas-dev__pandas-23652\n",
      "Token count is too large: googleapis__google-cloud-python-11302\n",
      "Token count is too large: pandas-dev__pandas-6373\n",
      "Token count is too large: ipython__ipython-13501\n",
      "Token count is too large: pandas-dev__pandas-29553\n",
      "Token count is too large: Lightning-AI__lightning-2379\n",
      "Token count is too large: pandas-dev__pandas-36730\n",
      "Token count is too large: Qiskit__qiskit-3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 872 examples [00:58, 18.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9929\n",
      "Token count is too large: googleapis__google-cloud-python-509\n",
      "Token count is too large: pantsbuild__pants-12699\n",
      "Token count is too large: mesonbuild__meson-10306\n",
      "Token count is too large: conan-io__conan-5841\n",
      "Token count is too large: pandas-dev__pandas-22667\n",
      "Token count is too large: apache__airflow-22964\n",
      "Token count is too large: pandas-dev__pandas-39353\n",
      "Token count is too large: conda__conda-1808\n",
      "Token count is too large: conda__conda-6928\n",
      "Token count is too large: pypa__pip-5798\n",
      "Token count is too large: numpy__numpy-12898\n",
      "Token count is too large: pandas-dev__pandas-26306\n",
      "Token count is too large: pandas-dev__pandas-19790\n",
      "Token count is too large: google__jax-910\n",
      "Token count is too large: pandas-dev__pandas-7674\n",
      "Token count is too large: google__jax-638\n",
      "Token count is too large: wagtail__wagtail-10661\n",
      "Token count is too large: pandas-dev__pandas-20017\n",
      "Token count is too large: googleapis__google-cloud-python-6438\n",
      "Token count is too large: pandas-dev__pandas-4302\n",
      "Token count is too large: ipython__ipython-5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 875 examples [00:59, 14.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-25995\n",
      "Token count is too large: pandas-dev__pandas-5638\n",
      "Token count is too large: docker__compose-8178\n",
      "Token count is too large: Qiskit__qiskit-4568\n",
      "Token count is too large: pandas-dev__pandas-36224\n",
      "Token count is too large: google__jax-495\n",
      "Token count is too large: googleapis__google-cloud-python-4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 878 examples [00:59, 12.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21062\n",
      "Token count is too large: ytdl-org__youtube-dl-31360\n",
      "Token count is too large: huggingface__transformers-23641\n",
      "Token count is too large: pandas-dev__pandas-27077\n",
      "Token count is too large: ray-project__ray-1760\n",
      "Token count is too large: pandas-dev__pandas-18718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 881 examples [00:59, 14.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12551\n",
      "Token count is too large: pandas-dev__pandas-36655\n",
      "Token count is too large: google__jax-960\n",
      "Token count is too large: huggingface__transformers-873\n",
      "Token count is too large: googleapis__google-cloud-python-9875\n",
      "Token count is too large: pandas-dev__pandas-27773\n",
      "Token count is too large: Qiskit__qiskit-5073\n",
      "Token count is too large: pandas-dev__pandas-8671\n",
      "Token count is too large: pandas-dev__pandas-35664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 883 examples [01:00, 11.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11346\n",
      "Token count is too large: pandas-dev__pandas-7323\n",
      "Token count is too large: pandas-dev__pandas-37320\n",
      "Token count is too large: pandas-dev__pandas-37249\n",
      "Token count is too large: pandas-dev__pandas-6506\n",
      "Token count is too large: pandas-dev__pandas-36348\n",
      "Token count is too large: Qiskit__qiskit-9100\n",
      "Token count is too large: apache__airflow-9843\n",
      "Token count is too large: pandas-dev__pandas-6579\n",
      "Token count is too large: Qiskit__qiskit-2890\n",
      "Token count is too large: pandas-dev__pandas-29257\n",
      "Token count is too large: mesonbuild__meson-1171\n",
      "Token count is too large: pandas-dev__pandas-24968\n",
      "Token count is too large: jupyterlab__jupyterlab-3168\n",
      "Token count is too large: scipy__scipy-5288\n",
      "Token count is too large: pandas-dev__pandas-6481\n",
      "Token count is too large: pandas-dev__pandas-26465\n",
      "Token count is too large: pandas-dev__pandas-3597\n",
      "Token count is too large: huggingface__transformers-16496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 885 examples [01:00,  7.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5752\n",
      "Token count is too large: pandas-dev__pandas-19251\n",
      "Token count is too large: pandas-dev__pandas-32959\n",
      "Token count is too large: numpy__numpy-19775\n",
      "Token count is too large: huggingface__transformers-18650\n",
      "Token count is too large: ray-project__ray-1445\n",
      "Token count is too large: jupyterlab__jupyterlab-2697\n",
      "Token count is too large: pantsbuild__pants-15610\n",
      "Token count is too large: google__jax-965\n",
      "Token count is too large: Qiskit__qiskit-7211\n",
      "Token count is too large: apache__airflow-15105\n",
      "Token count is too large: pandas-dev__pandas-38571\n",
      "Token count is too large: Qiskit__qiskit-8173\n",
      "Token count is too large: google__jax-199\n",
      "Token count is too large: pandas-dev__pandas-39737\n",
      "Token count is too large: docker__compose-5926\n",
      "Token count is too large: google__jax-3061\n",
      "Token count is too large: conan-io__conan-4494\n",
      "Token count is too large: mesonbuild__meson-7976\n",
      "Token count is too large: wagtail__wagtail-8382\n",
      "Token count is too large: pantsbuild__pants-17787\n",
      "Token count is too large: apache__airflow-26608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 896 examples [01:01, 13.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32477\n",
      "Token count is too large: apache__airflow-27591\n",
      "Token count is too large: pandas-dev__pandas-23167\n",
      "Token count is too large: mesonbuild__meson-6005\n",
      "Token count is too large: pandas-dev__pandas-11865\n",
      "Token count is too large: conan-io__conan-622\n",
      "Token count is too large: pandas-dev__pandas-6814\n",
      "Token count is too large: pandas-dev__pandas-17341\n",
      "Token count is too large: googleapis__google-cloud-python-1557\n",
      "Token count is too large: open-mmlab__mmdetection-9734\n",
      "Token count is too large: Qiskit__qiskit-4940\n",
      "Token count is too large: conda__conda-12487\n",
      "Token count is too large: pypa__pip-1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 898 examples [01:01, 12.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22647\n",
      "Token count is too large: numpy__numpy-9845\n",
      "Token count is too large: googleapis__google-cloud-python-5654\n",
      "Token count is too large: conan-io__conan-4122\n",
      "Token count is too large: pandas-dev__pandas-22511\n",
      "Token count is too large: docker__compose-4997\n",
      "Token count is too large: Qiskit__qiskit-4885\n",
      "Token count is too large: google__jax-1697\n",
      "Token count is too large: pandas-dev__pandas-7862\n",
      "Token count is too large: googleapis__google-cloud-python-5966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 902 examples [01:01, 14.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18729\n",
      "Token count is too large: pandas-dev__pandas-26744\n",
      "Token count is too large: open-mmlab__mmdetection-3522\n",
      "Token count is too large: numpy__numpy-11733\n",
      "Token count is too large: pandas-dev__pandas-17624\n",
      "Token count is too large: huggingface__transformers-18046\n",
      "Token count is too large: pandas-dev__pandas-23237\n",
      "Token count is too large: Lightning-AI__lightning-2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 905 examples [01:01, 14.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-25795\n",
      "Token count is too large: ray-project__ray-4323\n",
      "Token count is too large: conda__conda-3210\n",
      "Token count is too large: pantsbuild__pants-6880\n",
      "Token count is too large: jupyterlab__jupyterlab-9232\n",
      "Token count is too large: pandas-dev__pandas-23739\n",
      "Token count is too large: pyca__cryptography-4864\n",
      "Token count is too large: pandas-dev__pandas-7798\n",
      "Token count is too large: pandas-dev__pandas-34983\n",
      "Token count is too large: huggingface__transformers-9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 907 examples [01:01, 12.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-8370\n",
      "Token count is too large: pandas-dev__pandas-30585\n",
      "Token count is too large: pandas-dev__pandas-3874\n",
      "Token count is too large: mesonbuild__meson-3481\n",
      "Token count is too large: Lightning-AI__lightning-481\n",
      "Token count is too large: mesonbuild__meson-9708\n",
      "Token count is too large: huggingface__transformers-14746\n",
      "Token count is too large: huggingface__transformers-10856\n",
      "Token count is too large: numpy__numpy-11859\n",
      "Token count is too large: huggingface__transformers-4448\n",
      "Token count is too large: pantsbuild__pants-18877\n",
      "Token count is too large: mesonbuild__meson-6829\n",
      "Token count is too large: PrefectHQ__prefect-437\n",
      "Token count is too large: numpy__numpy-11382\n",
      "Token count is too large: numpy__numpy-10544\n",
      "Token count is too large: gitpython-developers__GitPython-1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 913 examples [01:02, 14.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39482\n",
      "Token count is too large: apache__airflow-23674\n",
      "Token count is too large: Qiskit__qiskit-5630\n",
      "Token count is too large: wagtail__wagtail-9161\n",
      "Token count is too large: pandas-dev__pandas-7665\n",
      "Token count is too large: ytdl-org__youtube-dl-31181\n",
      "Token count is too large: mesonbuild__meson-10783\n",
      "Token count is too large: pandas-dev__pandas-33118\n",
      "Token count is too large: pandas-dev__pandas-19923\n",
      "Token count is too large: numpy__numpy-21807\n",
      "Token count is too large: huggingface__transformers-13275\n",
      "Token count is too large: pantsbuild__pants-5045\n",
      "Token count is too large: pypa__pip-10044\n",
      "Token count is too large: pantsbuild__pants-13319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 926 examples [01:02, 24.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-7285\n",
      "Token count is too large: pyca__cryptography-2828\n",
      "Token count is too large: apache__airflow-15074\n",
      "Token count is too large: jupyterlab__jupyterlab-3270\n",
      "Token count is too large: pandas-dev__pandas-21711\n",
      "Token count is too large: numpy__numpy-10947\n",
      "Token count is too large: jupyterlab__jupyterlab-7979\n",
      "Token count is too large: celery__celery-5500\n",
      "Token count is too large: huggingface__transformers-3973\n",
      "Token count is too large: googleapis__google-cloud-python-364\n",
      "Token count is too large: huggingface__transformers-18443\n",
      "Token count is too large: ytdl-org__youtube-dl-5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 930 examples [01:02, 25.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23034\n",
      "Token count is too large: pypa__pip-9264\n",
      "Token count is too large: pandas-dev__pandas-22535\n",
      "Token count is too large: apache__airflow-29225\n",
      "Token count is too large: scipy__scipy-456\n",
      "Token count is too large: pandas-dev__pandas-23921\n",
      "Token count is too large: jupyterlab__jupyterlab-7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 935 examples [01:03, 26.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-2917\n",
      "Token count is too large: google__jax-720\n",
      "Token count is too large: Qiskit__qiskit-6580\n",
      "Token count is too large: pandas-dev__pandas-14708\n",
      "Token count is too large: jupyterlab__jupyterlab-6058\n",
      "Token count is too large: pandas-dev__pandas-39083\n",
      "Token count is too large: Qiskit__qiskit-2933\n",
      "Token count is too large: google__jax-868\n",
      "Token count is too large: pandas-dev__pandas-34718\n",
      "Token count is too large: google__jax-1955\n",
      "Token count is too large: ipython__ipython-11528\n",
      "Token count is too large: Lightning-AI__lightning-848\n",
      "Token count is too large: pandas-dev__pandas-21686\n",
      "Token count is too large: ytdl-org__youtube-dl-30532\n",
      "Token count is too large: pandas-dev__pandas-38861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 943 examples [01:03, 25.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-12627\n",
      "Token count is too large: Qiskit__qiskit-8299\n",
      "Token count is too large: pandas-dev__pandas-36299\n",
      "Token count is too large: numpy__numpy-3608\n",
      "Token count is too large: pandas-dev__pandas-32124\n",
      "Token count is too large: numpy__numpy-8200\n",
      "Token count is too large: mesonbuild__meson-4207\n",
      "Token count is too large: docker__compose-7714\n",
      "Token count is too large: Qiskit__qiskit-7431\n",
      "Token count is too large: docker__compose-5329\n",
      "Token count is too large: mesonbuild__meson-4084\n",
      "Token count is too large: pandas-dev__pandas-31897\n",
      "Token count is too large: pantsbuild__pants-5267\n",
      "Token count is too large: Qiskit__qiskit-2812\n",
      "Token count is too large: celery__celery-6447\n",
      "Token count is too large: pandas-dev__pandas-5819\n",
      "Token count is too large: pandas-dev__pandas-18550\n",
      "Token count is too large: googleapis__google-cloud-python-11332\n",
      "Token count is too large: huggingface__transformers-19684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 947 examples [01:03, 19.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23618\n",
      "Token count is too large: conan-io__conan-1065\n",
      "Token count is too large: pandas-dev__pandas-37181\n",
      "Token count is too large: googleapis__google-cloud-python-9176\n",
      "Token count is too large: googleapis__google-cloud-python-581\n",
      "Token count is too large: ray-project__ray-6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 951 examples [01:04, 14.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21401\n",
      "Token count is too large: numpy__numpy-4666\n",
      "Token count is too large: huggingface__transformers-8868\n",
      "Token count is too large: huggingface__transformers-11964\n",
      "Token count is too large: ray-project__ray-3937\n",
      "Token count is too large: ray-project__ray-7662\n",
      "Token count is too large: mesonbuild__meson-1396\n",
      "Token count is too large: pantsbuild__pants-17461\n",
      "Token count is too large: mesonbuild__meson-5477\n",
      "Token count is too large: pandas-dev__pandas-16153\n",
      "Token count is too large: PrefectHQ__prefect-583\n",
      "Token count is too large: Lightning-AI__lightning-2925\n",
      "Token count is too large: pandas-dev__pandas-14308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 953 examples [01:04, 13.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23223\n",
      "Token count is too large: jupyterlab__jupyterlab-7461\n",
      "Token count is too large: pandas-dev__pandas-3166\n",
      "Token count is too large: pandas-dev__pandas-7362\n",
      "Token count is too large: conan-io__conan-2770\n",
      "Token count is too large: conan-io__conan-5875\n",
      "Token count is too large: ray-project__ray-8511\n",
      "Token count is too large: mesonbuild__meson-6156\n",
      "Token count is too large: pandas-dev__pandas-4729\n",
      "Token count is too large: Qiskit__qiskit-5954\n",
      "Token count is too large: mesonbuild__meson-4649\n",
      "Token count is too large: Qiskit__qiskit-3100\n",
      "Token count is too large: googleapis__google-cloud-python-1750\n",
      "Token count is too large: google__jax-1298\n",
      "Token count is too large: pandas-dev__pandas-36911\n",
      "Token count is too large: Lightning-AI__lightning-903\n",
      "Token count is too large: pypa__pip-1748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 958 examples [01:04, 12.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23611\n",
      "Token count is too large: pandas-dev__pandas-22982\n",
      "Token count is too large: pandas-dev__pandas-29179\n",
      "Token count is too large: DataDog__integrations-core-5694\n",
      "Token count is too large: pandas-dev__pandas-16196\n",
      "Token count is too large: Qiskit__qiskit-7450\n",
      "Token count is too large: celery__celery-5095\n",
      "Token count is too large: ray-project__ray-3130\n",
      "Token count is too large: Lightning-AI__lightning-3043\n",
      "Token count is too large: Lightning-AI__lightning-3274\n",
      "Token count is too large: pandas-dev__pandas-31841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 962 examples [01:04, 15.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-7195\n",
      "Token count is too large: pandas-dev__pandas-3675\n",
      "Token count is too large: pandas-dev__pandas-7416\n",
      "Token count is too large: Qiskit__qiskit-6530\n",
      "Token count is too large: pandas-dev__pandas-27279\n",
      "Token count is too large: ipython__ipython-2776\n",
      "Token count is too large: PrefectHQ__prefect-610\n",
      "Token count is too large: docker__compose-5476\n",
      "Token count is too large: google__jax-742\n",
      "Token count is too large: conda__conda-3633\n",
      "Token count is too large: pypa__pip-5053\n",
      "Token count is too large: pandas-dev__pandas-22786\n",
      "Token count is too large: google__jax-800\n",
      "Token count is too large: mesonbuild__meson-9152\n",
      "Token count is too large: google__jax-2810\n",
      "Token count is too large: Lightning-AI__lightning-2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 965 examples [01:05, 12.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23871\n",
      "Token count is too large: google__jax-3149\n",
      "Token count is too large: Qiskit__qiskit-6348\n",
      "Token count is too large: pandas-dev__pandas-17298\n",
      "Token count is too large: ipython__ipython-4489\n",
      "Token count is too large: pyca__cryptography-3473\n",
      "Token count is too large: conda__conda-5382\n",
      "Token count is too large: pandas-dev__pandas-26228\n",
      "Token count is too large: pypa__pip-2937\n",
      "Token count is too large: mesonbuild__meson-8489\n",
      "Token count is too large: conda__conda-8999\n",
      "Token count is too large: huggingface__transformers-24407\n",
      "Token count is too large: mesonbuild__meson-3724\n",
      "Token count is too large: pyca__cryptography-2186\n",
      "Token count is too large: gitpython-developers__GitPython-537\n",
      "Token count is too large: huggingface__transformers-15623\n",
      "Token count is too large: huggingface__transformers-11492\n",
      "Token count is too large: googleapis__google-cloud-python-7206\n",
      "Token count is too large: pandas-dev__pandas-21531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 971 examples [01:05, 11.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25375\n",
      "Token count is too large: pyca__cryptography-4592\n",
      "Token count is too large: numpy__numpy-22657\n",
      "Token count is too large: huggingface__transformers-6915\n",
      "Token count is too large: mesonbuild__meson-5971\n",
      "Token count is too large: pyca__cryptography-2072\n",
      "Token count is too large: pandas-dev__pandas-39605\n",
      "Token count is too large: huggingface__transformers-20662\n",
      "Token count is too large: pantsbuild__pants-13539\n",
      "Token count is too large: huggingface__transformers-5331\n",
      "Token count is too large: Qiskit__qiskit-2266\n",
      "Token count is too large: pandas-dev__pandas-3286\n",
      "Token count is too large: jupyterlab__jupyterlab-3914\n",
      "Token count is too large: conda__conda-7562\n",
      "Token count is too large: pandas-dev__pandas-36716\n",
      "Token count is too large: numpy__numpy-3237\n",
      "Token count is too large: pandas-dev__pandas-4153\n",
      "Token count is too large: celery__celery-5684\n",
      "Token count is too large: numpy__numpy-6763\n",
      "Token count is too large: conan-io__conan-4128\n",
      "Token count is too large: pandas-dev__pandas-16858\n",
      "Token count is too large: huggingface__transformers-15310\n",
      "Token count is too large: googleapis__google-cloud-python-4895\n",
      "Token count is too large: numpy__numpy-20972\n",
      "Token count is too large: pandas-dev__pandas-16489\n",
      "Token count is too large: pandas-dev__pandas-25533\n",
      "Token count is too large: pypa__pip-3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 975 examples [01:06,  8.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20839\n",
      "Token count is too large: pandas-dev__pandas-38010\n",
      "Token count is too large: conda__conda-11044\n",
      "Token count is too large: Qiskit__qiskit-2103\n",
      "Token count is too large: ipython__ipython-1284\n",
      "Token count is too large: numpy__numpy-12413\n",
      "Token count is too large: pandas-dev__pandas-4039\n",
      "Token count is too large: pantsbuild__pants-7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 977 examples [01:06,  8.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10812\n",
      "Token count is too large: tensorflow__models-2727\n",
      "Token count is too large: huggingface__transformers-23468\n",
      "Token count is too large: Qiskit__qiskit-7682\n",
      "Token count is too large: huggingface__transformers-14294\n",
      "Token count is too large: ipython__ipython-2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 986 examples [01:07, 13.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22653\n",
      "Token count is too large: conda__conda-8163\n",
      "Token count is too large: conan-io__conan-242\n",
      "Token count is too large: numpy__numpy-14540\n",
      "Token count is too large: numpy__numpy-5092\n",
      "Token count is too large: PrefectHQ__prefect-568\n",
      "Token count is too large: google__jax-3155\n",
      "Token count is too large: docker__compose-5822\n",
      "Token count is too large: numpy__numpy-10371\n",
      "Token count is too large: huggingface__transformers-21410\n",
      "Token count is too large: ipython__ipython-10907\n",
      "Token count is too large: docker__compose-2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 993 examples [01:07, 19.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11765\n",
      "Token count is too large: googleapis__google-cloud-python-10010\n",
      "Token count is too large: pandas-dev__pandas-10105\n",
      "Token count is too large: pandas-dev__pandas-25427\n",
      "Token count is too large: ytdl-org__youtube-dl-23885\n",
      "Token count is too large: mesonbuild__meson-4129\n",
      "Token count is too large: ipython__ipython-6961\n",
      "Token count is too large: Lightning-AI__lightning-2269\n",
      "Token count is too large: PrefectHQ__prefect-670\n",
      "Token count is too large: pantsbuild__pants-6686\n",
      "Token count is too large: huggingface__transformers-4538\n",
      "Token count is too large: numpy__numpy-13499\n",
      "Token count is too large: conda__conda-3832\n",
      "Token count is too large: Qiskit__qiskit-10392\n",
      "Token count is too large: pandas-dev__pandas-6968\n",
      "Token count is too large: pandas-dev__pandas-21162\n",
      "Token count is too large: conda__conda-620\n",
      "Token count is too large: mesonbuild__meson-4954\n",
      "Token count is too large: Qiskit__qiskit-10400\n",
      "Token count is too large: mesonbuild__meson-1286\n",
      "Token count is too large: pantsbuild__pants-12280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 997 examples [01:07, 13.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6818\n",
      "Token count is too large: Qiskit__qiskit-7229\n",
      "Token count is too large: pandas-dev__pandas-31482\n",
      "Token count is too large: conda__conda-5250\n",
      "Token count is too large: huggingface__transformers-9486\n",
      "Token count is too large: ray-project__ray-10866\n",
      "Token count is too large: ipython__ipython-10638\n",
      "Token count is too large: numpy__numpy-16291\n",
      "Token count is too large: Qiskit__qiskit-8648\n",
      "Token count is too large: conan-io__conan-10984\n",
      "Token count is too large: google__jax-1658\n",
      "Token count is too large: pypa__pip-4384\n",
      "Token count is too large: ray-project__ray-3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [01:08, 11.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-11854\n",
      "Token count is too large: Qiskit__qiskit-4297\n",
      "Token count is too large: pandas-dev__pandas-14737\n",
      "Token count is too large: numpy__numpy-7608\n",
      "Token count is too large: pandas-dev__pandas-4410\n",
      "Token count is too large: pyca__cryptography-4681\n",
      "Token count is too large: pandas-dev__pandas-36015\n",
      "Token count is too large: pandas-dev__pandas-29808\n",
      "Token count is too large: pypa__pip-5090\n",
      "Token count is too large: pandas-dev__pandas-8668\n",
      "Token count is too large: ipython__ipython-8046\n",
      "Token count is too large: pandas-dev__pandas-12058\n",
      "Token count is too large: pandas-dev__pandas-22600\n",
      "Token count is too large: pandas-dev__pandas-18883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1004 examples [01:08, 11.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11223\n",
      "Token count is too large: Qiskit__qiskit-2559\n",
      "Token count is too large: celery__celery-6758\n",
      "Token count is too large: huggingface__transformers-17513\n",
      "Token count is too large: docker__compose-5583\n",
      "Token count is too large: pandas-dev__pandas-36094\n",
      "Token count is too large: Qiskit__qiskit-1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1006 examples [01:08, 11.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21288\n",
      "Token count is too large: ytdl-org__youtube-dl-764\n",
      "Token count is too large: pandas-dev__pandas-37744\n",
      "Token count is too large: mesonbuild__meson-428\n",
      "Token count is too large: pandas-dev__pandas-7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1010 examples [01:09, 11.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: scipy__scipy-2730\n",
      "Token count is too large: twisted__twisted-971\n",
      "Token count is too large: pandas-dev__pandas-28444\n",
      "Token count is too large: google__jax-1429\n",
      "Token count is too large: googleapis__google-cloud-python-11327\n",
      "Token count is too large: PrefectHQ__prefect-2934\n",
      "Token count is too large: pandas-dev__pandas-11102\n",
      "Token count is too large: pyca__cryptography-6272\n",
      "Token count is too large: apache__airflow-11195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1012 examples [01:09, 11.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-9566\n",
      "Token count is too large: mesonbuild__meson-7084\n",
      "Token count is too large: Qiskit__qiskit-5827\n",
      "Token count is too large: pantsbuild__pants-7924\n",
      "Token count is too large: docker__compose-7435\n",
      "Token count is too large: Qiskit__qiskit-5548\n",
      "Token count is too large: Qiskit__qiskit-4678\n",
      "Token count is too large: huggingface__transformers-2400\n",
      "Token count is too large: huggingface__transformers-11945\n",
      "Token count is too large: conda__conda-7180\n",
      "Token count is too large: mesonbuild__meson-9165\n",
      "Token count is too large: conan-io__conan-7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1019 examples [01:09, 19.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32701\n",
      "Token count is too large: Qiskit__qiskit-8250\n",
      "Token count is too large: celery__celery-6059\n",
      "Token count is too large: numpy__numpy-9013\n",
      "Token count is too large: ytdl-org__youtube-dl-5533\n",
      "Token count is too large: pandas-dev__pandas-28935\n",
      "Token count is too large: numpy__numpy-14392\n",
      "Token count is too large: Lightning-AI__lightning-2981\n",
      "Token count is too large: ipython__ipython-4624\n",
      "Token count is too large: ray-project__ray-10953\n",
      "Token count is too large: apache__airflow-15599\n",
      "Token count is too large: google__jax-1664\n",
      "Token count is too large: Qiskit__qiskit-10148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1027 examples [01:09, 20.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20912\n",
      "Token count is too large: numpy__numpy-8617\n",
      "Token count is too large: conan-io__conan-6700\n",
      "Token count is too large: scipy__scipy-148\n",
      "Token count is too large: pandas-dev__pandas-26816\n",
      "Token count is too large: pandas-dev__pandas-34767\n",
      "Token count is too large: pandas-dev__pandas-9818\n",
      "Token count is too large: google__jax-2400\n",
      "Token count is too large: pandas-dev__pandas-34416\n",
      "Token count is too large: apache__airflow-10643\n",
      "Token count is too large: pandas-dev__pandas-35498\n",
      "Token count is too large: mesonbuild__meson-3744\n",
      "Token count is too large: pantsbuild__pants-17649\n",
      "Token count is too large: pypa__pip-6225\n",
      "Token count is too large: mesonbuild__meson-8833\n",
      "Token count is too large: ytdl-org__youtube-dl-14107\n",
      "Token count is too large: Qiskit__qiskit-8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1033 examples [01:10, 17.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21861\n",
      "Token count is too large: huggingface__transformers-13813\n",
      "Token count is too large: pandas-dev__pandas-25469\n",
      "Token count is too large: mesonbuild__meson-10803\n",
      "Token count is too large: googleapis__google-cloud-python-2039\n",
      "Token count is too large: pantsbuild__pants-14229\n",
      "Token count is too large: pandas-dev__pandas-36364\n",
      "Token count is too large: pandas-dev__pandas-25810\n",
      "Token count is too large: apache__airflow-23053\n",
      "Token count is too large: mesonbuild__meson-10049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1035 examples [01:10, 16.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-18554\n",
      "Token count is too large: conda__conda-12097\n",
      "Token count is too large: Qiskit__qiskit-6040\n",
      "Token count is too large: wagtail__wagtail-7850\n",
      "Token count is too large: gitpython-developers__GitPython-1314\n",
      "Token count is too large: pandas-dev__pandas-9109\n",
      "Token count is too large: ipython__ipython-3529\n",
      "Token count is too large: celery__celery-4690\n",
      "Token count is too large: docker__compose-3762\n",
      "Token count is too large: Qiskit__qiskit-3777\n",
      "Token count is too large: Qiskit__qiskit-5808\n",
      "Token count is too large: huggingface__transformers-7610\n",
      "Token count is too large: pandas-dev__pandas-10794\n",
      "Token count is too large: mesonbuild__meson-4414\n",
      "Token count is too large: pandas-dev__pandas-25853\n",
      "Token count is too large: Lightning-AI__lightning-1773\n",
      "Token count is too large: huggingface__transformers-13859\n",
      "Token count is too large: google__jax-3390\n",
      "Token count is too large: numpy__numpy-22046\n",
      "Token count is too large: pandas-dev__pandas-9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1038 examples [01:10, 12.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-9128\n",
      "Token count is too large: pandas-dev__pandas-31875\n",
      "Token count is too large: pandas-dev__pandas-33962\n",
      "Token count is too large: pandas-dev__pandas-25431\n",
      "Token count is too large: pandas-dev__pandas-19772\n",
      "Token count is too large: pandas-dev__pandas-37132\n",
      "Token count is too large: pantsbuild__pants-11620\n",
      "Token count is too large: conan-io__conan-2884\n",
      "Token count is too large: mesonbuild__meson-4696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1046 examples [01:11, 16.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9258\n",
      "Token count is too large: googleapis__google-cloud-python-7793\n",
      "Token count is too large: ytdl-org__youtube-dl-1204\n",
      "Token count is too large: scipy__scipy-2917\n",
      "Token count is too large: conda__conda-1807\n",
      "Token count is too large: wagtail__wagtail-7590\n",
      "Token count is too large: apache__airflow-33408\n",
      "Token count is too large: numpy__numpy-10674\n",
      "Token count is too large: pandas-dev__pandas-11923\n",
      "Token count is too large: pandas-dev__pandas-13894\n",
      "Token count is too large: pantsbuild__pants-13078\n",
      "Token count is too large: DataDog__integrations-core-8362\n",
      "Token count is too large: ytdl-org__youtube-dl-30122\n",
      "Token count is too large: docker__compose-3898\n",
      "Token count is too large: pandas-dev__pandas-10889\n",
      "Token count is too large: conan-io__conan-2967\n",
      "Token count is too large: ipython__ipython-374\n",
      "Token count is too large: mesonbuild__meson-10250\n",
      "Token count is too large: pandas-dev__pandas-27467\n",
      "Token count is too large: apache__airflow-13057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1053 examples [01:11, 18.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33884\n",
      "Token count is too large: pandas-dev__pandas-39141\n",
      "Token count is too large: pandas-dev__pandas-22754\n",
      "Token count is too large: googleapis__google-cloud-python-5756\n",
      "Token count is too large: Lightning-AI__lightning-3345\n",
      "Token count is too large: huggingface__transformers-11825\n",
      "Token count is too large: pandas-dev__pandas-13858\n",
      "Token count is too large: conan-io__conan-2653\n",
      "Token count is too large: pyca__cryptography-2813\n",
      "Token count is too large: huggingface__transformers-5025\n",
      "Token count is too large: pandas-dev__pandas-22987\n",
      "Token count is too large: celery__celery-5954\n",
      "Token count is too large: pandas-dev__pandas-20971\n",
      "Token count is too large: scipy__scipy-188\n",
      "Token count is too large: google__jax-298\n",
      "Token count is too large: mesonbuild__meson-9636\n",
      "Token count is too large: huggingface__transformers-21766\n",
      "Token count is too large: numpy__numpy-5824\n",
      "Token count is too large: mesonbuild__meson-6199\n",
      "Token count is too large: pandas-dev__pandas-34334\n",
      "Token count is too large: pandas-dev__pandas-4530\n",
      "Token count is too large: huggingface__transformers-21956\n",
      "Token count is too large: conan-io__conan-7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1060 examples [01:12, 13.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-8556\n",
      "Token count is too large: pandas-dev__pandas-30978\n",
      "There was an error processing\n",
      "Token count is too large: pypa__pip-2076\n",
      "Token count is too large: Qiskit__qiskit-7856\n",
      "Token count is too large: pandas-dev__pandas-28428\n",
      "Token count is too large: googleapis__google-cloud-python-2806\n",
      "Token count is too large: pandas-dev__pandas-23114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1066 examples [01:12, 15.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-7599\n",
      "Token count is too large: celery__celery-8374\n",
      "Token count is too large: pandas-dev__pandas-16752\n",
      "Token count is too large: pantsbuild__pants-16481\n",
      "Token count is too large: ipython__ipython-11182\n",
      "Token count is too large: numpy__numpy-12353\n",
      "Token count is too large: pandas-dev__pandas-2962\n",
      "Token count is too large: open-mmlab__mmdetection-7808\n",
      "Token count is too large: apache__airflow-22658\n",
      "Token count is too large: pandas-dev__pandas-22131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1072 examples [01:13, 14.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-6146\n",
      "Token count is too large: mesonbuild__meson-997\n",
      "Token count is too large: mesonbuild__meson-2624\n",
      "Token count is too large: Qiskit__qiskit-2043\n",
      "Token count is too large: huggingface__transformers-13989\n",
      "Token count is too large: DataDog__integrations-core-9468\n",
      "Token count is too large: ytdl-org__youtube-dl-4009\n",
      "Token count is too large: wagtail__wagtail-7591\n",
      "Token count is too large: pandas-dev__pandas-22106\n",
      "Token count is too large: google__jax-3463\n",
      "Token count is too large: docker__compose-2722\n",
      "Token count is too large: pantsbuild__pants-5170\n",
      "Token count is too large: Lightning-AI__lightning-3042\n",
      "Token count is too large: apache__airflow-26191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1074 examples [01:13, 12.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-13768\n",
      "Token count is too large: conda__conda-5230\n",
      "Token count is too large: conan-io__conan-6780\n",
      "Token count is too large: pandas-dev__pandas-22762\n",
      "Token count is too large: wagtail__wagtail-621\n",
      "Token count is too large: huggingface__transformers-3517\n",
      "Token count is too large: huggingface__transformers-8518\n",
      "Token count is too large: pandas-dev__pandas-8812\n",
      "Token count is too large: PrefectHQ__prefect-266\n",
      "Token count is too large: PrefectHQ__prefect-2413\n",
      "Token count is too large: pandas-dev__pandas-28181\n",
      "Token count is too large: pandas-dev__pandas-19024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1076 examples [01:13, 13.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24927\n",
      "Token count is too large: pandas-dev__pandas-20698\n",
      "Token count is too large: pandas-dev__pandas-21923\n",
      "Token count is too large: conda__conda-12880\n",
      "Token count is too large: ipython__ipython-3787\n",
      "Token count is too large: pandas-dev__pandas-23321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1082 examples [01:13, 14.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-28003\n",
      "Token count is too large: apache__airflow-24142\n",
      "Token count is too large: pandas-dev__pandas-5640\n",
      "Token count is too large: Lightning-AI__lightning-2388\n",
      "Token count is too large: pandas-dev__pandas-21780\n",
      "Token count is too large: Qiskit__qiskit-4764\n",
      "Token count is too large: pandas-dev__pandas-17932\n",
      "Token count is too large: pandas-dev__pandas-7639\n",
      "Token count is too large: pandas-dev__pandas-34193\n",
      "Token count is too large: docker__compose-5725\n",
      "Token count is too large: Lightning-AI__lightning-453\n",
      "Token count is too large: mesonbuild__meson-3962\n",
      "Token count is too large: open-mmlab__mmdetection-10056\n",
      "Token count is too large: pandas-dev__pandas-38126\n",
      "Token count is too large: Qiskit__qiskit-2823\n",
      "Token count is too large: wagtail__wagtail-6442\n",
      "Token count is too large: pandas-dev__pandas-28226\n",
      "Token count is too large: pandas-dev__pandas-9812\n",
      "Token count is too large: googleapis__google-cloud-python-1318\n",
      "Token count is too large: ipython__ipython-8888\n",
      "Token count is too large: numpy__numpy-20650\n",
      "Token count is too large: ipython__ipython-10382\n",
      "Token count is too large: docker__compose-7039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1089 examples [01:14, 15.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22318\n",
      "Token count is too large: pandas-dev__pandas-16978\n",
      "Token count is too large: conan-io__conan-9463\n",
      "Token count is too large: pandas-dev__pandas-27669\n",
      "Token count is too large: pandas-dev__pandas-30833\n",
      "Token count is too large: Qiskit__qiskit-1080\n",
      "Token count is too large: ray-project__ray-9108\n",
      "Token count is too large: ipython__ipython-10304\n",
      "Token count is too large: pandas-dev__pandas-11049\n",
      "Token count is too large: Qiskit__qiskit-5662\n",
      "Token count is too large: docker__compose-3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1091 examples [01:14, 11.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11305\n",
      "Token count is too large: pandas-dev__pandas-36004\n",
      "Token count is too large: pandas-dev__pandas-32721\n",
      "Token count is too large: huggingface__transformers-7872\n",
      "Token count is too large: pandas-dev__pandas-30546\n",
      "Token count is too large: numpy__numpy-18180\n",
      "Token count is too large: googleapis__google-cloud-python-6103\n",
      "Token count is too large: pypa__pip-984\n",
      "Token count is too large: numpy__numpy-10524\n",
      "Token count is too large: pandas-dev__pandas-4018\n",
      "Token count is too large: apache__airflow-9759\n",
      "Token count is too large: pypa__pip-6273\n",
      "Token count is too large: pandas-dev__pandas-23893\n",
      "Token count is too large: numpy__numpy-16821\n",
      "Token count is too large: ray-project__ray-8953\n",
      "Token count is too large: mesonbuild__meson-2874\n",
      "Token count is too large: tensorflow__models-4181\n",
      "Token count is too large: huggingface__transformers-13564\n",
      "Token count is too large: ytdl-org__youtube-dl-4025\n",
      "Token count is too large: pandas-dev__pandas-4718\n",
      "Token count is too large: conda__conda-10938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1099 examples [01:15, 18.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34194\n",
      "Token count is too large: pandas-dev__pandas-31456\n",
      "Token count is too large: conda__conda-7269\n",
      "Token count is too large: huggingface__transformers-1764\n",
      "Token count is too large: apache__airflow-25757\n",
      "Token count is too large: pantsbuild__pants-13418\n",
      "Token count is too large: pandas-dev__pandas-36437\n",
      "Token count is too large: ytdl-org__youtube-dl-3042\n",
      "Token count is too large: pandas-dev__pandas-26316\n",
      "Token count is too large: apache__airflow-29279\n",
      "Token count is too large: pandas-dev__pandas-6275\n",
      "Token count is too large: mesonbuild__meson-9016\n",
      "Token count is too large: pandas-dev__pandas-4962\n",
      "Token count is too large: apache__airflow-22772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1104 examples [01:15, 23.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-774\n",
      "Token count is too large: mesonbuild__meson-756\n",
      "Token count is too large: Qiskit__qiskit-5059\n",
      "Token count is too large: huggingface__transformers-6984\n",
      "Token count is too large: pandas-dev__pandas-24863\n",
      "Token count is too large: huggingface__transformers-24255\n",
      "Token count is too large: celery__celery-5759\n",
      "Token count is too large: wagtail__wagtail-9018\n",
      "Token count is too large: huggingface__transformers-14586\n",
      "Token count is too large: Qiskit__qiskit-5182\n",
      "Token count is too large: pandas-dev__pandas-21515\n",
      "Token count is too large: pandas-dev__pandas-36753\n",
      "Token count is too large: apache__airflow-30375\n",
      "Token count is too large: numpy__numpy-11348\n",
      "Token count is too large: mesonbuild__meson-7232\n",
      "Token count is too large: pandas-dev__pandas-6222\n",
      "Token count is too large: conan-io__conan-13757\n",
      "Token count is too large: googleapis__google-cloud-python-8105\n",
      "Token count is too large: googleapis__google-cloud-python-9627\n",
      "Token count is too large: pandas-dev__pandas-27663\n",
      "Token count is too large: huggingface__transformers-13650\n",
      "Token count is too large: pantsbuild__pants-6246\n",
      "Token count is too large: pandas-dev__pandas-33630\n",
      "Token count is too large: pandas-dev__pandas-9647\n",
      "Token count is too large: PrefectHQ__prefect-288\n",
      "Token count is too large: Qiskit__qiskit-6930\n",
      "Token count is too large: mesonbuild__meson-9156\n",
      "Token count is too large: pandas-dev__pandas-38394\n",
      "Token count is too large: numpy__numpy-22280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1108 examples [01:15, 11.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8135\n",
      "Token count is too large: pandas-dev__pandas-6256\n",
      "Token count is too large: Qiskit__qiskit-5156\n",
      "Token count is too large: pandas-dev__pandas-6761\n",
      "Token count is too large: pandas-dev__pandas-3580\n",
      "Token count is too large: mesonbuild__meson-4540\n",
      "Token count is too large: pyca__cryptography-604\n",
      "Token count is too large: pandas-dev__pandas-24027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1114 examples [01:16, 14.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-17990\n",
      "Token count is too large: pandas-dev__pandas-39069\n",
      "Token count is too large: pantsbuild__pants-7299\n",
      "Token count is too large: Qiskit__qiskit-9095\n",
      "Token count is too large: Qiskit__qiskit-6153\n",
      "Token count is too large: pandas-dev__pandas-16523\n",
      "Token count is too large: Qiskit__qiskit-5139\n",
      "Token count is too large: pypa__pip-1869\n",
      "Token count is too large: PrefectHQ__prefect-2388\n",
      "Token count is too large: pandas-dev__pandas-18099\n",
      "Token count is too large: PrefectHQ__prefect-2867\n",
      "Token count is too large: conda__conda-8259\n",
      "Token count is too large: conan-io__conan-5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1118 examples [01:16, 17.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18925\n",
      "Token count is too large: conan-io__conan-9218\n",
      "Token count is too large: Lightning-AI__lightning-2970\n",
      "Token count is too large: conan-io__conan-5293\n",
      "Token count is too large: pantsbuild__pants-17941\n",
      "Token count is too large: Qiskit__qiskit-9403\n",
      "Token count is too large: ytdl-org__youtube-dl-31043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1121 examples [01:16, 15.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20457\n",
      "Token count is too large: pandas-dev__pandas-24340\n",
      "Token count is too large: conda__conda-5237\n",
      "Token count is too large: pantsbuild__pants-14715\n",
      "Token count is too large: ipython__ipython-4389\n",
      "Token count is too large: twisted__twisted-1142\n",
      "Token count is too large: mesonbuild__meson-5065\n",
      "Token count is too large: Qiskit__qiskit-1998\n",
      "Token count is too large: pandas-dev__pandas-16351\n",
      "Token count is too large: googleapis__google-cloud-python-597\n",
      "Token count is too large: pandas-dev__pandas-21728\n",
      "Token count is too large: pandas-dev__pandas-22988\n",
      "Token count is too large: mesonbuild__meson-592\n",
      "Token count is too large: pyca__cryptography-3361\n",
      "Token count is too large: numpy__numpy-23559\n",
      "Token count is too large: huggingface__transformers-18861\n",
      "Token count is too large: huggingface__transformers-10095\n",
      "Token count is too large: pandas-dev__pandas-24850\n",
      "Token count is too large: googleapis__google-cloud-python-5674\n",
      "Token count is too large: google__jax-889\n",
      "Token count is too large: googleapis__google-cloud-python-6085\n",
      "Token count is too large: numpy__numpy-22294\n",
      "Token count is too large: pandas-dev__pandas-11706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1124 examples [01:16, 13.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-1763\n",
      "Token count is too large: huggingface__transformers-17987\n",
      "Token count is too large: numpy__numpy-2816\n",
      "Token count is too large: celery__celery-1899\n",
      "Token count is too large: ray-project__ray-9525\n",
      "Token count is too large: wagtail__wagtail-6872\n",
      "Token count is too large: conan-io__conan-4233\n",
      "Token count is too large: pypa__pip-3401\n",
      "Token count is too large: conda__conda-7725\n",
      "Token count is too large: pandas-dev__pandas-36872\n",
      "Token count is too large: jupyterlab__jupyterlab-13336\n",
      "Token count is too large: numpy__numpy-21448\n",
      "Token count is too large: googleapis__google-cloud-python-629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1134 examples [01:17, 20.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23749\n",
      "Token count is too large: apache__airflow-9879\n",
      "Token count is too large: Qiskit__qiskit-1542\n",
      "Token count is too large: huggingface__transformers-22942\n",
      "Token count is too large: PrefectHQ__prefect-2942\n",
      "Token count is too large: pantsbuild__pants-6000\n",
      "Token count is too large: pantsbuild__pants-17516\n",
      "Token count is too large: huggingface__transformers-18272\n",
      "Token count is too large: Qiskit__qiskit-5505\n",
      "Token count is too large: numpy__numpy-5178\n",
      "Token count is too large: pandas-dev__pandas-4820\n",
      "Token count is too large: wagtail__wagtail-8949\n",
      "Token count is too large: huggingface__transformers-21263\n",
      "Token count is too large: PrefectHQ__prefect-2805\n",
      "Token count is too large: Qiskit__qiskit-4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1137 examples [01:17, 15.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5217\n",
      "Token count is too large: Qiskit__qiskit-977\n",
      "Token count is too large: pandas-dev__pandas-22919\n",
      "Token count is too large: Qiskit__qiskit-4763\n",
      "Token count is too large: celery__celery-2349\n",
      "Token count is too large: pandas-dev__pandas-34056\n",
      "Token count is too large: ipython__ipython-10533\n",
      "Token count is too large: Qiskit__qiskit-1280\n",
      "Token count is too large: pypa__pip-7557\n",
      "Token count is too large: Qiskit__qiskit-6500\n",
      "Token count is too large: PrefectHQ__prefect-749\n",
      "Token count is too large: ytdl-org__youtube-dl-2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1146 examples [01:17, 19.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23944\n",
      "Token count is too large: Qiskit__qiskit-10153\n",
      "Token count is too large: numpy__numpy-3830\n",
      "Token count is too large: apache__airflow-17989\n",
      "Token count is too large: huggingface__transformers-16018\n",
      "Token count is too large: googleapis__google-cloud-python-3776\n",
      "Token count is too large: googleapis__google-cloud-python-6837\n",
      "Token count is too large: docker__compose-6914\n",
      "Token count is too large: PrefectHQ__prefect-1899\n",
      "Token count is too large: docker__compose-3139\n",
      "Token count is too large: ytdl-org__youtube-dl-7599\n",
      "Token count is too large: conan-io__conan-7200\n",
      "Token count is too large: celery__celery-5682\n",
      "Token count is too large: ipython__ipython-4158\n",
      "Token count is too large: huggingface__transformers-16673\n",
      "Token count is too large: Qiskit__qiskit-773\n",
      "Token count is too large: ipython__ipython-6616\n",
      "Token count is too large: pandas-dev__pandas-13516\n",
      "Token count is too large: pandas-dev__pandas-36814\n",
      "Token count is too large: huggingface__transformers-20434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1150 examples [01:18, 14.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10236\n",
      "Token count is too large: pandas-dev__pandas-31238\n",
      "Token count is too large: Qiskit__qiskit-9537\n",
      "Token count is too large: Lightning-AI__lightning-1865\n",
      "Token count is too large: conan-io__conan-4810\n",
      "Token count is too large: pandas-dev__pandas-20422\n",
      "Token count is too large: Lightning-AI__lightning-936\n",
      "Token count is too large: Lightning-AI__lightning-2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1155 examples [01:18, 16.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-383\n",
      "Token count is too large: pypa__pip-11117\n",
      "Token count is too large: pandas-dev__pandas-5870\n",
      "Token count is too large: numpy__numpy-4633\n",
      "Token count is too large: Qiskit__qiskit-8404\n",
      "Token count is too large: Qiskit__qiskit-688\n",
      "Token count is too large: apache__airflow-15848\n",
      "Token count is too large: Qiskit__qiskit-5980\n",
      "Token count is too large: pandas-dev__pandas-3152\n",
      "Token count is too large: ytdl-org__youtube-dl-7057\n",
      "Token count is too large: conan-io__conan-5492\n",
      "Token count is too large: googleapis__google-cloud-python-8721\n",
      "Token count is too large: pandas-dev__pandas-13812\n",
      "Token count is too large: Qiskit__qiskit-7409\n",
      "Token count is too large: Qiskit__qiskit-1060\n",
      "Token count is too large: pandas-dev__pandas-25474\n",
      "Token count is too large: wagtail__wagtail-10113\n",
      "Token count is too large: pandas-dev__pandas-28951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1162 examples [01:19, 16.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7994\n",
      "Token count is too large: google__jax-168\n",
      "Token count is too large: conan-io__conan-3361\n",
      "Token count is too large: pandas-dev__pandas-8036\n",
      "Token count is too large: pandas-dev__pandas-19553\n",
      "Token count is too large: Qiskit__qiskit-1334\n",
      "Token count is too large: Qiskit__qiskit-6064\n",
      "Token count is too large: docker__compose-6597\n",
      "Token count is too large: ray-project__ray-11084\n",
      "Token count is too large: huggingface__transformers-25429\n",
      "Token count is too large: mesonbuild__meson-3571\n",
      "Token count is too large: celery__celery-6713\n",
      "Token count is too large: huggingface__transformers-3948\n",
      "Token count is too large: pandas-dev__pandas-25943\n",
      "Token count is too large: conan-io__conan-2633\n",
      "Token count is too large: pandas-dev__pandas-23118\n",
      "Token count is too large: ipython__ipython-1155\n",
      "Token count is too large: pypa__pip-2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1169 examples [01:19, 15.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10472\n",
      "Token count is too large: pandas-dev__pandas-19980\n",
      "Token count is too large: conan-io__conan-13661\n",
      "Token count is too large: huggingface__transformers-13109\n",
      "Token count is too large: huggingface__transformers-24893\n",
      "Token count is too large: PrefectHQ__prefect-1610\n",
      "Token count is too large: google__jax-332\n",
      "Token count is too large: pandas-dev__pandas-21198\n",
      "Token count is too large: pandas-dev__pandas-24486\n",
      "Token count is too large: pandas-dev__pandas-19148\n",
      "Token count is too large: huggingface__transformers-22828\n",
      "Token count is too large: numpy__numpy-6363\n",
      "Token count is too large: conda__conda-8924\n",
      "Token count is too large: pypa__pip-11710\n",
      "Token count is too large: pandas-dev__pandas-34939\n",
      "Token count is too large: pandas-dev__pandas-10825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1171 examples [01:19, 13.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29313\n",
      "Token count is too large: pandas-dev__pandas-28569\n",
      "Token count is too large: ipython__ipython-13888\n",
      "Token count is too large: numpy__numpy-11698\n",
      "Token count is too large: apache__airflow-16388\n",
      "Token count is too large: pandas-dev__pandas-37803\n",
      "Token count is too large: docker__compose-6937\n",
      "Token count is too large: pandas-dev__pandas-16079\n",
      "Token count is too large: pandas-dev__pandas-22015\n",
      "Token count is too large: dagster-io__dagster-9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1173 examples [01:20, 11.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10272\n",
      "Token count is too large: pandas-dev__pandas-5894\n",
      "Token count is too large: conan-io__conan-10213\n",
      "Token count is too large: pandas-dev__pandas-5359\n",
      "Token count is too large: celery__celery-2651\n",
      "Token count is too large: googleapis__google-cloud-python-6099\n",
      "Token count is too large: huggingface__transformers-12350\n",
      "Token count is too large: numpy__numpy-5031\n",
      "Token count is too large: huggingface__transformers-17898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1179 examples [01:20, 15.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-1905\n",
      "Token count is too large: mesonbuild__meson-2348\n",
      "Token count is too large: ytdl-org__youtube-dl-4543\n",
      "Token count is too large: Qiskit__qiskit-1000\n",
      "Token count is too large: apache__airflow-17236\n",
      "Token count is too large: numpy__numpy-9020\n",
      "Token count is too large: pypa__pip-6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1181 examples [01:20, 10.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-3387\n",
      "Token count is too large: mesonbuild__meson-8355\n",
      "Token count is too large: Qiskit__qiskit-4711\n",
      "Token count is too large: pantsbuild__pants-5808\n",
      "Token count is too large: numpy__numpy-17344\n",
      "Token count is too large: pandas-dev__pandas-3670\n",
      "Token count is too large: conan-io__conan-7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1186 examples [01:21, 13.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19794\n",
      "Token count is too large: huggingface__transformers-12328\n",
      "Token count is too large: pandas-dev__pandas-22280\n",
      "Token count is too large: pandas-dev__pandas-36693\n",
      "Token count is too large: pandas-dev__pandas-36532\n",
      "Token count is too large: numpy__numpy-13574\n",
      "Token count is too large: mesonbuild__meson-5212\n",
      "Token count is too large: apache__airflow-21289\n",
      "Token count is too large: apache__airflow-13512\n",
      "Token count is too large: conan-io__conan-4748\n",
      "Token count is too large: mesonbuild__meson-3739\n",
      "Token count is too large: googleapis__google-cloud-python-494\n",
      "Token count is too large: pandas-dev__pandas-22232\n",
      "Token count is too large: Lightning-AI__lightning-619\n",
      "Token count is too large: wagtail__wagtail-4689\n",
      "Token count is too large: pypa__pip-2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1189 examples [01:21,  9.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24629\n",
      "Token count is too large: google__jax-1930\n",
      "Token count is too large: ray-project__ray-11104\n",
      "Token count is too large: numpy__numpy-9487\n",
      "Token count is too large: pantsbuild__pants-18412\n",
      "Token count is too large: mesonbuild__meson-5475\n",
      "Token count is too large: numpy__numpy-13182\n",
      "Token count is too large: pandas-dev__pandas-10951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1194 examples [01:21, 12.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-21977\n",
      "Token count is too large: celery__celery-6360\n",
      "Token count is too large: mesonbuild__meson-3314\n",
      "Token count is too large: pandas-dev__pandas-7044\n",
      "Token count is too large: conan-io__conan-3846\n",
      "Token count is too large: huggingface__transformers-11537\n",
      "Token count is too large: huggingface__transformers-4243\n",
      "Token count is too large: celery__celery-3721\n",
      "Token count is too large: Lightning-AI__lightning-1453\n",
      "Token count is too large: celery__celery-7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1197 examples [01:21, 13.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11893\n",
      "Token count is too large: pandas-dev__pandas-18623\n",
      "Token count is too large: huggingface__transformers-12770\n",
      "Token count is too large: Qiskit__qiskit-7942\n",
      "Token count is too large: apache__airflow-31033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1200 examples [01:22, 14.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-11427\n",
      "Token count is too large: pantsbuild__pants-13578\n",
      "Token count is too large: pandas-dev__pandas-25502\n",
      "Token count is too large: ipython__ipython-10529\n",
      "Token count is too large: explosion__spaCy-692\n",
      "Token count is too large: numpy__numpy-19656\n",
      "Token count is too large: pandas-dev__pandas-2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1211 examples [01:22, 24.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35941\n",
      "Token count is too large: pandas-dev__pandas-17142\n",
      "Token count is too large: huggingface__transformers-17589\n",
      "Token count is too large: pantsbuild__pants-12868\n",
      "Token count is too large: dagster-io__dagster-8635\n",
      "Token count is too large: gitpython-developers__GitPython-1340\n",
      "Token count is too large: pandas-dev__pandas-16208\n",
      "Token count is too large: huggingface__transformers-4747\n",
      "Token count is too large: pantsbuild__pants-5407\n",
      "Token count is too large: pandas-dev__pandas-9105\n",
      "Token count is too large: pandas-dev__pandas-24303\n",
      "Token count is too large: pandas-dev__pandas-16426\n",
      "Token count is too large: huggingface__transformers-21047\n",
      "Token count is too large: pandas-dev__pandas-32439\n",
      "Token count is too large: pandas-dev__pandas-6848\n",
      "Token count is too large: pandas-dev__pandas-19176\n",
      "Token count is too large: pandas-dev__pandas-6447\n",
      "Token count is too large: pandas-dev__pandas-27424\n",
      "Token count is too large: ytdl-org__youtube-dl-31398\n",
      "Token count is too large: pypa__pip-4553\n",
      "Token count is too large: ytdl-org__youtube-dl-9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1215 examples [01:23, 14.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-7410\n",
      "Token count is too large: googleapis__google-cloud-python-9113\n",
      "Token count is too large: ray-project__ray-1088\n",
      "Token count is too large: PrefectHQ__prefect-292\n",
      "Token count is too large: googleapis__google-cloud-python-11354\n",
      "Token count is too large: huggingface__transformers-16368\n",
      "Token count is too large: pandas-dev__pandas-8399\n",
      "Token count is too large: pantsbuild__pants-15375\n",
      "Token count is too large: pandas-dev__pandas-26651\n",
      "Token count is too large: conan-io__conan-4673\n",
      "Token count is too large: huggingface__transformers-4477\n",
      "Token count is too large: pandas-dev__pandas-5970\n",
      "Token count is too large: wagtail__wagtail-10175\n",
      "Token count is too large: conda__conda-6922\n",
      "Token count is too large: huggingface__transformers-6213\n",
      "Token count is too large: ipython__ipython-12280\n",
      "Token count is too large: pandas-dev__pandas-16960\n",
      "Token count is too large: pandas-dev__pandas-33436\n",
      "Token count is too large: Lightning-AI__lightning-2014\n",
      "Token count is too large: huggingface__transformers-1042\n",
      "Token count is too large: pandas-dev__pandas-5601\n",
      "Token count is too large: pandas-dev__pandas-37870\n",
      "Token count is too large: pandas-dev__pandas-23145\n",
      "Token count is too large: pantsbuild__pants-12500\n",
      "Token count is too large: docker__compose-5273\n",
      "Token count is too large: pandas-dev__pandas-10450\n",
      "Token count is too large: apache__airflow-11078\n",
      "Token count is too large: ytdl-org__youtube-dl-7399\n",
      "Token count is too large: pypa__pip-5971\n",
      "Token count is too large: huggingface__transformers-22489\n",
      "Token count is too large: numpy__numpy-11493\n",
      "Token count is too large: apache__airflow-20671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1226 examples [01:23, 16.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-9194\n",
      "Token count is too large: pantsbuild__pants-13953\n",
      "Token count is too large: conan-io__conan-5178\n",
      "Token count is too large: pandas-dev__pandas-21508\n",
      "Token count is too large: pandas-dev__pandas-18826\n",
      "Token count is too large: pandas-dev__pandas-39439\n",
      "Token count is too large: open-mmlab__mmdetection-4056\n",
      "Token count is too large: pandas-dev__pandas-5704\n",
      "Token count is too large: pandas-dev__pandas-38094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1231 examples [01:23, 19.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4680\n",
      "Token count is too large: google__jax-1002\n",
      "Token count is too large: pandas-dev__pandas-6375\n",
      "Token count is too large: jupyterlab__jupyterlab-6779\n",
      "Token count is too large: apache__airflow-1132\n",
      "Token count is too large: googleapis__google-cloud-python-3661\n",
      "Token count is too large: dagster-io__dagster-5624\n",
      "Token count is too large: pandas-dev__pandas-19579\n",
      "Token count is too large: pandas-dev__pandas-36514\n",
      "Token count is too large: Qiskit__qiskit-5597\n",
      "Token count is too large: pandas-dev__pandas-10206\n",
      "Token count is too large: ipython__ipython-10555\n",
      "Token count is too large: Qiskit__qiskit-2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1241 examples [01:24, 24.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-7457\n",
      "Token count is too large: huggingface__transformers-14355\n",
      "Token count is too large: conan-io__conan-10812\n",
      "Token count is too large: ray-project__ray-9110\n",
      "Token count is too large: conda__conda-7735\n",
      "Token count is too large: pantsbuild__pants-15096\n",
      "Token count is too large: pandas-dev__pandas-6905\n",
      "Token count is too large: conan-io__conan-3613\n",
      "Token count is too large: pandas-dev__pandas-16509\n",
      "Token count is too large: mesonbuild__meson-3369\n",
      "Token count is too large: ipython__ipython-13140\n",
      "Token count is too large: ray-project__ray-4734\n",
      "Token count is too large: apache__airflow-8220\n",
      "Token count is too large: huggingface__transformers-22470\n",
      "Token count is too large: pandas-dev__pandas-3744\n",
      "Token count is too large: pandas-dev__pandas-28632\n",
      "Token count is too large: conda__conda-8562\n",
      "Token count is too large: pandas-dev__pandas-33102\n",
      "Token count is too large: apache__airflow-33277\n",
      "Token count is too large: celery__celery-6020\n",
      "Token count is too large: pandas-dev__pandas-4610\n",
      "Token count is too large: pandas-dev__pandas-25102\n",
      "Token count is too large: ipython__ipython-3568\n",
      "Token count is too large: pypa__pip-3906\n",
      "Token count is too large: pantsbuild__pants-15407\n",
      "Token count is too large: Qiskit__qiskit-2459\n",
      "Token count is too large: pandas-dev__pandas-17774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1245 examples [01:24, 13.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17925\n",
      "Token count is too large: pypa__pip-10084\n",
      "Token count is too large: pandas-dev__pandas-26374\n",
      "Token count is too large: pypa__pip-1601\n",
      "Token count is too large: numpy__numpy-24161\n",
      "Token count is too large: Qiskit__qiskit-10659\n",
      "Token count is too large: pandas-dev__pandas-30507\n",
      "Token count is too large: mesonbuild__meson-10303\n",
      "Token count is too large: mesonbuild__meson-7840\n",
      "Token count is too large: pandas-dev__pandas-39280\n",
      "Token count is too large: pantsbuild__pants-15755\n",
      "Token count is too large: docker__compose-7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1249 examples [01:25, 15.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23888\n",
      "Token count is too large: pandas-dev__pandas-26876\n",
      "Token count is too large: conda__conda-6447\n",
      "Token count is too large: Qiskit__qiskit-3138\n",
      "Token count is too large: huggingface__transformers-4098\n",
      "Token count is too large: mesonbuild__meson-9899\n",
      "Token count is too large: pandas-dev__pandas-16565\n",
      "Token count is too large: jupyterlab__jupyterlab-5099\n",
      "Token count is too large: ray-project__ray-9680\n",
      "Token count is too large: googleapis__google-cloud-python-1997\n",
      "Token count is too large: docker__compose-8122\n",
      "Token count is too large: googleapis__google-cloud-python-8748\n",
      "Token count is too large: pandas-dev__pandas-26721\n",
      "Token count is too large: mesonbuild__meson-7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1255 examples [01:25, 19.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33502\n",
      "Token count is too large: apache__airflow-23860\n",
      "Token count is too large: huggingface__transformers-11672\n",
      "Token count is too large: docker__compose-5234\n",
      "Token count is too large: googleapis__google-cloud-python-5687\n",
      "Token count is too large: pantsbuild__pants-11660\n",
      "Token count is too large: docker__compose-3466\n",
      "Token count is too large: pandas-dev__pandas-16430\n",
      "Token count is too large: numpy__numpy-6432\n",
      "Token count is too large: docker__compose-3418\n",
      "Token count is too large: pypa__pip-4987\n",
      "Token count is too large: mesonbuild__meson-11548\n",
      "Token count is too large: pandas-dev__pandas-33292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1258 examples [01:25, 18.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-8647\n",
      "Token count is too large: pandas-dev__pandas-18082\n",
      "Token count is too large: pandas-dev__pandas-16897\n",
      "Token count is too large: pandas-dev__pandas-23318\n",
      "Token count is too large: pandas-dev__pandas-20965\n",
      "Token count is too large: huggingface__transformers-20645\n",
      "Token count is too large: apache__airflow-32382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1263 examples [01:25, 17.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14401\n",
      "Token count is too large: conda__conda-10413\n",
      "Token count is too large: conan-io__conan-4204\n",
      "Token count is too large: huggingface__transformers-17751\n",
      "Token count is too large: google__jax-415\n",
      "Token count is too large: pandas-dev__pandas-20571\n",
      "Token count is too large: pandas-dev__pandas-13477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1266 examples [01:26, 14.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19590\n",
      "Token count is too large: huggingface__transformers-11906\n",
      "Token count is too large: huggingface__transformers-24666\n",
      "Token count is too large: Qiskit__qiskit-2735\n",
      "Token count is too large: apache__airflow-396\n",
      "Token count is too large: ytdl-org__youtube-dl-30531\n",
      "Token count is too large: google__jax-761\n",
      "Token count is too large: ray-project__ray-4104\n",
      "Token count is too large: numpy__numpy-7729\n",
      "Token count is too large: gitpython-developers__GitPython-1399\n",
      "Token count is too large: apache__airflow-19994\n",
      "Token count is too large: pyca__cryptography-3897\n",
      "Token count is too large: pandas-dev__pandas-13660\n",
      "Token count is too large: numpy__numpy-9505\n",
      "Token count is too large: PrefectHQ__prefect-3136\n",
      "Token count is too large: pandas-dev__pandas-11627\n",
      "Token count is too large: numpy__numpy-3248\n",
      "Token count is too large: Qiskit__qiskit-936\n",
      "Token count is too large: pandas-dev__pandas-21160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1271 examples [01:26, 13.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-595\n",
      "Token count is too large: docker__compose-3400\n",
      "Token count is too large: pandas-dev__pandas-16181\n",
      "Token count is too large: pandas-dev__pandas-28267\n",
      "Token count is too large: scipy__scipy-3348\n",
      "Token count is too large: conan-io__conan-2659\n",
      "Token count is too large: huggingface__transformers-21542\n",
      "Token count is too large: ytdl-org__youtube-dl-1248\n",
      "Token count is too large: Qiskit__qiskit-4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1276 examples [01:26, 14.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7006\n",
      "Token count is too large: celery__celery-7873\n",
      "Token count is too large: google__jax-3140\n",
      "Token count is too large: ray-project__ray-1225\n",
      "Token count is too large: docker__compose-6140\n",
      "Token count is too large: mesonbuild__meson-1060\n",
      "Token count is too large: celery__celery-6598\n",
      "Token count is too large: Qiskit__qiskit-7655\n",
      "Token count is too large: mesonbuild__meson-10742\n",
      "Token count is too large: googleapis__google-cloud-python-4584\n",
      "Token count is too large: pandas-dev__pandas-7902\n",
      "Token count is too large: docker__compose-1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1282 examples [01:27, 15.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10396\n",
      "Token count is too large: huggingface__transformers-9401\n",
      "Token count is too large: ipython__ipython-12095\n",
      "Token count is too large: google__jax-1622\n",
      "Token count is too large: pandas-dev__pandas-10931\n",
      "Token count is too large: pantsbuild__pants-7186\n",
      "Token count is too large: pandas-dev__pandas-22464\n",
      "Token count is too large: pandas-dev__pandas-25521\n",
      "Token count is too large: numpy__numpy-18415\n",
      "Token count is too large: pandas-dev__pandas-24426\n",
      "Token count is too large: conan-io__conan-10981\n",
      "Token count is too large: google__jax-285\n",
      "Token count is too large: pandas-dev__pandas-23550\n",
      "Token count is too large: numpy__numpy-14621\n",
      "Token count is too large: docker__compose-6313\n",
      "Token count is too large: google__jax-351\n",
      "Token count is too large: pandas-dev__pandas-11913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1286 examples [01:27, 15.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9345\n",
      "Token count is too large: googleapis__google-cloud-python-5181\n",
      "Token count is too large: pandas-dev__pandas-22109\n",
      "Token count is too large: pandas-dev__pandas-18651\n",
      "Token count is too large: pandas-dev__pandas-34473\n",
      "Token count is too large: apache__airflow-11578\n",
      "Token count is too large: docker__compose-6077\n",
      "Token count is too large: tiangolo__fastapi-538\n",
      "Token count is too large: pandas-dev__pandas-23143\n",
      "Token count is too large: numpy__numpy-13348\n",
      "Token count is too large: pandas-dev__pandas-36580\n",
      "Token count is too large: pandas-dev__pandas-32370\n",
      "Token count is too large: ipython__ipython-8483\n",
      "Token count is too large: Lightning-AI__lightning-1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1294 examples [01:27, 18.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36114\n",
      "Token count is too large: mesonbuild__meson-8596\n",
      "Token count is too large: ipython__ipython-8096\n",
      "Token count is too large: googleapis__google-cloud-python-7843\n",
      "Token count is too large: conan-io__conan-4293\n",
      "Token count is too large: pyca__cryptography-3738\n",
      "Token count is too large: pandas-dev__pandas-25738\n",
      "Token count is too large: conda__conda-5372\n",
      "Token count is too large: wagtail__wagtail-1444\n",
      "Token count is too large: open-mmlab__mmdetection-4621\n",
      "Token count is too large: wagtail__wagtail-10209\n",
      "Token count is too large: numpy__numpy-16644\n",
      "Token count is too large: huggingface__transformers-7016\n",
      "Token count is too large: pandas-dev__pandas-37508\n",
      "Token count is too large: docker__compose-6466\n",
      "Token count is too large: pandas-dev__pandas-21098\n",
      "Token count is too large: mesonbuild__meson-2840\n",
      "Token count is too large: huggingface__transformers-9150\n",
      "Token count is too large: pandas-dev__pandas-17683\n",
      "Token count is too large: pypa__pip-8045\n",
      "Token count is too large: pandas-dev__pandas-9358\n",
      "Token count is too large: conda__conda-3550\n",
      "Token count is too large: Qiskit__qiskit-7535\n",
      "Token count is too large: Qiskit__qiskit-3155\n",
      "Token count is too large: pandas-dev__pandas-18188\n",
      "Token count is too large: numpy__numpy-10748\n",
      "Token count is too large: pantsbuild__pants-17365\n",
      "Token count is too large: pandas-dev__pandas-24634\n",
      "Token count is too large: docker__compose-4268\n",
      "Token count is too large: celery__celery-567\n",
      "Token count is too large: pandas-dev__pandas-7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1297 examples [01:28, 10.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-10479\n",
      "Token count is too large: ipython__ipython-3500\n",
      "Token count is too large: celery__celery-8446\n",
      "Token count is too large: googleapis__google-cloud-python-4616\n",
      "Token count is too large: celery__celery-8143\n",
      "Token count is too large: pandas-dev__pandas-5716\n",
      "Token count is too large: pandas-dev__pandas-16443\n",
      "Token count is too large: pandas-dev__pandas-27890\n",
      "Token count is too large: conda__conda-9835\n",
      "Token count is too large: pandas-dev__pandas-30858\n",
      "Token count is too large: googleapis__google-cloud-python-73\n",
      "Token count is too large: jupyterlab__jupyterlab-6509\n",
      "Token count is too large: Qiskit__qiskit-1767\n",
      "Token count is too large: open-mmlab__mmdetection-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1299 examples [01:28, 10.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38098\n",
      "Token count is too large: ray-project__ray-7597\n",
      "Token count is too large: pandas-dev__pandas-10558\n",
      "Token count is too large: pandas-dev__pandas-20079\n",
      "Token count is too large: numpy__numpy-19613\n",
      "Token count is too large: pandas-dev__pandas-23255\n",
      "Token count is too large: numpy__numpy-23357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1310 examples [01:28, 19.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-357\n",
      "Token count is too large: conan-io__conan-3680\n",
      "Token count is too large: pandas-dev__pandas-21175\n",
      "Token count is too large: ytdl-org__youtube-dl-31515\n",
      "Token count is too large: pandas-dev__pandas-37069\n",
      "Token count is too large: pantsbuild__pants-13931\n",
      "Token count is too large: ipython__ipython-4552\n",
      "Token count is too large: conan-io__conan-9685\n",
      "Token count is too large: pandas-dev__pandas-34223\n",
      "Token count is too large: pantsbuild__pants-6308\n",
      "Token count is too large: pandas-dev__pandas-33138\n",
      "Token count is too large: pantsbuild__pants-7502\n",
      "Token count is too large: mesonbuild__meson-1580\n",
      "Token count is too large: dagster-io__dagster-12633\n",
      "Token count is too large: PrefectHQ__prefect-2406\n",
      "Token count is too large: pandas-dev__pandas-3720\n",
      "Token count is too large: numpy__numpy-8349\n",
      "Token count is too large: pandas-dev__pandas-7696\n",
      "Token count is too large: numpy__numpy-7373\n",
      "Token count is too large: pandas-dev__pandas-8472\n",
      "Token count is too large: docker__compose-2491\n",
      "Token count is too large: conda__conda-6935\n",
      "Token count is too large: google__jax-113\n",
      "Token count is too large: huggingface__transformers-8791\n",
      "Token count is too large: Qiskit__qiskit-1284\n",
      "Token count is too large: pandas-dev__pandas-6354\n",
      "Token count is too large: ytdl-org__youtube-dl-3441\n",
      "Token count is too large: googleapis__google-cloud-python-1758\n",
      "Token count is too large: ipython__ipython-8945\n",
      "Token count is too large: pandas-dev__pandas-22508\n",
      "Token count is too large: pypa__pip-3972\n",
      "Token count is too large: pandas-dev__pandas-8843\n",
      "Token count is too large: Lightning-AI__lightning-387\n",
      "Token count is too large: numpy__numpy-3463\n",
      "Token count is too large: pandas-dev__pandas-17162\n",
      "Token count is too large: pandas-dev__pandas-20995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1314 examples [01:29, 14.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22034\n",
      "Token count is too large: docker__compose-2023\n",
      "Token count is too large: PrefectHQ__prefect-2744\n",
      "Token count is too large: pandas-dev__pandas-30569\n",
      "Token count is too large: mesonbuild__meson-8154\n",
      "Token count is too large: jupyterlab__jupyterlab-10444\n",
      "Token count is too large: huggingface__transformers-8049\n",
      "Token count is too large: Qiskit__qiskit-10389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1319 examples [01:29, 15.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35704\n",
      "Token count is too large: Qiskit__qiskit-5026\n",
      "Token count is too large: numpy__numpy-12869\n",
      "Token count is too large: mesonbuild__meson-9211\n",
      "Token count is too large: Lightning-AI__lightning-1126\n",
      "Token count is too large: pandas-dev__pandas-8041\n",
      "Token count is too large: pandas-dev__pandas-7961\n",
      "Token count is too large: conan-io__conan-278\n",
      "Token count is too large: Lightning-AI__lightning-1670\n",
      "Token count is too large: pandas-dev__pandas-5659\n",
      "Token count is too large: mesonbuild__meson-3963\n",
      "Token count is too large: huggingface__transformers-8877\n",
      "Token count is too large: Qiskit__qiskit-4663\n",
      "Token count is too large: pandas-dev__pandas-5918\n",
      "Token count is too large: Qiskit__qiskit-4276\n",
      "Token count is too large: googleapis__google-cloud-python-9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1324 examples [01:29, 18.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28681\n",
      "Token count is too large: googleapis__google-cloud-python-5187\n",
      "Token count is too large: pantsbuild__pants-6278\n",
      "Token count is too large: pandas-dev__pandas-28717\n",
      "Token count is too large: apache__airflow-19878\n",
      "Token count is too large: pypa__pip-1335\n",
      "Token count is too large: conan-io__conan-3438\n",
      "Token count is too large: pyca__cryptography-3279\n",
      "Token count is too large: wagtail__wagtail-5999\n",
      "Token count is too large: pandas-dev__pandas-14665\n",
      "Token count is too large: huggingface__transformers-8237\n",
      "Token count is too large: google__jax-2034\n",
      "Token count is too large: ray-project__ray-5091\n",
      "Token count is too large: pandas-dev__pandas-18893\n",
      "Token count is too large: celery__celery-5141\n",
      "Token count is too large: Qiskit__qiskit-4803\n",
      "Token count is too large: wagtail__wagtail-5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1327 examples [01:30, 14.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-5582\n",
      "Token count is too large: pandas-dev__pandas-10418\n",
      "Token count is too large: Qiskit__qiskit-3051\n",
      "Token count is too large: wagtail__wagtail-6344\n",
      "Token count is too large: pandas-dev__pandas-27876\n",
      "Token count is too large: conda__conda-10759\n",
      "Token count is too large: googleapis__google-cloud-python-4635\n",
      "Token count is too large: Lightning-AI__lightning-743\n",
      "Token count is too large: pandas-dev__pandas-35654\n",
      "Token count is too large: Qiskit__qiskit-10382\n",
      "Token count is too large: pyca__cryptography-714\n",
      "Token count is too large: googleapis__google-cloud-python-3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1331 examples [01:30, 17.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17324\n",
      "Token count is too large: pantsbuild__pants-4226\n",
      "Token count is too large: mesonbuild__meson-5872\n",
      "Token count is too large: Qiskit__qiskit-5593\n",
      "Token count is too large: pandas-dev__pandas-23839\n",
      "Token count is too large: huggingface__transformers-7334\n",
      "Token count is too large: pandas-dev__pandas-4684\n",
      "Token count is too large: pandas-dev__pandas-28354\n",
      "Token count is too large: pandas-dev__pandas-17934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1335 examples [01:30, 17.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-21630\n",
      "Token count is too large: mesonbuild__meson-4907\n",
      "Token count is too large: pandas-dev__pandas-38332\n",
      "Token count is too large: pandas-dev__pandas-7531\n",
      "Token count is too large: pantsbuild__pants-12067\n",
      "Token count is too large: googleapis__google-cloud-python-4977\n",
      "Token count is too large: Qiskit__qiskit-3230\n",
      "Token count is too large: pandas-dev__pandas-31552\n",
      "Token count is too large: Qiskit__qiskit-7230\n",
      "Token count is too large: huggingface__transformers-15603\n",
      "Token count is too large: pyca__cryptography-3553\n",
      "Token count is too large: Qiskit__qiskit-8679\n",
      "Token count is too large: pandas-dev__pandas-21487\n",
      "Token count is too large: pandas-dev__pandas-35408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1338 examples [01:30, 17.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17903\n",
      "Token count is too large: pantsbuild__pants-13908\n",
      "Token count is too large: pandas-dev__pandas-20703\n",
      "Token count is too large: pandas-dev__pandas-21176\n",
      "Token count is too large: conda__conda-5469\n",
      "Token count is too large: conan-io__conan-7781\n",
      "Token count is too large: pandas-dev__pandas-38728\n",
      "Token count is too large: open-mmlab__mmdetection-854\n",
      "Token count is too large: mesonbuild__meson-8158\n",
      "Token count is too large: numpy__numpy-15993\n",
      "Token count is too large: apache__airflow-32756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1343 examples [01:30, 18.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31529\n",
      "Token count is too large: apache__airflow-33481\n",
      "Token count is too large: pandas-dev__pandas-14743\n",
      "Token count is too large: googleapis__google-cloud-python-8939\n",
      "Token count is too large: conda__conda-6723\n",
      "Token count is too large: ytdl-org__youtube-dl-27618\n",
      "Token count is too large: ipython__ipython-10403\n",
      "Token count is too large: mesonbuild__meson-4255\n",
      "Token count is too large: gitpython-developers__GitPython-156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1346 examples [01:31, 15.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24785\n",
      "Token count is too large: huggingface__transformers-19626\n",
      "Token count is too large: explosion__spaCy-3471\n",
      "Token count is too large: huggingface__transformers-20969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1350 examples [01:31, 18.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6018\n",
      "Token count is too large: conan-io__conan-4103\n",
      "Token count is too large: dagster-io__dagster-7673\n",
      "Token count is too large: pandas-dev__pandas-16275\n",
      "Token count is too large: wagtail__wagtail-8189\n",
      "Token count is too large: pandas-dev__pandas-35741\n",
      "Token count is too large: Lightning-AI__lightning-2360\n",
      "Token count is too large: pandas-dev__pandas-18577\n",
      "Token count is too large: pandas-dev__pandas-8384\n",
      "Token count is too large: huggingface__transformers-18684\n",
      "Token count is too large: pandas-dev__pandas-19048\n",
      "Token count is too large: pandas-dev__pandas-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1354 examples [01:31, 13.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9877\n",
      "Token count is too large: pantsbuild__pants-8226\n",
      "Token count is too large: conan-io__conan-5571\n",
      "Token count is too large: pandas-dev__pandas-15456\n",
      "Token count is too large: pandas-dev__pandas-24909\n",
      "Token count is too large: pandas-dev__pandas-18496\n",
      "Token count is too large: mesonbuild__meson-1735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1356 examples [01:32, 10.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20770\n",
      "Token count is too large: huggingface__transformers-24532\n",
      "Token count is too large: ytdl-org__youtube-dl-2696\n",
      "Token count is too large: pandas-dev__pandas-9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1359 examples [01:32, 11.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24749\n",
      "Token count is too large: ipython__ipython-12033\n",
      "Token count is too large: Qiskit__qiskit-2790\n",
      "Token count is too large: mesonbuild__meson-5230\n",
      "Token count is too large: pandas-dev__pandas-6790\n",
      "Token count is too large: huggingface__transformers-18585\n",
      "Token count is too large: huggingface__transformers-14477\n",
      "Token count is too large: tiangolo__fastapi-856\n",
      "Token count is too large: pandas-dev__pandas-23289\n",
      "Token count is too large: pandas-dev__pandas-34844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1365 examples [01:32, 16.37 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5372\n",
      "Token count is too large: ytdl-org__youtube-dl-316\n",
      "Token count is too large: Lightning-AI__lightning-1596\n",
      "Token count is too large: pantsbuild__pants-17471\n",
      "Token count is too large: Lightning-AI__lightning-2073\n",
      "Token count is too large: pandas-dev__pandas-24529\n",
      "Token count is too large: pandas-dev__pandas-15081\n",
      "Token count is too large: pandas-dev__pandas-37965\n",
      "Token count is too large: pyca__cryptography-1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1368 examples [01:32, 16.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38641\n",
      "Token count is too large: pandas-dev__pandas-11155\n",
      "Token count is too large: pypa__pip-1901\n",
      "Token count is too large: Qiskit__qiskit-1285\n",
      "Token count is too large: ytdl-org__youtube-dl-31453\n",
      "Token count is too large: mesonbuild__meson-2094\n",
      "Token count is too large: celery__celery-4131\n",
      "Token count is too large: Qiskit__qiskit-8321\n",
      "Token count is too large: pandas-dev__pandas-17766\n",
      "Token count is too large: pantsbuild__pants-14603\n",
      "Token count is too large: pandas-dev__pandas-30885\n",
      "Token count is too large: Lightning-AI__lightning-516\n",
      "Token count is too large: apache__airflow-9097\n",
      "Token count is too large: conda__conda-7162\n",
      "Token count is too large: googleapis__google-cloud-python-9550\n",
      "Token count is too large: PrefectHQ__prefect-254\n",
      "Token count is too large: pandas-dev__pandas-8370\n",
      "Token count is too large: pandas-dev__pandas-23639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1375 examples [01:33, 13.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5962\n",
      "Token count is too large: apache__airflow-12108\n",
      "Token count is too large: pandas-dev__pandas-38317\n",
      "Token count is too large: conan-io__conan-4721\n",
      "Token count is too large: Qiskit__qiskit-6403\n",
      "Token count is too large: conan-io__conan-4894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1381 examples [01:33, 18.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39777\n",
      "Token count is too large: googleapis__google-cloud-python-248\n",
      "Token count is too large: Lightning-AI__lightning-2910\n",
      "Token count is too large: pandas-dev__pandas-26167\n",
      "Token count is too large: pandas-dev__pandas-29690\n",
      "Token count is too large: docker__compose-6599\n",
      "Token count is too large: pandas-dev__pandas-5524\n",
      "Token count is too large: pandas-dev__pandas-4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1386 examples [01:33, 17.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29646\n",
      "Token count is too large: ytdl-org__youtube-dl-15929\n",
      "Token count is too large: pantsbuild__pants-15112\n",
      "Token count is too large: ipython__ipython-11365\n",
      "Token count is too large: ray-project__ray-11001\n",
      "Token count is too large: pandas-dev__pandas-28398\n",
      "Token count is too large: pandas-dev__pandas-17654\n",
      "Token count is too large: pantsbuild__pants-19149\n",
      "Token count is too large: pandas-dev__pandas-8634\n",
      "Token count is too large: ytdl-org__youtube-dl-20740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1389 examples [01:33, 17.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9604\n",
      "Token count is too large: wagtail__wagtail-6440\n",
      "Token count is too large: pandas-dev__pandas-16403\n",
      "Token count is too large: pantsbuild__pants-16936\n",
      "Token count is too large: ipython__ipython-878\n",
      "Token count is too large: open-mmlab__mmdetection-5249\n",
      "Token count is too large: pandas-dev__pandas-23874\n",
      "Token count is too large: celery__celery-5462\n",
      "Token count is too large: ray-project__ray-9960\n",
      "Token count is too large: ytdl-org__youtube-dl-27396\n",
      "Token count is too large: mesonbuild__meson-5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1394 examples [01:34, 14.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-7134\n",
      "Token count is too large: mesonbuild__meson-5835\n",
      "Token count is too large: googleapis__google-cloud-python-2423\n",
      "Token count is too large: PrefectHQ__prefect-2641\n",
      "There was an error processing\n",
      "Token count is too large: googleapis__google-cloud-python-4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1398 examples [01:34, 16.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-3816\n",
      "Token count is too large: ytdl-org__youtube-dl-30577\n",
      "Token count is too large: pandas-dev__pandas-36152\n",
      "Token count is too large: Lightning-AI__lightning-3020\n",
      "Token count is too large: pandas-dev__pandas-39432\n",
      "Token count is too large: Lightning-AI__lightning-1029\n",
      "Token count is too large: docker__compose-6547\n",
      "Token count is too large: docker__compose-4414\n",
      "Token count is too large: pandas-dev__pandas-24621\n",
      "Token count is too large: wagtail__wagtail-8812\n",
      "Token count is too large: mesonbuild__meson-6444\n",
      "Token count is too large: pandas-dev__pandas-8981\n",
      "Token count is too large: docker__compose-7093\n",
      "Token count is too large: pandas-dev__pandas-32914\n",
      "Token count is too large: numpy__numpy-22588\n",
      "Token count is too large: pandas-dev__pandas-36350\n",
      "Token count is too large: apache__airflow-28379\n",
      "Token count is too large: pandas-dev__pandas-30338\n",
      "Token count is too large: ray-project__ray-7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1406 examples [01:35, 13.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-12554\n",
      "Token count is too large: PrefectHQ__prefect-1862\n",
      "Token count is too large: Lightning-AI__lightning-2467\n",
      "Token count is too large: pypa__pip-8083\n",
      "Token count is too large: pandas-dev__pandas-3107\n",
      "Token count is too large: pandas-dev__pandas-29944\n",
      "Token count is too large: pandas-dev__pandas-28230\n",
      "Token count is too large: huggingface__transformers-12619\n",
      "Token count is too large: scipy__scipy-2756\n",
      "Token count is too large: scipy__scipy-3109\n",
      "Token count is too large: pandas-dev__pandas-39326\n",
      "Token count is too large: numpy__numpy-3881\n",
      "Token count is too large: pandas-dev__pandas-37096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1415 examples [01:35, 19.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-2094\n",
      "Token count is too large: ytdl-org__youtube-dl-3089\n",
      "Token count is too large: googleapis__google-cloud-python-8718\n",
      "Token count is too large: pandas-dev__pandas-35152\n",
      "Token count is too large: conan-io__conan-4042\n",
      "Token count is too large: ray-project__ray-7080\n",
      "Token count is too large: conda__conda-12923\n",
      "Token count is too large: pandas-dev__pandas-25540\n",
      "Token count is too large: googleapis__google-cloud-python-6050\n",
      "Token count is too large: ray-project__ray-3779\n",
      "Token count is too large: Qiskit__qiskit-8938\n",
      "Token count is too large: pandas-dev__pandas-11219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1419 examples [01:35, 20.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23503\n",
      "Token count is too large: pantsbuild__pants-4624\n",
      "Token count is too large: Qiskit__qiskit-3663\n",
      "Token count is too large: pypa__pip-2153\n",
      "Token count is too large: ytdl-org__youtube-dl-4599\n",
      "Token count is too large: conda__conda-5095\n",
      "Token count is too large: mesonbuild__meson-6743\n",
      "Token count is too large: pandas-dev__pandas-36249\n",
      "Token count is too large: docker__compose-1835\n",
      "Token count is too large: Qiskit__qiskit-7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1422 examples [01:35, 21.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-1043\n",
      "Token count is too large: googleapis__google-cloud-python-1992\n",
      "Token count is too large: googleapis__google-cloud-python-2051\n",
      "Token count is too large: apache__airflow-22619\n",
      "Token count is too large: pypa__pip-4563\n",
      "Token count is too large: pantsbuild__pants-14296\n",
      "Token count is too large: pandas-dev__pandas-3936\n",
      "Token count is too large: numpy__numpy-21377\n",
      "Token count is too large: pandas-dev__pandas-19722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1431 examples [01:36, 29.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3884\n",
      "Token count is too large: Qiskit__qiskit-1815\n",
      "Token count is too large: pandas-dev__pandas-19975\n",
      "Token count is too large: numpy__numpy-10361\n",
      "Token count is too large: pandas-dev__pandas-3048\n",
      "Token count is too large: ipython__ipython-2015\n",
      "Token count is too large: mesonbuild__meson-1523\n",
      "Token count is too large: ray-project__ray-5678\n",
      "Token count is too large: pandas-dev__pandas-36175\n",
      "Token count is too large: googleapis__google-cloud-python-5007\n",
      "Token count is too large: pandas-dev__pandas-14967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1435 examples [01:36, 26.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-12858\n",
      "Token count is too large: apache__airflow-8671\n",
      "Token count is too large: ray-project__ray-4924\n",
      "Token count is too large: conan-io__conan-5244\n",
      "Token count is too large: numpy__numpy-8168\n",
      "Token count is too large: conda__conda-10356\n",
      "Token count is too large: pandas-dev__pandas-7368\n",
      "Token count is too large: numpy__numpy-5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1439 examples [01:36, 25.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25371\n",
      "Token count is too large: huggingface__transformers-22743\n",
      "Token count is too large: ipython__ipython-6036\n",
      "Token count is too large: conan-io__conan-2818\n",
      "Token count is too large: pandas-dev__pandas-6611\n",
      "Token count is too large: mesonbuild__meson-2141\n",
      "Token count is too large: mesonbuild__meson-2718\n",
      "Token count is too large: numpy__numpy-8939\n",
      "Token count is too large: ytdl-org__youtube-dl-7208\n",
      "Token count is too large: pandas-dev__pandas-7232\n",
      "Token count is too large: conan-io__conan-4766\n",
      "Token count is too large: huggingface__transformers-8664\n",
      "Token count is too large: Lightning-AI__lightning-2246\n",
      "Token count is too large: pandas-dev__pandas-11398\n",
      "Token count is too large: ytdl-org__youtube-dl-31175\n",
      "Token count is too large: conda__conda-5831\n",
      "Token count is too large: ytdl-org__youtube-dl-2997\n",
      "Token count is too large: numpy__numpy-5496\n",
      "Token count is too large: mesonbuild__meson-11058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1445 examples [01:37, 16.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5298\n",
      "Token count is too large: pandas-dev__pandas-25266\n",
      "Token count is too large: Qiskit__qiskit-4446\n",
      "Token count is too large: wagtail__wagtail-10638\n",
      "Token count is too large: numpy__numpy-16650\n",
      "Token count is too large: ray-project__ray-4694\n",
      "Token count is too large: conda__conda-8528\n",
      "Token count is too large: pandas-dev__pandas-33784\n",
      "Token count is too large: pandas-dev__pandas-5325\n",
      "Token count is too large: apache__airflow-28394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1450 examples [01:37, 18.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31794\n",
      "Token count is too large: pantsbuild__pants-17666\n",
      "Token count is too large: apache__airflow-21815\n",
      "Token count is too large: ipython__ipython-9804\n",
      "Token count is too large: pandas-dev__pandas-18982\n",
      "Token count is too large: conda__conda-2226\n",
      "Token count is too large: pantsbuild__pants-15571\n",
      "Token count is too large: ray-project__ray-10507\n",
      "Token count is too large: conda__conda-4799\n",
      "Token count is too large: pandas-dev__pandas-26185\n",
      "Token count is too large: pandas-dev__pandas-11366\n",
      "Token count is too large: apache__airflow-2128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1453 examples [01:37, 19.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11309\n",
      "Token count is too large: pandas-dev__pandas-17238\n",
      "Token count is too large: Lightning-AI__lightning-808\n",
      "Token count is too large: pandas-dev__pandas-3199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1458 examples [01:37, 18.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21519\n",
      "Token count is too large: conda__conda-8328\n",
      "Token count is too large: pantsbuild__pants-11315\n",
      "Token count is too large: pandas-dev__pandas-31167\n",
      "Token count is too large: numpy__numpy-22952\n",
      "Token count is too large: wagtail__wagtail-1660\n",
      "Token count is too large: pandas-dev__pandas-3731\n",
      "Token count is too large: conan-io__conan-5650\n",
      "Token count is too large: docker__compose-5580\n",
      "Token count is too large: numpy__numpy-22539\n",
      "Token count is too large: huggingface__transformers-16148\n",
      "Token count is too large: huggingface__transformers-13493\n",
      "Token count is too large: mesonbuild__meson-6528\n",
      "Token count is too large: huggingface__transformers-11927\n",
      "Token count is too large: mesonbuild__meson-5572\n",
      "Token count is too large: pyca__cryptography-2641\n",
      "Token count is too large: conan-io__conan-3426\n",
      "Token count is too large: Qiskit__qiskit-5421\n",
      "Token count is too large: pypa__pip-4819\n",
      "Token count is too large: tiangolo__fastapi-347\n",
      "Token count is too large: dagster-io__dagster-14039\n",
      "Token count is too large: pandas-dev__pandas-16441\n",
      "Token count is too large: pandas-dev__pandas-31613\n",
      "Token count is too large: pandas-dev__pandas-16355\n",
      "Token count is too large: google__jax-1807\n",
      "Token count is too large: apache__airflow-19978\n",
      "Token count is too large: docker__compose-5718\n",
      "Token count is too large: pantsbuild__pants-12477\n",
      "Token count is too large: pandas-dev__pandas-30652\n",
      "Token count is too large: huggingface__transformers-24088\n",
      "There was an error processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1462 examples [01:38, 10.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-8182\n",
      "Token count is too large: ray-project__ray-10921\n",
      "Token count is too large: pandas-dev__pandas-35338\n",
      "Token count is too large: pandas-dev__pandas-5211\n",
      "Token count is too large: pandas-dev__pandas-9291\n",
      "Token count is too large: google__jax-1514\n",
      "Token count is too large: pandas-dev__pandas-36121\n",
      "There was an error processing\n",
      "Token count is too large: pandas-dev__pandas-17295\n",
      "Token count is too large: mesonbuild__meson-3055\n",
      "Token count is too large: gitpython-developers__GitPython-841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1464 examples [01:38, 10.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21279\n",
      "Token count is too large: conan-io__conan-4902\n",
      "Token count is too large: PrefectHQ__prefect-2629\n",
      "Token count is too large: mesonbuild__meson-934\n",
      "Token count is too large: google__jax-3162\n",
      "Token count is too large: pandas-dev__pandas-36051\n",
      "Token count is too large: pandas-dev__pandas-16080\n",
      "Token count is too large: pandas-dev__pandas-31591\n",
      "Token count is too large: mesonbuild__meson-1255\n",
      "Token count is too large: pandas-dev__pandas-25260\n",
      "Token count is too large: pandas-dev__pandas-34220\n",
      "Token count is too large: jupyterlab__jupyterlab-7790\n",
      "Token count is too large: pandas-dev__pandas-25768\n",
      "Token count is too large: mesonbuild__meson-4593\n",
      "Token count is too large: huggingface__transformers-23724\n",
      "Token count is too large: ipython__ipython-3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1467 examples [01:39,  8.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-15000\n",
      "Token count is too large: pandas-dev__pandas-8227\n",
      "Token count is too large: pandas-dev__pandas-5037\n",
      "Token count is too large: ipython__ipython-4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1470 examples [01:39,  9.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3708\n",
      "Token count is too large: google__jax-874\n",
      "Token count is too large: pandas-dev__pandas-4002\n",
      "Token count is too large: Qiskit__qiskit-9941\n",
      "Token count is too large: pandas-dev__pandas-4166\n",
      "Token count is too large: pandas-dev__pandas-18486\n",
      "Token count is too large: huggingface__transformers-7991\n",
      "Token count is too large: conan-io__conan-5940\n",
      "Token count is too large: pantsbuild__pants-10827\n",
      "Token count is too large: huggingface__transformers-11449\n",
      "Token count is too large: Qiskit__qiskit-8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1473 examples [01:39, 10.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36177\n",
      "Token count is too large: pandas-dev__pandas-38649\n",
      "Token count is too large: wagtail__wagtail-1232\n",
      "Token count is too large: pandas-dev__pandas-35936\n",
      "Token count is too large: apache__airflow-19130\n",
      "Token count is too large: pandas-dev__pandas-27070\n",
      "Token count is too large: pantsbuild__pants-17435\n",
      "Token count is too large: pyca__cryptography-905\n",
      "Token count is too large: celery__celery-6259\n",
      "Token count is too large: Qiskit__qiskit-870\n",
      "Token count is too large: pantsbuild__pants-10287\n",
      "Token count is too large: jupyterlab__jupyterlab-8944\n",
      "Token count is too large: mesonbuild__meson-692\n",
      "Token count is too large: pandas-dev__pandas-23162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1477 examples [01:39, 11.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11895\n",
      "Token count is too large: googleapis__google-cloud-python-9533\n",
      "Token count is too large: twisted__twisted-11712\n",
      "Token count is too large: numpy__numpy-6859\n",
      "Token count is too large: google__jax-2206\n",
      "Token count is too large: numpy__numpy-18357\n",
      "Token count is too large: ytdl-org__youtube-dl-2138\n",
      "Token count is too large: pandas-dev__pandas-10513\n",
      "Token count is too large: pandas-dev__pandas-19066\n",
      "Token count is too large: pandas-dev__pandas-30562\n",
      "Token count is too large: mesonbuild__meson-1039\n",
      "Token count is too large: mesonbuild__meson-1666\n",
      "Token count is too large: huggingface__transformers-8437\n",
      "Token count is too large: celery__celery-6401\n",
      "Token count is too large: numpy__numpy-13823\n",
      "Token count is too large: pantsbuild__pants-18216\n",
      "Token count is too large: Qiskit__qiskit-3657\n",
      "Token count is too large: ray-project__ray-7669\n",
      "Token count is too large: ytdl-org__youtube-dl-25804\n",
      "Token count is too large: pandas-dev__pandas-39420\n",
      "Token count is too large: pandas-dev__pandas-4833\n",
      "Token count is too large: pandas-dev__pandas-33798\n",
      "Token count is too large: ytdl-org__youtube-dl-30621\n",
      "Token count is too large: google__jax-3048\n",
      "Token count is too large: apache__airflow-21705\n",
      "Token count is too large: pandas-dev__pandas-5287\n",
      "Token count is too large: numpy__numpy-12808\n",
      "Token count is too large: pandas-dev__pandas-39715\n",
      "Token count is too large: apache__airflow-1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1479 examples [01:40,  8.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4830\n",
      "Token count is too large: ray-project__ray-3691\n",
      "Token count is too large: pandas-dev__pandas-39507\n",
      "Token count is too large: pantsbuild__pants-18251\n",
      "Token count is too large: pandas-dev__pandas-34991\n",
      "Token count is too large: pandas-dev__pandas-14184\n",
      "Token count is too large: pandas-dev__pandas-19472\n",
      "Token count is too large: huggingface__transformers-15158\n",
      "Token count is too large: mesonbuild__meson-1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1483 examples [01:40, 10.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20062\n",
      "Token count is too large: pypa__pip-4764\n",
      "Token count is too large: numpy__numpy-9773\n",
      "Token count is too large: pandas-dev__pandas-5985\n",
      "Token count is too large: conda__conda-9738\n",
      "Token count is too large: Qiskit__qiskit-6570\n",
      "Token count is too large: google__jax-1749\n",
      "Token count is too large: pandas-dev__pandas-16505\n",
      "Token count is too large: wagtail__wagtail-3608\n",
      "Token count is too large: Lightning-AI__lightning-950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1487 examples [01:40, 13.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32223\n",
      "Token count is too large: pypa__pip-10675\n",
      "Token count is too large: pandas-dev__pandas-25908\n",
      "Token count is too large: pandas-dev__pandas-35229\n",
      "Token count is too large: celery__celery-6804\n",
      "Token count is too large: ipython__ipython-6029\n",
      "Token count is too large: ipython__ipython-1361\n",
      "Token count is too large: pandas-dev__pandas-37728\n",
      "Token count is too large: google__jax-384\n",
      "Token count is too large: Lightning-AI__lightning-932\n",
      "Token count is too large: Lightning-AI__lightning-1804\n",
      "Token count is too large: pandas-dev__pandas-27645\n",
      "Token count is too large: Lightning-AI__lightning-521\n",
      "Token count is too large: pypa__pip-11359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1490 examples [01:41, 14.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: kubeflow__pipelines-1032\n",
      "Token count is too large: ipython__ipython-12453\n",
      "Token count is too large: open-mmlab__mmdetection-6795\n",
      "Token count is too large: huggingface__transformers-17416\n",
      "Token count is too large: pandas-dev__pandas-10937\n",
      "Token count is too large: pandas-dev__pandas-16930\n",
      "Token count is too large: pantsbuild__pants-16232\n",
      "Token count is too large: pandas-dev__pandas-3548\n",
      "Token count is too large: huggingface__transformers-13897\n",
      "Token count is too large: pandas-dev__pandas-14063\n",
      "Token count is too large: numpy__numpy-3460\n",
      "Token count is too large: google__jax-1694\n",
      "Token count is too large: conan-io__conan-9624\n",
      "Token count is too large: wagtail__wagtail-8623\n",
      "Token count is too large: mesonbuild__meson-5319\n",
      "Token count is too large: huggingface__transformers-19766\n",
      "Token count is too large: pandas-dev__pandas-25263\n",
      "Token count is too large: ytdl-org__youtube-dl-13415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1497 examples [01:41, 14.37 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3772\n",
      "Token count is too large: pandas-dev__pandas-26417\n",
      "Token count is too large: conan-io__conan-3647\n",
      "Token count is too large: pandas-dev__pandas-18354\n",
      "Token count is too large: numpy__numpy-14993\n",
      "Token count is too large: numpy__numpy-19905\n",
      "Token count is too large: pandas-dev__pandas-11322\n",
      "Token count is too large: huggingface__transformers-5122\n",
      "Token count is too large: docker__compose-4956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1502 examples [01:41, 17.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33070\n",
      "Token count is too large: pandas-dev__pandas-18402\n",
      "Token count is too large: wagtail__wagtail-2441\n",
      "Token count is too large: googleapis__google-cloud-python-8838\n",
      "Token count is too large: pantsbuild__pants-10815\n",
      "Token count is too large: Qiskit__qiskit-8799\n",
      "Token count is too large: conda__conda-4627\n",
      "Token count is too large: pandas-dev__pandas-7905\n",
      "Token count is too large: PrefectHQ__prefect-59\n",
      "Token count is too large: pandas-dev__pandas-27888\n",
      "Token count is too large: pandas-dev__pandas-35140\n",
      "Token count is too large: ray-project__ray-4605\n",
      "Token count is too large: pantsbuild__pants-15071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1505 examples [01:41, 18.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15612\n",
      "Token count is too large: pandas-dev__pandas-31756\n",
      "Token count is too large: googleapis__google-cloud-python-5784\n",
      "Token count is too large: Lightning-AI__lightning-270\n",
      "Token count is too large: pandas-dev__pandas-34641\n",
      "Token count is too large: pandas-dev__pandas-7582\n",
      "Token count is too large: pandas-dev__pandas-23507\n",
      "Token count is too large: pandas-dev__pandas-4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1511 examples [01:42, 20.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-10934\n",
      "Token count is too large: pandas-dev__pandas-2965\n",
      "Token count is too large: pandas-dev__pandas-5169\n",
      "Token count is too large: pandas-dev__pandas-19021\n",
      "Token count is too large: ytdl-org__youtube-dl-4973\n",
      "Token count is too large: mesonbuild__meson-634\n",
      "Token count is too large: numpy__numpy-6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1519 examples [01:42, 22.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-20914\n",
      "Token count is too large: pypa__pip-3231\n",
      "Token count is too large: huggingface__transformers-9683\n",
      "Token count is too large: pandas-dev__pandas-24854\n",
      "Token count is too large: pandas-dev__pandas-26324\n",
      "Token count is too large: ipython__ipython-5712\n",
      "Token count is too large: pandas-dev__pandas-7802\n",
      "Token count is too large: pandas-dev__pandas-37208\n",
      "Token count is too large: pandas-dev__pandas-18017\n",
      "Token count is too large: ray-project__ray-2837\n",
      "Token count is too large: pandas-dev__pandas-19355\n",
      "Token count is too large: pandas-dev__pandas-37534\n",
      "Token count is too large: conan-io__conan-6098\n",
      "Token count is too large: huggingface__transformers-19218\n",
      "Token count is too large: ytdl-org__youtube-dl-6537\n",
      "Token count is too large: pandas-dev__pandas-28459\n",
      "Token count is too large: Lightning-AI__lightning-1572\n",
      "Token count is too large: pandas-dev__pandas-18517\n",
      "Token count is too large: Qiskit__qiskit-7880\n",
      "Token count is too large: dagster-io__dagster-10246\n",
      "Token count is too large: explosion__spaCy-3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1525 examples [01:42, 21.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13865\n",
      "Token count is too large: Lightning-AI__lightning-413\n",
      "Token count is too large: pandas-dev__pandas-26875\n",
      "Token count is too large: pandas-dev__pandas-22169\n",
      "Token count is too large: numpy__numpy-24185\n",
      "Token count is too large: pantsbuild__pants-11317\n",
      "Token count is too large: huggingface__transformers-24550\n",
      "Token count is too large: pandas-dev__pandas-30301\n",
      "Token count is too large: google__jax-2114\n",
      "Token count is too large: pandas-dev__pandas-22394\n",
      "Token count is too large: pantsbuild__pants-12585\n",
      "Token count is too large: apache__airflow-15989\n",
      "Token count is too large: ytdl-org__youtube-dl-1869\n",
      "Token count is too large: huggingface__transformers-6998\n",
      "Token count is too large: huggingface__transformers-9681\n",
      "Token count is too large: huggingface__transformers-15913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1529 examples [01:43, 13.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29496\n",
      "Token count is too large: pandas-dev__pandas-6813\n",
      "Token count is too large: docker__compose-4589\n",
      "Token count is too large: numpy__numpy-11038\n",
      "Token count is too large: mesonbuild__meson-1066\n",
      "Token count is too large: pypa__pip-4352\n",
      "Token count is too large: dagster-io__dagster-13855\n",
      "Token count is too large: pantsbuild__pants-19023\n",
      "Token count is too large: ray-project__ray-6320\n",
      "Token count is too large: mesonbuild__meson-10299\n",
      "Token count is too large: Qiskit__qiskit-8568\n",
      "Token count is too large: ipython__ipython-7777\n",
      "Token count is too large: docker__compose-6455\n",
      "Token count is too large: PrefectHQ__prefect-1532\n",
      "Token count is too large: numpy__numpy-15124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1535 examples [01:43, 14.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-11347\n",
      "Token count is too large: huggingface__transformers-598\n",
      "Token count is too large: apache__airflow-19258\n",
      "Token count is too large: pandas-dev__pandas-19236\n",
      "Token count is too large: Lightning-AI__lightning-2417\n",
      "Token count is too large: pandas-dev__pandas-37453\n",
      "Token count is too large: docker__compose-5982\n",
      "Token count is too large: conda__conda-1133\n",
      "Token count is too large: numpy__numpy-10164\n",
      "Token count is too large: numpy__numpy-11986\n",
      "Token count is too large: conda__conda-909\n",
      "Token count is too large: Qiskit__qiskit-9300\n",
      "Token count is too large: pandas-dev__pandas-7599\n",
      "Token count is too large: pandas-dev__pandas-34944\n",
      "Token count is too large: pantsbuild__pants-14594\n",
      "Token count is too large: pandas-dev__pandas-34266\n",
      "Token count is too large: conan-io__conan-4285\n",
      "Token count is too large: docker__compose-2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1539 examples [01:44, 11.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33470\n",
      "Token count is too large: pandas-dev__pandas-5070\n",
      "Token count is too large: google__jax-494\n",
      "Token count is too large: mesonbuild__meson-8656\n",
      "Token count is too large: mesonbuild__meson-6288\n",
      "Token count is too large: mesonbuild__meson-2516\n",
      "Token count is too large: pandas-dev__pandas-4645\n",
      "Token count is too large: numpy__numpy-15949\n",
      "Token count is too large: mesonbuild__meson-8119\n",
      "Token count is too large: ytdl-org__youtube-dl-5975\n",
      "Token count is too large: ray-project__ray-7392\n",
      "Token count is too large: pandas-dev__pandas-19554\n",
      "Token count is too large: numpy__numpy-13698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1546 examples [01:44, 14.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-233\n",
      "Token count is too large: PrefectHQ__prefect-887\n",
      "Token count is too large: conda__conda-6776\n",
      "Token count is too large: mesonbuild__meson-2884\n",
      "Token count is too large: pandas-dev__pandas-8264\n",
      "Token count is too large: pandas-dev__pandas-36793\n",
      "Token count is too large: Qiskit__qiskit-5887\n",
      "Token count is too large: pandas-dev__pandas-35885\n",
      "Token count is too large: Qiskit__qiskit-2840\n",
      "Token count is too large: conda__conda-8846\n",
      "Token count is too large: celery__celery-6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1549 examples [01:44, 15.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6465\n",
      "Token count is too large: conda__conda-8229\n",
      "Token count is too large: pandas-dev__pandas-33821\n",
      "Token count is too large: docker__compose-3292\n",
      "Token count is too large: Qiskit__qiskit-5101\n",
      "Token count is too large: googleapis__google-cloud-python-7863\n",
      "Token count is too large: pandas-dev__pandas-18426\n",
      "Token count is too large: mesonbuild__meson-11405\n",
      "Token count is too large: celery__celery-8427\n",
      "Token count is too large: pandas-dev__pandas-34429\n",
      "Token count is too large: mesonbuild__meson-11613\n",
      "Token count is too large: ipython__ipython-10369\n",
      "Token count is too large: conda__conda-3538\n",
      "Token count is too large: googleapis__google-cloud-python-1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1554 examples [01:44, 19.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-2734\n",
      "Token count is too large: pyca__cryptography-2219\n",
      "Token count is too large: conan-io__conan-5298\n",
      "Token count is too large: ray-project__ray-10573\n",
      "Token count is too large: pandas-dev__pandas-36238\n",
      "Token count is too large: numpy__numpy-8054\n",
      "Token count is too large: pandas-dev__pandas-37433\n",
      "Token count is too large: ytdl-org__youtube-dl-554\n",
      "Token count is too large: ytdl-org__youtube-dl-3375\n",
      "Token count is too large: pandas-dev__pandas-16932\n",
      "Token count is too large: mesonbuild__meson-11672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1560 examples [01:44, 24.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7672\n",
      "Token count is too large: pypa__pip-3136\n",
      "Token count is too large: pandas-dev__pandas-4850\n",
      "Token count is too large: pandas-dev__pandas-30336\n",
      "Token count is too large: mesonbuild__meson-1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1563 examples [01:45, 21.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26584\n",
      "Token count is too large: Lightning-AI__lightning-1357\n",
      "Token count is too large: numpy__numpy-8678\n",
      "Token count is too large: Qiskit__qiskit-9063\n",
      "Token count is too large: pandas-dev__pandas-23688\n",
      "Token count is too large: Lightning-AI__lightning-3258\n",
      "Token count is too large: pandas-dev__pandas-5848\n",
      "Token count is too large: pantsbuild__pants-15587\n",
      "Token count is too large: Qiskit__qiskit-5479\n",
      "Token count is too large: huggingface__transformers-7858\n",
      "Token count is too large: pandas-dev__pandas-24274\n",
      "Token count is too large: ytdl-org__youtube-dl-4394\n",
      "Token count is too large: conan-io__conan-4626\n",
      "Token count is too large: wagtail__wagtail-8697\n",
      "Token count is too large: conda__conda-662\n",
      "Token count is too large: dagster-io__dagster-15082\n",
      "Token count is too large: pandas-dev__pandas-3509\n",
      "Token count is too large: numpy__numpy-20420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1566 examples [01:45, 13.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-767\n",
      "Token count is too large: celery__celery-6138\n",
      "Token count is too large: pandas-dev__pandas-25925\n",
      "Token count is too large: ytdl-org__youtube-dl-2859\n",
      "Token count is too large: pandas-dev__pandas-29444\n",
      "Token count is too large: googleapis__google-cloud-python-355\n",
      "Token count is too large: pandas-dev__pandas-39355\n",
      "Token count is too large: Lightning-AI__lightning-2721\n",
      "Token count is too large: wagtail__wagtail-4184\n",
      "Token count is too large: pandas-dev__pandas-8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1572 examples [01:45, 15.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-11760\n",
      "Token count is too large: ytdl-org__youtube-dl-8348\n",
      "Token count is too large: celery__celery-6770\n",
      "Token count is too large: pandas-dev__pandas-13575\n",
      "Token count is too large: pandas-dev__pandas-22601\n",
      "Token count is too large: apache__airflow-29136\n",
      "Token count is too large: pyca__cryptography-6348\n",
      "Token count is too large: pandas-dev__pandas-6204\n",
      "Token count is too large: celery__celery-7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1579 examples [01:46, 21.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17105\n",
      "Token count is too large: googleapis__google-cloud-python-2805\n",
      "Token count is too large: pandas-dev__pandas-7015\n",
      "Token count is too large: pandas-dev__pandas-4269\n",
      "Token count is too large: huggingface__transformers-23872\n",
      "Token count is too large: docker__compose-7689\n",
      "Token count is too large: pandas-dev__pandas-38582\n",
      "Token count is too large: pypa__pip-10943\n",
      "Token count is too large: conan-io__conan-4172\n",
      "Token count is too large: google__jax-1605\n",
      "Token count is too large: conda__conda-4433\n",
      "Token count is too large: pandas-dev__pandas-14520\n",
      "Token count is too large: wagtail__wagtail-6422\n",
      "Token count is too large: huggingface__transformers-22536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1582 examples [01:46, 15.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7616\n",
      "Token count is too large: Qiskit__qiskit-6070\n",
      "Token count is too large: conan-io__conan-5444\n",
      "Token count is too large: DataDog__integrations-core-1620\n",
      "Token count is too large: conan-io__conan-5461\n",
      "Token count is too large: pandas-dev__pandas-20826\n",
      "Token count is too large: Qiskit__qiskit-4517\n",
      "Token count is too large: conan-io__conan-8125\n",
      "Token count is too large: huggingface__transformers-5972\n",
      "Token count is too large: celery__celery-8383\n",
      "Token count is too large: numpy__numpy-20497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1585 examples [01:46, 12.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6806\n",
      "Token count is too large: pandas-dev__pandas-30905\n",
      "Token count is too large: numpy__numpy-3854\n",
      "Token count is too large: Lightning-AI__lightning-1192\n",
      "Token count is too large: numpy__numpy-13163\n",
      "Token count is too large: PrefectHQ__prefect-2482\n",
      "Token count is too large: mesonbuild__meson-4601\n",
      "Token count is too large: Qiskit__qiskit-2301\n",
      "Token count is too large: celery__celery-6488\n",
      "Token count is too large: Qiskit__qiskit-10322\n",
      "Token count is too large: pandas-dev__pandas-29654\n",
      "Token count is too large: pandas-dev__pandas-39500\n",
      "Token count is too large: pandas-dev__pandas-35195\n",
      "Token count is too large: pandas-dev__pandas-16895\n",
      "Token count is too large: wagtail__wagtail-6402\n",
      "Token count is too large: ipython__ipython-1836\n",
      "Token count is too large: huggingface__transformers-13489\n",
      "Token count is too large: googleapis__google-cloud-python-8416\n",
      "Token count is too large: pandas-dev__pandas-37185\n",
      "Token count is too large: huggingface__transformers-19426\n",
      "Token count is too large: huggingface__transformers-25184\n",
      "Token count is too large: pandas-dev__pandas-6133\n",
      "Token count is too large: apache__airflow-15827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1587 examples [01:47,  9.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-6123\n",
      "Token count is too large: Qiskit__qiskit-4811\n",
      "Token count is too large: mesonbuild__meson-3135\n",
      "Token count is too large: pandas-dev__pandas-32478\n",
      "Token count is too large: ytdl-org__youtube-dl-16427\n",
      "Token count is too large: Qiskit__qiskit-5268\n",
      "Token count is too large: Qiskit__qiskit-10545\n",
      "Token count is too large: ipython__ipython-7496\n",
      "Token count is too large: numpy__numpy-3448\n",
      "Token count is too large: pandas-dev__pandas-17879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1589 examples [01:47,  9.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35607\n",
      "Token count is too large: mesonbuild__meson-6182\n",
      "Token count is too large: mesonbuild__meson-11125\n",
      "Token count is too large: mesonbuild__meson-1948\n",
      "Token count is too large: pandas-dev__pandas-31232\n",
      "Token count is too large: pandas-dev__pandas-29447\n",
      "Token count is too large: pandas-dev__pandas-11345\n",
      "Token count is too large: tiangolo__fastapi-437\n",
      "Token count is too large: Lightning-AI__lightning-1492\n",
      "Token count is too large: mesonbuild__meson-1879\n",
      "Token count is too large: pantsbuild__pants-6614\n",
      "Token count is too large: mesonbuild__meson-11863\n",
      "Token count is too large: googleapis__google-cloud-python-9525\n",
      "Token count is too large: numpy__numpy-12439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1596 examples [01:48, 12.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36862\n",
      "Token count is too large: pandas-dev__pandas-37251\n",
      "Token count is too large: pandas-dev__pandas-36675\n",
      "Token count is too large: huggingface__transformers-15554\n",
      "Token count is too large: mesonbuild__meson-4725\n",
      "Token count is too large: pandas-dev__pandas-36709\n",
      "Token count is too large: celery__celery-7945\n",
      "Token count is too large: huggingface__transformers-19056\n",
      "Token count is too large: huggingface__transformers-24960\n",
      "Token count is too large: Lightning-AI__lightning-2169\n",
      "Token count is too large: googleapis__google-cloud-python-506\n",
      "Token count is too large: conan-io__conan-2885\n",
      "Token count is too large: pandas-dev__pandas-14225\n",
      "Token count is too large: pandas-dev__pandas-22293\n",
      "Token count is too large: pypa__pip-9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1608 examples [01:48, 15.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-2708\n",
      "Token count is too large: kubeflow__pipelines-1886\n",
      "Token count is too large: google__jax-1329\n",
      "Token count is too large: pantsbuild__pants-13560\n",
      "Token count is too large: googleapis__google-cloud-python-6513\n",
      "Token count is too large: mesonbuild__meson-2760\n",
      "Token count is too large: mesonbuild__meson-5767\n",
      "Token count is too large: pandas-dev__pandas-8699\n",
      "Token count is too large: ray-project__ray-4379\n",
      "Token count is too large: ipython__ipython-4977\n",
      "Token count is too large: PrefectHQ__prefect-2853\n",
      "Token count is too large: conda__conda-4778\n",
      "Token count is too large: pypa__pip-3204\n",
      "Token count is too large: Qiskit__qiskit-6324\n",
      "Token count is too large: mesonbuild__meson-5824\n",
      "Token count is too large: pandas-dev__pandas-38150\n",
      "Token count is too large: mesonbuild__meson-3932\n",
      "Token count is too large: numpy__numpy-12842\n",
      "Token count is too large: Qiskit__qiskit-2480\n",
      "Token count is too large: pandas-dev__pandas-2328\n",
      "Token count is too large: pandas-dev__pandas-21456\n",
      "Token count is too large: pandas-dev__pandas-6605\n",
      "Token count is too large: conda__conda-8723\n",
      "Token count is too large: conan-io__conan-2728\n",
      "Token count is too large: Qiskit__qiskit-6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1612 examples [01:49, 12.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24447\n",
      "Token count is too large: pandas-dev__pandas-18181\n",
      "Token count is too large: open-mmlab__mmdetection-6767\n",
      "Token count is too large: pyca__cryptography-2558\n",
      "Token count is too large: pandas-dev__pandas-10026\n",
      "Token count is too large: pandas-dev__pandas-37999\n",
      "Token count is too large: pandas-dev__pandas-28982\n",
      "Token count is too large: conda__conda-5839\n",
      "Token count is too large: Qiskit__qiskit-1404\n",
      "Token count is too large: ytdl-org__youtube-dl-5953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1614 examples [01:49, 12.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21397\n",
      "Token count is too large: pandas-dev__pandas-27827\n",
      "Token count is too large: pandas-dev__pandas-4622\n",
      "Token count is too large: conan-io__conan-4737\n",
      "Token count is too large: ipython__ipython-6643\n",
      "Token count is too large: pypa__pip-8522\n",
      "Token count is too large: pandas-dev__pandas-34756\n",
      "Token count is too large: gitpython-developers__GitPython-681\n",
      "Token count is too large: googleapis__google-cloud-python-8176\n",
      "Token count is too large: pantsbuild__pants-4412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1618 examples [01:49, 14.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-394\n",
      "Token count is too large: tensorflow__models-2146\n",
      "Token count is too large: pandas-dev__pandas-18624\n",
      "Token count is too large: numpy__numpy-24191\n",
      "Token count is too large: googleapis__google-cloud-python-10011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1621 examples [01:50,  8.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-4038\n",
      "Token count is too large: Lightning-AI__lightning-617\n",
      "Token count is too large: wagtail__wagtail-10303\n",
      "Token count is too large: Qiskit__qiskit-2185\n",
      "Token count is too large: jupyterlab__jupyterlab-6040\n",
      "Token count is too large: pandas-dev__pandas-22072\n",
      "Token count is too large: google__jax-2111\n",
      "Token count is too large: numpy__numpy-3249\n",
      "Token count is too large: pandas-dev__pandas-17017\n",
      "Token count is too large: pandas-dev__pandas-30515\n",
      "Token count is too large: pandas-dev__pandas-18209\n",
      "Token count is too large: docker__compose-5819\n",
      "Token count is too large: huggingface__transformers-22653\n",
      "Token count is too large: pandas-dev__pandas-7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1623 examples [01:50,  7.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-5684\n",
      "Token count is too large: pandas-dev__pandas-27105\n",
      "Token count is too large: Lightning-AI__lightning-252\n",
      "Token count is too large: pandas-dev__pandas-28229\n",
      "Token count is too large: mesonbuild__meson-6582\n",
      "Token count is too large: pandas-dev__pandas-23100\n",
      "Token count is too large: huggingface__transformers-8568\n",
      "Token count is too large: pandas-dev__pandas-6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1625 examples [01:50,  7.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-16829\n",
      "Token count is too large: pandas-dev__pandas-7728\n",
      "Token count is too large: conan-io__conan-3377\n",
      "Token count is too large: googleapis__google-cloud-python-2590\n",
      "Token count is too large: pandas-dev__pandas-26188\n",
      "Token count is too large: pantsbuild__pants-16250\n",
      "Token count is too large: ipython__ipython-1691\n",
      "Token count is too large: PrefectHQ__prefect-557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1633 examples [01:51, 13.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-4916\n",
      "Token count is too large: pandas-dev__pandas-21954\n",
      "Token count is too large: numpy__numpy-11522\n",
      "Token count is too large: pandas-dev__pandas-5634\n",
      "Token count is too large: pandas-dev__pandas-38892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1635 examples [01:51, 12.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25802\n",
      "Token count is too large: ytdl-org__youtube-dl-20731\n",
      "Token count is too large: pandas-dev__pandas-34508\n",
      "Token count is too large: pandas-dev__pandas-6601\n",
      "Token count is too large: pandas-dev__pandas-8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1641 examples [01:51, 14.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6440\n",
      "Token count is too large: pantsbuild__pants-13061\n",
      "Token count is too large: docker__compose-4669\n",
      "Token count is too large: apache__airflow-13286\n",
      "Token count is too large: twisted__twisted-11796\n",
      "Token count is too large: huggingface__transformers-7552\n",
      "Token count is too large: celery__celery-5638\n",
      "Token count is too large: pandas-dev__pandas-29680\n",
      "Token count is too large: huggingface__transformers-13338\n",
      "Token count is too large: conda__conda-5099\n",
      "Token count is too large: ytdl-org__youtube-dl-25239\n",
      "Token count is too large: Qiskit__qiskit-3867\n",
      "Token count is too large: apache__airflow-8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1644 examples [01:51, 16.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23751\n",
      "Token count is too large: pandas-dev__pandas-31097\n",
      "Token count is too large: pandas-dev__pandas-8752\n",
      "Token count is too large: pandas-dev__pandas-18525\n",
      "Token count is too large: pandas-dev__pandas-6433\n",
      "Token count is too large: pandas-dev__pandas-25844\n",
      "Token count is too large: numpy__numpy-6644\n",
      "Token count is too large: Qiskit__qiskit-2705\n",
      "Token count is too large: numpy__numpy-9133\n",
      "Token count is too large: googleapis__google-cloud-python-9495\n",
      "Token count is too large: ray-project__ray-2254\n",
      "Token count is too large: numpy__numpy-21141\n",
      "Token count is too large: wagtail__wagtail-1411\n",
      "Token count is too large: Lightning-AI__lightning-1913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1649 examples [01:52, 18.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-9350\n",
      "Token count is too large: pandas-dev__pandas-10171\n",
      "Token count is too large: googleapis__google-cloud-python-3180\n",
      "Token count is too large: huggingface__transformers-14783\n",
      "Token count is too large: mesonbuild__meson-8912\n",
      "Token count is too large: pandas-dev__pandas-4942\n",
      "Token count is too large: ytdl-org__youtube-dl-11122\n",
      "Token count is too large: numpy__numpy-94\n",
      "Token count is too large: Qiskit__qiskit-2650\n",
      "Token count is too large: pandas-dev__pandas-38679\n",
      "Token count is too large: docker__compose-5858\n",
      "Token count is too large: twisted__twisted-11706\n",
      "Token count is too large: numpy__numpy-12307\n",
      "Token count is too large: Qiskit__qiskit-2442\n",
      "Token count is too large: Qiskit__qiskit-9206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1652 examples [01:52, 10.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-12586\n",
      "Token count is too large: PrefectHQ__prefect-2898\n",
      "Token count is too large: pandas-dev__pandas-11110\n",
      "Token count is too large: pantsbuild__pants-7179\n",
      "Token count is too large: apache__airflow-26885\n",
      "Token count is too large: pandas-dev__pandas-24114\n",
      "Token count is too large: huggingface__transformers-7431\n",
      "Token count is too large: apache__airflow-27067\n",
      "Token count is too large: pandas-dev__pandas-30797\n",
      "Token count is too large: ipython__ipython-1852\n",
      "Token count is too large: conda__conda-8290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1654 examples [01:52, 10.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5930\n",
      "Token count is too large: Qiskit__qiskit-7517\n",
      "Token count is too large: huggingface__transformers-15416\n",
      "Token count is too large: Qiskit__qiskit-1135\n",
      "Token count is too large: pandas-dev__pandas-5723\n",
      "Token count is too large: tensorflow__models-4084\n",
      "Token count is too large: conan-io__conan-4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1656 examples [01:53,  9.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4076\n",
      "Token count is too large: conda__conda-7274\n",
      "Token count is too large: pandas-dev__pandas-6477\n",
      "Token count is too large: pandas-dev__pandas-16305\n",
      "Token count is too large: pandas-dev__pandas-23479\n",
      "Token count is too large: huggingface__transformers-14661\n",
      "Token count is too large: Qiskit__qiskit-2783\n",
      "Token count is too large: numpy__numpy-16311\n",
      "Token count is too large: google__jax-640\n",
      "Token count is too large: pandas-dev__pandas-8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1663 examples [01:53, 16.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-3760\n",
      "Token count is too large: pandas-dev__pandas-16191\n",
      "Token count is too large: pantsbuild__pants-13675\n",
      "Token count is too large: huggingface__transformers-1315\n",
      "There was an error processing\n",
      "Token count is too large: mesonbuild__meson-2885\n",
      "Token count is too large: pandas-dev__pandas-13814\n",
      "Token count is too large: celery__celery-5565\n",
      "Token count is too large: mesonbuild__meson-7309\n",
      "Token count is too large: pandas-dev__pandas-7951\n",
      "Token count is too large: pandas-dev__pandas-4837\n",
      "Token count is too large: pandas-dev__pandas-16431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1668 examples [01:53, 19.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-2890\n",
      "Token count is too large: numpy__numpy-8955\n",
      "Token count is too large: pandas-dev__pandas-9814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1671 examples [01:53, 14.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-12382\n",
      "Token count is too large: apache__airflow-15311\n",
      "Token count is too large: huggingface__transformers-25636\n",
      "Token count is too large: pantsbuild__pants-11223\n",
      "Token count is too large: pandas-dev__pandas-38701\n",
      "Token count is too large: apache__airflow-25370\n",
      "Token count is too large: dagster-io__dagster-14060\n",
      "Token count is too large: pandas-dev__pandas-20372\n",
      "Token count is too large: ytdl-org__youtube-dl-18336\n",
      "Token count is too large: pantsbuild__pants-16586\n",
      "Token count is too large: pandas-dev__pandas-16992\n",
      "Token count is too large: pypa__pip-5831\n",
      "Token count is too large: pandas-dev__pandas-27311\n",
      "Token count is too large: Qiskit__qiskit-9999\n",
      "Token count is too large: pandas-dev__pandas-39747\n",
      "Token count is too large: pantsbuild__pants-19366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1675 examples [01:54, 12.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24657\n",
      "Token count is too large: numpy__numpy-10375\n",
      "Token count is too large: mesonbuild__meson-6025\n",
      "Token count is too large: pantsbuild__pants-15368\n",
      "Token count is too large: pandas-dev__pandas-8026\n",
      "Token count is too large: pandas-dev__pandas-17272\n",
      "Token count is too large: pandas-dev__pandas-17871\n",
      "Token count is too large: ipython__ipython-5916\n",
      "Token count is too large: huggingface__transformers-11680\n",
      "Token count is too large: pandas-dev__pandas-9845\n",
      "Token count is too large: Lightning-AI__lightning-3394\n",
      "Token count is too large: Lightning-AI__lightning-1017\n",
      "Token count is too large: pandas-dev__pandas-5633\n",
      "Token count is too large: conan-io__conan-5350\n",
      "Token count is too large: pandas-dev__pandas-11750\n",
      "Token count is too large: apache__airflow-15425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1680 examples [01:54, 11.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27349\n",
      "Token count is too large: pantsbuild__pants-16251\n",
      "Token count is too large: pandas-dev__pandas-38099\n",
      "Token count is too large: numpy__numpy-13242\n",
      "Token count is too large: pandas-dev__pandas-30580\n",
      "Token count is too large: huggingface__transformers-11071\n",
      "Token count is too large: conan-io__conan-8483\n",
      "Token count is too large: Qiskit__qiskit-1360\n",
      "Token count is too large: dagster-io__dagster-14717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1684 examples [01:54, 13.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29118\n",
      "Token count is too large: pypa__pip-9522\n",
      "Token count is too large: huggingface__transformers-23914\n",
      "Token count is too large: pandas-dev__pandas-10379\n",
      "Token count is too large: pandas-dev__pandas-4430\n",
      "Token count is too large: pantsbuild__pants-14270\n",
      "Token count is too large: huggingface__transformers-13573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1686 examples [01:55, 12.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-3225\n",
      "Token count is too large: Lightning-AI__lightning-803\n",
      "Token count is too large: pandas-dev__pandas-39352\n",
      "Token count is too large: docker__compose-2467\n",
      "Token count is too large: Qiskit__qiskit-7190\n",
      "Token count is too large: mesonbuild__meson-3501\n",
      "Token count is too large: pandas-dev__pandas-16484\n",
      "Token count is too large: pandas-dev__pandas-23805\n",
      "Token count is too large: pandas-dev__pandas-20730\n",
      "Token count is too large: mesonbuild__meson-4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1690 examples [01:55, 13.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6067\n",
      "Token count is too large: googleapis__google-cloud-python-4931\n",
      "Token count is too large: mesonbuild__meson-6589\n",
      "Token count is too large: googleapis__google-cloud-python-502\n",
      "Token count is too large: pypa__pip-9835\n",
      "Token count is too large: apache__airflow-12240\n",
      "Token count is too large: huggingface__transformers-24526\n",
      "Token count is too large: docker__compose-2665\n",
      "Token count is too large: pyca__cryptography-5900\n",
      "Token count is too large: Qiskit__qiskit-579\n",
      "Token count is too large: numpy__numpy-16789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1693 examples [01:55, 13.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11870\n",
      "Token count is too large: pandas-dev__pandas-23621\n",
      "Token count is too large: wagtail__wagtail-8948\n",
      "Token count is too large: google__jax-1668\n",
      "Token count is too large: conan-io__conan-3352\n",
      "Token count is too large: pandas-dev__pandas-32782\n",
      "Token count is too large: pandas-dev__pandas-26665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1697 examples [01:55, 17.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38373\n",
      "Token count is too large: pypa__pip-10906\n",
      "Token count is too large: google__jax-752\n",
      "Token count is too large: ray-project__ray-4915\n",
      "Token count is too large: pandas-dev__pandas-37288\n",
      "Token count is too large: huggingface__transformers-19846\n",
      "Token count is too large: pandas-dev__pandas-10431\n",
      "Token count is too large: conda__conda-6956\n",
      "Token count is too large: apache__airflow-22536\n",
      "Token count is too large: pandas-dev__pandas-17156\n",
      "Token count is too large: celery__celery-4864\n",
      "Token count is too large: ytdl-org__youtube-dl-7382\n",
      "Token count is too large: pandas-dev__pandas-13662\n",
      "Token count is too large: pandas-dev__pandas-6473\n",
      "Token count is too large: pandas-dev__pandas-21740\n",
      "Token count is too large: pandas-dev__pandas-22058\n",
      "Token count is too large: huggingface__transformers-21490\n",
      "Token count is too large: conan-io__conan-7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1704 examples [01:56, 17.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9735\n",
      "Token count is too large: numpy__numpy-7425\n",
      "Token count is too large: pandas-dev__pandas-38014\n",
      "Token count is too large: googleapis__google-cloud-python-1250\n",
      "Token count is too large: huggingface__transformers-20353\n",
      "Token count is too large: docker__compose-3459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1711 examples [01:56, 21.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6560\n",
      "Token count is too large: google__jax-512\n",
      "Token count is too large: conda__conda-6602\n",
      "Token count is too large: dagster-io__dagster-9828\n",
      "Token count is too large: pypa__pip-3073\n",
      "Token count is too large: googleapis__google-cloud-python-9360\n",
      "Token count is too large: conan-io__conan-14362\n",
      "Token count is too large: numpy__numpy-10739\n",
      "Token count is too large: conda__conda-7243\n",
      "Token count is too large: huggingface__transformers-13436\n",
      "Token count is too large: wagtail__wagtail-10255\n",
      "Token count is too large: numpy__numpy-11717\n",
      "Token count is too large: pandas-dev__pandas-7392\n",
      "Token count is too large: conan-io__conan-4202\n",
      "Token count is too large: googleapis__google-cloud-python-6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1714 examples [01:56, 17.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4352\n",
      "Token count is too large: pandas-dev__pandas-3148\n",
      "Token count is too large: pandas-dev__pandas-21981\n",
      "Token count is too large: conan-io__conan-99\n",
      "Token count is too large: huggingface__transformers-22658\n",
      "Token count is too large: Qiskit__qiskit-8120\n",
      "Token count is too large: pandas-dev__pandas-19823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1716 examples [01:56, 15.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-4774\n",
      "Token count is too large: pypa__pip-7542\n",
      "Token count is too large: Qiskit__qiskit-2716\n",
      "Token count is too large: pandas-dev__pandas-3961\n",
      "Token count is too large: pandas-dev__pandas-19628\n",
      "Token count is too large: huggingface__transformers-7724\n",
      "Token count is too large: pandas-dev__pandas-6396\n",
      "Token count is too large: numpy__numpy-18630\n",
      "Token count is too large: huggingface__transformers-14744\n",
      "Token count is too large: ytdl-org__youtube-dl-21208\n",
      "Token count is too large: conan-io__conan-3212\n",
      "Token count is too large: numpy__numpy-8121\n",
      "Token count is too large: pandas-dev__pandas-21000\n",
      "Token count is too large: ipython__ipython-9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1718 examples [01:57, 11.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5123\n",
      "Token count is too large: pandas-dev__pandas-10727\n",
      "Token count is too large: Lightning-AI__lightning-2273\n",
      "Token count is too large: pandas-dev__pandas-5219\n",
      "Token count is too large: Lightning-AI__lightning-2213\n",
      "Token count is too large: pandas-dev__pandas-39372\n",
      "Token count is too large: numpy__numpy-23073\n",
      "Token count is too large: docker__compose-2851\n",
      "Token count is too large: apache__airflow-29518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1724 examples [01:57, 15.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-3635\n",
      "Token count is too large: jupyterlab__jupyterlab-2038\n",
      "Token count is too large: numpy__numpy-5504\n",
      "Token count is too large: pandas-dev__pandas-8753\n",
      "Token count is too large: pandas-dev__pandas-24034\n",
      "Token count is too large: conan-io__conan-6380\n",
      "Token count is too large: Qiskit__qiskit-3123\n",
      "Token count is too large: Qiskit__qiskit-3547\n",
      "Token count is too large: pypa__pip-3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1730 examples [01:57, 15.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6081\n",
      "Token count is too large: pandas-dev__pandas-38997\n",
      "Token count is too large: conan-io__conan-2812\n",
      "Token count is too large: jupyterlab__jupyterlab-5351\n",
      "Token count is too large: pandas-dev__pandas-35763\n",
      "Token count is too large: pandas-dev__pandas-7874\n",
      "Token count is too large: pantsbuild__pants-9551\n",
      "Token count is too large: conan-io__conan-4824\n",
      "Token count is too large: Lightning-AI__lightning-2121\n",
      "Token count is too large: huggingface__transformers-17712\n",
      "Token count is too large: pandas-dev__pandas-19067\n",
      "Token count is too large: celery__celery-4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1733 examples [01:58, 15.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-1399\n",
      "Token count is too large: pandas-dev__pandas-3125\n",
      "Token count is too large: huggingface__transformers-24448\n",
      "Token count is too large: ray-project__ray-8445\n",
      "Token count is too large: pandas-dev__pandas-29743\n",
      "Token count is too large: huggingface__transformers-18297\n",
      "Token count is too large: tensorflow__models-3622\n",
      "Token count is too large: pandas-dev__pandas-26518\n",
      "Token count is too large: pandas-dev__pandas-38909\n",
      "Token count is too large: numpy__numpy-4677\n",
      "Token count is too large: pandas-dev__pandas-4104\n",
      "Token count is too large: dagster-io__dagster-2640\n",
      "Token count is too large: google__jax-760\n",
      "Token count is too large: pandas-dev__pandas-35604\n",
      "Token count is too large: mesonbuild__meson-5665\n",
      "Token count is too large: ytdl-org__youtube-dl-5942\n",
      "Token count is too large: numpy__numpy-20499\n",
      "Token count is too large: huggingface__transformers-6168\n",
      "Token count is too large: wagtail__wagtail-4229\n",
      "Token count is too large: pandas-dev__pandas-5507\n",
      "Token count is too large: ipython__ipython-923\n",
      "Token count is too large: dagster-io__dagster-7453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1738 examples [01:58, 12.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3625\n",
      "Token count is too large: PrefectHQ__prefect-2625\n",
      "Token count is too large: pandas-dev__pandas-23991\n",
      "Token count is too large: Lightning-AI__lightning-1251\n",
      "Token count is too large: pandas-dev__pandas-34450\n",
      "Token count is too large: numpy__numpy-20724\n",
      "Token count is too large: pandas-dev__pandas-29508\n",
      "Token count is too large: numpy__numpy-11721\n",
      "Token count is too large: Lightning-AI__lightning-1512\n",
      "Token count is too large: googleapis__google-cloud-python-9577\n",
      "Token count is too large: Qiskit__qiskit-10581\n",
      "Token count is too large: jupyterlab__jupyterlab-4410\n",
      "Token count is too large: mesonbuild__meson-5338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1743 examples [01:59, 10.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-6567\n",
      "Token count is too large: google__jax-169\n",
      "Token count is too large: numpy__numpy-9930\n",
      "Token count is too large: Lightning-AI__lightning-360\n",
      "Token count is too large: numpy__numpy-9299\n",
      "Token count is too large: pandas-dev__pandas-3564\n",
      "Token count is too large: pypa__pip-3070\n",
      "Token count is too large: jupyterlab__jupyterlab-9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1746 examples [01:59, 11.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7120\n",
      "Token count is too large: ipython__ipython-11716\n",
      "Token count is too large: pandas-dev__pandas-21203\n",
      "Token count is too large: Qiskit__qiskit-1197\n",
      "Token count is too large: pandas-dev__pandas-39212\n",
      "Token count is too large: huggingface__transformers-5629\n",
      "Token count is too large: pandas-dev__pandas-14234\n",
      "Token count is too large: huggingface__transformers-14713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1749 examples [01:59, 11.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-7103\n",
      "Token count is too large: mesonbuild__meson-3272\n",
      "Token count is too large: googleapis__google-cloud-python-11343\n",
      "Token count is too large: pandas-dev__pandas-26024\n",
      "Token count is too large: huggingface__transformers-21111\n",
      "Token count is too large: pypa__pip-8056\n",
      "Token count is too large: pandas-dev__pandas-38740\n",
      "Token count is too large: Qiskit__qiskit-169\n",
      "Token count is too large: ipython__ipython-876\n",
      "Token count is too large: pandas-dev__pandas-36228\n",
      "Token count is too large: pandas-dev__pandas-7303\n",
      "Token count is too large: conda__conda-5373\n",
      "Token count is too large: conda__conda-4843\n",
      "Token count is too large: conan-io__conan-3567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1751 examples [02:00,  5.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-17669\n",
      "Token count is too large: pandas-dev__pandas-24159\n",
      "Token count is too large: huggingface__transformers-16913\n",
      "Token count is too large: wagtail__wagtail-5093\n",
      "Token count is too large: pantsbuild__pants-11811\n",
      "Token count is too large: pandas-dev__pandas-21069\n",
      "Token count is too large: conda__conda-6764\n",
      "Token count is too large: ytdl-org__youtube-dl-31414\n",
      "Token count is too large: Qiskit__qiskit-4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1754 examples [02:00,  6.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16487\n",
      "Token count is too large: huggingface__transformers-12314\n",
      "Token count is too large: pandas-dev__pandas-23327\n",
      "Token count is too large: Qiskit__qiskit-1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1762 examples [02:01, 13.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24067\n",
      "Token count is too large: numpy__numpy-9996\n",
      "Token count is too large: Qiskit__qiskit-2247\n",
      "Token count is too large: pandas-dev__pandas-19525\n",
      "Token count is too large: pandas-dev__pandas-32142\n",
      "Token count is too large: google__jax-914\n",
      "Token count is too large: conda__conda-6916\n",
      "Token count is too large: huggingface__transformers-15751\n",
      "Token count is too large: docker__compose-2019\n",
      "Token count is too large: Qiskit__qiskit-363\n",
      "Token count is too large: pypa__pip-5952\n",
      "Token count is too large: conda__conda-2821\n",
      "Token count is too large: mesonbuild__meson-10407\n",
      "Token count is too large: pandas-dev__pandas-22564\n",
      "Token count is too large: pandas-dev__pandas-29393\n",
      "Token count is too large: Lightning-AI__lightning-2473\n",
      "Token count is too large: pandas-dev__pandas-37321\n",
      "Token count is too large: pandas-dev__pandas-13849\n",
      "Token count is too large: pandas-dev__pandas-38074\n",
      "Token count is too large: Qiskit__qiskit-867\n",
      "Token count is too large: pandas-dev__pandas-18476\n",
      "Token count is too large: pandas-dev__pandas-19065\n",
      "Token count is too large: numpy__numpy-19098\n",
      "Token count is too large: huggingface__transformers-12720\n",
      "Token count is too large: pandas-dev__pandas-14514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1766 examples [02:01,  9.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3281\n",
      "Token count is too large: pandas-dev__pandas-8975\n",
      "Token count is too large: Qiskit__qiskit-5298\n",
      "Token count is too large: pypa__pip-7023\n",
      "Token count is too large: twisted__twisted-11654\n",
      "Token count is too large: apache__airflow-30596\n",
      "Token count is too large: celery__celery-3746\n",
      "Token count is too large: pandas-dev__pandas-3818\n",
      "Token count is too large: pandas-dev__pandas-7931\n",
      "Token count is too large: PrefectHQ__prefect-598\n",
      "Token count is too large: huggingface__transformers-10602\n",
      "Token count is too large: pandas-dev__pandas-4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1771 examples [02:02, 12.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-8030\n",
      "Token count is too large: mesonbuild__meson-9221\n",
      "Token count is too large: pandas-dev__pandas-22345\n",
      "Token count is too large: pypa__pip-5339\n",
      "There was an error processing\n",
      "Token count is too large: ray-project__ray-8771\n",
      "Token count is too large: huggingface__transformers-25344\n",
      "Token count is too large: Qiskit__qiskit-9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1777 examples [02:02, 15.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-9516\n",
      "Token count is too large: python__typeshed-8775\n",
      "Token count is too large: numpy__numpy-5943\n",
      "Token count is too large: conda__conda-6044\n",
      "Token count is too large: numpy__numpy-6199\n",
      "Token count is too large: pandas-dev__pandas-5034\n",
      "Token count is too large: huggingface__transformers-1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1781 examples [02:02, 17.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4571\n",
      "Token count is too large: apache__airflow-23106\n",
      "Token count is too large: gitpython-developers__GitPython-1618\n",
      "Token count is too large: conda__conda-7498\n",
      "Token count is too large: googleapis__google-cloud-python-407\n",
      "Token count is too large: huggingface__transformers-9379\n",
      "Token count is too large: twisted__twisted-11884\n",
      "Token count is too large: pypa__pip-5483\n",
      "Token count is too large: conda__conda-4100\n",
      "Token count is too large: mesonbuild__meson-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1785 examples [02:02, 18.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18238\n",
      "Token count is too large: huggingface__transformers-9474\n",
      "Token count is too large: google__jax-1718\n",
      "Token count is too large: googleapis__google-cloud-python-8100\n",
      "Token count is too large: pandas-dev__pandas-14917\n",
      "There was an error processing\n",
      "Token count is too large: pandas-dev__pandas-17956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1793 examples [02:02, 24.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11458\n",
      "Token count is too large: ray-project__ray-8107\n",
      "Token count is too large: jupyterlab__jupyterlab-3207\n",
      "Token count is too large: pandas-dev__pandas-35778\n",
      "Token count is too large: pandas-dev__pandas-5787\n",
      "Token count is too large: apache__airflow-15411\n",
      "Token count is too large: ipython__ipython-10806\n",
      "Token count is too large: pandas-dev__pandas-24635\n",
      "Token count is too large: huggingface__transformers-6463\n",
      "Token count is too large: googleapis__google-cloud-python-9164\n",
      "Token count is too large: googleapis__google-cloud-python-6349\n",
      "Token count is too large: numpy__numpy-9986\n",
      "Token count is too large: pyca__cryptography-4114\n",
      "Token count is too large: pypa__pip-6029\n",
      "Token count is too large: PrefectHQ__prefect-1994\n",
      "Token count is too large: docker__compose-5726\n",
      "Token count is too large: pandas-dev__pandas-38145\n",
      "Token count is too large: googleapis__google-cloud-python-6578\n",
      "Token count is too large: pandas-dev__pandas-14768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1797 examples [02:03, 19.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5251\n",
      "Token count is too large: pandas-dev__pandas-5941\n",
      "Token count is too large: ytdl-org__youtube-dl-28849\n",
      "Token count is too large: pandas-dev__pandas-14479\n",
      "Token count is too large: Qiskit__qiskit-9391\n",
      "Token count is too large: Qiskit__qiskit-8055\n",
      "Token count is too large: googleapis__google-cloud-python-1479\n",
      "Token count is too large: Qiskit__qiskit-447\n",
      "Token count is too large: pandas-dev__pandas-4031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1801 examples [02:03, 19.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27156\n",
      "There was an error processing\n",
      "Token count is too large: numpy__numpy-11805\n",
      "Token count is too large: pandas-dev__pandas-11291\n",
      "Token count is too large: conda__conda-7156\n",
      "Token count is too large: mesonbuild__meson-11874\n",
      "Token count is too large: googleapis__google-cloud-python-2107\n",
      "Token count is too large: Qiskit__qiskit-4797\n",
      "Token count is too large: pantsbuild__pants-16108\n",
      "Token count is too large: pandas-dev__pandas-3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1807 examples [02:03, 17.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-974\n",
      "Token count is too large: pandas-dev__pandas-39378\n",
      "Token count is too large: googleapis__google-cloud-python-11334\n",
      "Token count is too large: ray-project__ray-10504\n",
      "Token count is too large: celery__celery-4549\n",
      "Token count is too large: pantsbuild__pants-6538\n",
      "Token count is too large: pandas-dev__pandas-17906\n",
      "Token count is too large: pandas-dev__pandas-26015\n",
      "Token count is too large: PrefectHQ__prefect-473\n",
      "Token count is too large: pandas-dev__pandas-3236\n",
      "Token count is too large: Qiskit__qiskit-1086\n",
      "Token count is too large: pandas-dev__pandas-20841\n",
      "Token count is too large: pandas-dev__pandas-22213\n",
      "Token count is too large: pandas-dev__pandas-32242\n",
      "Token count is too large: dagster-io__dagster-6237\n",
      "Token count is too large: google__jax-1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1809 examples [02:04, 13.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-8586\n",
      "Token count is too large: pantsbuild__pants-17451\n",
      "Token count is too large: pandas-dev__pandas-30219\n",
      "Token count is too large: pandas-dev__pandas-18385\n",
      "Token count is too large: Lightning-AI__lightning-2020\n",
      "Token count is too large: ipython__ipython-12860\n",
      "Token count is too large: huggingface__transformers-16165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1814 examples [02:04, 16.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17361\n",
      "Token count is too large: pandas-dev__pandas-7974\n",
      "Token count is too large: numpy__numpy-18629\n",
      "Token count is too large: mesonbuild__meson-10140\n",
      "Token count is too large: dagster-io__dagster-14025\n",
      "Token count is too large: huggingface__transformers-18414\n",
      "Token count is too large: pandas-dev__pandas-22074\n",
      "Token count is too large: celery__celery-4473\n",
      "Token count is too large: pandas-dev__pandas-18934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1816 examples [02:04, 11.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36231\n",
      "Token count is too large: huggingface__transformers-20966\n",
      "Token count is too large: pandas-dev__pandas-4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1819 examples [02:05,  9.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19558\n",
      "Token count is too large: PrefectHQ__prefect-3005\n",
      "Token count is too large: conda__conda-3629\n",
      "Token count is too large: pantsbuild__pants-13027\n",
      "Token count is too large: huggingface__transformers-21612\n",
      "Token count is too large: pandas-dev__pandas-36595\n",
      "Token count is too large: ipython__ipython-7564\n",
      "Token count is too large: pandas-dev__pandas-28993\n",
      "Token count is too large: pandas-dev__pandas-34049\n",
      "Token count is too large: pantsbuild__pants-12982\n",
      "Token count is too large: apache__airflow-15285\n",
      "Token count is too large: pandas-dev__pandas-39409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1821 examples [02:05, 10.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-1626\n",
      "Token count is too large: google__jax-110\n",
      "Token count is too large: pandas-dev__pandas-25693\n",
      "Token count is too large: numpy__numpy-5584\n",
      "Token count is too large: numpy__numpy-20974\n",
      "Token count is too large: docker__compose-1159\n",
      "Token count is too large: pandas-dev__pandas-11329\n",
      "Token count is too large: pandas-dev__pandas-6551\n",
      "Token count is too large: pandas-dev__pandas-6902\n",
      "Token count is too large: pandas-dev__pandas-11850\n",
      "Token count is too large: pandas-dev__pandas-22132\n",
      "Token count is too large: pandas-dev__pandas-11892\n",
      "Token count is too large: pantsbuild__pants-12808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1826 examples [02:05, 10.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-4830\n",
      "Token count is too large: pandas-dev__pandas-38408\n",
      "Token count is too large: conda__conda-6856\n",
      "Token count is too large: pandas-dev__pandas-6164\n",
      "Token count is too large: huggingface__transformers-7384\n",
      "Token count is too large: celery__celery-5915\n",
      "Token count is too large: Qiskit__qiskit-8741\n",
      "Token count is too large: apache__airflow-21793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1831 examples [02:05, 16.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-1549\n",
      "Token count is too large: mesonbuild__meson-3860\n",
      "Token count is too large: googleapis__google-cloud-python-8303\n",
      "Token count is too large: pandas-dev__pandas-10887\n",
      "Token count is too large: docker__compose-7754\n",
      "Token count is too large: pandas-dev__pandas-14318\n",
      "Token count is too large: mesonbuild__meson-1956\n",
      "Token count is too large: pandas-dev__pandas-25157\n",
      "Token count is too large: mesonbuild__meson-4926\n",
      "Token count is too large: docker__compose-2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1836 examples [02:06, 14.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19177\n",
      "Token count is too large: conan-io__conan-5849\n",
      "Token count is too large: pandas-dev__pandas-38931\n",
      "Token count is too large: open-mmlab__mmdetection-2032\n",
      "Token count is too large: ray-project__ray-5751\n",
      "Token count is too large: docker__compose-2334\n",
      "Token count is too large: conda__conda-3886\n",
      "Token count is too large: pandas-dev__pandas-17374\n",
      "Token count is too large: pantsbuild__pants-12717\n",
      "Token count is too large: Qiskit__qiskit-2451\n",
      "Token count is too large: googleapis__google-cloud-python-330\n",
      "Token count is too large: numpy__numpy-6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1840 examples [02:06, 15.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19669\n",
      "Token count is too large: PrefectHQ__prefect-2502\n",
      "Token count is too large: ipython__ipython-13943\n",
      "Token count is too large: pandas-dev__pandas-27677\n",
      "Token count is too large: Qiskit__qiskit-7733\n",
      "Token count is too large: pandas-dev__pandas-30526\n",
      "Token count is too large: ipython__ipython-7748\n",
      "Token count is too large: ipython__ipython-9644\n",
      "Token count is too large: conda__conda-7919\n",
      "Token count is too large: Qiskit__qiskit-4555\n",
      "Token count is too large: huggingface__transformers-18486\n",
      "Token count is too large: huggingface__transformers-15622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1844 examples [02:07, 10.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21768\n",
      "Token count is too large: ipython__ipython-1662\n",
      "Token count is too large: conda__conda-3683\n",
      "Token count is too large: jupyterlab__jupyterlab-2610\n",
      "Token count is too large: pandas-dev__pandas-36141\n",
      "Token count is too large: pantsbuild__pants-14606\n",
      "Token count is too large: pandas-dev__pandas-14527\n",
      "Token count is too large: docker__compose-5142\n",
      "Token count is too large: pandas-dev__pandas-4829\n",
      "Token count is too large: pandas-dev__pandas-27144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1848 examples [02:07, 13.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-6418\n",
      "Token count is too large: pandas-dev__pandas-5268\n",
      "Token count is too large: mesonbuild__meson-11553\n",
      "Token count is too large: pandas-dev__pandas-6304\n",
      "Token count is too large: Qiskit__qiskit-3779\n",
      "Token count is too large: ipython__ipython-12659\n",
      "Token count is too large: celery__celery-7785\n",
      "Token count is too large: pantsbuild__pants-4914\n",
      "Token count is too large: pandas-dev__pandas-36000\n",
      "Token count is too large: wagtail__wagtail-9176\n",
      "Token count is too large: pypa__pip-8098\n",
      "Token count is too large: huggingface__transformers-17968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1851 examples [02:07, 13.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22288\n",
      "Token count is too large: wagtail__wagtail-9345\n",
      "Token count is too large: Qiskit__qiskit-911\n",
      "Token count is too large: numpy__numpy-7670\n",
      "Token count is too large: pandas-dev__pandas-22296\n",
      "Token count is too large: conda__conda-5921\n",
      "Token count is too large: pantsbuild__pants-15402\n",
      "Token count is too large: mesonbuild__meson-6398\n",
      "Token count is too large: pandas-dev__pandas-21016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1855 examples [02:07, 15.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39191\n",
      "Token count is too large: wagtail__wagtail-6420\n",
      "Token count is too large: numpy__numpy-16253\n",
      "Token count is too large: conda__conda-5284\n",
      "Token count is too large: ytdl-org__youtube-dl-3407\n",
      "Token count is too large: docker__compose-3136\n",
      "Token count is too large: docker__compose-2027\n",
      "Token count is too large: pandas-dev__pandas-27767\n",
      "Token count is too large: pandas-dev__pandas-23544\n",
      "Token count is too large: googleapis__google-cloud-python-1112\n",
      "Token count is too large: pandas-dev__pandas-5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1859 examples [02:07, 17.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6111\n",
      "Token count is too large: mesonbuild__meson-7279\n",
      "Token count is too large: jupyterlab__jupyterlab-2098\n",
      "Token count is too large: pandas-dev__pandas-9667\n",
      "Token count is too large: pypa__pip-10360\n",
      "Token count is too large: conan-io__conan-4548\n",
      "Token count is too large: open-mmlab__mmdetection-2524\n",
      "Token count is too large: pyca__cryptography-2574\n",
      "Token count is too large: google__jax-3110\n",
      "Token count is too large: mesonbuild__meson-3461\n",
      "Token count is too large: google__jax-1956\n",
      "Token count is too large: conan-io__conan-5812\n",
      "Token count is too large: pandas-dev__pandas-31818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1862 examples [02:08, 14.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24138\n",
      "Token count is too large: pandas-dev__pandas-9994\n",
      "Token count is too large: huggingface__transformers-9132\n",
      "Token count is too large: conan-io__conan-2902\n",
      "Token count is too large: pandas-dev__pandas-5295\n",
      "Token count is too large: mesonbuild__meson-9424\n",
      "Token count is too large: pandas-dev__pandas-25202\n",
      "Token count is too large: conda__conda-5365\n",
      "Token count is too large: pandas-dev__pandas-38737\n",
      "Token count is too large: pandas-dev__pandas-34811\n",
      "Token count is too large: huggingface__transformers-18398\n",
      "Token count is too large: pandas-dev__pandas-7434\n",
      "Token count is too large: ytdl-org__youtube-dl-1063\n",
      "Token count is too large: dagster-io__dagster-9546\n",
      "Token count is too large: ytdl-org__youtube-dl-17542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1864 examples [02:08,  9.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1256\n",
      "Token count is too large: pandas-dev__pandas-35723\n",
      "Token count is too large: pandas-dev__pandas-39869\n",
      "Token count is too large: pandas-dev__pandas-27495\n",
      "Token count is too large: googleapis__google-cloud-python-3631\n",
      "Token count is too large: dagster-io__dagster-13310\n",
      "Token count is too large: pandas-dev__pandas-31748\n",
      "Token count is too large: ytdl-org__youtube-dl-18281\n",
      "Token count is too large: pandas-dev__pandas-5060\n",
      "Token count is too large: pandas-dev__pandas-5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1867 examples [02:08, 10.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-5301\n",
      "Token count is too large: docker__compose-5722\n",
      "Token count is too large: pandas-dev__pandas-16294\n",
      "Token count is too large: pantsbuild__pants-17057\n",
      "Token count is too large: numpy__numpy-22519\n",
      "Token count is too large: numpy__numpy-7660\n",
      "Token count is too large: pandas-dev__pandas-37035\n",
      "Token count is too large: pandas-dev__pandas-3680\n",
      "Token count is too large: apache__airflow-28191\n",
      "Token count is too large: apache__airflow-22849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1870 examples [02:09, 11.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-6208\n",
      "Token count is too large: pandas-dev__pandas-9741\n",
      "Token count is too large: pandas-dev__pandas-15040\n",
      "Token count is too large: pandas-dev__pandas-38087\n",
      "Token count is too large: docker__compose-1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1872 examples [02:09, 11.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5018\n",
      "Token count is too large: pandas-dev__pandas-27814\n",
      "Token count is too large: pandas-dev__pandas-19244\n",
      "Token count is too large: conan-io__conan-3077\n",
      "Token count is too large: apache__airflow-33601\n",
      "Token count is too large: pandas-dev__pandas-3677\n",
      "Token count is too large: pantsbuild__pants-12675\n",
      "Token count is too large: pypa__pip-4071\n",
      "Token count is too large: pandas-dev__pandas-7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1876 examples [02:09, 12.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19208\n",
      "Token count is too large: pandas-dev__pandas-4120\n",
      "Token count is too large: Lightning-AI__lightning-345\n",
      "Token count is too large: pantsbuild__pants-13386\n",
      "Token count is too large: googleapis__google-cloud-python-3340\n",
      "Token count is too large: twisted__twisted-11873\n",
      "Token count is too large: pandas-dev__pandas-25136\n",
      "Token count is too large: conan-io__conan-5025\n",
      "Token count is too large: huggingface__transformers-20158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1884 examples [02:09, 16.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6087\n",
      "Token count is too large: googleapis__google-cloud-python-6825\n",
      "Token count is too large: pandas-dev__pandas-19257\n",
      "Token count is too large: pandas-dev__pandas-21432\n",
      "Token count is too large: docker__compose-2508\n",
      "Token count is too large: googleapis__google-cloud-python-9076\n",
      "Token count is too large: mesonbuild__meson-8262\n",
      "Token count is too large: pandas-dev__pandas-36836\n",
      "Token count is too large: googleapis__google-cloud-python-8231\n",
      "Token count is too large: Lightning-AI__lightning-2463\n",
      "Token count is too large: pandas-dev__pandas-16091\n",
      "Token count is too large: pandas-dev__pandas-17611\n",
      "Token count is too large: apache__airflow-22904\n",
      "Token count is too large: pandas-dev__pandas-27436\n",
      "Token count is too large: Qiskit__qiskit-5881\n",
      "Token count is too large: conan-io__conan-4708\n",
      "Token count is too large: conda__conda-5312\n",
      "Token count is too large: huggingface__transformers-20276\n",
      "Token count is too large: huggingface__transformers-20282\n",
      "Token count is too large: pandas-dev__pandas-8201\n",
      "Token count is too large: pandas-dev__pandas-20583\n",
      "Token count is too large: pandas-dev__pandas-7779\n",
      "Token count is too large: celery__celery-7608\n",
      "Token count is too large: PrefectHQ__prefect-2353\n",
      "Token count is too large: pandas-dev__pandas-18884\n",
      "Token count is too large: pandas-dev__pandas-16638\n",
      "Token count is too large: apache__airflow-24373\n",
      "Token count is too large: pypa__pip-6753\n",
      "Token count is too large: conan-io__conan-3384\n",
      "Token count is too large: pandas-dev__pandas-35258\n",
      "Token count is too large: numpy__numpy-20404\n",
      "Token count is too large: pypa__pip-2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1888 examples [02:10, 10.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-4858\n",
      "Token count is too large: pantsbuild__pants-16276\n",
      "Token count is too large: ray-project__ray-5580\n",
      "Token count is too large: conda__conda-7418\n",
      "Token count is too large: pandas-dev__pandas-6108\n",
      "Token count is too large: huggingface__transformers-16465\n",
      "Token count is too large: pypa__pip-4037\n",
      "Token count is too large: docker__compose-7745\n",
      "Token count is too large: pantsbuild__pants-4784\n",
      "Token count is too large: jupyterlab__jupyterlab-14792\n",
      "Token count is too large: conda__conda-6853\n",
      "Token count is too large: pandas-dev__pandas-20988\n",
      "Token count is too large: mesonbuild__meson-5473\n",
      "Token count is too large: pandas-dev__pandas-30628\n",
      "Token count is too large: pandas-dev__pandas-25109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1898 examples [02:27,  1.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: explosion__spaCy-1502\n",
      "Token count is too large: pandas-dev__pandas-31840\n",
      "Token count is too large: pandas-dev__pandas-26754\n",
      "Token count is too large: pandas-dev__pandas-23466\n",
      "Token count is too large: ytdl-org__youtube-dl-4247\n",
      "Token count is too large: Qiskit__qiskit-5755\n",
      "Token count is too large: pandas-dev__pandas-16553\n",
      "Token count is too large: PrefectHQ__prefect-349\n",
      "Token count is too large: pandas-dev__pandas-5009\n",
      "Token count is too large: numpy__numpy-7340\n",
      "Token count is too large: mesonbuild__meson-3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1903 examples [02:27,  1.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10335\n",
      "Token count is too large: open-mmlab__mmdetection-5654\n",
      "Token count is too large: mesonbuild__meson-1373\n",
      "Token count is too large: pandas-dev__pandas-5477\n",
      "Token count is too large: google__jax-749\n",
      "Token count is too large: googleapis__google-cloud-python-9029\n",
      "Token count is too large: pandas-dev__pandas-22644\n",
      "Token count is too large: pantsbuild__pants-10268\n",
      "Token count is too large: PrefectHQ__prefect-485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1908 examples [02:27,  2.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3021\n",
      "Token count is too large: Qiskit__qiskit-4945\n",
      "Token count is too large: huggingface__transformers-11405\n",
      "Token count is too large: numpy__numpy-22736\n",
      "Token count is too large: ipython__ipython-6680\n",
      "Token count is too large: ipython__ipython-2352\n",
      "Token count is too large: huggingface__transformers-8231\n",
      "Token count is too large: huggingface__transformers-12280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1912 examples [02:28,  3.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17082\n",
      "Token count is too large: ipython__ipython-10030\n",
      "Token count is too large: pandas-dev__pandas-14378\n",
      "Token count is too large: mesonbuild__meson-10048\n",
      "Token count is too large: celery__celery-7734\n",
      "Token count is too large: googleapis__google-cloud-python-10028\n",
      "Token count is too large: ipython__ipython-11425\n",
      "Token count is too large: ray-project__ray-4844\n",
      "Token count is too large: mesonbuild__meson-11077\n",
      "Token count is too large: huggingface__transformers-6890\n",
      "Token count is too large: dagster-io__dagster-8677\n",
      "Token count is too large: apache__airflow-15194\n",
      "Token count is too large: wagtail__wagtail-2080\n",
      "Token count is too large: PrefectHQ__prefect-2109\n",
      "Token count is too large: Qiskit__qiskit-3902\n",
      "Token count is too large: ipython__ipython-10668\n",
      "Token count is too large: mesonbuild__meson-9134\n",
      "Token count is too large: pandas-dev__pandas-31066\n",
      "Token count is too large: pypa__pip-2924\n",
      "Token count is too large: ipython__ipython-6615\n",
      "Token count is too large: pandas-dev__pandas-4043\n",
      "Token count is too large: apache__airflow-26276\n",
      "Token count is too large: pandas-dev__pandas-11780\n",
      "Token count is too large: apache__airflow-12200\n",
      "Token count is too large: numpy__numpy-9586\n",
      "Token count is too large: Qiskit__qiskit-4841\n",
      "Token count is too large: pypa__pip-6976\n",
      "Token count is too large: mesonbuild__meson-4311\n",
      "Token count is too large: googleapis__google-cloud-python-2907\n",
      "Token count is too large: Lightning-AI__lightning-918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1915 examples [02:28,  3.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10674\n",
      "Token count is too large: pandas-dev__pandas-19673\n",
      "Token count is too large: google__jax-391\n",
      "Token count is too large: pandas-dev__pandas-36560\n",
      "Token count is too large: wagtail__wagtail-1406\n",
      "Token count is too large: mesonbuild__meson-2466\n",
      "Token count is too large: ytdl-org__youtube-dl-19204\n",
      "Token count is too large: huggingface__transformers-13194\n",
      "Token count is too large: mesonbuild__meson-2888\n",
      "Token count is too large: googleapis__google-cloud-python-7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1924 examples [02:28,  6.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19027\n",
      "Token count is too large: pandas-dev__pandas-21260\n",
      "Token count is too large: Lightning-AI__lightning-2391\n",
      "Token count is too large: ipython__ipython-12884\n",
      "Token count is too large: pandas-dev__pandas-20484\n",
      "Token count is too large: pandas-dev__pandas-16801\n",
      "Token count is too large: apache__airflow-14978\n",
      "Token count is too large: pandas-dev__pandas-36356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1928 examples [02:29,  8.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-866\n",
      "Token count is too large: Qiskit__qiskit-4140\n",
      "Token count is too large: googleapis__google-cloud-python-359\n",
      "Token count is too large: ray-project__ray-8480\n",
      "Token count is too large: pantsbuild__pants-17095\n",
      "Token count is too large: gitpython-developers__GitPython-695\n",
      "Token count is too large: pandas-dev__pandas-14059\n",
      "Token count is too large: pandas-dev__pandas-4911\n",
      "Token count is too large: Qiskit__qiskit-766\n",
      "Token count is too large: huggingface__transformers-18351\n",
      "Token count is too large: pandas-dev__pandas-28948\n",
      "Token count is too large: dagster-io__dagster-12293\n",
      "Token count is too large: ray-project__ray-8806\n",
      "Token count is too large: numpy__numpy-8594\n",
      "Token count is too large: pandas-dev__pandas-28601\n",
      "Token count is too large: docker__compose-3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1933 examples [02:29,  9.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30277\n",
      "Token count is too large: ray-project__ray-5354\n",
      "Token count is too large: Qiskit__qiskit-2926\n",
      "Token count is too large: mesonbuild__meson-10961\n",
      "Token count is too large: docker__compose-6529\n",
      "Token count is too large: PrefectHQ__prefect-587\n",
      "Token count is too large: huggingface__transformers-8479\n",
      "Token count is too large: pandas-dev__pandas-35639\n",
      "Token count is too large: pandas-dev__pandas-33585\n",
      "Token count is too large: huggingface__transformers-8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1937 examples [02:29,  9.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7217\n",
      "Token count is too large: pandas-dev__pandas-26825\n",
      "Token count is too large: Qiskit__qiskit-2342\n",
      "Token count is too large: tensorflow__models-881\n",
      "Token count is too large: pandas-dev__pandas-14118\n",
      "Token count is too large: Qiskit__qiskit-9726\n",
      "Token count is too large: conda__conda-6909\n",
      "Token count is too large: huggingface__transformers-14525\n",
      "Token count is too large: pandas-dev__pandas-5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1943 examples [02:30, 11.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-3042\n",
      "Token count is too large: pandas-dev__pandas-35116\n",
      "Token count is too large: Qiskit__qiskit-9829\n",
      "Token count is too large: Qiskit__qiskit-10034\n",
      "Token count is too large: pandas-dev__pandas-21657\n",
      "Token count is too large: ipython__ipython-5855\n",
      "Token count is too large: mesonbuild__meson-5881\n",
      "Token count is too large: pandas-dev__pandas-5666\n",
      "Token count is too large: explosion__spaCy-3038\n",
      "Token count is too large: pandas-dev__pandas-18191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1946 examples [02:30, 13.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-22302\n",
      "Token count is too large: Qiskit__qiskit-7321\n",
      "Token count is too large: pandas-dev__pandas-37607\n",
      "Token count is too large: huggingface__transformers-9047\n",
      "Token count is too large: Qiskit__qiskit-6370\n",
      "Token count is too large: numpy__numpy-13301\n",
      "Token count is too large: pandas-dev__pandas-34912\n",
      "Token count is too large: apache__airflow-24054\n",
      "Token count is too large: pandas-dev__pandas-8423\n",
      "Token count is too large: google__jax-542\n",
      "Token count is too large: Qiskit__qiskit-2241\n",
      "Token count is too large: huggingface__transformers-11874\n",
      "Token count is too large: ytdl-org__youtube-dl-10971\n",
      "Token count is too large: pandas-dev__pandas-37557\n",
      "Token count is too large: ipython__ipython-10012\n",
      "Token count is too large: pandas-dev__pandas-15501\n",
      "Token count is too large: pandas-dev__pandas-14056\n",
      "Token count is too large: numpy__numpy-16627\n",
      "Token count is too large: pandas-dev__pandas-7000\n",
      "Token count is too large: huggingface__transformers-21400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1950 examples [02:31,  9.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37029\n",
      "Token count is too large: Lightning-AI__lightning-2874\n",
      "Token count is too large: mesonbuild__meson-4303\n",
      "Token count is too large: ytdl-org__youtube-dl-3954\n",
      "Token count is too large: Lightning-AI__lightning-971\n",
      "Token count is too large: scipy__scipy-3006\n",
      "Token count is too large: pandas-dev__pandas-36767\n",
      "Token count is too large: huggingface__transformers-13077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1955 examples [02:31, 12.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31898\n",
      "Token count is too large: apache__airflow-21116\n",
      "Token count is too large: numpy__numpy-23382\n",
      "Token count is too large: pandas-dev__pandas-25264\n",
      "Token count is too large: googleapis__google-cloud-python-7378\n",
      "Token count is too large: Qiskit__qiskit-10591\n",
      "Token count is too large: numpy__numpy-7274\n",
      "Token count is too large: pyca__cryptography-3497\n",
      "Token count is too large: pandas-dev__pandas-26516\n",
      "Token count is too large: wagtail__wagtail-6756\n",
      "Token count is too large: pandas-dev__pandas-26770\n",
      "Token count is too large: apache__airflow-16916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1958 examples [02:31, 11.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6359\n",
      "Token count is too large: mesonbuild__meson-1342\n",
      "Token count is too large: googleapis__google-cloud-python-7948\n",
      "Token count is too large: pantsbuild__pants-11765\n",
      "Token count is too large: pandas-dev__pandas-35673\n",
      "Token count is too large: pandas-dev__pandas-24758\n",
      "Token count is too large: numpy__numpy-9701\n",
      "Token count is too large: mesonbuild__meson-4230\n",
      "Token count is too large: dagster-io__dagster-8779\n",
      "Token count is too large: pandas-dev__pandas-5281\n",
      "Token count is too large: conda__conda-6564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1964 examples [02:31, 15.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-10267\n",
      "Token count is too large: numpy__numpy-5577\n",
      "Token count is too large: ipython__ipython-7105\n",
      "Token count is too large: ipython__ipython-4112\n",
      "Token count is too large: Qiskit__qiskit-6294\n",
      "Token count is too large: mesonbuild__meson-3733\n",
      "Token count is too large: Qiskit__qiskit-4979\n",
      "Token count is too large: pandas-dev__pandas-8291\n",
      "Token count is too large: dagster-io__dagster-8023\n",
      "Token count is too large: conda__conda-11589\n",
      "Token count is too large: pandas-dev__pandas-39516\n",
      "Token count is too large: pantsbuild__pants-14516\n",
      "Token count is too large: pandas-dev__pandas-2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1969 examples [02:32, 13.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20760\n",
      "Token count is too large: conda__conda-3041\n",
      "Token count is too large: pantsbuild__pants-18458\n",
      "Token count is too large: Qiskit__qiskit-7744\n",
      "Token count is too large: pantsbuild__pants-9215\n",
      "Token count is too large: PrefectHQ__prefect-1534\n",
      "Token count is too large: pandas-dev__pandas-38587\n",
      "Token count is too large: pandas-dev__pandas-14228\n",
      "Token count is too large: pantsbuild__pants-14803\n",
      "Token count is too large: googleapis__google-cloud-python-5002\n",
      "Token count is too large: pandas-dev__pandas-27808\n",
      "Token count is too large: pandas-dev__pandas-7318\n",
      "Token count is too large: numpy__numpy-10543\n",
      "Token count is too large: numpy__numpy-9599\n",
      "Token count is too large: jupyterlab__jupyterlab-13907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1977 examples [02:32, 20.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-17265\n",
      "Token count is too large: PrefectHQ__prefect-2959\n",
      "Token count is too large: pypa__pip-9469\n",
      "Token count is too large: pandas-dev__pandas-37196\n",
      "Token count is too large: pandas-dev__pandas-25110\n",
      "Token count is too large: PrefectHQ__prefect-1701\n",
      "Token count is too large: ray-project__ray-786\n",
      "Token count is too large: apache__airflow-32697\n",
      "Token count is too large: gitpython-developers__GitPython-1335\n",
      "Token count is too large: pyca__cryptography-2436\n",
      "Token count is too large: huggingface__transformers-18014\n",
      "Token count is too large: pandas-dev__pandas-36626\n",
      "Token count is too large: pandas-dev__pandas-32758\n",
      "Token count is too large: conan-io__conan-3517\n",
      "Token count is too large: pantsbuild__pants-16419\n",
      "Token count is too large: pypa__pip-6518\n",
      "Token count is too large: celery__celery-4892\n",
      "Token count is too large: pantsbuild__pants-5021\n",
      "Token count is too large: mesonbuild__meson-7686\n",
      "Token count is too large: pandas-dev__pandas-35643\n",
      "Token count is too large: conan-io__conan-3599\n",
      "Token count is too large: huggingface__transformers-9977\n",
      "Token count is too large: huggingface__transformers-1118\n",
      "Token count is too large: pandas-dev__pandas-33235\n",
      "Token count is too large: huggingface__transformers-8731\n",
      "Token count is too large: apache__airflow-31477\n",
      "Token count is too large: numpy__numpy-19102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1981 examples [02:32, 18.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-1736\n",
      "Token count is too large: ytdl-org__youtube-dl-3053\n",
      "There was an error processing\n",
      "Token count is too large: huggingface__transformers-8328\n",
      "Token count is too large: huggingface__transformers-10493\n",
      "Token count is too large: numpy__numpy-20807\n",
      "Token count is too large: googleapis__google-cloud-python-5374\n",
      "Token count is too large: apache__airflow-11723\n",
      "Token count is too large: pandas-dev__pandas-33233\n",
      "Token count is too large: apache__airflow-1224\n",
      "Token count is too large: DataDog__integrations-core-12675\n",
      "Token count is too large: pandas-dev__pandas-10826\n",
      "Token count is too large: pandas-dev__pandas-6931\n",
      "Token count is too large: pandas-dev__pandas-4458\n",
      "Token count is too large: pandas-dev__pandas-5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1987 examples [02:33, 16.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6826\n",
      "Token count is too large: pandas-dev__pandas-17881\n",
      "Token count is too large: pantsbuild__pants-18188\n",
      "Token count is too large: pandas-dev__pandas-22814\n",
      "Token count is too large: googleapis__google-cloud-python-8889\n",
      "Token count is too large: pandas-dev__pandas-22561\n",
      "Token count is too large: pypa__pip-10082\n",
      "Token count is too large: ytdl-org__youtube-dl-17448\n",
      "Token count is too large: pandas-dev__pandas-27993\n",
      "Token count is too large: pandas-dev__pandas-20292\n",
      "Token count is too large: mesonbuild__meson-11432\n",
      "Token count is too large: googleapis__google-cloud-python-2714\n",
      "Token count is too large: pandas-dev__pandas-5584\n",
      "Token count is too large: huggingface__transformers-17060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1989 examples [02:33, 13.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11400\n",
      "Token count is too large: huggingface__transformers-17143\n",
      "Token count is too large: pandas-dev__pandas-10602\n",
      "Token count is too large: pandas-dev__pandas-32516\n",
      "Token count is too large: wagtail__wagtail-1770\n",
      "Token count is too large: huggingface__transformers-9411\n",
      "Token count is too large: conan-io__conan-3687\n",
      "Token count is too large: ray-project__ray-7794\n",
      "Token count is too large: Qiskit__qiskit-8198\n",
      "Token count is too large: pandas-dev__pandas-24397\n",
      "Token count is too large: Qiskit__qiskit-2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2002 examples [02:34, 16.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-11352\n",
      "Token count is too large: pantsbuild__pants-13970\n",
      "Token count is too large: huggingface__transformers-11353\n",
      "Token count is too large: pandas-dev__pandas-21485\n",
      "Token count is too large: numpy__numpy-23514\n",
      "Token count is too large: pandas-dev__pandas-23161\n",
      "Token count is too large: huggingface__transformers-20198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2004 examples [02:34, 15.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6588\n",
      "Token count is too large: Qiskit__qiskit-6292\n",
      "Token count is too large: huggingface__transformers-7642\n",
      "Token count is too large: pantsbuild__pants-14497\n",
      "Token count is too large: conda__conda-4935\n",
      "Token count is too large: pandas-dev__pandas-6786\n",
      "Token count is too large: apache__airflow-30948\n",
      "Token count is too large: Lightning-AI__lightning-2567\n",
      "Token count is too large: Qiskit__qiskit-2095\n",
      "Token count is too large: numpy__numpy-12239\n",
      "Token count is too large: ray-project__ray-5346\n",
      "Token count is too large: dagster-io__dagster-14174\n",
      "Token count is too large: scipy__scipy-2807\n",
      "Token count is too large: docker__compose-1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2009 examples [02:34, 15.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24771\n",
      "Token count is too large: Qiskit__qiskit-4915\n",
      "Token count is too large: PrefectHQ__prefect-525\n",
      "Token count is too large: mesonbuild__meson-887\n",
      "Token count is too large: explosion__spaCy-1792\n",
      "Token count is too large: docker__compose-2364\n",
      "Token count is too large: pandas-dev__pandas-10719\n",
      "Token count is too large: Lightning-AI__lightning-1283\n",
      "Token count is too large: mesonbuild__meson-6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2011 examples [02:34, 16.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19986\n",
      "Token count is too large: numpy__numpy-11033\n",
      "Token count is too large: pantsbuild__pants-13336\n",
      "Token count is too large: conda__conda-11422\n",
      "Token count is too large: docker__compose-3102\n",
      "Token count is too large: mesonbuild__meson-7682\n",
      "Token count is too large: huggingface__transformers-9807\n",
      "Token count is too large: pandas-dev__pandas-20796\n",
      "Token count is too large: pantsbuild__pants-15836\n",
      "Token count is too large: dagster-io__dagster-1143\n",
      "Token count is too large: pypa__pip-11698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2020 examples [02:34, 21.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-8693\n",
      "Token count is too large: numpy__numpy-22878\n",
      "Token count is too large: conda__conda-9261\n",
      "Token count is too large: pandas-dev__pandas-36605\n",
      "Token count is too large: dagster-io__dagster-9327\n",
      "Token count is too large: conda__conda-6205\n",
      "Token count is too large: conda__conda-8352\n",
      "Token count is too large: pandas-dev__pandas-39440\n",
      "Token count is too large: ytdl-org__youtube-dl-3565\n",
      "Token count is too large: ipython__ipython-9022\n",
      "Token count is too large: ytdl-org__youtube-dl-20801\n",
      "Token count is too large: pandas-dev__pandas-18652\n",
      "Token count is too large: mesonbuild__meson-5243\n",
      "Token count is too large: Lightning-AI__lightning-833\n",
      "Token count is too large: pantsbuild__pants-5930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2024 examples [02:35, 19.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29116\n",
      "Token count is too large: google__jax-2834\n",
      "Token count is too large: pandas-dev__pandas-7684\n",
      "Token count is too large: conan-io__conan-4481\n",
      "Token count is too large: conan-io__conan-8861\n",
      "Token count is too large: pandas-dev__pandas-18300\n",
      "Token count is too large: pandas-dev__pandas-39421\n",
      "Token count is too large: mesonbuild__meson-6759\n",
      "Token count is too large: jupyterlab__jupyterlab-7583\n",
      "Token count is too large: huggingface__transformers-9169\n",
      "Token count is too large: pandas-dev__pandas-9721\n",
      "Token count is too large: tiangolo__fastapi-338\n",
      "Token count is too large: pandas-dev__pandas-5208\n",
      "Token count is too large: pandas-dev__pandas-9417\n",
      "Token count is too large: pandas-dev__pandas-20584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2027 examples [02:35, 15.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-2182\n",
      "Token count is too large: Qiskit__qiskit-3696\n",
      "Token count is too large: scipy__scipy-3857\n",
      "Token count is too large: Qiskit__qiskit-2849\n",
      "Token count is too large: dagster-io__dagster-8859\n",
      "Token count is too large: pandas-dev__pandas-26585\n",
      "Token count is too large: pandas-dev__pandas-7114\n",
      "Token count is too large: conan-io__conan-3192\n",
      "Token count is too large: huggingface__transformers-10215\n",
      "Token count is too large: pandas-dev__pandas-31877\n",
      "Token count is too large: conda__conda-12005\n",
      "Token count is too large: pandas-dev__pandas-25490\n",
      "Token count is too large: DataDog__integrations-core-2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2032 examples [02:35, 18.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-13551\n",
      "Token count is too large: pyca__cryptography-4785\n",
      "Token count is too large: Qiskit__qiskit-5192\n",
      "Token count is too large: pandas-dev__pandas-4233\n",
      "Token count is too large: numpy__numpy-19083\n",
      "Token count is too large: pandas-dev__pandas-11774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2039 examples [02:36, 17.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3696\n",
      "Token count is too large: google__jax-2794\n",
      "Token count is too large: Lightning-AI__lightning-1862\n",
      "Token count is too large: Qiskit__qiskit-7665\n",
      "Token count is too large: Qiskit__qiskit-6418\n",
      "Token count is too large: pandas-dev__pandas-36900\n",
      "Token count is too large: conda__conda-7722\n",
      "Token count is too large: mesonbuild__meson-334\n",
      "Token count is too large: pandas-dev__pandas-9470\n",
      "Token count is too large: conan-io__conan-4595\n",
      "Token count is too large: Qiskit__qiskit-1727\n",
      "Token count is too large: pandas-dev__pandas-21235\n",
      "Token count is too large: Qiskit__qiskit-5672\n",
      "Token count is too large: mesonbuild__meson-968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2041 examples [02:36, 16.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4401\n",
      "Token count is too large: mesonbuild__meson-1961\n",
      "Token count is too large: Qiskit__qiskit-2764\n",
      "Token count is too large: pandas-dev__pandas-35780\n",
      "Token count is too large: huggingface__transformers-13400\n",
      "Token count is too large: Qiskit__qiskit-1181\n",
      "Token count is too large: pandas-dev__pandas-8693\n",
      "Token count is too large: ipython__ipython-3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2044 examples [02:36, 18.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-10026\n",
      "Token count is too large: twisted__twisted-11644\n",
      "Token count is too large: dagster-io__dagster-10991\n",
      "Token count is too large: apache__airflow-33135\n",
      "Token count is too large: huggingface__transformers-19158\n",
      "Token count is too large: huggingface__transformers-25136\n",
      "Token count is too large: numpy__numpy-6733\n",
      "Token count is too large: pandas-dev__pandas-37357\n",
      "Token count is too large: conan-io__conan-3717\n",
      "Token count is too large: Lightning-AI__lightning-1326\n",
      "Token count is too large: pandas-dev__pandas-13735\n",
      "Token count is too large: pandas-dev__pandas-17859\n",
      "Token count is too large: pandas-dev__pandas-9479\n",
      "Token count is too large: twisted__twisted-11810\n",
      "Token count is too large: pandas-dev__pandas-18905\n",
      "Token count is too large: pantsbuild__pants-18369\n",
      "Token count is too large: apache__airflow-22685\n",
      "Token count is too large: pandas-dev__pandas-21811\n",
      "Token count is too large: ipython__ipython-4713\n",
      "Token count is too large: Qiskit__qiskit-1866\n",
      "Token count is too large: googleapis__google-cloud-python-11351\n",
      "Token count is too large: pandas-dev__pandas-18164\n",
      "Token count is too large: pandas-dev__pandas-19022\n",
      "Token count is too large: pandas-dev__pandas-18395\n",
      "Token count is too large: pandas-dev__pandas-28666\n",
      "Token count is too large: mesonbuild__meson-5596\n",
      "Token count is too large: pypa__pip-5336\n",
      "Token count is too large: google__jax-399\n",
      "Token count is too large: docker__compose-3364\n",
      "Token count is too large: numpy__numpy-23923\n",
      "Token count is too large: mesonbuild__meson-4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2047 examples [02:38,  5.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-3396\n",
      "Token count is too large: pandas-dev__pandas-4250\n",
      "Token count is too large: mesonbuild__meson-2338\n",
      "Token count is too large: conda__conda-11290\n",
      "Token count is too large: ytdl-org__youtube-dl-486\n",
      "Token count is too large: Lightning-AI__lightning-2459\n",
      "Token count is too large: pandas-dev__pandas-37161\n",
      "Token count is too large: pantsbuild__pants-15682\n",
      "Token count is too large: pandas-dev__pandas-34158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2050 examples [02:38,  6.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-1836\n",
      "Token count is too large: Lightning-AI__lightning-1493\n",
      "Token count is too large: pandas-dev__pandas-9177\n",
      "Token count is too large: huggingface__transformers-22518\n",
      "Token count is too large: Lightning-AI__lightning-2535\n",
      "Token count is too large: docker__compose-6813\n",
      "Token count is too large: docker__compose-3006\n",
      "Token count is too large: pandas-dev__pandas-7634\n",
      "Token count is too large: huggingface__transformers-17917\n",
      "Token count is too large: conan-io__conan-7259\n",
      "Token count is too large: pandas-dev__pandas-17588\n",
      "Token count is too large: pandas-dev__pandas-28241\n",
      "Token count is too large: pandas-dev__pandas-7503\n",
      "Token count is too large: pandas-dev__pandas-28735\n",
      "Token count is too large: docker__compose-3436\n",
      "Token count is too large: pandas-dev__pandas-34615\n",
      "Token count is too large: docker__compose-5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2053 examples [02:38,  5.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5438\n",
      "Token count is too large: pandas-dev__pandas-26403\n",
      "Token count is too large: pandas-dev__pandas-31207\n",
      "Token count is too large: pandas-dev__pandas-20437\n",
      "Token count is too large: pantsbuild__pants-18352\n",
      "Token count is too large: conda__conda-7360\n",
      "Token count is too large: wagtail__wagtail-566\n",
      "Token count is too large: google__jax-736\n",
      "Token count is too large: pandas-dev__pandas-4832\n",
      "Token count is too large: huggingface__transformers-12519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2060 examples [02:39,  8.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16570\n",
      "Token count is too large: pypa__pip-3324\n",
      "Token count is too large: pandas-dev__pandas-30146\n",
      "Token count is too large: huggingface__transformers-19249\n",
      "Token count is too large: pandas-dev__pandas-35547\n",
      "Token count is too large: huggingface__transformers-12121\n",
      "Token count is too large: conan-io__conan-2875\n",
      "Token count is too large: pypa__pip-7087\n",
      "Token count is too large: numpy__numpy-4531\n",
      "Token count is too large: conda__conda-5291\n",
      "Token count is too large: mesonbuild__meson-6741\n",
      "Token count is too large: pandas-dev__pandas-19979\n",
      "Token count is too large: huggingface__transformers-15789\n",
      "Token count is too large: pandas-dev__pandas-19339\n",
      "Token count is too large: google__jax-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2062 examples [02:39,  7.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-14124\n",
      "Token count is too large: pandas-dev__pandas-28834\n",
      "Token count is too large: Qiskit__qiskit-6282\n",
      "Token count is too large: ray-project__ray-10464\n",
      "Token count is too large: apache__airflow-24065\n",
      "Token count is too large: pandas-dev__pandas-38446\n",
      "Token count is too large: pandas-dev__pandas-20959\n",
      "Token count is too large: mesonbuild__meson-10214\n",
      "Token count is too large: pandas-dev__pandas-20846\n",
      "Token count is too large: PrefectHQ__prefect-2443\n",
      "Token count is too large: pyca__cryptography-2066\n",
      "Token count is too large: pyca__cryptography-7080\n",
      "Token count is too large: pandas-dev__pandas-24541\n",
      "Token count is too large: wagtail__wagtail-10123\n",
      "Token count is too large: pandas-dev__pandas-33241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2067 examples [02:40,  9.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21486\n",
      "Token count is too large: Lightning-AI__lightning-448\n",
      "Token count is too large: conan-io__conan-6675\n",
      "There was an error processing\n",
      "Token count is too large: pandas-dev__pandas-26355\n",
      "Token count is too large: apache__airflow-10633\n",
      "Token count is too large: conan-io__conan-9758\n",
      "Token count is too large: pandas-dev__pandas-29237\n",
      "Token count is too large: google__jax-312\n",
      "Token count is too large: pandas-dev__pandas-6017\n",
      "Token count is too large: pandas-dev__pandas-7790\n",
      "Token count is too large: pandas-dev__pandas-38073\n",
      "Token count is too large: pandas-dev__pandas-9377\n",
      "Token count is too large: numpy__numpy-11218\n",
      "Token count is too large: ipython__ipython-10829\n",
      "Token count is too large: ytdl-org__youtube-dl-4794\n",
      "Token count is too large: scipy__scipy-3313\n",
      "Token count is too large: huggingface__transformers-25496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2072 examples [02:40,  9.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-8551\n",
      "Token count is too large: pandas-dev__pandas-6385\n",
      "Token count is too large: pandas-dev__pandas-34634\n",
      "Token count is too large: pandas-dev__pandas-18376\n",
      "Token count is too large: pypa__pip-7187\n",
      "Token count is too large: pandas-dev__pandas-37780\n",
      "Token count is too large: pandas-dev__pandas-36115\n",
      "Token count is too large: pandas-dev__pandas-6458\n",
      "Token count is too large: conan-io__conan-5910\n",
      "Token count is too large: ipython__ipython-4120\n",
      "Token count is too large: pandas-dev__pandas-31350\n",
      "Token count is too large: tensorflow__models-864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2077 examples [02:40, 12.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-3491\n",
      "Token count is too large: pantsbuild__pants-16668\n",
      "Token count is too large: apache__airflow-8834\n",
      "Token count is too large: apache__airflow-17839\n",
      "Token count is too large: pantsbuild__pants-13793\n",
      "Token count is too large: wagtail__wagtail-10731\n",
      "Token count is too large: google__jax-131\n",
      "Token count is too large: ray-project__ray-3121\n",
      "Token count is too large: conan-io__conan-7524\n",
      "Token count is too large: jupyterlab__jupyterlab-9256\n",
      "Token count is too large: pandas-dev__pandas-35171\n",
      "Token count is too large: Qiskit__qiskit-8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2082 examples [02:40, 14.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-2374\n",
      "Token count is too large: numpy__numpy-11233\n",
      "Token count is too large: pandas-dev__pandas-25732\n",
      "Token count is too large: pandas-dev__pandas-18953\n",
      "Token count is too large: pandas-dev__pandas-19338\n",
      "Token count is too large: huggingface__transformers-18984\n",
      "Token count is too large: pandas-dev__pandas-7040\n",
      "Token count is too large: pandas-dev__pandas-29143\n",
      "Token count is too large: ytdl-org__youtube-dl-21421\n",
      "Token count is too large: Qiskit__qiskit-9133\n",
      "Token count is too large: pandas-dev__pandas-37966\n",
      "Token count is too large: mesonbuild__meson-4699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2084 examples [02:41,  9.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13926\n",
      "Token count is too large: conda__conda-6779\n",
      "Token count is too large: ytdl-org__youtube-dl-1531\n",
      "Token count is too large: pandas-dev__pandas-11410\n",
      "Token count is too large: pypa__pip-1868\n",
      "Token count is too large: pandas-dev__pandas-36563\n",
      "Token count is too large: celery__celery-423\n",
      "Token count is too large: pandas-dev__pandas-5199\n",
      "Token count is too large: mesonbuild__meson-3188\n",
      "Token count is too large: apache__airflow-17105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2087 examples [02:41, 11.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1775\n",
      "Token count is too large: google__jax-1308\n",
      "Token count is too large: pyca__cryptography-4096\n",
      "Token count is too large: ytdl-org__youtube-dl-4076\n",
      "Token count is too large: pandas-dev__pandas-17377\n",
      "Token count is too large: pandas-dev__pandas-29318\n",
      "Token count is too large: pandas-dev__pandas-25230\n",
      "Token count is too large: celery__celery-5869\n",
      "Token count is too large: pypa__pip-11245\n",
      "Token count is too large: pandas-dev__pandas-11822\n",
      "Token count is too large: pandas-dev__pandas-3018\n",
      "Token count is too large: pandas-dev__pandas-7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2089 examples [02:41, 10.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5342\n",
      "Token count is too large: conda__conda-6448\n",
      "Token count is too large: googleapis__google-cloud-python-416\n",
      "Token count is too large: ipython__ipython-3560\n",
      "Token count is too large: numpy__numpy-5327\n",
      "Token count is too large: ray-project__ray-4195\n",
      "Token count is too large: jupyterlab__jupyterlab-3346\n",
      "Token count is too large: pandas-dev__pandas-18313\n",
      "Token count is too large: huggingface__transformers-20786\n",
      "Token count is too large: pandas-dev__pandas-23527\n",
      "Token count is too large: ytdl-org__youtube-dl-30635\n",
      "Token count is too large: pandas-dev__pandas-17603\n",
      "Token count is too large: huggingface__transformers-22920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2091 examples [02:42,  7.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12604\n",
      "Token count is too large: huggingface__transformers-25415\n",
      "Token count is too large: pypa__pip-11874\n",
      "Token count is too large: Qiskit__qiskit-7134\n",
      "Token count is too large: google__jax-671\n",
      "Token count is too large: wagtail__wagtail-9905\n",
      "Token count is too large: Lightning-AI__lightning-2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2096 examples [02:42, 11.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11703\n",
      "Token count is too large: ytdl-org__youtube-dl-5729\n",
      "Token count is too large: ytdl-org__youtube-dl-27732\n",
      "Token count is too large: Qiskit__qiskit-885\n",
      "Token count is too large: PrefectHQ__prefect-2680\n",
      "Token count is too large: pandas-dev__pandas-8652\n",
      "Token count is too large: docker__compose-5393\n",
      "Token count is too large: pandas-dev__pandas-28010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2105 examples [02:42, 18.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11861\n",
      "Token count is too large: ipython__ipython-1689\n",
      "Token count is too large: ray-project__ray-4305\n",
      "Token count is too large: pandas-dev__pandas-25968\n",
      "Token count is too large: pantsbuild__pants-4466\n",
      "Token count is too large: googleapis__google-cloud-python-1636\n",
      "Token count is too large: apache__airflow-6783\n",
      "Token count is too large: huggingface__transformers-7786\n",
      "Token count is too large: pandas-dev__pandas-21164\n",
      "Token count is too large: pandas-dev__pandas-26155\n",
      "Token count is too large: PrefectHQ__prefect-67\n",
      "Token count is too large: PrefectHQ__prefect-2390\n",
      "Token count is too large: pandas-dev__pandas-33749\n",
      "Token count is too large: Qiskit__qiskit-1534\n",
      "Token count is too large: googleapis__google-cloud-python-2409\n",
      "Token count is too large: Qiskit__qiskit-8989\n",
      "Token count is too large: pandas-dev__pandas-31119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2110 examples [02:43, 21.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-6416\n",
      "Token count is too large: numpy__numpy-18108\n",
      "Token count is too large: pandas-dev__pandas-14343\n",
      "Token count is too large: pandas-dev__pandas-16003\n",
      "Token count is too large: conda__conda-1541\n",
      "Token count is too large: pantsbuild__pants-14819\n",
      "Token count is too large: celery__celery-6917\n",
      "Token count is too large: googleapis__google-cloud-python-4859\n",
      "Token count is too large: ipython__ipython-13211\n",
      "Token count is too large: pandas-dev__pandas-16163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2114 examples [02:43, 19.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22253\n",
      "Token count is too large: pandas-dev__pandas-38194\n",
      "Token count is too large: pandas-dev__pandas-33865\n",
      "Token count is too large: pandas-dev__pandas-27874\n",
      "Token count is too large: jupyterlab__jupyterlab-9604\n",
      "Token count is too large: pandas-dev__pandas-23480\n",
      "Token count is too large: conda__conda-5030\n",
      "Token count is too large: mesonbuild__meson-8964\n",
      "Token count is too large: google__jax-2673\n",
      "Token count is too large: pandas-dev__pandas-15423\n",
      "Token count is too large: pypa__pip-9289\n",
      "Token count is too large: pantsbuild__pants-4542\n",
      "Token count is too large: pandas-dev__pandas-8282\n",
      "Token count is too large: pypa__pip-11259\n",
      "Token count is too large: Lightning-AI__lightning-876\n",
      "Token count is too large: pandas-dev__pandas-5100\n",
      "Token count is too large: conan-io__conan-3727\n",
      "Token count is too large: numpy__numpy-24100\n",
      "Token count is too large: huggingface__transformers-18598\n",
      "Token count is too large: pandas-dev__pandas-37706\n",
      "Token count is too large: google__jax-707\n",
      "Token count is too large: pandas-dev__pandas-5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2125 examples [02:44, 17.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20305\n",
      "Token count is too large: Lightning-AI__lightning-1253\n",
      "Token count is too large: conda__conda-5157\n",
      "Token count is too large: pandas-dev__pandas-17149\n",
      "Token count is too large: pandas-dev__pandas-25731\n",
      "Token count is too large: pandas-dev__pandas-34329\n",
      "Token count is too large: conan-io__conan-5357\n",
      "Token count is too large: pandas-dev__pandas-14799\n",
      "Token count is too large: pandas-dev__pandas-5903\n",
      "Token count is too large: googleapis__google-cloud-python-4299\n",
      "Token count is too large: mesonbuild__meson-9506\n",
      "Token count is too large: pandas-dev__pandas-9475\n",
      "Token count is too large: scipy__scipy-5479\n",
      "Token count is too large: wagtail__wagtail-2540\n",
      "Token count is too large: numpy__numpy-14070\n",
      "Token count is too large: pandas-dev__pandas-20799\n",
      "Token count is too large: pandas-dev__pandas-34589\n",
      "Token count is too large: pantsbuild__pants-7092\n",
      "Token count is too large: apache__airflow-14030\n",
      "Token count is too large: googleapis__google-cloud-python-2000\n",
      "Token count is too large: ipython__ipython-5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2129 examples [02:44, 16.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20544\n",
      "Token count is too large: Qiskit__qiskit-1725\n",
      "Token count is too large: pantsbuild__pants-5534\n",
      "Token count is too large: Qiskit__qiskit-9886\n",
      "Token count is too large: apache__airflow-11730\n",
      "Token count is too large: huggingface__transformers-11197\n",
      "Token count is too large: pandas-dev__pandas-25089\n",
      "Token count is too large: conda__conda-7516\n",
      "Token count is too large: huggingface__transformers-15001\n",
      "Token count is too large: conan-io__conan-4903\n",
      "Token count is too large: pandas-dev__pandas-8644\n",
      "Token count is too large: pandas-dev__pandas-19253\n",
      "Token count is too large: ipython__ipython-9109\n",
      "Token count is too large: huggingface__transformers-7616\n",
      "Token count is too large: Qiskit__qiskit-10031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2132 examples [02:44, 16.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-21952\n",
      "Token count is too large: pandas-dev__pandas-35284\n",
      "Token count is too large: mesonbuild__meson-11137\n",
      "Token count is too large: pandas-dev__pandas-4643\n",
      "Token count is too large: Qiskit__qiskit-5009\n",
      "Token count is too large: scipy__scipy-3924\n",
      "Token count is too large: pyca__cryptography-6562\n",
      "Token count is too large: wagtail__wagtail-10465\n",
      "Token count is too large: pandas-dev__pandas-30284\n",
      "Token count is too large: ytdl-org__youtube-dl-12587\n",
      "Token count is too large: pandas-dev__pandas-26836\n",
      "Token count is too large: pandas-dev__pandas-23749\n",
      "Token count is too large: ray-project__ray-9306\n",
      "Token count is too large: Qiskit__qiskit-8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2140 examples [02:45, 15.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4258\n",
      "Token count is too large: wagtail__wagtail-2038\n",
      "Token count is too large: pandas-dev__pandas-26267\n",
      "Token count is too large: mesonbuild__meson-10339\n",
      "Token count is too large: pandas-dev__pandas-35314\n",
      "Token count is too large: pandas-dev__pandas-10301\n",
      "Token count is too large: Qiskit__qiskit-4836\n",
      "Token count is too large: jupyterlab__jupyterlab-2714\n",
      "Token count is too large: google__jax-977\n",
      "Token count is too large: googleapis__google-cloud-python-7022\n",
      "Token count is too large: PrefectHQ__prefect-1063\n",
      "Token count is too large: jupyterlab__jupyterlab-2466\n",
      "Token count is too large: conda__conda-3410\n",
      "Token count is too large: huggingface__transformers-22603\n",
      "Token count is too large: mesonbuild__meson-10295\n",
      "Token count is too large: pandas-dev__pandas-24253\n",
      "Token count is too large: ipython__ipython-3282\n",
      "Token count is too large: pandas-dev__pandas-8388\n",
      "Token count is too large: celery__celery-6457\n",
      "Token count is too large: pypa__pip-4755\n",
      "Token count is too large: pandas-dev__pandas-35637\n",
      "Token count is too large: Lightning-AI__lightning-1541\n",
      "Token count is too large: celery__celery-3850\n",
      "Token count is too large: celery__celery-5921\n",
      "Token count is too large: pandas-dev__pandas-18086\n",
      "Token count is too large: ipython__ipython-2043\n",
      "Token count is too large: Qiskit__qiskit-3013\n",
      "Token count is too large: pantsbuild__pants-12724\n",
      "Token count is too large: pypa__pip-4210\n",
      "Token count is too large: pandas-dev__pandas-35877\n",
      "Token count is too large: pandas-dev__pandas-20446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2143 examples [02:45,  9.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-435\n",
      "Token count is too large: googleapis__google-cloud-python-9337\n",
      "Token count is too large: pandas-dev__pandas-17630\n",
      "Token count is too large: googleapis__google-cloud-python-2537\n",
      "Token count is too large: pandas-dev__pandas-36623\n",
      "Token count is too large: numpy__numpy-20502\n",
      "Token count is too large: Qiskit__qiskit-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2147 examples [02:46, 12.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37571\n",
      "Token count is too large: gitpython-developers__GitPython-686\n",
      "Token count is too large: mesonbuild__meson-11849\n",
      "Token count is too large: Lightning-AI__lightning-1235\n",
      "Token count is too large: google__jax-527\n",
      "Token count is too large: huggingface__transformers-4881\n",
      "Token count is too large: pandas-dev__pandas-39028\n",
      "Token count is too large: apache__airflow-28685\n",
      "Token count is too large: huggingface__transformers-23799\n",
      "Token count is too large: Lightning-AI__lightning-3060\n",
      "Token count is too large: celery__celery-4779\n",
      "Token count is too large: huggingface__transformers-20592\n",
      "Token count is too large: Qiskit__qiskit-9368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2151 examples [02:46,  9.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22235\n",
      "Token count is too large: pandas-dev__pandas-6259\n",
      "Token count is too large: conda__conda-7629\n",
      "Token count is too large: huggingface__transformers-8881\n",
      "Token count is too large: pantsbuild__pants-15665\n",
      "Token count is too large: pandas-dev__pandas-25898\n",
      "Token count is too large: google__jax-675\n",
      "Token count is too large: googleapis__google-cloud-python-9205\n",
      "Token count is too large: ipython__ipython-6978\n",
      "Token count is too large: conda__conda-5986\n",
      "Token count is too large: mesonbuild__meson-9566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2156 examples [02:46, 11.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26471\n",
      "Token count is too large: PrefectHQ__prefect-1429\n",
      "Token count is too large: conda__conda-12104\n",
      "Token count is too large: conan-io__conan-2118\n",
      "Token count is too large: Qiskit__qiskit-2838\n",
      "Token count is too large: pandas-dev__pandas-24554\n",
      "Token count is too large: pyca__cryptography-4063\n",
      "Token count is too large: conda__conda-2291\n",
      "Token count is too large: pandas-dev__pandas-5810\n",
      "Token count is too large: pandas-dev__pandas-38668\n",
      "Token count is too large: numpy__numpy-12807\n",
      "Token count is too large: docker__compose-370\n",
      "Token count is too large: ipython__ipython-7903\n",
      "Token count is too large: pandas-dev__pandas-10703\n",
      "Token count is too large: Qiskit__qiskit-2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2159 examples [02:47, 12.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-3211\n",
      "Token count is too large: pandas-dev__pandas-26292\n",
      "Token count is too large: pandas-dev__pandas-17865\n",
      "Token count is too large: pandas-dev__pandas-13551\n",
      "Token count is too large: wagtail__wagtail-9721\n",
      "Token count is too large: pandas-dev__pandas-33628\n",
      "Token count is too large: pandas-dev__pandas-36077\n",
      "Token count is too large: pandas-dev__pandas-39484\n",
      "Token count is too large: ytdl-org__youtube-dl-3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2167 examples [02:47, 20.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-5889\n",
      "Token count is too large: conan-io__conan-378\n",
      "Token count is too large: Qiskit__qiskit-10279\n",
      "Token count is too large: pandas-dev__pandas-17990\n",
      "Token count is too large: pandas-dev__pandas-25009\n",
      "Token count is too large: Qiskit__qiskit-3084\n",
      "Token count is too large: Qiskit__qiskit-6487\n",
      "Token count is too large: pantsbuild__pants-5007\n",
      "Token count is too large: ray-project__ray-1499\n",
      "Token count is too large: pandas-dev__pandas-36264\n",
      "Token count is too large: googleapis__google-cloud-python-430\n",
      "Token count is too large: pandas-dev__pandas-36604\n",
      "Token count is too large: pandas-dev__pandas-5292\n",
      "Token count is too large: conda__conda-6274\n",
      "Token count is too large: Qiskit__qiskit-5417\n",
      "Token count is too large: PrefectHQ__prefect-94\n",
      "Token count is too large: pandas-dev__pandas-39229\n",
      "Token count is too large: pandas-dev__pandas-22952\n",
      "Token count is too large: mesonbuild__meson-7447\n",
      "Token count is too large: googleapis__google-cloud-python-11348\n",
      "Token count is too large: Qiskit__qiskit-9128\n",
      "Token count is too large: celery__celery-6853\n",
      "Token count is too large: pandas-dev__pandas-6045\n",
      "Token count is too large: numpy__numpy-13599\n",
      "Token count is too large: pandas-dev__pandas-5448\n",
      "Token count is too large: numpy__numpy-10609\n",
      "Token count is too large: pandas-dev__pandas-18795\n",
      "Token count is too large: pandas-dev__pandas-18586\n",
      "Token count is too large: PrefectHQ__prefect-2475\n",
      "Token count is too large: pandas-dev__pandas-24811\n",
      "Token count is too large: ytdl-org__youtube-dl-4033\n",
      "Token count is too large: pandas-dev__pandas-24199\n",
      "Token count is too large: pandas-dev__pandas-3848\n",
      "Token count is too large: huggingface__transformers-21198\n",
      "Token count is too large: PrefectHQ__prefect-1884\n",
      "Token count is too large: numpy__numpy-18843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2172 examples [02:47, 13.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-9599\n",
      "Token count is too large: apache__airflow-25556\n",
      "Token count is too large: pandas-dev__pandas-4360\n",
      "Token count is too large: ipython__ipython-3319\n",
      "Token count is too large: wagtail__wagtail-9726\n",
      "Token count is too large: conda__conda-8222\n",
      "Token count is too large: Qiskit__qiskit-3722\n",
      "Token count is too large: pandas-dev__pandas-37363\n",
      "Token count is too large: pandas-dev__pandas-26588\n",
      "Token count is too large: celery__celery-8432\n",
      "Token count is too large: wagtail__wagtail-227\n",
      "Token count is too large: Qiskit__qiskit-6318\n",
      "Token count is too large: jupyterlab__jupyterlab-3127\n",
      "Token count is too large: celery__celery-5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2177 examples [02:48, 14.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7133\n",
      "Token count is too large: wagtail__wagtail-1018\n",
      "Token count is too large: conan-io__conan-5407\n",
      "Token count is too large: open-mmlab__mmdetection-3608\n",
      "Token count is too large: pandas-dev__pandas-26425\n",
      "Token count is too large: conda__conda-4325\n",
      "Token count is too large: pandas-dev__pandas-6104\n",
      "Token count is too large: ipython__ipython-11452\n",
      "Token count is too large: numpy__numpy-9815\n",
      "Token count is too large: mesonbuild__meson-6704\n",
      "Token count is too large: pypa__pip-6764\n",
      "Token count is too large: pandas-dev__pandas-4662\n",
      "Token count is too large: pandas-dev__pandas-38380\n",
      "Token count is too large: pandas-dev__pandas-31511\n",
      "Token count is too large: pandas-dev__pandas-37097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2183 examples [02:48, 13.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21144\n",
      "Token count is too large: pypa__pip-2025\n",
      "Token count is too large: googleapis__google-cloud-python-5412\n",
      "Token count is too large: docker__compose-2948\n",
      "Token count is too large: conan-io__conan-5950\n",
      "Token count is too large: Qiskit__qiskit-4123\n",
      "Token count is too large: pandas-dev__pandas-16015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2186 examples [02:48, 13.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3866\n",
      "Token count is too large: ytdl-org__youtube-dl-13382\n",
      "Token count is too large: Qiskit__qiskit-6059\n",
      "Token count is too large: ytdl-org__youtube-dl-428\n",
      "Token count is too large: pandas-dev__pandas-36026\n",
      "Token count is too large: Qiskit__qiskit-6556\n",
      "Token count is too large: Qiskit__qiskit-1231\n",
      "Token count is too large: pantsbuild__pants-19161\n",
      "Token count is too large: pandas-dev__pandas-29566\n",
      "Token count is too large: pandas-dev__pandas-11393\n",
      "Token count is too large: conda__conda-7386\n",
      "Token count is too large: huggingface__transformers-13855\n",
      "Token count is too large: DataDog__integrations-core-4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2195 examples [02:49, 19.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11306\n",
      "Token count is too large: googleapis__google-cloud-python-6828\n",
      "Token count is too large: docker__compose-2934\n",
      "Token count is too large: pandas-dev__pandas-17741\n",
      "Token count is too large: Qiskit__qiskit-7408\n",
      "Token count is too large: pypa__pip-11897\n",
      "Token count is too large: pandas-dev__pandas-17405\n",
      "Token count is too large: numpy__numpy-11203\n",
      "Token count is too large: wagtail__wagtail-1879\n",
      "Token count is too large: pandas-dev__pandas-25982\n",
      "Token count is too large: celery__celery-6440\n",
      "Token count is too large: pypa__pip-437\n",
      "Token count is too large: conan-io__conan-2602\n",
      "Token count is too large: pypa__pip-1751\n",
      "Token count is too large: mesonbuild__meson-9828\n",
      "Token count is too large: googleapis__google-cloud-python-3744\n",
      "Token count is too large: googleapis__google-cloud-python-3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2198 examples [02:49, 18.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26496\n",
      "Token count is too large: pandas-dev__pandas-22308\n",
      "Token count is too large: numpy__numpy-8963\n",
      "Token count is too large: huggingface__transformers-15122\n",
      "Token count is too large: google__jax-2674\n",
      "Token count is too large: pandas-dev__pandas-36305\n",
      "Token count is too large: Lightning-AI__lightning-1458\n",
      "Token count is too large: huggingface__transformers-13882\n",
      "Token count is too large: conan-io__conan-4354\n",
      "Token count is too large: pandas-dev__pandas-23591\n",
      "Token count is too large: pandas-dev__pandas-31894\n",
      "Token count is too large: googleapis__google-cloud-python-2724\n",
      "Token count is too large: celery__celery-5918\n",
      "Token count is too large: pypa__pip-11324\n",
      "Token count is too large: conda__conda-5148\n",
      "Token count is too large: pandas-dev__pandas-6135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2203 examples [02:49, 14.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23398\n",
      "Token count is too large: conan-io__conan-3413\n",
      "Token count is too large: googleapis__google-cloud-python-258\n",
      "Token count is too large: huggingface__transformers-23725\n",
      "Token count is too large: pandas-dev__pandas-27932\n",
      "Token count is too large: pandas-dev__pandas-10615\n",
      "Token count is too large: conan-io__conan-11799\n",
      "Token count is too large: pantsbuild__pants-5932\n",
      "Token count is too large: pandas-dev__pandas-38539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2207 examples [02:50, 10.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33983\n",
      "Token count is too large: pandas-dev__pandas-3959\n",
      "Token count is too large: docker__compose-5844\n",
      "Token count is too large: ytdl-org__youtube-dl-7660\n",
      "Token count is too large: pandas-dev__pandas-32202\n",
      "Token count is too large: mesonbuild__meson-5348\n",
      "Token count is too large: docker__compose-5449\n",
      "Token count is too large: huggingface__transformers-19706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2209 examples [02:50, 10.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39046\n",
      "Token count is too large: pantsbuild__pants-4745\n",
      "Token count is too large: Lightning-AI__lightning-2657\n",
      "Token count is too large: pandas-dev__pandas-26818\n",
      "Token count is too large: Qiskit__qiskit-6940\n",
      "Token count is too large: pantsbuild__pants-16077\n",
      "Token count is too large: pandas-dev__pandas-14208\n",
      "Token count is too large: apache__airflow-20263\n",
      "Token count is too large: pandas-dev__pandas-22759\n",
      "Token count is too large: google__jax-2447\n",
      "Token count is too large: Qiskit__qiskit-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2213 examples [02:50, 11.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-12727\n",
      "Token count is too large: scipy__scipy-5129\n",
      "Token count is too large: docker__compose-3334\n",
      "Token count is too large: jupyterlab__jupyterlab-1397\n",
      "Token count is too large: googleapis__google-cloud-python-5446\n",
      "Token count is too large: conda__conda-7377\n",
      "Token count is too large: scipy__scipy-3938\n",
      "Token count is too large: ipython__ipython-13282\n",
      "Token count is too large: ray-project__ray-3124\n",
      "Token count is too large: numpy__numpy-13117\n",
      "Token count is too large: dagster-io__dagster-10057\n",
      "Token count is too large: pandas-dev__pandas-21612\n",
      "Token count is too large: pypa__pip-2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2218 examples [02:51, 15.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8200\n",
      "Token count is too large: huggingface__transformers-7039\n",
      "Token count is too large: Qiskit__qiskit-6621\n",
      "Token count is too large: pandas-dev__pandas-24255\n",
      "Token count is too large: apache__airflow-25782\n",
      "Token count is too large: conda__conda-3811\n",
      "Token count is too large: numpy__numpy-23757\n",
      "Token count is too large: pandas-dev__pandas-38746\n",
      "Token count is too large: docker__compose-6371\n",
      "Token count is too large: pyca__cryptography-2196\n",
      "Token count is too large: pandas-dev__pandas-16458\n",
      "Token count is too large: huggingface__transformers-2217\n",
      "Token count is too large: jupyterlab__jupyterlab-8779\n",
      "Token count is too large: pandas-dev__pandas-19881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2224 examples [02:51, 17.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24189\n",
      "Token count is too large: pandas-dev__pandas-17447\n",
      "Token count is too large: ytdl-org__youtube-dl-17934\n",
      "Token count is too large: wagtail__wagtail-714\n",
      "Token count is too large: numpy__numpy-6053\n",
      "Token count is too large: pandas-dev__pandas-33477\n",
      "Token count is too large: Lightning-AI__lightning-2767\n",
      "Token count is too large: pandas-dev__pandas-37355\n",
      "Token count is too large: numpy__numpy-12463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2226 examples [02:51, 14.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3978\n",
      "Token count is too large: apache__airflow-32354\n",
      "Token count is too large: mesonbuild__meson-3223\n",
      "Token count is too large: pandas-dev__pandas-14077\n",
      "Token count is too large: numpy__numpy-13571\n",
      "Token count is too large: mesonbuild__meson-4356\n",
      "Token count is too large: pandas-dev__pandas-28047\n",
      "Token count is too large: pandas-dev__pandas-20938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2228 examples [02:52,  9.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4010\n",
      "Token count is too large: pandas-dev__pandas-17742\n",
      "Token count is too large: conda__conda-3080\n",
      "Token count is too large: huggingface__transformers-24916\n",
      "Token count is too large: ytdl-org__youtube-dl-17407\n",
      "Token count is too large: Qiskit__qiskit-6236\n",
      "Token count is too large: pandas-dev__pandas-6718\n",
      "Token count is too large: pandas-dev__pandas-18788\n",
      "Token count is too large: pandas-dev__pandas-26561\n",
      "Token count is too large: pandas-dev__pandas-16444\n",
      "Token count is too large: pantsbuild__pants-17010\n",
      "Token count is too large: pandas-dev__pandas-20569\n",
      "Token count is too large: mesonbuild__meson-3743\n",
      "Token count is too large: numpy__numpy-7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2236 examples [02:52, 14.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11811\n",
      "Token count is too large: pandas-dev__pandas-33220\n",
      "Token count is too large: apache__airflow-24943\n",
      "Token count is too large: conan-io__conan-2546\n",
      "Token count is too large: Lightning-AI__lightning-3322\n",
      "Token count is too large: googleapis__google-cloud-python-9084\n",
      "Token count is too large: googleapis__google-cloud-python-6853\n",
      "Token count is too large: docker__compose-2210\n",
      "Token count is too large: pyca__cryptography-3550\n",
      "Token count is too large: pandas-dev__pandas-10042\n",
      "Token count is too large: googleapis__google-cloud-python-9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2243 examples [02:52, 19.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-7527\n",
      "Token count is too large: pandas-dev__pandas-30976\n",
      "Token count is too large: pandas-dev__pandas-36540\n",
      "Token count is too large: huggingface__transformers-10632\n",
      "Token count is too large: pandas-dev__pandas-38387\n",
      "Token count is too large: conan-io__conan-5908\n",
      "Token count is too large: ytdl-org__youtube-dl-16129\n",
      "Token count is too large: pandas-dev__pandas-26152\n",
      "Token count is too large: googleapis__google-cloud-python-5509\n",
      "Token count is too large: conda__conda-6653\n",
      "Token count is too large: pandas-dev__pandas-3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2246 examples [02:52, 17.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18617\n",
      "Token count is too large: docker__compose-2996\n",
      "Token count is too large: numpy__numpy-3450\n",
      "Token count is too large: Lightning-AI__lightning-2997\n",
      "Token count is too large: Qiskit__qiskit-2108\n",
      "Token count is too large: dagster-io__dagster-1101\n",
      "Token count is too large: numpy__numpy-3182\n",
      "Token count is too large: huggingface__transformers-2232\n",
      "Token count is too large: pypa__pip-10525\n",
      "Token count is too large: pandas-dev__pandas-15913\n",
      "Token count is too large: pandas-dev__pandas-3124\n",
      "Token count is too large: pandas-dev__pandas-28052\n",
      "Token count is too large: pantsbuild__pants-15373\n",
      "Token count is too large: pandas-dev__pandas-38727\n",
      "Token count is too large: huggingface__transformers-20210\n",
      "Token count is too large: google__jax-666\n",
      "Token count is too large: pypa__pip-7962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2249 examples [02:53, 14.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17656\n",
      "Token count is too large: PrefectHQ__prefect-324\n",
      "Token count is too large: googleapis__google-cloud-python-488\n",
      "Token count is too large: ipython__ipython-6394\n",
      "Token count is too large: pandas-dev__pandas-19247\n",
      "Token count is too large: pandas-dev__pandas-34453\n",
      "Token count is too large: huggingface__transformers-14514\n",
      "Token count is too large: googleapis__google-cloud-python-1688\n",
      "Token count is too large: pandas-dev__pandas-19849\n",
      "Token count is too large: pandas-dev__pandas-10974\n",
      "Token count is too large: pandas-dev__pandas-6221\n",
      "Token count is too large: mesonbuild__meson-5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2251 examples [02:53,  9.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17798\n",
      "Token count is too large: Lightning-AI__lightning-567\n",
      "Token count is too large: pypa__pip-6253\n",
      "Token count is too large: celery__celery-6378\n",
      "Token count is too large: jupyterlab__jupyterlab-2759\n",
      "Token count is too large: googleapis__google-cloud-python-3370\n",
      "Token count is too large: pandas-dev__pandas-33498\n",
      "Token count is too large: pandas-dev__pandas-4217\n",
      "Token count is too large: pandas-dev__pandas-18783\n",
      "Token count is too large: mesonbuild__meson-8066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2258 examples [02:54, 14.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9506\n",
      "Token count is too large: pandas-dev__pandas-16939\n",
      "Token count is too large: apache__airflow-32819\n",
      "Token count is too large: mesonbuild__meson-6688\n",
      "Token count is too large: ytdl-org__youtube-dl-29765\n",
      "Token count is too large: pandas-dev__pandas-38330\n",
      "Token count is too large: Qiskit__qiskit-6593\n",
      "Token count is too large: pandas-dev__pandas-5327\n",
      "Token count is too large: scipy__scipy-3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2262 examples [02:54, 16.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19893\n",
      "Token count is too large: pantsbuild__pants-14949\n",
      "Token count is too large: googleapis__google-cloud-python-2321\n",
      "Token count is too large: Qiskit__qiskit-5286\n",
      "Token count is too large: Qiskit__qiskit-9836\n",
      "Token count is too large: pandas-dev__pandas-21293\n",
      "Token count is too large: googleapis__google-cloud-python-2149\n",
      "Token count is too large: ray-project__ray-960\n",
      "Token count is too large: Qiskit__qiskit-4192\n",
      "Token count is too large: huggingface__transformers-13586\n",
      "Token count is too large: ipython__ipython-2811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2266 examples [02:54, 16.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27777\n",
      "Token count is too large: mesonbuild__meson-6132\n",
      "Token count is too large: pandas-dev__pandas-38654\n",
      "Token count is too large: twisted__twisted-11914\n",
      "Token count is too large: pandas-dev__pandas-17090\n",
      "Token count is too large: docker__compose-2547\n",
      "Token count is too large: pyca__cryptography-2435\n",
      "Token count is too large: celery__celery-4443\n",
      "Token count is too large: ray-project__ray-1984\n",
      "Token count is too large: ipython__ipython-7005\n",
      "Token count is too large: huggingface__transformers-18097\n",
      "Token count is too large: mesonbuild__meson-7128\n",
      "Token count is too large: pandas-dev__pandas-20786\n",
      "Token count is too large: PrefectHQ__prefect-948\n",
      "Token count is too large: jupyterlab__jupyterlab-7268\n",
      "Token count is too large: pandas-dev__pandas-3384\n",
      "Token count is too large: pandas-dev__pandas-7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2269 examples [02:54, 14.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-6892\n",
      "Token count is too large: numpy__numpy-20786\n",
      "Token count is too large: google__jax-1358\n",
      "Token count is too large: Lightning-AI__lightning-2973\n",
      "Token count is too large: googleapis__google-cloud-python-321\n",
      "Token count is too large: pandas-dev__pandas-35027\n",
      "Token count is too large: tiangolo__fastapi-439\n",
      "Token count is too large: mesonbuild__meson-5204\n",
      "Token count is too large: pandas-dev__pandas-15451\n",
      "Token count is too large: numpy__numpy-20505\n",
      "Token count is too large: pandas-dev__pandas-19189\n",
      "Token count is too large: docker__compose-6041\n",
      "Token count is too large: pandas-dev__pandas-7191\n",
      "Token count is too large: Qiskit__qiskit-2683\n",
      "Token count is too large: gitpython-developers__GitPython-950\n",
      "Token count is too large: pantsbuild__pants-4822\n",
      "Token count is too large: PrefectHQ__prefect-695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2273 examples [02:55, 13.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4784\n",
      "Token count is too large: pandas-dev__pandas-10097\n",
      "Token count is too large: huggingface__transformers-5252\n",
      "Token count is too large: Lightning-AI__lightning-424\n",
      "Token count is too large: pypa__pip-8659\n",
      "Token count is too large: ipython__ipython-11426\n",
      "Token count is too large: huggingface__transformers-6929\n",
      "Token count is too large: apache__airflow-27609\n",
      "Token count is too large: pandas-dev__pandas-27855\n",
      "Token count is too large: Qiskit__qiskit-4444\n",
      "Token count is too large: pypa__pip-5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2280 examples [02:55, 16.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-4730\n",
      "Token count is too large: docker__compose-2877\n",
      "Token count is too large: Qiskit__qiskit-8731\n",
      "Token count is too large: Qiskit__qiskit-7301\n",
      "Token count is too large: googleapis__google-cloud-python-257\n",
      "Token count is too large: gitpython-developers__GitPython-961\n",
      "Token count is too large: pandas-dev__pandas-39759\n",
      "Token count is too large: pandas-dev__pandas-17888\n",
      "Token count is too large: pandas-dev__pandas-32121\n",
      "Token count is too large: ipython__ipython-6249\n",
      "Token count is too large: apache__airflow-18757\n",
      "Token count is too large: pandas-dev__pandas-8705\n",
      "Token count is too large: mesonbuild__meson-4479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2282 examples [02:55, 15.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17091\n",
      "Token count is too large: scipy__scipy-5525\n",
      "Token count is too large: googleapis__google-cloud-python-8568\n",
      "Token count is too large: pandas-dev__pandas-24132\n",
      "Token count is too large: pandas-dev__pandas-7823\n",
      "Token count is too large: numpy__numpy-22834\n",
      "Token count is too large: jupyterlab__jupyterlab-2838\n",
      "Token count is too large: pandas-dev__pandas-23405\n",
      "Token count is too large: docker__compose-2746\n",
      "Token count is too large: numpy__numpy-9881\n",
      "Token count is too large: pandas-dev__pandas-6728\n",
      "Token count is too large: ipython__ipython-6969\n",
      "Token count is too large: Lightning-AI__lightning-2134\n",
      "Token count is too large: scipy__scipy-4762\n",
      "Token count is too large: ipython__ipython-4928\n",
      "Token count is too large: numpy__numpy-16476\n",
      "Token count is too large: pandas-dev__pandas-9555\n",
      "Token count is too large: ipython__ipython-4453\n",
      "Token count is too large: pandas-dev__pandas-26080\n",
      "Token count is too large: pandas-dev__pandas-25020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2293 examples [02:56, 20.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16821\n",
      "Token count is too large: pantsbuild__pants-14510\n",
      "Token count is too large: huggingface__transformers-14193\n",
      "Token count is too large: docker__compose-3052\n",
      "Token count is too large: docker__compose-4419\n",
      "Token count is too large: pandas-dev__pandas-35568\n",
      "Token count is too large: pandas-dev__pandas-32990\n",
      "Token count is too large: conda__conda-6363\n",
      "Token count is too large: pandas-dev__pandas-9889\n",
      "Token count is too large: pandas-dev__pandas-8512\n",
      "Token count is too large: mesonbuild__meson-1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2298 examples [02:56, 22.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6391\n",
      "Token count is too large: Qiskit__qiskit-4747\n",
      "Token count is too large: pandas-dev__pandas-17066\n",
      "Token count is too large: celery__celery-4260\n",
      "Token count is too large: ipython__ipython-4796\n",
      "Token count is too large: Qiskit__qiskit-6673\n",
      "Token count is too large: ytdl-org__youtube-dl-7113\n",
      "Token count is too large: apache__airflow-31836\n",
      "Token count is too large: pandas-dev__pandas-16989\n",
      "Token count is too large: pandas-dev__pandas-36080\n",
      "Token count is too large: pantsbuild__pants-16249\n",
      "Token count is too large: pandas-dev__pandas-39623\n",
      "Token count is too large: pandas-dev__pandas-11134\n",
      "Token count is too large: pantsbuild__pants-15014\n",
      "Token count is too large: pandas-dev__pandas-26590\n",
      "Token count is too large: pandas-dev__pandas-36109\n",
      "Token count is too large: huggingface__transformers-13408\n",
      "Token count is too large: Qiskit__qiskit-4150\n",
      "Token count is too large: pandas-dev__pandas-6677\n",
      "Token count is too large: pandas-dev__pandas-20772\n",
      "Token count is too large: ray-project__ray-8886\n",
      "Token count is too large: wagtail__wagtail-769\n",
      "Token count is too large: conan-io__conan-10978\n",
      "Token count is too large: pandas-dev__pandas-7850\n",
      "Token count is too large: conan-io__conan-3836\n",
      "Token count is too large: pandas-dev__pandas-5011\n",
      "Token count is too large: Qiskit__qiskit-9038\n",
      "Token count is too large: docker__compose-4484\n",
      "Token count is too large: pandas-dev__pandas-10512\n",
      "Token count is too large: docker__compose-711\n",
      "Token count is too large: numpy__numpy-10390\n",
      "Token count is too large: apache__airflow-26688\n",
      "Token count is too large: jupyterlab__jupyterlab-2488\n",
      "Token count is too large: pandas-dev__pandas-35522\n",
      "Token count is too large: Qiskit__qiskit-10408\n",
      "Token count is too large: pandas-dev__pandas-34948\n",
      "Token count is too large: pandas-dev__pandas-14329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2306 examples [02:57, 12.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-9596\n",
      "Token count is too large: Lightning-AI__lightning-701\n",
      "Token count is too large: open-mmlab__mmdetection-9479\n",
      "Token count is too large: apache__airflow-12154\n",
      "Token count is too large: huggingface__transformers-10070\n",
      "Token count is too large: mesonbuild__meson-2635\n",
      "Token count is too large: pandas-dev__pandas-10240\n",
      "Token count is too large: ytdl-org__youtube-dl-2944\n",
      "Token count is too large: conda__conda-6295\n",
      "Token count is too large: googleapis__google-cloud-python-11335\n",
      "Token count is too large: mesonbuild__meson-607\n",
      "Token count is too large: pandas-dev__pandas-27929\n",
      "Token count is too large: pandas-dev__pandas-18787\n",
      "Token count is too large: huggingface__transformers-8996\n",
      "Token count is too large: huggingface__transformers-2065\n",
      "Token count is too large: pandas-dev__pandas-33026\n",
      "Token count is too large: pandas-dev__pandas-10054\n",
      "Token count is too large: pandas-dev__pandas-32036\n",
      "Token count is too large: ray-project__ray-10792\n",
      "Token count is too large: pandas-dev__pandas-26280\n",
      "Token count is too large: Lightning-AI__lightning-2719\n",
      "Token count is too large: gitpython-developers__GitPython-782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2312 examples [02:57, 14.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16266\n",
      "Token count is too large: Qiskit__qiskit-4481\n",
      "Token count is too large: numpy__numpy-4305\n",
      "Token count is too large: conan-io__conan-4514\n",
      "Token count is too large: Qiskit__qiskit-5570\n",
      "Token count is too large: pandas-dev__pandas-24190\n",
      "Token count is too large: pandas-dev__pandas-39040\n",
      "Token count is too large: mesonbuild__meson-5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2318 examples [02:57, 17.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-733\n",
      "Token count is too large: docker__compose-2458\n",
      "Token count is too large: pandas-dev__pandas-31724\n",
      "Token count is too large: mesonbuild__meson-5520\n",
      "Token count is too large: numpy__numpy-21306\n",
      "Token count is too large: numpy__numpy-16953\n",
      "Token count is too large: mesonbuild__meson-9402\n",
      "Token count is too large: mesonbuild__meson-4147\n",
      "Token count is too large: pandas-dev__pandas-23915\n",
      "Token count is too large: wagtail__wagtail-8391\n",
      "Token count is too large: numpy__numpy-21904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2327 examples [02:58, 21.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-6647\n",
      "Token count is too large: docker__compose-2880\n",
      "Token count is too large: pandas-dev__pandas-38445\n",
      "Token count is too large: ray-project__ray-4338\n",
      "Token count is too large: docker__compose-6327\n",
      "Token count is too large: pandas-dev__pandas-28793\n",
      "Token count is too large: mesonbuild__meson-7919\n",
      "Token count is too large: ipython__ipython-3538\n",
      "Token count is too large: pantsbuild__pants-7241\n",
      "Token count is too large: pandas-dev__pandas-27426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2330 examples [02:58, 22.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-13606\n",
      "Token count is too large: ipython__ipython-13276\n",
      "Token count is too large: ytdl-org__youtube-dl-8374\n",
      "Token count is too large: pandas-dev__pandas-22230\n",
      "Token count is too large: mesonbuild__meson-490\n",
      "Token count is too large: Lightning-AI__lightning-2356\n",
      "Token count is too large: mesonbuild__meson-9679\n",
      "Token count is too large: open-mmlab__mmdetection-4391\n",
      "Token count is too large: pandas-dev__pandas-16438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2337 examples [02:58, 20.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-20206\n",
      "Token count is too large: huggingface__transformers-11746\n",
      "Token count is too large: pandas-dev__pandas-25224\n",
      "Token count is too large: pandas-dev__pandas-13276\n",
      "Token count is too large: huggingface__transformers-17764\n",
      "Token count is too large: Qiskit__qiskit-8997\n",
      "Token count is too large: numpy__numpy-18369\n",
      "Token count is too large: numpy__numpy-19545\n",
      "Token count is too large: pandas-dev__pandas-5739\n",
      "Token count is too large: mesonbuild__meson-7263\n",
      "Token count is too large: googleapis__google-cloud-python-6916\n",
      "Token count is too large: pandas-dev__pandas-22488\n",
      "Token count is too large: pandas-dev__pandas-10716\n",
      "Token count is too large: pandas-dev__pandas-27530\n",
      "Token count is too large: pandas-dev__pandas-20549\n",
      "Token count is too large: googleapis__google-cloud-python-5021\n",
      "Token count is too large: numpy__numpy-260\n",
      "Token count is too large: jupyterlab__jupyterlab-5119\n",
      "Token count is too large: pandas-dev__pandas-25182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2340 examples [02:58, 16.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22272\n",
      "Token count is too large: pandas-dev__pandas-23506\n",
      "Token count is too large: pantsbuild__pants-16037\n",
      "Token count is too large: pandas-dev__pandas-4232\n",
      "Token count is too large: pandas-dev__pandas-17772\n",
      "Token count is too large: dagster-io__dagster-9518\n",
      "Token count is too large: apache__airflow-16352\n",
      "Token count is too large: apache__airflow-13654\n",
      "Token count is too large: apache__airflow-33045\n",
      "Token count is too large: jupyterlab__jupyterlab-7723\n",
      "Token count is too large: pandas-dev__pandas-20946\n",
      "Token count is too large: mesonbuild__meson-4644\n",
      "Token count is too large: mesonbuild__meson-8096\n",
      "Token count is too large: pandas-dev__pandas-5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2348 examples [02:59, 16.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36997\n",
      "Token count is too large: pandas-dev__pandas-22617\n",
      "Token count is too large: huggingface__transformers-7630\n",
      "Token count is too large: pantsbuild__pants-4373\n",
      "Token count is too large: Lightning-AI__lightning-1425\n",
      "Token count is too large: pandas-dev__pandas-20873\n",
      "Token count is too large: wagtail__wagtail-10618\n",
      "Token count is too large: pandas-dev__pandas-38070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2352 examples [02:59, 18.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9268\n",
      "Token count is too large: pandas-dev__pandas-26580\n",
      "Token count is too large: twisted__twisted-11747\n",
      "Token count is too large: pantsbuild__pants-10900\n",
      "Token count is too large: pandas-dev__pandas-16859\n",
      "Token count is too large: pyca__cryptography-3769\n",
      "Token count is too large: Qiskit__qiskit-655\n",
      "Token count is too large: pyca__cryptography-7439\n",
      "Token count is too large: mesonbuild__meson-1098\n",
      "Token count is too large: conan-io__conan-2964\n",
      "Token count is too large: pandas-dev__pandas-19377\n",
      "Token count is too large: huggingface__transformers-10703\n",
      "Token count is too large: twisted__twisted-11805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2360 examples [02:59, 21.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29140\n",
      "Token count is too large: pandas-dev__pandas-4308\n",
      "Token count is too large: pandas-dev__pandas-34709\n",
      "Token count is too large: huggingface__transformers-4109\n",
      "Token count is too large: ipython__ipython-5788\n",
      "Token count is too large: pandas-dev__pandas-32594\n",
      "Token count is too large: pandas-dev__pandas-24819\n",
      "Token count is too large: Qiskit__qiskit-8998\n",
      "Token count is too large: Lightning-AI__lightning-1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2365 examples [03:00, 18.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6364\n",
      "Token count is too large: ytdl-org__youtube-dl-14497\n",
      "Token count is too large: huggingface__transformers-5060\n",
      "Token count is too large: pandas-dev__pandas-36842\n",
      "Token count is too large: PrefectHQ__prefect-1504\n",
      "Token count is too large: googleapis__google-cloud-python-5576\n",
      "Token count is too large: Qiskit__qiskit-8560\n",
      "Token count is too large: Qiskit__qiskit-2748\n",
      "Token count is too large: celery__celery-6818\n",
      "Token count is too large: Lightning-AI__lightning-2255\n",
      "Token count is too large: Qiskit__qiskit-1849\n",
      "Token count is too large: pandas-dev__pandas-31684\n",
      "Token count is too large: google__jax-1736\n",
      "Token count is too large: Lightning-AI__lightning-1760\n",
      "Token count is too large: googleapis__google-cloud-python-2141\n",
      "Token count is too large: ray-project__ray-5160\n",
      "Token count is too large: mesonbuild__meson-9743\n",
      "Token count is too large: Lightning-AI__lightning-3066\n",
      "Token count is too large: Qiskit__qiskit-6084\n",
      "Token count is too large: Lightning-AI__lightning-3271\n",
      "Token count is too large: pandas-dev__pandas-33236\n",
      "Token count is too large: numpy__numpy-3520\n",
      "Token count is too large: conan-io__conan-6824\n",
      "Token count is too large: apache__airflow-12787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2374 examples [03:00, 19.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-8689\n",
      "Token count is too large: apache__airflow-11797\n",
      "Token count is too large: pandas-dev__pandas-14116\n",
      "Token count is too large: pandas-dev__pandas-17819\n",
      "Token count is too large: pandas-dev__pandas-38597\n",
      "Token count is too large: Lightning-AI__lightning-543\n",
      "Token count is too large: pandas-dev__pandas-38638\n",
      "Token count is too large: pandas-dev__pandas-6301\n",
      "Token count is too large: pandas-dev__pandas-7043\n",
      "Token count is too large: pandas-dev__pandas-4761\n",
      "Token count is too large: pandas-dev__pandas-23190\n",
      "Token count is too large: huggingface__transformers-9381\n",
      "Token count is too large: pandas-dev__pandas-18177\n",
      "Token count is too large: pandas-dev__pandas-11148\n",
      "Token count is too large: mesonbuild__meson-3374\n",
      "Token count is too large: conda__conda-2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2379 examples [03:01, 15.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-10930\n",
      "Token count is too large: pandas-dev__pandas-16317\n",
      "Token count is too large: pandas-dev__pandas-6202\n",
      "Token count is too large: pantsbuild__pants-11635\n",
      "Token count is too large: wagtail__wagtail-9518\n",
      "Token count is too large: numpy__numpy-20344\n",
      "Token count is too large: pandas-dev__pandas-8984\n",
      "Token count is too large: pandas-dev__pandas-30676\n",
      "Token count is too large: jupyterlab__jupyterlab-9492\n",
      "Token count is too large: pypa__pip-3652\n",
      "Token count is too large: pandas-dev__pandas-27607\n",
      "Token count is too large: pyca__cryptography-2124\n",
      "Token count is too large: google__jax-360\n",
      "Token count is too large: gitpython-developers__GitPython-936\n",
      "Token count is too large: DataDog__integrations-core-1583\n",
      "Token count is too large: mesonbuild__meson-2340\n",
      "Token count is too large: mesonbuild__meson-6877\n",
      "Token count is too large: wagtail__wagtail-7669\n",
      "Token count is too large: google__jax-2805\n",
      "Token count is too large: pandas-dev__pandas-10283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2395 examples [03:01, 28.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6088\n",
      "Token count is too large: ray-project__ray-6141\n",
      "Token count is too large: conda__conda-2706\n",
      "Token count is too large: mesonbuild__meson-10089\n",
      "Token count is too large: huggingface__transformers-10868\n",
      "Token count is too large: pandas-dev__pandas-3138\n",
      "Token count is too large: apache__airflow-30190\n",
      "Token count is too large: pyca__cryptography-3124\n",
      "Token count is too large: gitpython-developers__GitPython-697\n",
      "Token count is too large: ipython__ipython-12207\n",
      "Token count is too large: numpy__numpy-22375\n",
      "Token count is too large: ytdl-org__youtube-dl-4388\n",
      "Token count is too large: huggingface__transformers-15590\n",
      "Token count is too large: huggingface__transformers-24429\n",
      "Token count is too large: pantsbuild__pants-17251\n",
      "Token count is too large: conda__conda-5226\n",
      "Token count is too large: Qiskit__qiskit-7288\n",
      "Token count is too large: googleapis__google-cloud-python-602\n",
      "Token count is too large: pantsbuild__pants-16110\n",
      "Token count is too large: numpy__numpy-15483\n",
      "Token count is too large: Qiskit__qiskit-2736\n",
      "Token count is too large: pypa__pip-2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2399 examples [03:01, 21.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-30292\n",
      "Token count is too large: Lightning-AI__lightning-625\n",
      "Token count is too large: huggingface__transformers-18902\n",
      "Token count is too large: pandas-dev__pandas-7094\n",
      "Token count is too large: pandas-dev__pandas-20655\n",
      "Token count is too large: pantsbuild__pants-14822\n",
      "Token count is too large: PrefectHQ__prefect-2076\n",
      "Token count is too large: ipython__ipython-4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2412 examples [03:02, 30.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30083\n",
      "Token count is too large: conda__conda-5096\n",
      "Token count is too large: google__jax-780\n",
      "Token count is too large: Lightning-AI__lightning-2253\n",
      "Token count is too large: mesonbuild__meson-3599\n",
      "Token count is too large: ipython__ipython-9419\n",
      "Token count is too large: celery__celery-6942\n",
      "Token count is too large: googleapis__google-cloud-python-1280\n",
      "Token count is too large: pandas-dev__pandas-34222\n",
      "Token count is too large: pandas-dev__pandas-33629\n",
      "Token count is too large: pandas-dev__pandas-16133\n",
      "Token count is too large: pandas-dev__pandas-24510\n",
      "Token count is too large: Qiskit__qiskit-1055\n",
      "Token count is too large: huggingface__transformers-17119\n",
      "Token count is too large: pypa__pip-1040\n",
      "Token count is too large: huggingface__transformers-11896\n",
      "Token count is too large: PrefectHQ__prefect-2944\n",
      "Token count is too large: Qiskit__qiskit-2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2416 examples [03:02, 19.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1209\n",
      "Token count is too large: docker__compose-2646\n",
      "Token count is too large: pandas-dev__pandas-28974\n",
      "Token count is too large: pandas-dev__pandas-35986\n",
      "Token count is too large: dagster-io__dagster-14707\n",
      "Token count is too large: huggingface__transformers-21651\n",
      "Token count is too large: numpy__numpy-439\n",
      "Token count is too large: google__jax-2214\n",
      "Token count is too large: pandas-dev__pandas-17812\n",
      "Token count is too large: huggingface__transformers-18078\n",
      "Token count is too large: pandas-dev__pandas-16952\n",
      "Token count is too large: pypa__pip-7593\n",
      "Token count is too large: pandas-dev__pandas-18352\n",
      "Token count is too large: pandas-dev__pandas-28239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2421 examples [03:03, 15.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27696\n",
      "Token count is too large: Qiskit__qiskit-4522\n",
      "Token count is too large: pandas-dev__pandas-13458\n",
      "Token count is too large: numpy__numpy-13673\n",
      "Token count is too large: pandas-dev__pandas-5512\n",
      "Token count is too large: huggingface__transformers-5999\n",
      "Token count is too large: ipython__ipython-2255\n",
      "Token count is too large: pandas-dev__pandas-29373\n",
      "Token count is too large: pandas-dev__pandas-14501\n",
      "Token count is too large: ytdl-org__youtube-dl-9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2426 examples [03:03, 17.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-5810\n",
      "Token count is too large: huggingface__transformers-18833\n",
      "Token count is too large: pandas-dev__pandas-38018\n",
      "Token count is too large: conan-io__conan-4872\n",
      "Token count is too large: pandas-dev__pandas-7497\n",
      "Token count is too large: conan-io__conan-7871\n",
      "Token count is too large: docker__compose-5701\n",
      "Token count is too large: pandas-dev__pandas-19139\n",
      "Token count is too large: Lightning-AI__lightning-1529\n",
      "Token count is too large: apache__airflow-22557\n",
      "Token count is too large: pandas-dev__pandas-19818\n",
      "Token count is too large: pandas-dev__pandas-38141\n",
      "Token count is too large: pandas-dev__pandas-36440\n",
      "Token count is too large: huggingface__transformers-13495\n",
      "Token count is too large: pandas-dev__pandas-25069\n",
      "Token count is too large: huggingface__transformers-21345\n",
      "Token count is too large: Lightning-AI__lightning-744\n",
      "Token count is too large: pandas-dev__pandas-6652\n",
      "Token count is too large: pypa__pip-2304\n",
      "Token count is too large: conda__conda-7048\n",
      "Token count is too large: Qiskit__qiskit-6975\n",
      "Token count is too large: huggingface__transformers-20911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2429 examples [03:04, 10.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-6633\n",
      "Token count is too large: Qiskit__qiskit-1061\n",
      "Token count is too large: pandas-dev__pandas-7264\n",
      "Token count is too large: docker__compose-5896\n",
      "Token count is too large: pandas-dev__pandas-25686\n",
      "Token count is too large: celery__celery-6218\n",
      "Token count is too large: pandas-dev__pandas-23540\n",
      "Token count is too large: pandas-dev__pandas-37138\n",
      "Token count is too large: Qiskit__qiskit-1054\n",
      "Token count is too large: pandas-dev__pandas-21183\n",
      "Token count is too large: docker__compose-2783\n",
      "Token count is too large: PrefectHQ__prefect-729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2431 examples [03:04, 10.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-136\n",
      "Token count is too large: numpy__numpy-23335\n",
      "Token count is too large: pandas-dev__pandas-25541\n",
      "Token count is too large: conan-io__conan-2504\n",
      "Token count is too large: conda__conda-7729\n",
      "Token count is too large: ytdl-org__youtube-dl-30596\n",
      "Token count is too large: pandas-dev__pandas-4957\n",
      "Token count is too large: apache__airflow-20737\n",
      "Token count is too large: pandas-dev__pandas-5864\n",
      "Token count is too large: pandas-dev__pandas-27665\n",
      "There was an error processing\n",
      "Token count is too large: googleapis__google-cloud-python-7008\n",
      "Token count is too large: huggingface__transformers-14306\n",
      "Token count is too large: numpy__numpy-9942\n",
      "Token count is too large: PrefectHQ__prefect-2590\n",
      "Token count is too large: ytdl-org__youtube-dl-1007\n",
      "Token count is too large: apache__airflow-32217\n",
      "Token count is too large: pandas-dev__pandas-23132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2436 examples [03:04, 10.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8364\n",
      "Token count is too large: wagtail__wagtail-5837\n",
      "Token count is too large: pandas-dev__pandas-31641\n",
      "Token count is too large: pandas-dev__pandas-23285\n",
      "Token count is too large: docker__compose-6126\n",
      "Token count is too large: Qiskit__qiskit-10383\n",
      "Token count is too large: ipython__ipython-1569\n",
      "Token count is too large: conda__conda-1496\n",
      "Token count is too large: ipython__ipython-3184\n",
      "Token count is too large: Qiskit__qiskit-6942\n",
      "Token count is too large: conda__conda-5936\n",
      "Token count is too large: pandas-dev__pandas-24841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2439 examples [03:04, 12.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-272\n",
      "Token count is too large: pandas-dev__pandas-37801\n",
      "Token count is too large: apache__airflow-27881\n",
      "Token count is too large: huggingface__transformers-10229\n",
      "Token count is too large: huggingface__transformers-17785\n",
      "Token count is too large: Qiskit__qiskit-5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2442 examples [03:05, 12.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-13592\n",
      "Token count is too large: mesonbuild__meson-6635\n",
      "Token count is too large: pandas-dev__pandas-30925\n",
      "Token count is too large: numpy__numpy-21868\n",
      "Token count is too large: googleapis__google-cloud-python-6829\n",
      "Token count is too large: pandas-dev__pandas-18514\n",
      "Token count is too large: gitpython-developers__GitPython-859\n",
      "Token count is too large: conda__conda-6657\n",
      "Token count is too large: google__jax-2593\n",
      "Token count is too large: Qiskit__qiskit-807\n",
      "Token count is too large: huggingface__transformers-11682\n",
      "Token count is too large: mesonbuild__meson-10464\n",
      "Token count is too large: pantsbuild__pants-4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2447 examples [03:05, 13.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14508\n",
      "Token count is too large: pantsbuild__pants-5911\n",
      "Token count is too large: Lightning-AI__lightning-2890\n",
      "Token count is too large: Qiskit__qiskit-5360\n",
      "Token count is too large: pandas-dev__pandas-35587\n",
      "Token count is too large: pandas-dev__pandas-3277\n",
      "Token count is too large: huggingface__transformers-19204\n",
      "Token count is too large: conda__conda-5478\n",
      "Token count is too large: numpy__numpy-19089\n",
      "Token count is too large: Lightning-AI__lightning-1528\n",
      "Token count is too large: pandas-dev__pandas-36724\n",
      "Token count is too large: numpy__numpy-4861\n",
      "Token count is too large: huggingface__transformers-7282\n",
      "Token count is too large: google__jax-1568\n",
      "Token count is too large: Qiskit__qiskit-2205\n",
      "Token count is too large: ytdl-org__youtube-dl-12391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2449 examples [03:05, 13.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3452\n",
      "Token count is too large: apache__airflow-32785\n",
      "Token count is too large: googleapis__google-cloud-python-2002\n",
      "Token count is too large: googleapis__google-cloud-python-7297\n",
      "Token count is too large: conda__conda-6887\n",
      "Token count is too large: numpy__numpy-21558\n",
      "Token count is too large: apache__airflow-20888\n",
      "Token count is too large: pyca__cryptography-3014\n",
      "Token count is too large: huggingface__transformers-8368\n",
      "Token count is too large: huggingface__transformers-10213\n",
      "Token count is too large: pandas-dev__pandas-36054\n",
      "Token count is too large: pandas-dev__pandas-30096\n",
      "Token count is too large: twisted__twisted-11678\n",
      "Token count is too large: celery__celery-2840\n",
      "Token count is too large: mesonbuild__meson-6558\n",
      "Token count is too large: docker__compose-6131\n",
      "Token count is too large: pandas-dev__pandas-31383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2456 examples [03:05, 21.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11830\n",
      "Token count is too large: mesonbuild__meson-3036\n",
      "Token count is too large: Lightning-AI__lightning-2033\n",
      "Token count is too large: conan-io__conan-226\n",
      "Token count is too large: pandas-dev__pandas-27852\n",
      "Token count is too large: pandas-dev__pandas-18340\n",
      "Token count is too large: huggingface__transformers-6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2459 examples [03:06, 12.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-8611\n",
      "Token count is too large: pandas-dev__pandas-18167\n",
      "Token count is too large: mesonbuild__meson-5516\n",
      "Token count is too large: huggingface__transformers-24404\n",
      "Token count is too large: Qiskit__qiskit-7972\n",
      "Token count is too large: googleapis__google-cloud-python-2262\n",
      "Token count is too large: pyca__cryptography-6303\n",
      "Token count is too large: pandas-dev__pandas-5043\n",
      "Token count is too large: mesonbuild__meson-8340\n",
      "Token count is too large: pandas-dev__pandas-6031\n",
      "Token count is too large: docker__compose-4635\n",
      "Token count is too large: pandas-dev__pandas-19529\n",
      "Token count is too large: apache__airflow-33055\n",
      "Token count is too large: numpy__numpy-24542\n",
      "Token count is too large: numpy__numpy-7133\n",
      "Token count is too large: ipython__ipython-8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2465 examples [03:06, 14.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23941\n",
      "Token count is too large: huggingface__transformers-11524\n",
      "Token count is too large: googleapis__google-cloud-python-888\n",
      "Token count is too large: pandas-dev__pandas-38954\n",
      "Token count is too large: pypa__pip-12140\n",
      "Token count is too large: ytdl-org__youtube-dl-8332\n",
      "Token count is too large: pandas-dev__pandas-14545\n",
      "Token count is too large: ipython__ipython-7202\n",
      "Token count is too large: pandas-dev__pandas-14004\n",
      "Token count is too large: pantsbuild__pants-8047\n",
      "Token count is too large: tiangolo__fastapi-1547\n",
      "Token count is too large: Lightning-AI__lightning-1360\n",
      "Token count is too large: pandas-dev__pandas-3802\n",
      "Token count is too large: huggingface__transformers-13613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2474 examples [03:06, 19.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28412\n",
      "Token count is too large: conda__conda-6277\n",
      "Token count is too large: mesonbuild__meson-4860\n",
      "Token count is too large: apache__airflow-11406\n",
      "Token count is too large: ytdl-org__youtube-dl-25198\n",
      "Token count is too large: pandas-dev__pandas-29334\n",
      "Token count is too large: numpy__numpy-20659\n",
      "Token count is too large: Qiskit__qiskit-7997\n",
      "Token count is too large: ipython__ipython-6076\n",
      "Token count is too large: ray-project__ray-3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2478 examples [03:07, 20.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13678\n",
      "Token count is too large: pantsbuild__pants-15034\n",
      "Token count is too large: pandas-dev__pandas-37013\n",
      "Token count is too large: ytdl-org__youtube-dl-22921\n",
      "Token count is too large: apache__airflow-16809\n",
      "Token count is too large: Lightning-AI__lightning-1265\n",
      "Token count is too large: Qiskit__qiskit-1082\n",
      "Token count is too large: numpy__numpy-3852\n",
      "Token count is too large: numpy__numpy-6668\n",
      "Token count is too large: googleapis__google-cloud-python-1282\n",
      "Token count is too large: pandas-dev__pandas-34116\n",
      "Token count is too large: pandas-dev__pandas-5137\n",
      "Token count is too large: docker__compose-5361\n",
      "Token count is too large: Qiskit__qiskit-808\n",
      "Token count is too large: ytdl-org__youtube-dl-26032\n",
      "Token count is too large: ytdl-org__youtube-dl-8249\n",
      "Token count is too large: huggingface__transformers-22237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2481 examples [03:07, 14.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-10551\n",
      "Token count is too large: googleapis__google-cloud-python-2809\n",
      "Token count is too large: docker__compose-3789\n",
      "Token count is too large: pandas-dev__pandas-17626\n",
      "Token count is too large: pandas-dev__pandas-13499\n",
      "Token count is too large: mesonbuild__meson-8804\n",
      "Token count is too large: pandas-dev__pandas-15873\n",
      "Token count is too large: ytdl-org__youtube-dl-7659\n",
      "Token count is too large: pandas-dev__pandas-17840\n",
      "Token count is too large: pandas-dev__pandas-4921\n",
      "Token count is too large: googleapis__google-cloud-python-10079\n",
      "Token count is too large: huggingface__transformers-17549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2483 examples [03:07, 11.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5145\n",
      "Token count is too large: ipython__ipython-2926\n",
      "Token count is too large: pandas-dev__pandas-5214\n",
      "Token count is too large: mesonbuild__meson-1807\n",
      "Token count is too large: pantsbuild__pants-13956\n",
      "Token count is too large: pantsbuild__pants-15033\n",
      "Token count is too large: conda__conda-5824\n",
      "Token count is too large: pandas-dev__pandas-17424\n",
      "Token count is too large: conda__conda-11440\n",
      "Token count is too large: numpy__numpy-5393\n",
      "Token count is too large: apache__airflow-16102\n",
      "Token count is too large: google__jax-3224\n",
      "Token count is too large: conda__conda-8912\n",
      "Token count is too large: ytdl-org__youtube-dl-26826\n",
      "Token count is too large: huggingface__transformers-17518\n",
      "Token count is too large: pyca__cryptography-2129\n",
      "Token count is too large: pandas-dev__pandas-38257\n",
      "Token count is too large: Lightning-AI__lightning-852\n",
      "Token count is too large: docker__compose-970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2485 examples [03:08,  8.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37302\n",
      "Token count is too large: pandas-dev__pandas-10249\n",
      "Token count is too large: pandas-dev__pandas-18924\n",
      "Token count is too large: pandas-dev__pandas-12208\n",
      "Token count is too large: pantsbuild__pants-15415\n",
      "Token count is too large: ipython__ipython-13483\n",
      "Token count is too large: numpy__numpy-14932\n",
      "Token count is too large: google__jax-335\n",
      "Token count is too large: numpy__numpy-4339\n",
      "Token count is too large: huggingface__transformers-25523\n",
      "Token count is too large: pandas-dev__pandas-26273\n",
      "Token count is too large: ipython__ipython-3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2495 examples [03:08, 14.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21044\n",
      "Token count is too large: PrefectHQ__prefect-2180\n",
      "Token count is too large: jupyterlab__jupyterlab-3071\n",
      "Token count is too large: pypa__pip-6851\n",
      "Token count is too large: conda__conda-9418\n",
      "Token count is too large: pandas-dev__pandas-35440\n",
      "Token count is too large: conan-io__conan-4229\n",
      "Token count is too large: Qiskit__qiskit-4470\n",
      "Token count is too large: pandas-dev__pandas-23581\n",
      "Token count is too large: celery__celery-5664\n",
      "Token count is too large: wagtail__wagtail-9590\n",
      "Token count is too large: pandas-dev__pandas-3655\n",
      "Token count is too large: pandas-dev__pandas-37794\n",
      "Token count is too large: pandas-dev__pandas-5197\n",
      "Token count is too large: numpy__numpy-16811\n",
      "Token count is too large: pandas-dev__pandas-22253\n",
      "Token count is too large: pantsbuild__pants-16735\n",
      "Token count is too large: pandas-dev__pandas-16237\n",
      "Token count is too large: huggingface__transformers-7683\n",
      "Token count is too large: numpy__numpy-8905\n",
      "Token count is too large: celery__celery-5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2500 examples [03:09, 14.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-7126\n",
      "Token count is too large: Lightning-AI__lightning-715\n",
      "Token count is too large: Qiskit__qiskit-8752\n",
      "Token count is too large: pandas-dev__pandas-23096\n",
      "Token count is too large: pandas-dev__pandas-10497\n",
      "Token count is too large: apache__airflow-18438\n",
      "Token count is too large: pandas-dev__pandas-9357\n",
      "Token count is too large: ipython__ipython-9515\n",
      "Token count is too large: tiangolo__fastapi-621\n",
      "Token count is too large: pandas-dev__pandas-1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2503 examples [03:09, 15.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33299\n",
      "Token count is too large: pandas-dev__pandas-34956\n",
      "Token count is too large: numpy__numpy-18416\n",
      "Token count is too large: Qiskit__qiskit-7389\n",
      "Token count is too large: conan-io__conan-4662\n",
      "Token count is too large: mesonbuild__meson-10966\n",
      "Token count is too large: mesonbuild__meson-10085\n",
      "Token count is too large: docker__compose-5825\n",
      "Token count is too large: Lightning-AI__lightning-1647\n",
      "Token count is too large: pypa__pip-10129\n",
      "Token count is too large: docker__compose-5098\n",
      "Token count is too large: pandas-dev__pandas-10172\n",
      "Token count is too large: huggingface__transformers-14291\n",
      "Token count is too large: googleapis__google-cloud-python-9911\n",
      "Token count is too large: ipython__ipython-2073\n",
      "Token count is too large: conan-io__conan-5070\n",
      "Token count is too large: pantsbuild__pants-4729\n",
      "Token count is too large: pandas-dev__pandas-25909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2507 examples [03:09, 12.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22852\n",
      "Token count is too large: googleapis__google-cloud-python-8423\n",
      "Token count is too large: conda__conda-5090\n",
      "Token count is too large: docker__compose-5079\n",
      "Token count is too large: wagtail__wagtail-2880\n",
      "Token count is too large: pandas-dev__pandas-38819\n",
      "Token count is too large: pandas-dev__pandas-11233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2509 examples [03:09, 11.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35681\n",
      "Token count is too large: Lightning-AI__lightning-649\n",
      "Token count is too large: pypa__pip-10697\n",
      "Token count is too large: conda__conda-8834\n",
      "Token count is too large: pandas-dev__pandas-7478\n",
      "Token count is too large: pandas-dev__pandas-23127\n",
      "Token count is too large: numpy__numpy-10097\n",
      "Token count is too large: pandas-dev__pandas-21285\n",
      "Token count is too large: google__jax-79\n",
      "Token count is too large: ipython__ipython-2110\n",
      "Token count is too large: googleapis__google-cloud-python-9572\n",
      "Token count is too large: apache__airflow-14774\n",
      "Token count is too large: huggingface__transformers-14085\n",
      "Token count is too large: googleapis__google-cloud-python-5678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2516 examples [03:10, 16.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26162\n",
      "Token count is too large: conan-io__conan-10174\n",
      "Token count is too large: numpy__numpy-11708\n",
      "Token count is too large: pandas-dev__pandas-21366\n",
      "Token count is too large: celery__celery-6576\n",
      "Token count is too large: Qiskit__qiskit-7109\n",
      "Token count is too large: pandas-dev__pandas-19344\n",
      "Token count is too large: googleapis__google-cloud-python-11313\n",
      "Token count is too large: pandas-dev__pandas-21731\n",
      "Token count is too large: numpy__numpy-3461\n",
      "Token count is too large: docker__compose-5093\n",
      "Token count is too large: pyca__cryptography-1952\n",
      "Token count is too large: mesonbuild__meson-5018\n",
      "Token count is too large: pyca__cryptography-4985\n",
      "Token count is too large: huggingface__transformers-18187\n",
      "Token count is too large: Qiskit__qiskit-4851\n",
      "Token count is too large: pandas-dev__pandas-26399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2519 examples [03:10, 10.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-8648\n",
      "Token count is too large: pandas-dev__pandas-36797\n",
      "Token count is too large: google__jax-1030\n",
      "Token count is too large: celery__celery-5348\n",
      "Token count is too large: conda__conda-10992\n",
      "Token count is too large: ipython__ipython-8062\n",
      "Token count is too large: mesonbuild__meson-11644\n",
      "Token count is too large: ipython__ipython-4996\n",
      "Token count is too large: conan-io__conan-6334\n",
      "Token count is too large: pandas-dev__pandas-3139\n",
      "Token count is too large: explosion__spaCy-3324\n",
      "Token count is too large: pypa__pip-10206\n",
      "Token count is too large: gitpython-developers__GitPython-1521\n",
      "Token count is too large: huggingface__transformers-14124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2521 examples [03:11,  9.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30241\n",
      "Token count is too large: pandas-dev__pandas-19280\n",
      "Token count is too large: Qiskit__qiskit-1366\n",
      "Token count is too large: pandas-dev__pandas-14073\n",
      "Token count is too large: Qiskit__qiskit-6998\n",
      "Token count is too large: ipython__ipython-4382\n",
      "Token count is too large: pandas-dev__pandas-39051\n",
      "Token count is too large: ytdl-org__youtube-dl-6097\n",
      "Token count is too large: jupyterlab__jupyterlab-8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2525 examples [03:11, 12.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36147\n",
      "Token count is too large: pandas-dev__pandas-14445\n",
      "Token count is too large: ytdl-org__youtube-dl-16115\n",
      "Token count is too large: pandas-dev__pandas-18923\n",
      "Token count is too large: numpy__numpy-13739\n",
      "Token count is too large: conda__conda-4711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2531 examples [03:11, 13.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6634\n",
      "Token count is too large: pandas-dev__pandas-9007\n",
      "Token count is too large: pandas-dev__pandas-15093\n",
      "Token count is too large: Qiskit__qiskit-973\n",
      "Token count is too large: Qiskit__qiskit-4478\n",
      "Token count is too large: Qiskit__qiskit-626\n",
      "Token count is too large: ipython__ipython-11409\n",
      "Token count is too large: pandas-dev__pandas-9808\n",
      "Token count is too large: pandas-dev__pandas-5658\n",
      "Token count is too large: ipython__ipython-3082\n",
      "Token count is too large: pandas-dev__pandas-33907\n",
      "Token count is too large: pyca__cryptography-1883\n",
      "Token count is too large: huggingface__transformers-8962\n",
      "Token count is too large: Lightning-AI__lightning-2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2536 examples [03:11, 17.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12638\n",
      "Token count is too large: huggingface__transformers-25684\n",
      "Token count is too large: ipython__ipython-734\n",
      "Token count is too large: wagtail__wagtail-1533\n",
      "Token count is too large: pantsbuild__pants-14088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2542 examples [03:12, 21.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28438\n",
      "Token count is too large: Qiskit__qiskit-4382\n",
      "Token count is too large: googleapis__google-cloud-python-8938\n",
      "Token count is too large: conda__conda-6517\n",
      "Token count is too large: pandas-dev__pandas-27651\n",
      "Token count is too large: jupyterlab__jupyterlab-9580\n",
      "Token count is too large: pantsbuild__pants-4679\n",
      "Token count is too large: dagster-io__dagster-15078\n",
      "Token count is too large: Qiskit__qiskit-5274\n",
      "Token count is too large: pandas-dev__pandas-14965\n",
      "Token count is too large: googleapis__google-cloud-python-1051\n",
      "Token count is too large: pandas-dev__pandas-17119\n",
      "Token count is too large: pandas-dev__pandas-35377\n",
      "Token count is too large: conda__conda-2526\n",
      "Token count is too large: pandas-dev__pandas-17412\n",
      "Token count is too large: PrefectHQ__prefect-1434\n",
      "Token count is too large: mesonbuild__meson-982\n",
      "Token count is too large: pandas-dev__pandas-22576\n",
      "Token count is too large: ytdl-org__youtube-dl-9367\n",
      "Token count is too large: Lightning-AI__lightning-2462\n",
      "Token count is too large: apache__airflow-18896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2556 examples [03:12, 24.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16005\n",
      "Token count is too large: googleapis__google-cloud-python-1213\n",
      "Token count is too large: pandas-dev__pandas-24443\n",
      "Token count is too large: pandas-dev__pandas-30516\n",
      "Token count is too large: google__jax-303\n",
      "Token count is too large: pantsbuild__pants-13996\n",
      "Token count is too large: huggingface__transformers-14026\n",
      "Token count is too large: open-mmlab__mmdetection-4555\n",
      "Token count is too large: tensorflow__models-3448\n",
      "Token count is too large: pypa__pip-5559\n",
      "Token count is too large: conan-io__conan-3012\n",
      "Token count is too large: numpy__numpy-14051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2559 examples [03:12, 24.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22141\n",
      "Token count is too large: apache__airflow-27564\n",
      "Token count is too large: Qiskit__qiskit-7031\n",
      "Token count is too large: Qiskit__qiskit-2119\n",
      "Token count is too large: ytdl-org__youtube-dl-4395\n",
      "Token count is too large: Qiskit__qiskit-6458\n",
      "Token count is too large: docker__compose-2601\n",
      "Token count is too large: apache__airflow-26766\n",
      "Token count is too large: pandas-dev__pandas-29245\n",
      "Token count is too large: pandas-dev__pandas-7041\n",
      "Token count is too large: pandas-dev__pandas-21093\n",
      "Token count is too large: pantsbuild__pants-6023\n",
      "Token count is too large: conda__conda-6656\n",
      "Token count is too large: pandas-dev__pandas-21169\n",
      "Token count is too large: open-mmlab__mmdetection-7572\n",
      "Token count is too large: docker__compose-3128\n",
      "Token count is too large: huggingface__transformers-4531\n",
      "Token count is too large: pandas-dev__pandas-15774\n",
      "Token count is too large: pantsbuild__pants-18635\n",
      "Token count is too large: Lightning-AI__lightning-1954\n",
      "Token count is too large: conda__conda-6709\n",
      "Token count is too large: huggingface__transformers-6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2563 examples [03:13, 17.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28686\n",
      "Token count is too large: docker__compose-2907\n",
      "Token count is too large: mesonbuild__meson-2142\n",
      "Token count is too large: pandas-dev__pandas-26029\n",
      "Token count is too large: huggingface__transformers-17055\n",
      "Token count is too large: numpy__numpy-11449\n",
      "Token count is too large: apache__airflow-320\n",
      "Token count is too large: conan-io__conan-7215\n",
      "Token count is too large: pyca__cryptography-6922\n",
      "Token count is too large: pandas-dev__pandas-13617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2572 examples [03:13, 20.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9108\n",
      "Token count is too large: mesonbuild__meson-3795\n",
      "Token count is too large: wagtail__wagtail-10072\n",
      "Token count is too large: Lightning-AI__lightning-1780\n",
      "Token count is too large: huggingface__transformers-19219\n",
      "Token count is too large: conan-io__conan-3153\n",
      "Token count is too large: pandas-dev__pandas-8298\n",
      "Token count is too large: Qiskit__qiskit-9170\n",
      "Token count is too large: googleapis__google-cloud-python-9974\n",
      "Token count is too large: Qiskit__qiskit-3470\n",
      "Token count is too large: google__jax-1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2575 examples [03:13, 21.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-6430\n",
      "Token count is too large: pandas-dev__pandas-35582\n",
      "Token count is too large: pandas-dev__pandas-23864\n",
      "Token count is too large: google__jax-2885\n",
      "Token count is too large: Qiskit__qiskit-1224\n",
      "Token count is too large: Qiskit__qiskit-5581\n",
      "Token count is too large: Lightning-AI__lightning-1010\n",
      "Token count is too large: pandas-dev__pandas-19044\n",
      "Token count is too large: ipython__ipython-11183\n",
      "Token count is too large: pandas-dev__pandas-32911\n",
      "Token count is too large: pandas-dev__pandas-4989\n",
      "Token count is too large: numpy__numpy-22872\n",
      "Token count is too large: pandas-dev__pandas-3060\n",
      "Token count is too large: Lightning-AI__lightning-3266\n",
      "Token count is too large: huggingface__transformers-21005\n",
      "Token count is too large: ytdl-org__youtube-dl-8898\n",
      "Token count is too large: twisted__twisted-11714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2579 examples [03:14, 14.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-2878\n",
      "Token count is too large: ytdl-org__youtube-dl-12276\n",
      "Token count is too large: pandas-dev__pandas-9487\n",
      "Token count is too large: conan-io__conan-2996\n",
      "Token count is too large: pantsbuild__pants-13977\n",
      "Token count is too large: pandas-dev__pandas-24099\n",
      "Token count is too large: huggingface__transformers-8714\n",
      "Token count is too large: numpy__numpy-9132\n",
      "Token count is too large: googleapis__google-cloud-python-6436\n",
      "Token count is too large: celery__celery-6342\n",
      "Token count is too large: pandas-dev__pandas-29368\n",
      "Token count is too large: pandas-dev__pandas-8847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2582 examples [03:14, 15.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7038\n",
      "Token count is too large: pantsbuild__pants-9769\n",
      "Token count is too large: apache__airflow-19965\n",
      "Token count is too large: Lightning-AI__lightning-1932\n",
      "Token count is too large: Lightning-AI__lightning-2572\n",
      "Token count is too large: docker__compose-6209\n",
      "Token count is too large: pandas-dev__pandas-28858\n",
      "Token count is too large: ray-project__ray-10672\n",
      "Token count is too large: numpy__numpy-18351\n",
      "Token count is too large: Lightning-AI__lightning-2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2586 examples [03:14, 15.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3621\n",
      "Token count is too large: pandas-dev__pandas-27798\n",
      "Token count is too large: explosion__spaCy-3213\n",
      "Token count is too large: conan-io__conan-6618\n",
      "Token count is too large: pandas-dev__pandas-29788\n",
      "Token count is too large: pandas-dev__pandas-27109\n",
      "Token count is too large: ipython__ipython-4908\n",
      "Token count is too large: mesonbuild__meson-129\n",
      "Token count is too large: ipython__ipython-5379\n",
      "Token count is too large: apache__airflow-17613\n",
      "Token count is too large: googleapis__google-cloud-python-11311\n",
      "Token count is too large: Qiskit__qiskit-5994\n",
      "Token count is too large: pandas-dev__pandas-38175\n",
      "Token count is too large: numpy__numpy-24496\n",
      "Token count is too large: ipython__ipython-5961\n",
      "Token count is too large: conda__conda-10057\n",
      "Token count is too large: huggingface__transformers-19868\n",
      "Token count is too large: conda__conda-2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2592 examples [03:14, 13.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21349\n",
      "Token count is too large: pandas-dev__pandas-24842\n",
      "Token count is too large: wagtail__wagtail-3521\n",
      "Token count is too large: ray-project__ray-4285\n",
      "Token count is too large: pandas-dev__pandas-20727\n",
      "Token count is too large: docker__compose-5224\n",
      "Token count is too large: numpy__numpy-22771\n",
      "Token count is too large: huggingface__transformers-17311\n",
      "Token count is too large: Qiskit__qiskit-4270\n",
      "Token count is too large: pandas-dev__pandas-25796\n",
      "Token count is too large: pandas-dev__pandas-18292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2595 examples [03:15, 14.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5088\n",
      "Token count is too large: wagtail__wagtail-7093\n",
      "Token count is too large: pandas-dev__pandas-18228\n",
      "Token count is too large: conan-io__conan-9240\n",
      "Token count is too large: jupyterlab__jupyterlab-10769\n",
      "Token count is too large: conan-io__conan-4113\n",
      "Token count is too large: pandas-dev__pandas-33509\n",
      "Token count is too large: pandas-dev__pandas-22320\n",
      "Token count is too large: huggingface__transformers-7281\n",
      "Token count is too large: pandas-dev__pandas-6486\n",
      "Token count is too large: numpy__numpy-5498\n",
      "Token count is too large: pantsbuild__pants-4716\n",
      "Token count is too large: Qiskit__qiskit-3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2597 examples [03:15, 12.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31333\n",
      "Token count is too large: pandas-dev__pandas-23673\n",
      "Token count is too large: PrefectHQ__prefect-530\n",
      "Token count is too large: pandas-dev__pandas-19178\n",
      "Token count is too large: conan-io__conan-6003\n",
      "Token count is too large: huggingface__transformers-11128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2602 examples [03:15, 14.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4035\n",
      "Token count is too large: Qiskit__qiskit-4181\n",
      "Token count is too large: ipython__ipython-11418\n",
      "Token count is too large: Qiskit__qiskit-2881\n",
      "Token count is too large: apache__airflow-16441\n",
      "Token count is too large: pandas-dev__pandas-37426\n",
      "Token count is too large: mesonbuild__meson-3694\n",
      "Token count is too large: celery__celery-6481\n",
      "Token count is too large: numpy__numpy-23275\n",
      "Token count is too large: huggingface__transformers-4943\n",
      "Token count is too large: celery__celery-7553\n",
      "Token count is too large: pandas-dev__pandas-21853\n",
      "Token count is too large: pandas-dev__pandas-21655\n",
      "Token count is too large: pandas-dev__pandas-34888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2604 examples [03:15, 12.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-19264\n",
      "Token count is too large: pandas-dev__pandas-8877\n",
      "Token count is too large: pypa__pip-2925\n",
      "Token count is too large: Qiskit__qiskit-5358\n",
      "Token count is too large: pandas-dev__pandas-25913\n",
      "Token count is too large: huggingface__transformers-23156\n",
      "Token count is too large: Lightning-AI__lightning-2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2606 examples [03:16, 11.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6130\n",
      "Token count is too large: huggingface__transformers-15074\n",
      "Token count is too large: pypa__pip-2761\n",
      "Token count is too large: pandas-dev__pandas-22866\n",
      "Token count is too large: pandas-dev__pandas-4054\n",
      "Token count is too large: mesonbuild__meson-2942\n",
      "Token count is too large: pandas-dev__pandas-22918\n",
      "Token count is too large: pandas-dev__pandas-27322\n",
      "Token count is too large: pandas-dev__pandas-30636\n",
      "Token count is too large: pandas-dev__pandas-37014\n",
      "Token count is too large: pandas-dev__pandas-38029\n",
      "Token count is too large: google__jax-1512\n",
      "Token count is too large: google__jax-3318\n",
      "Token count is too large: docker__compose-2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2610 examples [03:16, 12.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25868\n",
      "Token count is too large: Qiskit__qiskit-7007\n",
      "Token count is too large: pandas-dev__pandas-8030\n",
      "Token count is too large: celery__celery-5931\n",
      "Token count is too large: huggingface__transformers-5184\n",
      "Token count is too large: pandas-dev__pandas-34053\n",
      "Token count is too large: conan-io__conan-2784\n",
      "Token count is too large: conan-io__conan-5224\n",
      "Token count is too large: pandas-dev__pandas-27878\n",
      "Token count is too large: pandas-dev__pandas-8840\n",
      "Token count is too large: pandas-dev__pandas-16095\n",
      "Token count is too large: pandas-dev__pandas-20049\n",
      "Token count is too large: pandas-dev__pandas-24748\n",
      "Token count is too large: huggingface__transformers-13888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2616 examples [03:16, 15.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19321\n",
      "Token count is too large: numpy__numpy-258\n",
      "Token count is too large: PrefectHQ__prefect-2558\n",
      "Token count is too large: pandas-dev__pandas-18844\n",
      "Token count is too large: pandas-dev__pandas-21323\n",
      "Token count is too large: pandas-dev__pandas-9612\n",
      "Token count is too large: pantsbuild__pants-5910\n",
      "Token count is too large: ipython__ipython-8428\n",
      "Token count is too large: pandas-dev__pandas-27095\n",
      "Token count is too large: pandas-dev__pandas-16420\n",
      "Token count is too large: gitpython-developers__GitPython-1391\n",
      "Token count is too large: googleapis__google-cloud-python-2773\n",
      "Token count is too large: huggingface__transformers-17206\n",
      "Token count is too large: huggingface__transformers-17293\n",
      "Token count is too large: pandas-dev__pandas-8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2620 examples [03:17, 13.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-18997\n",
      "Token count is too large: pandas-dev__pandas-33289\n",
      "Token count is too large: pandas-dev__pandas-38796\n",
      "Token count is too large: numpy__numpy-19766\n",
      "Token count is too large: mesonbuild__meson-8888\n",
      "Token count is too large: wagtail__wagtail-9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2622 examples [03:17, 10.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23886\n",
      "Token count is too large: conda__conda-12453\n",
      "Token count is too large: Qiskit__qiskit-8925\n",
      "Token count is too large: conda__conda-2534\n",
      "Token count is too large: docker__compose-2032\n",
      "Token count is too large: conda__conda-8531\n",
      "Token count is too large: numpy__numpy-24134\n",
      "Token count is too large: conan-io__conan-12967\n",
      "Token count is too large: conda__conda-7675\n",
      "Token count is too large: ytdl-org__youtube-dl-21003\n",
      "Token count is too large: numpy__numpy-12813\n",
      "Token count is too large: ytdl-org__youtube-dl-14281\n",
      "Token count is too large: ray-project__ray-7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2631 examples [03:17, 18.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-9096\n",
      "Token count is too large: pandas-dev__pandas-37032\n",
      "Token count is too large: pandas-dev__pandas-18810\n",
      "Token count is too large: Lightning-AI__lightning-3067\n",
      "Token count is too large: huggingface__transformers-24324\n",
      "Token count is too large: pypa__pip-4579\n",
      "Token count is too large: Qiskit__qiskit-1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2636 examples [03:17, 18.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-414\n",
      "Token count is too large: googleapis__google-cloud-python-9915\n",
      "Token count is too large: gitpython-developers__GitPython-1547\n",
      "Token count is too large: pandas-dev__pandas-17885\n",
      "Token count is too large: mesonbuild__meson-2684\n",
      "Token count is too large: celery__celery-6000\n",
      "Token count is too large: huggingface__transformers-14994\n",
      "Token count is too large: huggingface__transformers-15558\n",
      "Token count is too large: jupyterlab__jupyterlab-3555\n",
      "Token count is too large: googleapis__google-cloud-python-2496\n",
      "Token count is too large: huggingface__transformers-19316\n",
      "Token count is too large: huggingface__transformers-7732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2641 examples [03:18, 21.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20797\n",
      "Token count is too large: pandas-dev__pandas-6576\n",
      "Token count is too large: pandas-dev__pandas-6737\n",
      "Token count is too large: pandas-dev__pandas-39458\n",
      "Token count is too large: jupyterlab__jupyterlab-5174\n",
      "Token count is too large: conda__conda-4786\n",
      "Token count is too large: conan-io__conan-3868\n",
      "Token count is too large: Qiskit__qiskit-5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2644 examples [03:18, 15.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19770\n",
      "Token count is too large: pyca__cryptography-4944\n",
      "Token count is too large: pandas-dev__pandas-21251\n",
      "Token count is too large: pantsbuild__pants-12256\n",
      "Token count is too large: apache__airflow-28771\n",
      "Token count is too large: pypa__pip-2284\n",
      "Token count is too large: google__jax-1069\n",
      "Token count is too large: pandas-dev__pandas-3909\n",
      "Token count is too large: pantsbuild__pants-12198\n",
      "Token count is too large: PrefectHQ__prefect-2472\n",
      "Token count is too large: pandas-dev__pandas-20091\n",
      "Token count is too large: ipython__ipython-1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2650 examples [03:18, 18.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-13698\n",
      "Token count is too large: jupyterlab__jupyterlab-9286\n",
      "Token count is too large: docker__compose-7564\n",
      "Token count is too large: kubeflow__pipelines-522\n",
      "Token count is too large: pypa__pip-10503\n",
      "Token count is too large: pandas-dev__pandas-11182\n",
      "Token count is too large: pandas-dev__pandas-22947\n",
      "Token count is too large: pyca__cryptography-5056\n",
      "Token count is too large: Lightning-AI__lightning-926\n",
      "Token count is too large: mesonbuild__meson-9557\n",
      "Token count is too large: pantsbuild__pants-19100\n",
      "Token count is too large: huggingface__transformers-6719\n",
      "Token count is too large: pypa__pip-1432\n",
      "Token count is too large: huggingface__transformers-12147\n",
      "Token count is too large: celery__celery-6298\n",
      "Token count is too large: huggingface__transformers-8528\n",
      "Token count is too large: pandas-dev__pandas-8959\n",
      "Token count is too large: huggingface__transformers-17469\n",
      "Token count is too large: mesonbuild__meson-7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2656 examples [03:19, 16.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-2857\n",
      "Token count is too large: numpy__numpy-12009\n",
      "Token count is too large: numpy__numpy-10629\n",
      "Token count is too large: pandas-dev__pandas-36962\n",
      "Token count is too large: PrefectHQ__prefect-2191\n",
      "Token count is too large: pandas-dev__pandas-26872\n",
      "Token count is too large: googleapis__google-cloud-python-4921\n",
      "Token count is too large: googleapis__google-cloud-python-3735\n",
      "Token count is too large: mesonbuild__meson-1814\n",
      "Token count is too large: conda__conda-8644\n",
      "Token count is too large: Qiskit__qiskit-3245\n",
      "Token count is too large: ipython__ipython-9785\n",
      "Token count is too large: pandas-dev__pandas-9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2658 examples [03:19, 16.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18940\n",
      "Token count is too large: huggingface__transformers-24241\n",
      "Token count is too large: pantsbuild__pants-10879\n",
      "Token count is too large: googleapis__google-cloud-python-1279\n",
      "Token count is too large: pypa__pip-2386\n",
      "Token count is too large: Lightning-AI__lightning-2164\n",
      "Token count is too large: huggingface__transformers-18522\n",
      "Token count is too large: apache__airflow-27190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2665 examples [03:19, 19.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33107\n",
      "Token count is too large: googleapis__google-cloud-python-11338\n",
      "Token count is too large: conan-io__conan-8016\n",
      "Token count is too large: ray-project__ray-10750\n",
      "Token count is too large: numpy__numpy-20810\n",
      "Token count is too large: apache__airflow-25412\n",
      "Token count is too large: pypa__pip-7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2667 examples [03:19, 18.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24157\n",
      "Token count is too large: pandas-dev__pandas-38532\n",
      "Token count is too large: apache__airflow-25553\n",
      "Token count is too large: pandas-dev__pandas-7786\n",
      "Token count is too large: pandas-dev__pandas-24924\n",
      "Token count is too large: pantsbuild__pants-18051\n",
      "Token count is too large: docker__compose-4954\n",
      "Token count is too large: pandas-dev__pandas-10926\n",
      "Token count is too large: numpy__numpy-10542\n",
      "Token count is too large: pantsbuild__pants-15598\n",
      "Token count is too large: pandas-dev__pandas-34128\n",
      "Token count is too large: Qiskit__qiskit-6866\n",
      "Token count is too large: huggingface__transformers-9183\n",
      "Token count is too large: pandas-dev__pandas-10939\n",
      "Token count is too large: google__jax-2060\n",
      "Token count is too large: Qiskit__qiskit-1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2669 examples [03:20, 10.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16852\n",
      "Token count is too large: pandas-dev__pandas-8476\n",
      "Token count is too large: pypa__pip-1284\n",
      "Token count is too large: huggingface__transformers-21772\n",
      "Token count is too large: Qiskit__qiskit-8762\n",
      "Token count is too large: numpy__numpy-23955\n",
      "Token count is too large: ipython__ipython-3075\n",
      "Token count is too large: apache__airflow-20919\n",
      "Token count is too large: mesonbuild__meson-1068\n",
      "Token count is too large: google__jax-920\n",
      "Token count is too large: google__jax-3166\n",
      "Token count is too large: Qiskit__qiskit-2692\n",
      "Token count is too large: mesonbuild__meson-206\n",
      "Token count is too large: pantsbuild__pants-5368\n",
      "Token count is too large: pandas-dev__pandas-22201\n",
      "Token count is too large: ytdl-org__youtube-dl-15188\n",
      "Token count is too large: pandas-dev__pandas-30395\n",
      "Token count is too large: pypa__pip-4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2671 examples [03:20, 10.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8606\n",
      "Token count is too large: apache__airflow-25296\n",
      "Token count is too large: pantsbuild__pants-11203\n",
      "Token count is too large: huggingface__transformers-7756\n",
      "Token count is too large: celery__celery-3790\n",
      "Token count is too large: wagtail__wagtail-7937\n",
      "Token count is too large: Qiskit__qiskit-4546\n",
      "Token count is too large: googleapis__google-cloud-python-8102\n",
      "Token count is too large: huggingface__transformers-16357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2675 examples [03:20, 12.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-7973\n",
      "Token count is too large: mesonbuild__meson-7193\n",
      "Token count is too large: pantsbuild__pants-10805\n",
      "Token count is too large: huggingface__transformers-11538\n",
      "Token count is too large: pandas-dev__pandas-39766\n",
      "Token count is too large: pandas-dev__pandas-26862\n",
      "Token count is too large: pandas-dev__pandas-21210\n",
      "Token count is too large: pandas-dev__pandas-6053\n",
      "Token count is too large: pantsbuild__pants-6177\n",
      "Token count is too large: apache__airflow-8849\n",
      "Token count is too large: Qiskit__qiskit-9538\n",
      "Token count is too large: gitpython-developers__GitPython-1437\n",
      "Token count is too large: conan-io__conan-10874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2677 examples [03:20, 11.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4238\n",
      "Token count is too large: pandas-dev__pandas-29390\n",
      "Token count is too large: Lightning-AI__lightning-1177\n",
      "Token count is too large: conan-io__conan-6134\n",
      "Token count is too large: pandas-dev__pandas-7515\n",
      "Token count is too large: Qiskit__qiskit-5554\n",
      "Token count is too large: docker__compose-4955\n",
      "Token count is too large: pandas-dev__pandas-24495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2679 examples [03:21, 10.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15005\n",
      "Token count is too large: pypa__pip-5883\n",
      "Token count is too large: Lightning-AI__lightning-1630\n",
      "Token count is too large: mesonbuild__meson-6125\n",
      "Token count is too large: huggingface__transformers-12070\n",
      "Token count is too large: pandas-dev__pandas-5238\n",
      "Token count is too large: conda__conda-12496\n",
      "Token count is too large: googleapis__google-cloud-python-7674\n",
      "Token count is too large: celery__celery-6711\n",
      "There was an error processing\n",
      "Token count is too large: mesonbuild__meson-4887\n",
      "Token count is too large: docker__compose-2230\n",
      "Token count is too large: pandas-dev__pandas-6803\n",
      "Token count is too large: pandas-dev__pandas-16292\n",
      "Token count is too large: pandas-dev__pandas-28097\n",
      "Token count is too large: pandas-dev__pandas-39765\n",
      "Token count is too large: jupyterlab__jupyterlab-6340\n",
      "Token count is too large: pandas-dev__pandas-5231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2683 examples [03:21,  8.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39029\n",
      "Token count is too large: pandas-dev__pandas-38192\n",
      "Token count is too large: numpy__numpy-9817\n",
      "Token count is too large: pandas-dev__pandas-22517\n",
      "Token count is too large: pandas-dev__pandas-37945\n",
      "Token count is too large: googleapis__google-cloud-python-5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2684 examples [03:21,  8.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4494\n",
      "Token count is too large: apache__airflow-18602\n",
      "Token count is too large: pandas-dev__pandas-4108\n",
      "Token count is too large: googleapis__google-cloud-python-7954\n",
      "Token count is too large: Lightning-AI__lightning-2513\n",
      "Token count is too large: google__jax-2786\n",
      "Token count is too large: pantsbuild__pants-18157\n",
      "Token count is too large: pandas-dev__pandas-29657\n",
      "Token count is too large: wagtail__wagtail-10242\n",
      "Token count is too large: PrefectHQ__prefect-657\n",
      "Token count is too large: pandas-dev__pandas-6725\n",
      "Token count is too large: google__jax-599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2687 examples [03:21, 11.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-5189\n",
      "Token count is too large: googleapis__google-cloud-python-5503\n",
      "Token count is too large: conda__conda-2365\n",
      "Token count is too large: pandas-dev__pandas-18558\n",
      "Token count is too large: pandas-dev__pandas-13909\n",
      "Token count is too large: pandas-dev__pandas-22725\n",
      "Token count is too large: pandas-dev__pandas-23265\n",
      "Token count is too large: PrefectHQ__prefect-2617\n",
      "Token count is too large: huggingface__transformers-9713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2692 examples [03:22, 13.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11215\n",
      "Token count is too large: pandas-dev__pandas-32115\n",
      "Token count is too large: ytdl-org__youtube-dl-16100\n",
      "Token count is too large: jupyterlab__jupyterlab-2410\n",
      "Token count is too large: pandas-dev__pandas-27556\n",
      "Token count is too large: Lightning-AI__lightning-1477\n",
      "Token count is too large: apache__airflow-19700\n",
      "Token count is too large: pandas-dev__pandas-38709\n",
      "Token count is too large: pandas-dev__pandas-7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2694 examples [03:22, 12.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22486\n",
      "Token count is too large: conda__conda-7998\n",
      "Token count is too large: pandas-dev__pandas-6024\n",
      "Token count is too large: conan-io__conan-2424\n",
      "Token count is too large: pandas-dev__pandas-21896\n",
      "Token count is too large: pandas-dev__pandas-25046\n",
      "Token count is too large: pandas-dev__pandas-36535\n",
      "Token count is too large: pandas-dev__pandas-5544\n",
      "Token count is too large: Qiskit__qiskit-3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2696 examples [03:22,  7.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20613\n",
      "Token count is too large: huggingface__transformers-14316\n",
      "Token count is too large: pandas-dev__pandas-15052\n",
      "Token count is too large: Qiskit__qiskit-6102\n",
      "Token count is too large: celery__celery-8152\n",
      "Token count is too large: pandas-dev__pandas-30977\n",
      "Token count is too large: pandas-dev__pandas-23600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2698 examples [03:23,  8.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-6634\n",
      "Token count is too large: mesonbuild__meson-3898\n",
      "Token count is too large: pandas-dev__pandas-18330\n",
      "Token count is too large: numpy__numpy-16080\n",
      "Token count is too large: huggingface__transformers-13687\n",
      "Token count is too large: huggingface__transformers-9875\n",
      "Token count is too large: pandas-dev__pandas-7638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2702 examples [03:23, 11.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33091\n",
      "Token count is too large: pandas-dev__pandas-17801\n",
      "Token count is too large: numpy__numpy-15685\n",
      "Token count is too large: pypa__pip-5286\n",
      "Token count is too large: pandas-dev__pandas-27127\n",
      "Token count is too large: mesonbuild__meson-1763\n",
      "Token count is too large: wagtail__wagtail-9974\n",
      "Token count is too large: pandas-dev__pandas-30257\n",
      "Token count is too large: docker__compose-4561\n",
      "Token count is too large: pantsbuild__pants-6439\n",
      "Token count is too large: pandas-dev__pandas-28183\n",
      "Token count is too large: google__jax-1931\n",
      "Token count is too large: pantsbuild__pants-8093\n",
      "Token count is too large: numpy__numpy-10396\n",
      "Token count is too large: numpy__numpy-6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2706 examples [03:23, 13.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4985\n",
      "There was an error processing\n",
      "Token count is too large: conda__conda-5405\n",
      "Token count is too large: numpy__numpy-9302\n",
      "Token count is too large: pandas-dev__pandas-16701\n",
      "Token count is too large: docker__compose-2407\n",
      "Token count is too large: googleapis__google-cloud-python-9225\n",
      "Token count is too large: conda__conda-3686\n",
      "Token count is too large: huggingface__transformers-17637\n",
      "Token count is too large: mesonbuild__meson-691\n",
      "Token count is too large: huggingface__transformers-24942\n",
      "Token count is too large: dagster-io__dagster-2468\n",
      "Token count is too large: huggingface__transformers-9514\n",
      "Token count is too large: pandas-dev__pandas-29142\n",
      "Token count is too large: pandas-dev__pandas-4195\n",
      "Token count is too large: ray-project__ray-10703\n",
      "Token count is too large: numpy__numpy-8368\n",
      "Token count is too large: conan-io__conan-4783\n",
      "Token count is too large: pantsbuild__pants-14850\n",
      "Token count is too large: pandas-dev__pandas-20960\n",
      "Token count is too large: Qiskit__qiskit-8647\n",
      "Token count is too large: Qiskit__qiskit-8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2709 examples [03:24,  9.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33693\n",
      "Token count is too large: google__jax-1473\n",
      "Token count is too large: numpy__numpy-7347\n",
      "Token count is too large: pandas-dev__pandas-4091\n",
      "Token count is too large: pandas-dev__pandas-27988\n",
      "Token count is too large: apache__airflow-17626\n",
      "Token count is too large: google__jax-102\n",
      "Token count is too large: pantsbuild__pants-18850\n",
      "Token count is too large: pandas-dev__pandas-27366\n",
      "Token count is too large: googleapis__google-cloud-python-8808\n",
      "Token count is too large: conda__conda-8911\n",
      "Token count is too large: docker__compose-1642\n",
      "Token count is too large: googleapis__google-cloud-python-6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2715 examples [03:24, 15.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18042\n",
      "Token count is too large: Qiskit__qiskit-1702\n",
      "Token count is too large: pypa__pip-8223\n",
      "Token count is too large: pandas-dev__pandas-5730\n",
      "Token count is too large: mesonbuild__meson-557\n",
      "Token count is too large: mesonbuild__meson-11802\n",
      "Token count is too large: conan-io__conan-4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2721 examples [03:24, 18.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6398\n",
      "Token count is too large: pandas-dev__pandas-30656\n",
      "Token count is too large: numpy__numpy-5805\n",
      "Token count is too large: huggingface__transformers-12397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2730 examples [03:24, 21.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25392\n",
      "Token count is too large: Qiskit__qiskit-7085\n",
      "Token count is too large: mesonbuild__meson-2221\n",
      "Token count is too large: Qiskit__qiskit-7793\n",
      "Token count is too large: conan-io__conan-5810\n",
      "Token count is too large: huggingface__transformers-9789\n",
      "Token count is too large: pantsbuild__pants-13834\n",
      "Token count is too large: googleapis__google-cloud-python-2998\n",
      "Token count is too large: Qiskit__qiskit-5206\n",
      "Token count is too large: pantsbuild__pants-6894\n",
      "Token count is too large: pandas-dev__pandas-33709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2734 examples [03:24, 22.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34485\n",
      "Token count is too large: mesonbuild__meson-3131\n",
      "Token count is too large: apache__airflow-1196\n",
      "Token count is too large: google__jax-1515\n",
      "Token count is too large: pypa__pip-8702\n",
      "Token count is too large: mesonbuild__meson-5564\n",
      "Token count is too large: ipython__ipython-5285\n",
      "Token count is too large: googleapis__google-cloud-python-6703\n",
      "Token count is too large: pandas-dev__pandas-23913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2741 examples [03:25, 27.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13205\n",
      "Token count is too large: pypa__pip-6827\n",
      "Token count is too large: Qiskit__qiskit-10381\n",
      "Token count is too large: ytdl-org__youtube-dl-8346\n",
      "Token count is too large: numpy__numpy-19764\n",
      "Token count is too large: pantsbuild__pants-10645\n",
      "Token count is too large: pandas-dev__pandas-3809\n",
      "Token count is too large: ipython__ipython-12171\n",
      "Token count is too large: numpy__numpy-6489\n",
      "Token count is too large: pandas-dev__pandas-22505\n",
      "Token count is too large: apache__airflow-23008\n",
      "Token count is too large: pyca__cryptography-2529\n",
      "Token count is too large: PrefectHQ__prefect-224\n",
      "Token count is too large: googleapis__google-cloud-python-4679\n",
      "Token count is too large: numpy__numpy-13371\n",
      "Token count is too large: Qiskit__qiskit-5495\n",
      "Token count is too large: conan-io__conan-4133\n",
      "Token count is too large: pandas-dev__pandas-31528\n",
      "Token count is too large: conda__conda-11545\n",
      "Token count is too large: mesonbuild__meson-8517\n",
      "Token count is too large: pandas-dev__pandas-34261\n",
      "Token count is too large: huggingface__transformers-25685\n",
      "Token count is too large: pandas-dev__pandas-26514\n",
      "Token count is too large: pandas-dev__pandas-9411\n",
      "Token count is too large: ray-project__ray-10734\n",
      "Token count is too large: huggingface__transformers-24777\n",
      "Token count is too large: pandas-dev__pandas-37700\n",
      "Token count is too large: pypa__pip-7319\n",
      "Token count is too large: jupyterlab__jupyterlab-1449\n",
      "Token count is too large: googleapis__google-cloud-python-9489\n",
      "Token count is too large: huggingface__transformers-17398\n",
      "Token count is too large: pandas-dev__pandas-22805\n",
      "Token count is too large: pandas-dev__pandas-26243\n",
      "Token count is too large: scipy__scipy-3942\n",
      "Token count is too large: Lightning-AI__lightning-2094\n",
      "Token count is too large: conan-io__conan-3491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2748 examples [03:26, 13.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6682\n",
      "Token count is too large: apache__mxnet-627\n",
      "Token count is too large: pantsbuild__pants-17877\n",
      "Token count is too large: pandas-dev__pandas-7915\n",
      "Token count is too large: pypa__pip-2134\n",
      "Token count is too large: huggingface__transformers-7263\n",
      "Token count is too large: pandas-dev__pandas-8280\n",
      "Token count is too large: pandas-dev__pandas-32807\n",
      "Token count is too large: pandas-dev__pandas-31101\n",
      "Token count is too large: PrefectHQ__prefect-2151\n",
      "Token count is too large: numpy__numpy-14433\n",
      "Token count is too large: apache__airflow-9273\n",
      "Token count is too large: Lightning-AI__lightning-397\n",
      "Token count is too large: pandas-dev__pandas-20399\n",
      "Token count is too large: explosion__spaCy-3405\n",
      "Token count is too large: mesonbuild__meson-1431\n",
      "Token count is too large: Lightning-AI__lightning-2876\n",
      "Token count is too large: pantsbuild__pants-7752\n",
      "Token count is too large: Qiskit__qiskit-1255\n",
      "Token count is too large: Qiskit__qiskit-10183\n",
      "Token count is too large: numpy__numpy-8614\n",
      "Token count is too large: pandas-dev__pandas-10383\n",
      "Token count is too large: huggingface__transformers-10792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2752 examples [03:26, 12.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23147\n",
      "Token count is too large: pandas-dev__pandas-25498\n",
      "Token count is too large: pantsbuild__pants-13843\n",
      "Token count is too large: pandas-dev__pandas-24327\n",
      "Token count is too large: mesonbuild__meson-9838\n",
      "Token count is too large: apache__airflow-22834\n",
      "Token count is too large: pandas-dev__pandas-8700\n",
      "Token count is too large: wagtail__wagtail-719\n",
      "Token count is too large: ytdl-org__youtube-dl-14997\n",
      "Token count is too large: docker__compose-5724\n",
      "Token count is too large: huggingface__transformers-22880\n",
      "Token count is too large: pandas-dev__pandas-26684\n",
      "Token count is too large: pandas-dev__pandas-23291\n",
      "Token count is too large: pandas-dev__pandas-39009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2756 examples [03:26, 11.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34414\n",
      "Token count is too large: celery__celery-6294\n",
      "Token count is too large: docker__compose-5095\n",
      "Token count is too large: huggingface__transformers-7381\n",
      "Token count is too large: Lightning-AI__lightning-1100\n",
      "Token count is too large: pandas-dev__pandas-33398\n",
      "Token count is too large: conda__conda-8165\n",
      "Token count is too large: mesonbuild__meson-1326\n",
      "Token count is too large: pandas-dev__pandas-29799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2758 examples [03:27, 10.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21548\n",
      "Token count is too large: apache__airflow-16383\n",
      "Token count is too large: conda__conda-6589\n",
      "Token count is too large: mesonbuild__meson-3243\n",
      "Token count is too large: googleapis__google-cloud-python-6904\n",
      "Token count is too large: pandas-dev__pandas-10464\n",
      "Token count is too large: pandas-dev__pandas-10400\n",
      "Token count is too large: pandas-dev__pandas-33440\n",
      "Token count is too large: mesonbuild__meson-11385\n",
      "Token count is too large: pandas-dev__pandas-16968\n",
      "Token count is too large: pandas-dev__pandas-36876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2763 examples [03:27, 13.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7867\n",
      "Token count is too large: huggingface__transformers-6841\n",
      "Token count is too large: pandas-dev__pandas-32175\n",
      "Token count is too large: PrefectHQ__prefect-3127\n",
      "Token count is too large: pandas-dev__pandas-31939\n",
      "Token count is too large: pypa__pip-8656\n",
      "Token count is too large: pandas-dev__pandas-22745\n",
      "Token count is too large: apache__airflow-16118\n",
      "Token count is too large: pandas-dev__pandas-17943\n",
      "Token count is too large: Lightning-AI__lightning-1589\n",
      "Token count is too large: pandas-dev__pandas-34013\n",
      "Token count is too large: pandas-dev__pandas-38835\n",
      "Token count is too large: Qiskit__qiskit-1024\n",
      "Token count is too large: ray-project__ray-7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2766 examples [03:27, 13.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-30129\n",
      "Token count is too large: huggingface__transformers-19898\n",
      "Token count is too large: pandas-dev__pandas-35974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2773 examples [03:27, 16.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26526\n",
      "Token count is too large: Qiskit__qiskit-3210\n",
      "Token count is too large: googleapis__google-cloud-python-3715\n",
      "Token count is too large: pandas-dev__pandas-39464\n",
      "Token count is too large: conda__conda-6615\n",
      "Token count is too large: pandas-dev__pandas-37432\n",
      "Token count is too large: pypa__pip-12056\n",
      "Token count is too large: pandas-dev__pandas-6872\n",
      "Token count is too large: pandas-dev__pandas-39308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2775 examples [03:28, 15.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-6634\n",
      "Token count is too large: pandas-dev__pandas-15639\n",
      "Token count is too large: huggingface__transformers-10357\n",
      "Token count is too large: pandas-dev__pandas-33959\n",
      "Token count is too large: huggingface__transformers-3266\n",
      "Token count is too large: huggingface__transformers-7678\n",
      "Token count is too large: PrefectHQ__prefect-545\n",
      "Token count is too large: conan-io__conan-8915\n",
      "Token count is too large: conan-io__conan-14168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2780 examples [03:28, 17.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23813\n",
      "Token count is too large: ipython__ipython-2373\n",
      "Token count is too large: pandas-dev__pandas-21442\n",
      "Token count is too large: pandas-dev__pandas-16455\n",
      "Token count is too large: pandas-dev__pandas-22416\n",
      "Token count is too large: pandas-dev__pandas-6731\n",
      "Token count is too large: googleapis__google-cloud-python-6080\n",
      "Token count is too large: jupyterlab__jupyterlab-3294\n",
      "Token count is too large: Qiskit__qiskit-3329\n",
      "Token count is too large: Qiskit__qiskit-10438\n",
      "Token count is too large: pyca__cryptography-3686\n",
      "Token count is too large: numpy__numpy-3257\n",
      "Token count is too large: Qiskit__qiskit-5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2783 examples [03:28, 12.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-5680\n",
      "Token count is too large: pandas-dev__pandas-34796\n",
      "Token count is too large: Lightning-AI__lightning-1272\n",
      "Token count is too large: Lightning-AI__lightning-3048\n",
      "Token count is too large: googleapis__google-cloud-python-3079\n",
      "Token count is too large: apache__airflow-18209\n",
      "Token count is too large: huggingface__transformers-3924\n",
      "Token count is too large: pandas-dev__pandas-21966\n",
      "Token count is too large: mesonbuild__meson-537\n",
      "Token count is too large: pantsbuild__pants-16116\n",
      "Token count is too large: pandas-dev__pandas-23141\n",
      "Token count is too large: gitpython-developers__GitPython-1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2789 examples [03:29, 16.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21313\n",
      "Token count is too large: huggingface__transformers-16828\n",
      "Token count is too large: apache__airflow-21423\n",
      "Token count is too large: pandas-dev__pandas-38204\n",
      "Token count is too large: apache__airflow-8652\n",
      "Token count is too large: apache__airflow-25970\n",
      "Token count is too large: pandas-dev__pandas-39095\n",
      "Token count is too large: conda__conda-6669\n",
      "Token count is too large: conan-io__conan-9437\n",
      "Token count is too large: numpy__numpy-3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2792 examples [03:29, 13.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-7106\n",
      "Token count is too large: ytdl-org__youtube-dl-27143\n",
      "Token count is too large: google__jax-2627\n",
      "Token count is too large: pandas-dev__pandas-17168\n",
      "Token count is too large: pandas-dev__pandas-39204\n",
      "Token count is too large: pandas-dev__pandas-35328\n",
      "Token count is too large: mesonbuild__meson-7196\n",
      "Token count is too large: Qiskit__qiskit-6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2794 examples [03:29, 12.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-6662\n",
      "Token count is too large: conda__conda-7291\n",
      "Token count is too large: pandas-dev__pandas-4624\n",
      "Token count is too large: PrefectHQ__prefect-2602\n",
      "Token count is too large: docker__compose-5341\n",
      "Token count is too large: Qiskit__qiskit-2149\n",
      "Token count is too large: pandas-dev__pandas-39132\n",
      "Token count is too large: ipython__ipython-2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2798 examples [03:29, 14.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37997\n",
      "Token count is too large: open-mmlab__mmdetection-6317\n",
      "Token count is too large: jupyterlab__jupyterlab-7109\n",
      "Token count is too large: numpy__numpy-8674\n",
      "Token count is too large: JohnSnowLabs__spark-nlp-13912\n",
      "Token count is too large: Lightning-AI__lightning-3347\n",
      "Token count is too large: wagtail__wagtail-3919\n",
      "Token count is too large: pantsbuild__pants-16134\n",
      "Token count is too large: PrefectHQ__prefect-1612\n",
      "Token count is too large: docker__compose-5565\n",
      "Token count is too large: pantsbuild__pants-16107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2803 examples [03:29, 17.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35353\n",
      "Token count is too large: pandas-dev__pandas-26911\n",
      "Token count is too large: Qiskit__qiskit-9162\n",
      "Token count is too large: PrefectHQ__prefect-1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2807 examples [03:30, 16.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25164\n",
      "Token count is too large: conda__conda-1562\n",
      "Token count is too large: numpy__numpy-7298\n",
      "Token count is too large: pandas-dev__pandas-5979\n",
      "Token count is too large: pandas-dev__pandas-22200\n",
      "Token count is too large: conan-io__conan-508\n",
      "Token count is too large: pandas-dev__pandas-34599\n",
      "Token count is too large: pandas-dev__pandas-35379\n",
      "Token count is too large: pypa__pip-4982\n",
      "Token count is too large: ytdl-org__youtube-dl-2289\n",
      "Token count is too large: google__jax-786\n",
      "Token count is too large: pandas-dev__pandas-38103\n",
      "Token count is too large: pandas-dev__pandas-16738\n",
      "Token count is too large: pantsbuild__pants-11314\n",
      "Token count is too large: huggingface__transformers-23014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2811 examples [03:30, 12.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7954\n",
      "Token count is too large: google__jax-178\n",
      "Token count is too large: numpy__numpy-19627\n",
      "Token count is too large: numpy__numpy-15406\n",
      "Token count is too large: pantsbuild__pants-5526\n",
      "Token count is too large: celery__celery-6524\n",
      "Token count is too large: pandas-dev__pandas-21043\n",
      "Token count is too large: ipython__ipython-3575\n",
      "Token count is too large: pandas-dev__pandas-10157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2813 examples [03:31, 11.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-10530\n",
      "Token count is too large: google__jax-2364\n",
      "Token count is too large: numpy__numpy-4400\n",
      "Token count is too large: pandas-dev__pandas-8062\n",
      "Token count is too large: ytdl-org__youtube-dl-3958\n",
      "Token count is too large: google__jax-422\n",
      "Token count is too large: pandas-dev__pandas-34579\n",
      "Token count is too large: Qiskit__qiskit-7941\n",
      "Token count is too large: pypa__pip-4495\n",
      "Token count is too large: pypa__pip-1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2815 examples [03:31, 11.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3452\n",
      "Token count is too large: pandas-dev__pandas-24916\n",
      "Token count is too large: Lightning-AI__lightning-1269\n",
      "Token count is too large: mesonbuild__meson-1514\n",
      "Token count is too large: pandas-dev__pandas-27926\n",
      "Token count is too large: Qiskit__qiskit-4966\n",
      "Token count is too large: pandas-dev__pandas-30181\n",
      "Token count is too large: pypa__pip-968\n",
      "Token count is too large: pantsbuild__pants-17124\n",
      "Token count is too large: pandas-dev__pandas-30928\n",
      "Token count is too large: pandas-dev__pandas-15883\n",
      "Token count is too large: apache__airflow-17544\n",
      "Token count is too large: apache__airflow-25599\n",
      "Token count is too large: docker__compose-1544\n",
      "Token count is too large: pypa__pip-3695\n",
      "Token count is too large: conan-io__conan-6033\n",
      "Token count is too large: pandas-dev__pandas-9308\n",
      "Token count is too large: conda__conda-6798\n",
      "Token count is too large: scipy__scipy-3707\n",
      "Token count is too large: scipy__scipy-3920\n",
      "Token count is too large: pandas-dev__pandas-31155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2819 examples [03:31,  9.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23647\n",
      "Token count is too large: numpy__numpy-3099\n",
      "Token count is too large: ipython__ipython-7726\n",
      "Token count is too large: conan-io__conan-4195\n",
      "Token count is too large: pandas-dev__pandas-8454\n",
      "Token count is too large: ipython__ipython-8480\n",
      "Token count is too large: pandas-dev__pandas-34075\n",
      "Token count is too large: pandas-dev__pandas-20424\n",
      "Token count is too large: pandas-dev__pandas-27844\n",
      "Token count is too large: conan-io__conan-5174\n",
      "Token count is too large: scipy__scipy-4262\n",
      "Token count is too large: ipython__ipython-11367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2822 examples [03:31, 12.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19448\n",
      "Token count is too large: pandas-dev__pandas-5053\n",
      "Token count is too large: conda__conda-5269\n",
      "Token count is too large: huggingface__transformers-13820\n",
      "Token count is too large: ytdl-org__youtube-dl-3608\n",
      "Token count is too large: ray-project__ray-2036\n",
      "Token count is too large: ipython__ipython-3611\n",
      "Token count is too large: googleapis__google-cloud-python-3845\n",
      "Token count is too large: pandas-dev__pandas-33788\n",
      "Token count is too large: apache__airflow-13933\n",
      "Token count is too large: pandas-dev__pandas-16937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2830 examples [03:31, 22.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8322\n",
      "Token count is too large: pandas-dev__pandas-16364\n",
      "Token count is too large: huggingface__transformers-11663\n",
      "Token count is too large: pandas-dev__pandas-24236\n",
      "Token count is too large: wagtail__wagtail-8371\n",
      "Token count is too large: conda__conda-7710\n",
      "Token count is too large: pandas-dev__pandas-24320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2835 examples [03:32, 18.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8070\n",
      "Token count is too large: pandas-dev__pandas-3558\n",
      "Token count is too large: pandas-dev__pandas-36867\n",
      "Token count is too large: wagtail__wagtail-68\n",
      "Token count is too large: pandas-dev__pandas-32479\n",
      "Token count is too large: pandas-dev__pandas-34484\n",
      "Token count is too large: mesonbuild__meson-912\n",
      "Token count is too large: googleapis__google-cloud-python-1652\n",
      "Token count is too large: pandas-dev__pandas-28373\n",
      "Token count is too large: pantsbuild__pants-6683\n",
      "Token count is too large: ytdl-org__youtube-dl-1256\n",
      "Token count is too large: Lightning-AI__lightning-1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2839 examples [03:32, 19.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5292\n",
      "Token count is too large: Qiskit__qiskit-2427\n",
      "Token count is too large: pandas-dev__pandas-39393\n",
      "Token count is too large: mesonbuild__meson-5633\n",
      "Token count is too large: Qiskit__qiskit-713\n",
      "Token count is too large: docker__compose-2349\n",
      "Token count is too large: google__jax-3018\n",
      "Token count is too large: pandas-dev__pandas-27154\n",
      "Token count is too large: Lightning-AI__lightning-2781\n",
      "Token count is too large: pandas-dev__pandas-28130\n",
      "Token count is too large: google__jax-2183\n",
      "Token count is too large: numpy__numpy-6400\n",
      "Token count is too large: huggingface__transformers-9922\n",
      "Token count is too large: PrefectHQ__prefect-2150\n",
      "Token count is too large: conda__conda-11796\n",
      "Token count is too large: pantsbuild__pants-8430\n",
      "Token count is too large: numpy__numpy-18350\n",
      "Token count is too large: conda__conda-7395\n",
      "Token count is too large: ipython__ipython-2101\n",
      "Token count is too large: mesonbuild__meson-6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2843 examples [03:32, 17.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-2672\n",
      "Token count is too large: open-mmlab__mmdetection-2093\n",
      "Token count is too large: jupyterlab__jupyterlab-8913\n",
      "Token count is too large: pandas-dev__pandas-6366\n",
      "Token count is too large: open-mmlab__mmdetection-2824\n",
      "Token count is too large: pandas-dev__pandas-32598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2846 examples [03:33, 13.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21578\n",
      "Token count is too large: huggingface__transformers-17667\n",
      "Token count is too large: pandas-dev__pandas-36371\n",
      "Token count is too large: conan-io__conan-3014\n",
      "Token count is too large: google__jax-1058\n",
      "Token count is too large: pandas-dev__pandas-15939\n",
      "Token count is too large: docker__compose-5602\n",
      "Token count is too large: conda__conda-1618\n",
      "Token count is too large: pandas-dev__pandas-32591\n",
      "Token count is too large: celery__celery-6898\n",
      "Token count is too large: Qiskit__qiskit-2917\n",
      "Token count is too large: pandas-dev__pandas-22377\n",
      "Token count is too large: huggingface__transformers-23194\n",
      "Token count is too large: pyca__cryptography-1348\n",
      "Token count is too large: pypa__pip-3312\n",
      "Token count is too large: apache__airflow-22678\n",
      "Token count is too large: pandas-dev__pandas-20047\n",
      "Token count is too large: pandas-dev__pandas-10988\n",
      "Token count is too large: pypa__pip-8684\n",
      "Token count is too large: huggingface__transformers-7344\n",
      "Token count is too large: Lightning-AI__lightning-3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2850 examples [03:33, 13.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25961\n",
      "Token count is too large: pypa__pip-11871\n",
      "Token count is too large: pandas-dev__pandas-18961\n",
      "Token count is too large: ytdl-org__youtube-dl-26507\n",
      "Token count is too large: pantsbuild__pants-17939\n",
      "Token count is too large: mesonbuild__meson-6466\n",
      "Token count is too large: scipy__scipy-344\n",
      "Token count is too large: pandas-dev__pandas-24045\n",
      "Token count is too large: pypa__pip-4395\n",
      "Token count is too large: pandas-dev__pandas-34371\n",
      "Token count is too large: gitpython-developers__GitPython-667\n",
      "Token count is too large: docker__compose-6281\n",
      "Token count is too large: mesonbuild__meson-6561\n",
      "Token count is too large: wagtail__wagtail-9976\n",
      "Token count is too large: Qiskit__qiskit-8278\n",
      "Token count is too large: pandas-dev__pandas-22704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2854 examples [03:33, 15.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10473\n",
      "Token count is too large: pandas-dev__pandas-31734\n",
      "Token count is too large: Qiskit__qiskit-785\n",
      "Token count is too large: pandas-dev__pandas-4247\n",
      "Token count is too large: pantsbuild__pants-16948\n",
      "Token count is too large: apache__airflow-12636\n",
      "Token count is too large: conda__conda-2708\n",
      "Token count is too large: conda__conda-7607\n",
      "Token count is too large: Lightning-AI__lightning-3252\n",
      "Token count is too large: pandas-dev__pandas-20834\n",
      "Token count is too large: pandas-dev__pandas-23499\n",
      "Token count is too large: apache__airflow-1261\n",
      "Token count is too large: numpy__numpy-6538\n",
      "Token count is too large: google__jax-2150\n",
      "Token count is too large: huggingface__transformers-24349\n",
      "Token count is too large: pandas-dev__pandas-3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2856 examples [03:34,  9.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-4922\n",
      "Token count is too large: pandas-dev__pandas-25358\n",
      "Token count is too large: mesonbuild__meson-6890\n",
      "Token count is too large: pandas-dev__pandas-11427\n",
      "Token count is too large: numpy__numpy-10951\n",
      "Token count is too large: conan-io__conan-3684\n",
      "Token count is too large: apache__airflow-11732\n",
      "Token count is too large: pandas-dev__pandas-31905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2860 examples [03:34, 13.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38544\n",
      "Token count is too large: googleapis__google-cloud-python-8213\n",
      "Token count is too large: Qiskit__qiskit-10000\n",
      "Token count is too large: pypa__pip-1352\n",
      "Token count is too large: pandas-dev__pandas-33462\n",
      "Token count is too large: pantsbuild__pants-19022\n",
      "Token count is too large: pandas-dev__pandas-14096\n",
      "Token count is too large: pandas-dev__pandas-27786\n",
      "Token count is too large: Qiskit__qiskit-2325\n",
      "Token count is too large: conda__conda-8015\n",
      "Token count is too large: pandas-dev__pandas-3572\n",
      "Token count is too large: Qiskit__qiskit-4904\n",
      "Token count is too large: explosion__spaCy-3267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2869 examples [03:34, 17.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24633\n",
      "Token count is too large: conan-io__conan-8655\n",
      "Token count is too large: huggingface__transformers-18232\n",
      "Token count is too large: mesonbuild__meson-7667\n",
      "Token count is too large: pantsbuild__pants-18303\n",
      "Token count is too large: google__jax-3096\n",
      "Token count is too large: docker__compose-2938\n",
      "Token count is too large: conan-io__conan-6254\n",
      "Token count is too large: pandas-dev__pandas-6448\n",
      "Token count is too large: google__jax-2558\n",
      "Token count is too large: celery__celery-4278\n",
      "Token count is too large: huggingface__transformers-18451\n",
      "Token count is too large: huggingface__transformers-1120\n",
      "Token count is too large: pandas-dev__pandas-5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2872 examples [03:35, 13.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5263\n",
      "Token count is too large: jupyterlab__jupyterlab-7374\n",
      "Token count is too large: Lightning-AI__lightning-2829\n",
      "Token count is too large: open-mmlab__mmdetection-5930\n",
      "Token count is too large: google__jax-2513\n",
      "Token count is too large: ray-project__ray-8304\n",
      "Token count is too large: pandas-dev__pandas-18757\n",
      "Token count is too large: googleapis__google-cloud-python-5711\n",
      "Token count is too large: pandas-dev__pandas-16958\n",
      "Token count is too large: Qiskit__qiskit-9471\n",
      "Token count is too large: pandas-dev__pandas-830\n",
      "Token count is too large: docker__compose-6320\n",
      "Token count is too large: Qiskit__qiskit-2000\n",
      "Token count is too large: numpy__numpy-8643\n",
      "Token count is too large: ipython__ipython-3978\n",
      "Token count is too large: huggingface__transformers-3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2876 examples [03:35, 13.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34927\n",
      "Token count is too large: ipython__ipython-8882\n",
      "Token count is too large: ray-project__ray-7444\n",
      "Token count is too large: mesonbuild__meson-10331\n",
      "Token count is too large: pandas-dev__pandas-22825\n",
      "Token count is too large: wagtail__wagtail-10192\n",
      "Token count is too large: apache__airflow-13932\n",
      "Token count is too large: mesonbuild__meson-1136\n",
      "Token count is too large: pandas-dev__pandas-26239\n",
      "Token count is too large: Qiskit__qiskit-4097\n",
      "Token count is too large: mesonbuild__meson-6321\n",
      "Token count is too large: mesonbuild__meson-1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2881 examples [03:35, 13.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-6749\n",
      "Token count is too large: pandas-dev__pandas-31484\n",
      "Token count is too large: pandas-dev__pandas-10142\n",
      "Token count is too large: pandas-dev__pandas-6109\n",
      "Token count is too large: ray-project__ray-7262\n",
      "Token count is too large: apache__airflow-22355\n",
      "Token count is too large: Qiskit__qiskit-6299\n",
      "Token count is too large: open-mmlab__mmdetection-6918\n",
      "Token count is too large: jupyterlab__jupyterlab-13126\n",
      "Token count is too large: conan-io__conan-5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2886 examples [03:35, 18.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10397\n",
      "Token count is too large: huggingface__transformers-13873\n",
      "Token count is too large: apache__airflow-24488\n",
      "Token count is too large: PrefectHQ__prefect-2666\n",
      "Token count is too large: pypa__pip-10588\n",
      "Token count is too large: conda__conda-6957\n",
      "Token count is too large: pandas-dev__pandas-30710\n",
      "Token count is too large: Lightning-AI__lightning-457\n",
      "Token count is too large: celery__celery-3952\n",
      "Token count is too large: huggingface__transformers-9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2889 examples [03:36, 16.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24197\n",
      "Token count is too large: jupyterlab__jupyterlab-5723\n",
      "Token count is too large: pandas-dev__pandas-36292\n",
      "Token count is too large: mesonbuild__meson-10864\n",
      "Token count is too large: pandas-dev__pandas-10516\n",
      "Token count is too large: pypa__pip-8394\n",
      "Token count is too large: dagster-io__dagster-10501\n",
      "Token count is too large: scipy__scipy-5793\n",
      "Token count is too large: pandas-dev__pandas-36998\n",
      "Token count is too large: Lightning-AI__lightning-3213\n",
      "Token count is too large: Qiskit__qiskit-5807\n",
      "Token count is too large: pandas-dev__pandas-23187\n",
      "Token count is too large: ipython__ipython-4514\n",
      "Token count is too large: numpy__numpy-11428\n",
      "Token count is too large: pantsbuild__pants-6284\n",
      "Token count is too large: googleapis__google-cloud-python-480\n",
      "Token count is too large: apache__airflow-28664\n",
      "Token count is too large: apache__airflow-23237\n",
      "Token count is too large: googleapis__google-cloud-python-318\n",
      "Token count is too large: pandas-dev__pandas-22363\n",
      "Token count is too large: Lightning-AI__lightning-2433\n",
      "Token count is too large: huggingface__transformers-24111\n",
      "Token count is too large: pandas-dev__pandas-13815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2894 examples [03:36, 13.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24830\n",
      "Token count is too large: conan-io__conan-10416\n",
      "Token count is too large: conan-io__conan-10797\n",
      "Token count is too large: pandas-dev__pandas-32977\n",
      "Token count is too large: huggingface__transformers-18372\n",
      "Token count is too large: pandas-dev__pandas-37199\n",
      "Token count is too large: pandas-dev__pandas-10098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2897 examples [03:36, 15.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21660\n",
      "Token count is too large: mesonbuild__meson-11441\n",
      "Token count is too large: Lightning-AI__lightning-1666\n",
      "Token count is too large: numpy__numpy-9285\n",
      "Token count is too large: pandas-dev__pandas-8007\n",
      "Token count is too large: pypa__pip-9673\n",
      "Token count is too large: docker__compose-5011\n",
      "Token count is too large: Lightning-AI__lightning-336\n",
      "Token count is too large: ipython__ipython-950\n",
      "Token count is too large: ipython__ipython-11398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2903 examples [03:37, 15.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4856\n",
      "Token count is too large: huggingface__transformers-19347\n",
      "Token count is too large: Qiskit__qiskit-9222\n",
      "Token count is too large: Qiskit__qiskit-9067\n",
      "Token count is too large: Qiskit__qiskit-573\n",
      "Token count is too large: Qiskit__qiskit-8528\n",
      "Token count is too large: mesonbuild__meson-4416\n",
      "Token count is too large: apache__airflow-12466\n",
      "Token count is too large: Qiskit__qiskit-4079\n",
      "Token count is too large: PrefectHQ__prefect-2831\n",
      "Token count is too large: docker__compose-6222\n",
      "Token count is too large: ipython__ipython-10792\n",
      "Token count is too large: pandas-dev__pandas-35302\n",
      "Token count is too large: numpy__numpy-13561\n",
      "Token count is too large: conan-io__conan-9643\n",
      "Token count is too large: Qiskit__qiskit-5020\n",
      "Token count is too large: huggingface__transformers-23869\n",
      "Token count is too large: PrefectHQ__prefect-546\n",
      "Token count is too large: huggingface__transformers-12424\n",
      "Token count is too large: pandas-dev__pandas-28582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2906 examples [03:37, 11.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25146\n",
      "Token count is too large: pandas-dev__pandas-33190\n",
      "Token count is too large: Lightning-AI__lightning-499\n",
      "Token count is too large: conan-io__conan-4615\n",
      "Token count is too large: docker__compose-7684\n",
      "Token count is too large: Qiskit__qiskit-4631\n",
      "Token count is too large: pandas-dev__pandas-17364\n",
      "Token count is too large: pandas-dev__pandas-19610\n",
      "Token count is too large: huggingface__transformers-9018\n",
      "Token count is too large: numpy__numpy-16815\n",
      "Token count is too large: ipython__ipython-9225\n",
      "Token count is too large: pandas-dev__pandas-18555\n",
      "Token count is too large: mesonbuild__meson-1010\n",
      "Token count is too large: pandas-dev__pandas-35393\n",
      "Token count is too large: Qiskit__qiskit-4038\n",
      "Token count is too large: pandas-dev__pandas-32424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2909 examples [03:37, 12.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-237\n",
      "Token count is too large: pandas-dev__pandas-6622\n",
      "Token count is too large: pandas-dev__pandas-36683\n",
      "Token count is too large: numpy__numpy-9916\n",
      "Token count is too large: pandas-dev__pandas-18371\n",
      "Token count is too large: conda__conda-6491\n",
      "Token count is too large: mesonbuild__meson-1216\n",
      "Token count is too large: apache__airflow-18883\n",
      "Token count is too large: ray-project__ray-10705\n",
      "Token count is too large: open-mmlab__mmdetection-3011\n",
      "Token count is too large: pandas-dev__pandas-21650\n",
      "Token count is too large: pandas-dev__pandas-39316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2915 examples [03:37, 16.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-13447\n",
      "Token count is too large: pandas-dev__pandas-9127\n",
      "Token count is too large: pantsbuild__pants-17594\n",
      "Token count is too large: huggingface__transformers-15318\n",
      "Token count is too large: mesonbuild__meson-7736\n",
      "Token count is too large: pandas-dev__pandas-26055\n",
      "Token count is too large: pandas-dev__pandas-17950\n",
      "Token count is too large: explosion__spaCy-3273\n",
      "Token count is too large: celery__celery-3218\n",
      "Token count is too large: pandas-dev__pandas-35253\n",
      "Token count is too large: pandas-dev__pandas-26732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2917 examples [03:38, 14.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-11298\n",
      "Token count is too large: pandas-dev__pandas-24733\n",
      "Token count is too large: pandas-dev__pandas-3473\n",
      "Token count is too large: scipy__scipy-387\n",
      "Token count is too large: numpy__numpy-5490\n",
      "Token count is too large: huggingface__transformers-1723\n",
      "Token count is too large: Qiskit__qiskit-4328\n",
      "Token count is too large: huggingface__transformers-11318\n",
      "Token count is too large: pandas-dev__pandas-29493\n",
      "Token count is too large: Lightning-AI__lightning-1196\n",
      "Token count is too large: pantsbuild__pants-7430\n",
      "Token count is too large: ipython__ipython-13588\n",
      "Token count is too large: huggingface__transformers-3909\n",
      "Token count is too large: numpy__numpy-18961\n",
      "Token count is too large: pandas-dev__pandas-18380\n",
      "Token count is too large: googleapis__google-cloud-python-3426\n",
      "Token count is too large: pandas-dev__pandas-17930\n",
      "Token count is too large: Qiskit__qiskit-10164\n",
      "Token count is too large: pypa__pip-3117\n",
      "Token count is too large: pandas-dev__pandas-38106\n",
      "Token count is too large: pantsbuild__pants-9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2919 examples [03:38,  9.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21896\n",
      "Token count is too large: pandas-dev__pandas-37992\n",
      "Token count is too large: numpy__numpy-23045\n",
      "Token count is too large: ytdl-org__youtube-dl-20646\n",
      "Token count is too large: pandas-dev__pandas-21813\n",
      "Token count is too large: conan-io__conan-2280\n",
      "Token count is too large: conan-io__conan-8927\n",
      "Token count is too large: pandas-dev__pandas-24632\n",
      "Token count is too large: pandas-dev__pandas-33418\n",
      "Token count is too large: Qiskit__qiskit-762\n",
      "Token count is too large: pandas-dev__pandas-25759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2932 examples [03:38, 19.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22710\n",
      "Token count is too large: mesonbuild__meson-2457\n",
      "Token count is too large: pandas-dev__pandas-10401\n",
      "Token count is too large: pandas-dev__pandas-38939\n",
      "Token count is too large: Lightning-AI__lightning-1434\n",
      "Token count is too large: huggingface__transformers-12853\n",
      "Token count is too large: google__jax-580\n",
      "Token count is too large: PrefectHQ__prefect-246\n",
      "Token count is too large: huggingface__transformers-21489\n",
      "Token count is too large: googleapis__google-cloud-python-11339\n",
      "Token count is too large: pandas-dev__pandas-30340\n",
      "Token count is too large: mesonbuild__meson-6909\n",
      "Token count is too large: numpy__numpy-22561\n",
      "Token count is too large: conan-io__conan-3843\n",
      "Token count is too large: googleapis__google-cloud-python-9334\n",
      "Token count is too large: pandas-dev__pandas-4366\n",
      "Token count is too large: conan-io__conan-3545\n",
      "Token count is too large: pandas-dev__pandas-21594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2935 examples [03:39, 11.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24288\n",
      "Token count is too large: scipy__scipy-3922\n",
      "Token count is too large: pantsbuild__pants-15457\n",
      "Token count is too large: ray-project__ray-7366\n",
      "Token count is too large: conan-io__conan-5856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2941 examples [03:39, 13.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21785\n",
      "Token count is too large: mesonbuild__meson-7561\n",
      "Token count is too large: pandas-dev__pandas-37108\n",
      "Token count is too large: pandas-dev__pandas-16887\n",
      "Token count is too large: pandas-dev__pandas-38030\n",
      "Token count is too large: google__jax-1143\n",
      "Token count is too large: pandas-dev__pandas-3842\n",
      "Token count is too large: huggingface__transformers-21738\n",
      "Token count is too large: pandas-dev__pandas-16600\n",
      "Token count is too large: Qiskit__qiskit-667\n",
      "Token count is too large: numpy__numpy-15920\n",
      "Token count is too large: huggingface__transformers-13432\n",
      "Token count is too large: Qiskit__qiskit-3003\n",
      "Token count is too large: pandas-dev__pandas-15742\n",
      "Token count is too large: mesonbuild__meson-1210\n",
      "Token count is too large: pandas-dev__pandas-6908\n",
      "Token count is too large: pandas-dev__pandas-3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2944 examples [03:40, 12.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-13827\n",
      "Token count is too large: mesonbuild__meson-6891\n",
      "Token count is too large: numpy__numpy-4463\n",
      "Token count is too large: Qiskit__qiskit-6225\n",
      "Token count is too large: pandas-dev__pandas-39720\n",
      "Token count is too large: ytdl-org__youtube-dl-3786\n",
      "Token count is too large: huggingface__transformers-24529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2949 examples [03:40, 14.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5780\n",
      "Token count is too large: ray-project__ray-8840\n",
      "Token count is too large: pandas-dev__pandas-23811\n",
      "Token count is too large: ytdl-org__youtube-dl-3075\n",
      "Token count is too large: apache__airflow-9277\n",
      "Token count is too large: apache__airflow-8165\n",
      "Token count is too large: huggingface__transformers-18851\n",
      "Token count is too large: googleapis__google-cloud-python-2375\n",
      "Token count is too large: pandas-dev__pandas-23981\n",
      "Token count is too large: googleapis__google-cloud-python-6437\n",
      "Token count is too large: Qiskit__qiskit-9287\n",
      "Token count is too large: numpy__numpy-14799\n",
      "Token count is too large: pandas-dev__pandas-23370\n",
      "Token count is too large: numpy__numpy-10786\n",
      "Token count is too large: Lightning-AI__lightning-3287\n",
      "Token count is too large: Lightning-AI__lightning-1561\n",
      "Token count is too large: Qiskit__qiskit-9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2956 examples [03:41, 13.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-8984\n",
      "Token count is too large: huggingface__transformers-16814\n",
      "Token count is too large: pandas-dev__pandas-4283\n",
      "Token count is too large: pandas-dev__pandas-17507\n",
      "Token count is too large: huggingface__transformers-14420\n",
      "Token count is too large: Qiskit__qiskit-6986\n",
      "Token count is too large: googleapis__google-cloud-python-413\n",
      "Token count is too large: Qiskit__qiskit-459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2959 examples [03:41, 15.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30923\n",
      "There was an error processing\n",
      "Token count is too large: ipython__ipython-1707\n",
      "Token count is too large: pandas-dev__pandas-13804\n",
      "Token count is too large: Qiskit__qiskit-9660\n",
      "Token count is too large: googleapis__google-cloud-python-4357\n",
      "Token count is too large: pandas-dev__pandas-25008\n",
      "Token count is too large: pantsbuild__pants-5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2967 examples [03:41, 19.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24955\n",
      "Token count is too large: wagtail__wagtail-1623\n",
      "Token count is too large: pandas-dev__pandas-38548\n",
      "Token count is too large: huggingface__transformers-4759\n",
      "Token count is too large: mesonbuild__meson-5185\n",
      "Token count is too large: googleapis__google-cloud-python-3737\n",
      "Token count is too large: pandas-dev__pandas-26753\n",
      "Token count is too large: scipy__scipy-400\n",
      "Token count is too large: ray-project__ray-3464\n",
      "Token count is too large: docker__compose-3473\n",
      "Token count is too large: Qiskit__qiskit-3838\n",
      "Token count is too large: numpy__numpy-14974\n",
      "Token count is too large: pandas-dev__pandas-16028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2970 examples [03:41, 19.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4117\n",
      "Token count is too large: ray-project__ray-1261\n",
      "Token count is too large: pandas-dev__pandas-32512\n",
      "Token count is too large: pypa__pip-10869\n",
      "Token count is too large: pandas-dev__pandas-19921\n",
      "Token count is too large: pandas-dev__pandas-26854\n",
      "Token count is too large: PrefectHQ__prefect-3000\n",
      "Token count is too large: pandas-dev__pandas-31653\n",
      "Token count is too large: Qiskit__qiskit-6585\n",
      "Token count is too large: mesonbuild__meson-11022\n",
      "Token count is too large: PrefectHQ__prefect-663\n",
      "Token count is too large: docker__compose-2309\n",
      "Token count is too large: Qiskit__qiskit-8669\n",
      "Token count is too large: huggingface__transformers-8435\n",
      "Token count is too large: ipython__ipython-6651\n",
      "Token count is too large: apache__airflow-23160\n",
      "Token count is too large: wagtail__wagtail-9603\n",
      "Token count is too large: Qiskit__qiskit-3180\n",
      "Token count is too large: mesonbuild__meson-3474\n",
      "Token count is too large: pandas-dev__pandas-39486\n",
      "Token count is too large: wagtail__wagtail-9882\n",
      "Token count is too large: pandas-dev__pandas-3600\n",
      "Token count is too large: conda__conda-6694\n",
      "Token count is too large: Lightning-AI__lightning-580\n",
      "Token count is too large: pandas-dev__pandas-11834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2978 examples [03:42, 19.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-15383\n",
      "Token count is too large: numpy__numpy-8445\n",
      "Token count is too large: Lightning-AI__lightning-653\n",
      "Token count is too large: pandas-dev__pandas-29004\n",
      "Token count is too large: pandas-dev__pandas-8926\n",
      "Token count is too large: Qiskit__qiskit-76\n",
      "Token count is too large: pypa__pip-9436\n",
      "Token count is too large: conda__conda-5018\n",
      "Token count is too large: scipy__scipy-4426\n",
      "Token count is too large: ipython__ipython-6919\n",
      "Token count is too large: pantsbuild__pants-4630\n",
      "Token count is too large: Qiskit__qiskit-1867\n",
      "Token count is too large: pandas-dev__pandas-7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2982 examples [03:42, 18.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: jupyterlab__jupyterlab-8463\n",
      "Token count is too large: Qiskit__qiskit-10090\n",
      "Token count is too large: gitpython-developers__GitPython-953\n",
      "Token count is too large: Qiskit__qiskit-5039\n",
      "Token count is too large: docker__compose-6509\n",
      "Token count is too large: huggingface__transformers-3100\n",
      "Token count is too large: googleapis__google-cloud-python-1052\n",
      "Token count is too large: ipython__ipython-13030\n",
      "Token count is too large: pyca__cryptography-4442\n",
      "Token count is too large: Qiskit__qiskit-7144\n",
      "Token count is too large: Qiskit__qiskit-2106\n",
      "Token count is too large: docker__compose-1755\n",
      "Token count is too large: googleapis__google-cloud-python-5498\n",
      "Token count is too large: pandas-dev__pandas-9104\n",
      "Token count is too large: wagtail__wagtail-1368\n",
      "Token count is too large: conan-io__conan-2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2986 examples [03:42, 17.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36898\n",
      "Token count is too large: pandas-dev__pandas-10680\n",
      "Token count is too large: docker__compose-6494\n",
      "Token count is too large: ytdl-org__youtube-dl-31434\n",
      "Token count is too large: numpy__numpy-4390\n",
      "Token count is too large: pandas-dev__pandas-9605\n",
      "Token count is too large: pyca__cryptography-5849\n",
      "Token count is too large: scipy__scipy-5494\n",
      "Token count is too large: ipython__ipython-11137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2988 examples [03:42, 16.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39615\n",
      "Token count is too large: scipy__scipy-3347\n",
      "Token count is too large: celery__celery-4719\n",
      "Token count is too large: Qiskit__qiskit-10358\n",
      "Token count is too large: pyca__cryptography-2292\n",
      "Token count is too large: pandas-dev__pandas-9934\n",
      "Token count is too large: pandas-dev__pandas-25254\n",
      "Token count is too large: wagtail__wagtail-6335\n",
      "Token count is too large: PrefectHQ__prefect-406\n",
      "Token count is too large: docker__compose-3718\n",
      "Token count is too large: numpy__numpy-14629\n",
      "Token count is too large: google__jax-2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2992 examples [03:43, 15.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6299\n",
      "Token count is too large: pantsbuild__pants-15031\n",
      "Token count is too large: pandas-dev__pandas-4414\n",
      "Token count is too large: apache__airflow-19605\n",
      "Token count is too large: ytdl-org__youtube-dl-5780\n",
      "Token count is too large: pantsbuild__pants-4201\n",
      "Token count is too large: Qiskit__qiskit-4597\n",
      "Token count is too large: ray-project__ray-8366\n",
      "Token count is too large: open-mmlab__mmdetection-7516\n",
      "Token count is too large: pandas-dev__pandas-23435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2995 examples [03:43, 17.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-5877\n",
      "Token count is too large: mesonbuild__meson-5187\n",
      "Token count is too large: pandas-dev__pandas-23262\n",
      "Token count is too large: numpy__numpy-18831\n",
      "Token count is too large: mesonbuild__meson-4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2997 examples [03:43, 15.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7215\n",
      "Token count is too large: googleapis__google-cloud-python-11310\n",
      "Token count is too large: pandas-dev__pandas-33392\n",
      "Token count is too large: PrefectHQ__prefect-2707\n",
      "Token count is too large: pyca__cryptography-5338\n",
      "Token count is too large: pypa__pip-11860\n",
      "Token count is too large: pandas-dev__pandas-17803\n",
      "Token count is too large: pandas-dev__pandas-12068\n",
      "Token count is too large: celery__celery-8301\n",
      "Token count is too large: Lightning-AI__lightning-2681\n",
      "Token count is too large: googleapis__google-cloud-python-6335\n",
      "Token count is too large: conan-io__conan-4250\n",
      "Token count is too large: google__jax-822\n",
      "Token count is too large: pandas-dev__pandas-2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3000 examples [03:43, 14.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33723\n",
      "Token count is too large: pantsbuild__pants-5889\n",
      "Token count is too large: PrefectHQ__prefect-287\n",
      "Token count is too large: numpy__numpy-7433\n",
      "Token count is too large: googleapis__google-cloud-python-10017\n",
      "Token count is too large: apache__airflow-13470\n",
      "Token count is too large: pantsbuild__pants-11703\n",
      "Token count is too large: pandas-dev__pandas-24492\n",
      "Token count is too large: pandas-dev__pandas-23919\n",
      "Token count is too large: Qiskit__qiskit-2816\n",
      "Token count is too large: pandas-dev__pandas-8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3004 examples [03:43, 14.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-5234\n",
      "Token count is too large: huggingface__transformers-13988\n",
      "Token count is too large: huggingface__transformers-24501\n",
      "Token count is too large: huggingface__transformers-12930\n",
      "Token count is too large: pandas-dev__pandas-26341\n",
      "Token count is too large: numpy__numpy-4421\n",
      "Token count is too large: celery__celery-5681\n",
      "Token count is too large: Qiskit__qiskit-4438\n",
      "Token count is too large: pantsbuild__pants-13400\n",
      "Token count is too large: Qiskit__qiskit-7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3008 examples [03:44, 16.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3225\n",
      "Token count is too large: googleapis__google-cloud-python-349\n",
      "Token count is too large: numpy__numpy-5825\n",
      "Token count is too large: google__jax-203\n",
      "Token count is too large: googleapis__google-cloud-python-11317\n",
      "Token count is too large: Qiskit__qiskit-1096\n",
      "Token count is too large: gitpython-developers__GitPython-685\n",
      "Token count is too large: conda__conda-3682\n",
      "Token count is too large: huggingface__transformers-21881\n",
      "Token count is too large: pandas-dev__pandas-20966\n",
      "Token count is too large: conda__conda-10115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3010 examples [03:44, 10.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22375\n",
      "Token count is too large: pandas-dev__pandas-26746\n",
      "Token count is too large: scipy__scipy-3696\n",
      "Token count is too large: google__jax-146\n",
      "Token count is too large: ytdl-org__youtube-dl-4629\n",
      "Token count is too large: ray-project__ray-8964\n",
      "Token count is too large: huggingface__transformers-12561\n",
      "Token count is too large: Qiskit__qiskit-9309\n",
      "Token count is too large: googleapis__google-cloud-python-3352\n",
      "Token count is too large: pandas-dev__pandas-8973\n",
      "Token count is too large: pypa__pip-2469\n",
      "Token count is too large: numpy__numpy-20745\n",
      "Token count is too large: pantsbuild__pants-18144\n",
      "Token count is too large: open-mmlab__mmdetection-7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3012 examples [03:44,  9.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3841\n",
      "Token count is too large: pandas-dev__pandas-38266\n",
      "Token count is too large: huggingface__transformers-22746\n",
      "Token count is too large: pypa__pip-8861\n",
      "Token count is too large: googleapis__google-cloud-python-4987\n",
      "Token count is too large: PrefectHQ__prefect-2560\n",
      "Token count is too large: dagster-io__dagster-14392\n",
      "Token count is too large: huggingface__transformers-10780\n",
      "Token count is too large: Lightning-AI__lightning-2437\n",
      "Token count is too large: pandas-dev__pandas-17966\n",
      "Token count is too large: ipython__ipython-11400\n",
      "Token count is too large: ipython__ipython-11505\n",
      "Token count is too large: huggingface__transformers-14992\n",
      "Token count is too large: mesonbuild__meson-5744\n",
      "Token count is too large: Qiskit__qiskit-7264\n",
      "Token count is too large: google__jax-873\n",
      "Token count is too large: pandas-dev__pandas-34058\n",
      "Token count is too large: google__jax-3173\n",
      "Token count is too large: wagtail__wagtail-7864\n",
      "Token count is too large: pandas-dev__pandas-10072\n",
      "Token count is too large: pandas-dev__pandas-27044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3014 examples [03:45,  7.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22655\n",
      "Token count is too large: pandas-dev__pandas-6542\n",
      "Token count is too large: ray-project__ray-3238\n",
      "Token count is too large: apache__airflow-25633\n",
      "Token count is too large: googleapis__google-cloud-python-5760\n",
      "Token count is too large: conda__conda-11949\n",
      "Token count is too large: wagtail__wagtail-8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3019 examples [03:45, 10.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-12237\n",
      "Token count is too large: googleapis__google-cloud-python-1205\n",
      "Token count is too large: huggingface__transformers-1724\n",
      "Token count is too large: googleapis__google-cloud-python-264\n",
      "Token count is too large: apache__airflow-16415\n",
      "Token count is too large: huggingface__transformers-3855\n",
      "Token count is too large: google__jax-2395\n",
      "Token count is too large: conan-io__conan-2831\n",
      "Token count is too large: pandas-dev__pandas-27691\n",
      "Token count is too large: pandas-dev__pandas-18749\n",
      "Token count is too large: googleapis__google-cloud-python-1638\n",
      "Token count is too large: pypa__pip-6427\n",
      "Token count is too large: Lightning-AI__lightning-3229\n",
      "Token count is too large: pandas-dev__pandas-31571\n",
      "Token count is too large: pandas-dev__pandas-15050\n",
      "Token count is too large: ray-project__ray-10721\n",
      "Token count is too large: pandas-dev__pandas-38698\n",
      "Token count is too large: Qiskit__qiskit-3612\n",
      "Token count is too large: jupyterlab__jupyterlab-2958\n",
      "Token count is too large: PrefectHQ__prefect-1415\n",
      "Token count is too large: docker__compose-6948\n",
      "Token count is too large: mesonbuild__meson-926\n",
      "Token count is too large: huggingface__transformers-25297\n",
      "Token count is too large: Qiskit__qiskit-3620\n",
      "Token count is too large: pandas-dev__pandas-18572\n",
      "Token count is too large: conan-io__conan-5800\n",
      "Token count is too large: numpy__numpy-10559\n",
      "Token count is too large: pypa__pip-7612\n",
      "Token count is too large: pandas-dev__pandas-25535\n",
      "Token count is too large: Qiskit__qiskit-2993\n",
      "Token count is too large: pandas-dev__pandas-30847\n",
      "Token count is too large: pandas-dev__pandas-7304\n",
      "Token count is too large: numpy__numpy-6490\n",
      "Token count is too large: mesonbuild__meson-5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3027 examples [03:46,  9.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-2170\n",
      "Token count is too large: pandas-dev__pandas-16926\n",
      "Token count is too large: docker__compose-5384\n",
      "Token count is too large: celery__celery-7652\n",
      "Token count is too large: docker__compose-4590\n",
      "Token count is too large: conda__conda-6828\n",
      "Token count is too large: conan-io__conan-4596\n",
      "Token count is too large: pandas-dev__pandas-5266\n",
      "Token count is too large: pandas-dev__pandas-33804\n",
      "Token count is too large: pandas-dev__pandas-32304\n",
      "Token count is too large: pandas-dev__pandas-5040\n",
      "Token count is too large: pandas-dev__pandas-25993\n",
      "Token count is too large: conda__conda-3436\n",
      "Token count is too large: pypa__pip-1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3029 examples [03:46, 10.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-9486\n",
      "Token count is too large: numpy__numpy-22748\n",
      "Token count is too large: pandas-dev__pandas-19260\n",
      "Token count is too large: Lightning-AI__lightning-2776\n",
      "Token count is too large: wagtail__wagtail-9114\n",
      "Token count is too large: pantsbuild__pants-13278\n",
      "Token count is too large: Lightning-AI__lightning-1935\n",
      "Token count is too large: mesonbuild__meson-11369\n",
      "Token count is too large: pandas-dev__pandas-23147\n",
      "Token count is too large: numpy__numpy-2942\n",
      "Token count is too large: wagtail__wagtail-7212\n",
      "Token count is too large: pandas-dev__pandas-9441\n",
      "Token count is too large: mesonbuild__meson-5500\n",
      "Token count is too large: googleapis__google-cloud-python-8111\n",
      "Token count is too large: googleapis__google-cloud-python-4727\n",
      "Token count is too large: pypa__pip-9274\n",
      "Token count is too large: pandas-dev__pandas-13533\n",
      "Token count is too large: pypa__pip-1623\n",
      "Token count is too large: googleapis__google-cloud-python-74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3032 examples [03:47,  8.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27100\n",
      "Token count is too large: pypa__pip-11858\n",
      "Token count is too large: ipython__ipython-1851\n",
      "Token count is too large: Lightning-AI__lightning-597\n",
      "Token count is too large: apache__airflow-9698\n",
      "Token count is too large: googleapis__google-cloud-python-9541\n",
      "Token count is too large: pandas-dev__pandas-37023\n",
      "Token count is too large: celery__celery-5085\n",
      "Token count is too large: wagtail__wagtail-1382\n",
      "Token count is too large: pandas-dev__pandas-17783\n",
      "Token count is too large: ipython__ipython-542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3035 examples [03:47, 10.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-8981\n",
      "Token count is too large: conan-io__conan-4709\n",
      "Token count is too large: pandas-dev__pandas-17744\n",
      "Token count is too large: pandas-dev__pandas-36582\n",
      "Token count is too large: pandas-dev__pandas-37221\n",
      "Token count is too large: mesonbuild__meson-9193\n",
      "Token count is too large: mesonbuild__meson-8292\n",
      "Token count is too large: Qiskit__qiskit-7003\n",
      "Token count is too large: ytdl-org__youtube-dl-18583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3037 examples [03:47,  7.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21249\n",
      "Token count is too large: wagtail__wagtail-4166\n",
      "Token count is too large: ipython__ipython-7129\n",
      "Token count is too large: conan-io__conan-5537\n",
      "Token count is too large: Qiskit__qiskit-866\n",
      "Token count is too large: ytdl-org__youtube-dl-3050\n",
      "Token count is too large: pandas-dev__pandas-18460\n",
      "Token count is too large: open-mmlab__mmdetection-4615\n",
      "Token count is too large: pandas-dev__pandas-6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3039 examples [03:48,  6.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-5928\n",
      "Token count is too large: pandas-dev__pandas-18248\n",
      "Token count is too large: PrefectHQ__prefect-1945\n",
      "Token count is too large: pandas-dev__pandas-19856\n",
      "Token count is too large: scipy__scipy-5732\n",
      "Token count is too large: Qiskit__qiskit-606\n",
      "Token count is too large: apache__airflow-32781\n",
      "Token count is too large: Lightning-AI__lightning-1582\n",
      "Token count is too large: huggingface__transformers-12591\n",
      "Token count is too large: celery__celery-5331\n",
      "Token count is too large: numpy__numpy-9556\n",
      "Token count is too large: pandas-dev__pandas-37468\n",
      "Token count is too large: pandas-dev__pandas-36418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3041 examples [03:48,  7.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-10621\n",
      "Token count is too large: pyca__cryptography-2087\n",
      "Token count is too large: mesonbuild__meson-1126\n",
      "Token count is too large: apache__airflow-32216\n",
      "Token count is too large: huggingface__transformers-11079\n",
      "Token count is too large: pandas-dev__pandas-18229\n",
      "Token count is too large: numpy__numpy-8142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3048 examples [03:48, 14.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36927\n",
      "Token count is too large: pandas-dev__pandas-23512\n",
      "Token count is too large: pandas-dev__pandas-37192\n",
      "Token count is too large: ray-project__ray-6691\n",
      "Token count is too large: pandas-dev__pandas-18825\n",
      "Token count is too large: Lightning-AI__lightning-2446\n",
      "Token count is too large: tiangolo__fastapi-241\n",
      "Token count is too large: pandas-dev__pandas-37374\n",
      "Token count is too large: gitpython-developers__GitPython-949\n",
      "Token count is too large: mesonbuild__meson-9958\n",
      "Token count is too large: ray-project__ray-5606\n",
      "Token count is too large: apache__airflow-24099\n",
      "Token count is too large: conda__conda-5555\n",
      "Token count is too large: mesonbuild__meson-8383\n",
      "Token count is too large: googleapis__google-cloud-python-6270\n",
      "Token count is too large: pandas-dev__pandas-5760\n",
      "Token count is too large: Qiskit__qiskit-3642\n",
      "Token count is too large: numpy__numpy-7416\n",
      "Token count is too large: PrefectHQ__prefect-158\n",
      "Token count is too large: pandas-dev__pandas-25437\n",
      "Token count is too large: Qiskit__qiskit-2862\n",
      "Token count is too large: pandas-dev__pandas-38903\n",
      "Token count is too large: pandas-dev__pandas-36503\n",
      "Token count is too large: pandas-dev__pandas-14476\n",
      "Token count is too large: googleapis__google-cloud-python-6481\n",
      "Token count is too large: pantsbuild__pants-4369\n",
      "Token count is too large: conan-io__conan-3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3060 examples [03:49, 16.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20984\n",
      "Token count is too large: pandas-dev__pandas-18157\n",
      "Token count is too large: conan-io__conan-3197\n",
      "Token count is too large: dagster-io__dagster-8689\n",
      "Token count is too large: numpy__numpy-16247\n",
      "Token count is too large: huggingface__transformers-11675\n",
      "Token count is too large: huggingface__transformers-3198\n",
      "Token count is too large: scipy__scipy-3944\n",
      "Token count is too large: scipy__scipy-5749\n",
      "Token count is too large: pandas-dev__pandas-19879\n",
      "Token count is too large: conda__conda-7986\n",
      "Token count is too large: googleapis__google-cloud-python-5821\n",
      "Token count is too large: pandas-dev__pandas-38472\n",
      "Token count is too large: apache__airflow-13880\n",
      "Token count is too large: pandas-dev__pandas-19552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3066 examples [03:49, 19.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-7844\n",
      "Token count is too large: ray-project__ray-1880\n",
      "Token count is too large: pantsbuild__pants-13573\n",
      "Token count is too large: numpy__numpy-5364\n",
      "Token count is too large: numpy__numpy-23599\n",
      "Token count is too large: conan-io__conan-3918\n",
      "Token count is too large: numpy__numpy-22388\n",
      "Token count is too large: apache__airflow-8558\n",
      "Token count is too large: ipython__ipython-1391\n",
      "Token count is too large: ytdl-org__youtube-dl-16054\n",
      "Token count is too large: conan-io__conan-5381\n",
      "Token count is too large: conda__conda-3748\n",
      "Token count is too large: pandas-dev__pandas-23462\n",
      "Token count is too large: gitpython-developers__GitPython-368\n",
      "Token count is too large: conda__conda-4548\n",
      "Token count is too large: explosion__spaCy-1552\n",
      "Token count is too large: pyca__cryptography-3190\n",
      "Token count is too large: numpy__numpy-21205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3070 examples [03:50, 12.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4955\n",
      "Token count is too large: pyca__cryptography-1131\n",
      "Token count is too large: pandas-dev__pandas-15618\n",
      "Token count is too large: gitpython-developers__GitPython-1015\n",
      "Token count is too large: docker__compose-3964\n",
      "Token count is too large: huggingface__transformers-9932\n",
      "Token count is too large: apache__airflow-25355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3076 examples [03:50, 14.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-9677\n",
      "Token count is too large: pandas-dev__pandas-24129\n",
      "Token count is too large: googleapis__google-cloud-python-9491\n",
      "Token count is too large: googleapis__google-cloud-python-1421\n",
      "Token count is too large: pandas-dev__pandas-17488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3079 examples [03:50, 15.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10686\n",
      "Token count is too large: Lightning-AI__lightning-2881\n",
      "Token count is too large: docker__compose-6205\n",
      "Token count is too large: Lightning-AI__lightning-1164\n",
      "Token count is too large: jupyterlab__jupyterlab-2069\n",
      "Token count is too large: apache__airflow-24772\n",
      "Token count is too large: Qiskit__qiskit-9076\n",
      "Token count is too large: pypa__pip-6095\n",
      "Token count is too large: huggingface__transformers-11951\n",
      "Token count is too large: docker__compose-7485\n",
      "Token count is too large: pandas-dev__pandas-16340\n",
      "Token count is too large: huggingface__transformers-13022\n",
      "Token count is too large: pandas-dev__pandas-36433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3083 examples [03:50, 16.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23968\n",
      "Token count is too large: Qiskit__qiskit-1257\n",
      "Token count is too large: pandas-dev__pandas-16915\n",
      "Token count is too large: pandas-dev__pandas-14717\n",
      "Token count is too large: pandas-dev__pandas-37701\n",
      "Token count is too large: mesonbuild__meson-6855\n",
      "Token count is too large: conda__conda-1668\n",
      "Token count is too large: ray-project__ray-8731\n",
      "Token count is too large: numpy__numpy-5869\n",
      "Token count is too large: scipy__scipy-4996\n",
      "Token count is too large: pandas-dev__pandas-22912\n",
      "Token count is too large: pyca__cryptography-5595\n",
      "Token count is too large: pandas-dev__pandas-7092\n",
      "Token count is too large: Qiskit__qiskit-6339\n",
      "Token count is too large: PrefectHQ__prefect-131\n",
      "Token count is too large: wagtail__wagtail-1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3086 examples [03:51, 11.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4164\n",
      "Token count is too large: PrefectHQ__prefect-684\n",
      "Token count is too large: pandas-dev__pandas-11639\n",
      "Token count is too large: numpy__numpy-23010\n",
      "Token count is too large: apache__airflow-16860\n",
      "Token count is too large: ipython__ipython-14052\n",
      "Token count is too large: jupyterlab__jupyterlab-12772\n",
      "Token count is too large: numpy__numpy-22700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3088 examples [03:51,  9.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-5521\n",
      "Token count is too large: Qiskit__qiskit-2381\n",
      "Token count is too large: pandas-dev__pandas-31247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3096 examples [03:52, 12.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-3032\n",
      "Token count is too large: Lightning-AI__lightning-3320\n",
      "Token count is too large: Qiskit__qiskit-10163\n",
      "Token count is too large: pandas-dev__pandas-14765\n",
      "Token count is too large: huggingface__transformers-7560\n",
      "Token count is too large: pandas-dev__pandas-35324\n",
      "Token count is too large: mesonbuild__meson-2717\n",
      "Token count is too large: docker__compose-5566\n",
      "Token count is too large: pandas-dev__pandas-8941\n",
      "Token count is too large: pandas-dev__pandas-3632\n",
      "Token count is too large: Qiskit__qiskit-701\n",
      "Token count is too large: pandas-dev__pandas-34335\n",
      "Token count is too large: pandas-dev__pandas-26241\n",
      "Token count is too large: huggingface__transformers-14324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3106 examples [03:52, 14.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37025\n",
      "Token count is too large: huggingface__transformers-11378\n",
      "Token count is too large: pandas-dev__pandas-28919\n",
      "Token count is too large: mesonbuild__meson-1456\n",
      "Token count is too large: apache__airflow-12694\n",
      "Token count is too large: Qiskit__qiskit-3224\n",
      "Token count is too large: numpy__numpy-7793\n",
      "Token count is too large: ipython__ipython-11803\n",
      "Token count is too large: apache__airflow-10227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3109 examples [03:52, 15.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: explosion__spaCy-2808\n",
      "Token count is too large: pandas-dev__pandas-23514\n",
      "Token count is too large: pandas-dev__pandas-24338\n",
      "Token count is too large: pandas-dev__pandas-4099\n",
      "Token count is too large: numpy__numpy-5101\n",
      "Token count is too large: conda__conda-8342\n",
      "Token count is too large: Lightning-AI__lightning-1378\n",
      "Token count is too large: docker__compose-276\n",
      "Token count is too large: ray-project__ray-10821\n",
      "Token count is too large: PrefectHQ__prefect-409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3112 examples [03:53, 14.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17731\n",
      "Token count is too large: pandas-dev__pandas-3563\n",
      "Token count is too large: pandas-dev__pandas-6812\n",
      "Token count is too large: pandas-dev__pandas-31867\n",
      "Token count is too large: pandas-dev__pandas-26157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3114 examples [03:53, 12.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13925\n",
      "Token count is too large: Qiskit__qiskit-2239\n",
      "Token count is too large: mesonbuild__meson-2817\n",
      "Token count is too large: Qiskit__qiskit-7712\n",
      "Token count is too large: wagtail__wagtail-1626\n",
      "Token count is too large: ytdl-org__youtube-dl-14571\n",
      "Token count is too large: ytdl-org__youtube-dl-12879\n",
      "Token count is too large: scipy__scipy-3110\n",
      "Token count is too large: pandas-dev__pandas-23019\n",
      "Token count is too large: conan-io__conan-5817\n",
      "Token count is too large: PrefectHQ__prefect-725\n",
      "Token count is too large: numpy__numpy-8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3118 examples [03:53, 14.37 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4534\n",
      "Token count is too large: numpy__numpy-3056\n",
      "Token count is too large: conan-io__conan-2952\n",
      "Token count is too large: docker__compose-6234\n",
      "Token count is too large: conda__conda-2701\n",
      "Token count is too large: pandas-dev__pandas-14582\n",
      "Token count is too large: huggingface__transformers-5636\n",
      "Token count is too large: pandas-dev__pandas-23206\n",
      "Token count is too large: conda__conda-8917\n",
      "Token count is too large: jupyterlab__jupyterlab-12926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3127 examples [03:53, 18.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20043\n",
      "Token count is too large: pandas-dev__pandas-8462\n",
      "Token count is too large: pantsbuild__pants-10489\n",
      "Token count is too large: huggingface__transformers-19124\n",
      "Token count is too large: pantsbuild__pants-8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3130 examples [03:54, 17.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26997\n",
      "Token count is too large: pandas-dev__pandas-8455\n",
      "Token count is too large: ytdl-org__youtube-dl-7210\n",
      "Token count is too large: docker__compose-6406\n",
      "Token count is too large: huggingface__transformers-8747\n",
      "Token count is too large: pandas-dev__pandas-36838\n",
      "Token count is too large: huggingface__transformers-21879\n",
      "Token count is too large: pypa__pip-4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3136 examples [03:54, 18.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-9735\n",
      "Token count is too large: Lightning-AI__lightning-2482\n",
      "Token count is too large: pandas-dev__pandas-8237\n",
      "Token count is too large: Qiskit__qiskit-3418\n",
      "Token count is too large: ytdl-org__youtube-dl-8718\n",
      "Token count is too large: open-mmlab__mmdetection-8439\n",
      "Token count is too large: jupyterlab__jupyterlab-9244\n",
      "Token count is too large: pandas-dev__pandas-20819\n",
      "Token count is too large: googleapis__google-cloud-python-5607\n",
      "Token count is too large: ray-project__ray-7181\n",
      "Token count is too large: pandas-dev__pandas-30882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3138 examples [03:54, 18.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-10599\n",
      "Token count is too large: jupyterlab__jupyterlab-9040\n",
      "Token count is too large: pandas-dev__pandas-18211\n",
      "Token count is too large: apache__airflow-26100\n",
      "Token count is too large: Qiskit__qiskit-1799\n",
      "Token count is too large: numpy__numpy-15939\n",
      "Token count is too large: Qiskit__qiskit-4669\n",
      "Token count is too large: Lightning-AI__lightning-1753\n",
      "Token count is too large: pandas-dev__pandas-29846\n",
      "Token count is too large: googleapis__google-cloud-python-5815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3150 examples [03:54, 31.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39293\n",
      "Token count is too large: pypa__pip-9170\n",
      "Token count is too large: pandas-dev__pandas-19232\n",
      "Token count is too large: celery__celery-6251\n",
      "Token count is too large: conda__conda-12050\n",
      "Token count is too large: Qiskit__qiskit-1800\n",
      "Token count is too large: ipython__ipython-815\n",
      "Token count is too large: docker__compose-7762\n",
      "Token count is too large: pandas-dev__pandas-22198\n",
      "Token count is too large: conda__conda-5186\n",
      "Token count is too large: ytdl-org__youtube-dl-15807\n",
      "Token count is too large: wagtail__wagtail-6279\n",
      "Token count is too large: pandas-dev__pandas-39655\n",
      "Token count is too large: google__jax-1152\n",
      "Token count is too large: pandas-dev__pandas-34514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3154 examples [03:55, 28.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-621\n",
      "Token count is too large: pandas-dev__pandas-7818\n",
      "Token count is too large: pandas-dev__pandas-8293\n",
      "Token count is too large: pandas-dev__pandas-17214\n",
      "Token count is too large: pandas-dev__pandas-34812\n",
      "Token count is too large: googleapis__google-cloud-python-6920\n",
      "Token count is too large: pandas-dev__pandas-7181\n",
      "Token count is too large: conan-io__conan-3603\n",
      "Token count is too large: pandas-dev__pandas-28542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3158 examples [03:55, 28.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26408\n",
      "Token count is too large: mesonbuild__meson-11977\n",
      "Token count is too large: pandas-dev__pandas-30489\n",
      "Token count is too large: pantsbuild__pants-17928\n",
      "Token count is too large: pandas-dev__pandas-18225\n",
      "Token count is too large: huggingface__transformers-7322\n",
      "Token count is too large: pandas-dev__pandas-27925\n",
      "Token count is too large: pandas-dev__pandas-16533\n",
      "Token count is too large: pandas-dev__pandas-37322\n",
      "Token count is too large: pandas-dev__pandas-8706\n",
      "Token count is too large: huggingface__transformers-5551\n",
      "Token count is too large: pyca__cryptography-3919\n",
      "Token count is too large: mesonbuild__meson-5193\n",
      "Token count is too large: pandas-dev__pandas-34910\n",
      "Token count is too large: numpy__numpy-13374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3166 examples [03:55, 24.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21871\n",
      "Token count is too large: pandas-dev__pandas-38841\n",
      "Token count is too large: pandas-dev__pandas-29912\n",
      "Token count is too large: mesonbuild__meson-238\n",
      "Token count is too large: googleapis__google-cloud-python-3674\n",
      "Token count is too large: ipython__ipython-10318\n",
      "Token count is too large: celery__celery-4617\n",
      "Token count is too large: pantsbuild__pants-18366\n",
      "Token count is too large: pandas-dev__pandas-8929\n",
      "Token count is too large: Qiskit__qiskit-6345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3169 examples [03:55, 19.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35697\n",
      "Token count is too large: huggingface__transformers-10611\n",
      "Token count is too large: open-mmlab__mmdetection-7690\n",
      "Token count is too large: pantsbuild__pants-12618\n",
      "Token count is too large: Lightning-AI__lightning-449\n",
      "Token count is too large: pandas-dev__pandas-11888\n",
      "Token count is too large: mesonbuild__meson-4958\n",
      "Token count is too large: pandas-dev__pandas-27787\n",
      "Token count is too large: pandas-dev__pandas-5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3173 examples [03:56, 17.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-11753\n",
      "Token count is too large: huggingface__transformers-10692\n",
      "Token count is too large: Lightning-AI__lightning-1475\n",
      "Token count is too large: pandas-dev__pandas-32568\n",
      "Token count is too large: celery__celery-4357\n",
      "Token count is too large: conan-io__conan-2846\n",
      "Token count is too large: Qiskit__qiskit-10441\n",
      "Token count is too large: celery__celery-4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3182 examples [03:56, 26.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-3046\n",
      "Token count is too large: pyca__cryptography-3896\n",
      "Token count is too large: mesonbuild__meson-1694\n",
      "Token count is too large: Qiskit__qiskit-1450\n",
      "Token count is too large: pandas-dev__pandas-36729\n",
      "Token count is too large: google__jax-1175\n",
      "Token count is too large: pantsbuild__pants-14184\n",
      "Token count is too large: pandas-dev__pandas-33911\n",
      "Token count is too large: googleapis__google-cloud-python-5767\n",
      "Token count is too large: googleapis__google-cloud-python-3157\n",
      "Token count is too large: pandas-dev__pandas-28741\n",
      "Token count is too large: Lightning-AI__lightning-3061\n",
      "Token count is too large: googleapis__google-cloud-python-1517\n",
      "Token count is too large: jupyterlab__jupyterlab-946\n",
      "Token count is too large: open-mmlab__mmdetection-7449\n",
      "Token count is too large: googleapis__google-cloud-python-6521\n",
      "Token count is too large: pandas-dev__pandas-30213\n",
      "Token count is too large: conda__conda-12929\n",
      "Token count is too large: Qiskit__qiskit-7525\n",
      "Token count is too large: ipython__ipython-10669\n",
      "Token count is too large: pyca__cryptography-605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3188 examples [03:56, 19.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-2846\n",
      "Token count is too large: numpy__numpy-7296\n",
      "Token count is too large: pandas-dev__pandas-6974\n",
      "Token count is too large: pandas-dev__pandas-38417\n",
      "Token count is too large: googleapis__google-cloud-python-9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3191 examples [03:57, 18.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-20721\n",
      "Token count is too large: googleapis__google-cloud-python-615\n",
      "Token count is too large: pandas-dev__pandas-8266\n",
      "Token count is too large: conda__conda-3228\n",
      "Token count is too large: pantsbuild__pants-12878\n",
      "Token count is too large: Qiskit__qiskit-9597\n",
      "Token count is too large: twisted__twisted-11603\n",
      "Token count is too large: ytdl-org__youtube-dl-6196\n",
      "Token count is too large: pandas-dev__pandas-37830\n",
      "Token count is too large: pandas-dev__pandas-18307\n",
      "Token count is too large: apache__airflow-23804\n",
      "Token count is too large: pandas-dev__pandas-27321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3198 examples [03:57, 23.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-2818\n",
      "Token count is too large: pypa__pip-1691\n",
      "Token count is too large: jupyterlab__jupyterlab-6451\n",
      "Token count is too large: celery__celery-2783\n",
      "Token count is too large: pandas-dev__pandas-28213\n",
      "Token count is too large: PrefectHQ__prefect-1993\n",
      "Token count is too large: scipy__scipy-4618\n",
      "Token count is too large: pandas-dev__pandas-7328\n",
      "Token count is too large: pandas-dev__pandas-27674\n",
      "Token count is too large: pandas-dev__pandas-10920\n",
      "Token count is too large: pandas-dev__pandas-4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3201 examples [03:57, 21.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35035\n",
      "Token count is too large: pandas-dev__pandas-13836\n",
      "Token count is too large: wagtail__wagtail-4402\n",
      "Token count is too large: pantsbuild__pants-4753\n",
      "Token count is too large: huggingface__transformers-10863\n",
      "Token count is too large: Qiskit__qiskit-5336\n",
      "Token count is too large: mesonbuild__meson-585\n",
      "Token count is too large: pandas-dev__pandas-14801\n",
      "Token count is too large: google__jax-730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3206 examples [03:57, 20.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17491\n",
      "Token count is too large: pandas-dev__pandas-33404\n",
      "Token count is too large: pandas-dev__pandas-3985\n",
      "Token count is too large: pantsbuild__pants-17097\n",
      "Token count is too large: pandas-dev__pandas-35815\n",
      "Token count is too large: pandas-dev__pandas-39196\n",
      "Token count is too large: pandas-dev__pandas-28417\n",
      "Token count is too large: conan-io__conan-5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3212 examples [03:57, 19.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19006\n",
      "Token count is too large: twisted__twisted-11770\n",
      "Token count is too large: pandas-dev__pandas-18182\n",
      "Token count is too large: google__jax-2803\n",
      "Token count is too large: mesonbuild__meson-3416\n",
      "Token count is too large: pandas-dev__pandas-3627\n",
      "Token count is too large: pandas-dev__pandas-25467\n",
      "Token count is too large: docker__compose-258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3216 examples [03:58, 20.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18902\n",
      "Token count is too large: pandas-dev__pandas-21548\n",
      "Token count is too large: docker__compose-4216\n",
      "Token count is too large: pandas-dev__pandas-10376\n",
      "Token count is too large: pandas-dev__pandas-36722\n",
      "Token count is too large: numpy__numpy-13767\n",
      "Token count is too large: huggingface__transformers-9685\n",
      "Token count is too large: pandas-dev__pandas-25368\n",
      "Token count is too large: pandas-dev__pandas-26115\n",
      "Token count is too large: wagtail__wagtail-6757\n",
      "Token count is too large: pandas-dev__pandas-32839\n",
      "Token count is too large: pandas-dev__pandas-9640\n",
      "Token count is too large: pandas-dev__pandas-28185\n",
      "Token count is too large: conan-io__conan-4860\n",
      "Token count is too large: huggingface__transformers-14671\n",
      "Token count is too large: ytdl-org__youtube-dl-31243\n",
      "Token count is too large: PrefectHQ__prefect-2297\n",
      "Token count is too large: ray-project__ray-9020\n",
      "Token count is too large: pandas-dev__pandas-21187\n",
      "Token count is too large: pantsbuild__pants-11202\n",
      "Token count is too large: pandas-dev__pandas-7463\n",
      "Token count is too large: ytdl-org__youtube-dl-29332\n",
      "Token count is too large: googleapis__google-cloud-python-5108\n",
      "Token count is too large: numpy__numpy-11197\n",
      "Token count is too large: pandas-dev__pandas-4660\n",
      "Token count is too large: docker__compose-2336\n",
      "Token count is too large: pandas-dev__pandas-32090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3222 examples [03:58, 13.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18437\n",
      "Token count is too large: celery__celery-4709\n",
      "Token count is too large: pantsbuild__pants-15283\n",
      "Token count is too large: pypa__pip-6914\n",
      "Token count is too large: huggingface__transformers-17797\n",
      "Token count is too large: pantsbuild__pants-5416\n",
      "Token count is too large: ipython__ipython-13991\n",
      "Token count is too large: huggingface__transformers-3716\n",
      "Token count is too large: pandas-dev__pandas-2883\n",
      "Token count is too large: ipython__ipython-8884\n",
      "Token count is too large: PrefectHQ__prefect-713\n",
      "Token count is too large: PrefectHQ__prefect-320\n",
      "Token count is too large: pandas-dev__pandas-32699\n",
      "Token count is too large: ytdl-org__youtube-dl-2089\n",
      "Token count is too large: pandas-dev__pandas-17498\n",
      "Token count is too large: pandas-dev__pandas-14886\n",
      "Token count is too large: pandas-dev__pandas-36869\n",
      "Token count is too large: mesonbuild__meson-5344\n",
      "Token count is too large: Qiskit__qiskit-6519\n",
      "Token count is too large: Qiskit__qiskit-2389\n",
      "Token count is too large: pandas-dev__pandas-16965\n",
      "Token count is too large: pandas-dev__pandas-30640\n",
      "Token count is too large: pandas-dev__pandas-9041\n",
      "Token count is too large: pandas-dev__pandas-37771\n",
      "Token count is too large: Qiskit__qiskit-6315\n",
      "Token count is too large: pandas-dev__pandas-34545\n",
      "Token count is too large: celery__celery-3831\n",
      "Token count is too large: pandas-dev__pandas-3208\n",
      "Token count is too large: huggingface__transformers-11851\n",
      "Token count is too large: docker__compose-4991\n",
      "Token count is too large: ray-project__ray-10221\n",
      "Token count is too large: wagtail__wagtail-500\n",
      "Token count is too large: huggingface__transformers-7577\n",
      "Token count is too large: pandas-dev__pandas-16950\n",
      "Token count is too large: numpy__numpy-9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3229 examples [03:59, 10.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25627\n",
      "Token count is too large: numpy__numpy-3241\n",
      "Token count is too large: pypa__pip-10032\n",
      "Token count is too large: pandas-dev__pandas-18875\n",
      "Token count is too large: conan-io__conan-5088\n",
      "Token count is too large: pandas-dev__pandas-19834\n",
      "Token count is too large: pandas-dev__pandas-36093\n",
      "Token count is too large: pypa__pip-7908\n",
      "Token count is too large: google__jax-1594\n",
      "Token count is too large: Qiskit__qiskit-1765\n",
      "Token count is too large: googleapis__google-cloud-python-689\n",
      "Token count is too large: Qiskit__qiskit-6216\n",
      "Token count is too large: pandas-dev__pandas-22651\n",
      "Token count is too large: conan-io__conan-11238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3235 examples [04:00, 11.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21066\n",
      "Token count is too large: celery__celery-6923\n",
      "Token count is too large: apache__airflow-26369\n",
      "Token count is too large: Qiskit__qiskit-4535\n",
      "Token count is too large: googleapis__google-cloud-python-1559\n",
      "Token count is too large: huggingface__transformers-4289\n",
      "Token count is too large: pypa__pip-2978\n",
      "Token count is too large: Qiskit__qiskit-1797\n",
      "Token count is too large: conan-io__conan-5945\n",
      "Token count is too large: conan-io__conan-4106\n",
      "Token count is too large: pandas-dev__pandas-27265\n",
      "Token count is too large: tiangolo__fastapi-435\n",
      "Token count is too large: ipython__ipython-7608\n",
      "Token count is too large: conda__conda-6368\n",
      "Token count is too large: pandas-dev__pandas-37924\n",
      "Token count is too large: pandas-dev__pandas-21034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3237 examples [04:00,  9.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25132\n",
      "Token count is too large: pantsbuild__pants-14529\n",
      "Token count is too large: dagster-io__dagster-1244\n",
      "Token count is too large: huggingface__transformers-17852\n",
      "Token count is too large: pandas-dev__pandas-25297\n",
      "Token count is too large: Lightning-AI__lightning-1794\n",
      "Token count is too large: pandas-dev__pandas-10738\n",
      "Token count is too large: numpy__numpy-4428\n",
      "Token count is too large: huggingface__transformers-22159\n",
      "Token count is too large: pandas-dev__pandas-35182\n",
      "Token count is too large: huggingface__transformers-19287\n",
      "Token count is too large: docker__compose-5155\n",
      "Token count is too large: pantsbuild__pants-6472\n",
      "Token count is too large: PrefectHQ__prefect-988\n",
      "Token count is too large: conda__conda-6570\n",
      "Token count is too large: Lightning-AI__lightning-2184\n",
      "Token count is too large: open-mmlab__mmdetection-6034\n",
      "Token count is too large: PrefectHQ__prefect-2668\n",
      "Token count is too large: pandas-dev__pandas-16201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3243 examples [04:01, 11.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-415\n",
      "Token count is too large: pandas-dev__pandas-28798\n",
      "Token count is too large: conan-io__conan-7272\n",
      "Token count is too large: pandas-dev__pandas-5408\n",
      "Token count is too large: mesonbuild__meson-8164\n",
      "Token count is too large: pandas-dev__pandas-17431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3247 examples [04:01, 12.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18600\n",
      "Token count is too large: pandas-dev__pandas-29920\n",
      "Token count is too large: huggingface__transformers-20989\n",
      "Token count is too large: celery__celery-3827\n",
      "Token count is too large: pandas-dev__pandas-9630\n",
      "Token count is too large: PrefectHQ__prefect-1388\n",
      "Token count is too large: dagster-io__dagster-4336\n",
      "Token count is too large: ray-project__ray-8898\n",
      "Token count is too large: pantsbuild__pants-6315\n",
      "Token count is too large: pandas-dev__pandas-23394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3250 examples [04:01, 12.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-4205\n",
      "Token count is too large: mesonbuild__meson-10508\n",
      "Token count is too large: huggingface__transformers-14274\n",
      "Token count is too large: pandas-dev__pandas-7552\n",
      "Token count is too large: googleapis__google-cloud-python-4716\n",
      "Token count is too large: pandas-dev__pandas-27071\n",
      "Token count is too large: mesonbuild__meson-3061\n",
      "Token count is too large: numpy__numpy-10698\n",
      "Token count is too large: pypa__pip-8096\n",
      "Token count is too large: huggingface__transformers-21914\n",
      "Token count is too large: google__jax-429\n",
      "Token count is too large: ipython__ipython-13640\n",
      "Token count is too large: twisted__twisted-11617\n",
      "Token count is too large: mesonbuild__meson-1308\n",
      "Token count is too large: Qiskit__qiskit-7381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3252 examples [04:01,  9.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-16987\n",
      "Token count is too large: pandas-dev__pandas-22549\n",
      "Token count is too large: huggingface__transformers-10436\n",
      "Token count is too large: twisted__twisted-11767\n",
      "Token count is too large: jupyterlab__jupyterlab-6414\n",
      "Token count is too large: pandas-dev__pandas-26046\n",
      "Token count is too large: pandas-dev__pandas-3878\n",
      "Token count is too large: explosion__spaCy-2346\n",
      "Token count is too large: PrefectHQ__prefect-1933\n",
      "Token count is too large: pandas-dev__pandas-18424\n",
      "Token count is too large: docker__compose-5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3257 examples [04:02, 12.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-8122\n",
      "Token count is too large: apache__airflow-24865\n",
      "Token count is too large: pandas-dev__pandas-37559\n",
      "Token count is too large: huggingface__transformers-12365\n",
      "Token count is too large: pandas-dev__pandas-26628\n",
      "Token count is too large: google__jax-2596\n",
      "Token count is too large: huggingface__transformers-22031\n",
      "Token count is too large: google__jax-144\n",
      "Token count is too large: pypa__pip-6921\n",
      "Token count is too large: pandas-dev__pandas-9983\n",
      "Token count is too large: Qiskit__qiskit-765\n",
      "Token count is too large: Qiskit__qiskit-1375\n",
      "Token count is too large: pandas-dev__pandas-15099\n",
      "Token count is too large: pandas-dev__pandas-28700\n",
      "Token count is too large: pandas-dev__pandas-38101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3259 examples [04:02,  9.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24772\n",
      "Token count is too large: pandas-dev__pandas-36370\n",
      "Token count is too large: mesonbuild__meson-9347\n",
      "Token count is too large: pandas-dev__pandas-19875\n",
      "Token count is too large: huggingface__transformers-24853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3265 examples [04:02, 11.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5423\n",
      "Token count is too large: pandas-dev__pandas-7788\n",
      "Token count is too large: pandas-dev__pandas-23278\n",
      "Token count is too large: pandas-dev__pandas-23936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3270 examples [04:03, 13.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35129\n",
      "Token count is too large: pandas-dev__pandas-27951\n",
      "Token count is too large: Qiskit__qiskit-10469\n",
      "Token count is too large: PrefectHQ__prefect-214\n",
      "Token count is too large: pandas-dev__pandas-4231\n",
      "Token count is too large: docker__compose-2821\n",
      "Token count is too large: pandas-dev__pandas-33984\n",
      "Token count is too large: docker__compose-5006\n",
      "Token count is too large: pandas-dev__pandas-29872\n",
      "Token count is too large: huggingface__transformers-6461\n",
      "Token count is too large: pandas-dev__pandas-18069\n",
      "Token count is too large: DataDog__integrations-core-5659\n",
      "Token count is too large: pandas-dev__pandas-4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3272 examples [04:03,  9.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30852\n",
      "Token count is too large: googleapis__google-cloud-python-11460\n",
      "Token count is too large: ipython__ipython-4622\n",
      "Token count is too large: pantsbuild__pants-6872\n",
      "Token count is too large: mesonbuild__meson-10652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3277 examples [04:03, 12.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-2113\n",
      "Token count is too large: huggingface__transformers-21473\n",
      "Token count is too large: pantsbuild__pants-14186\n",
      "Token count is too large: googleapis__google-cloud-python-2210\n",
      "Token count is too large: pypa__pip-9096\n",
      "Token count is too large: huggingface__transformers-9567\n",
      "Token count is too large: pandas-dev__pandas-17071\n",
      "Token count is too large: Qiskit__qiskit-3709\n",
      "Token count is too large: huggingface__transformers-11117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3285 examples [04:04, 22.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-7562\n",
      "Token count is too large: ipython__ipython-4464\n",
      "Token count is too large: Qiskit__qiskit-5346\n",
      "Token count is too large: huggingface__transformers-12806\n",
      "Token count is too large: huggingface__transformers-24058\n",
      "Token count is too large: numpy__numpy-18100\n",
      "Token count is too large: numpy__numpy-6504\n",
      "Token count is too large: pandas-dev__pandas-26257\n",
      "Token count is too large: PrefectHQ__prefect-550\n",
      "Token count is too large: pandas-dev__pandas-24113\n",
      "Token count is too large: numpy__numpy-3449\n",
      "Token count is too large: Qiskit__qiskit-5830\n",
      "Token count is too large: apache__airflow-13232\n",
      "Token count is too large: pandas-dev__pandas-21541\n",
      "Token count is too large: mesonbuild__meson-7266\n",
      "Token count is too large: google__jax-2268\n",
      "Token count is too large: DataDog__integrations-core-7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3289 examples [04:04, 15.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25461\n",
      "Token count is too large: pandas-dev__pandas-16124\n",
      "Token count is too large: pandas-dev__pandas-25811\n",
      "Token count is too large: huggingface__transformers-19191\n",
      "Token count is too large: pandas-dev__pandas-26474\n",
      "Token count is too large: pandas-dev__pandas-20721\n",
      "Token count is too large: huggingface__transformers-15230\n",
      "Token count is too large: PrefectHQ__prefect-532\n",
      "Token count is too large: ipython__ipython-9655\n",
      "Token count is too large: pantsbuild__pants-6156\n",
      "Token count is too large: googleapis__google-cloud-python-993\n",
      "Token count is too large: pandas-dev__pandas-26012\n",
      "Token count is too large: pandas-dev__pandas-5160\n",
      "Token count is too large: pandas-dev__pandas-36747\n",
      "Token count is too large: PrefectHQ__prefect-1384\n",
      "Token count is too large: huggingface__transformers-9691\n",
      "Token count is too large: huggingface__transformers-20848\n",
      "Token count is too large: Qiskit__qiskit-8121\n",
      "Token count is too large: googleapis__google-cloud-python-522\n",
      "Token count is too large: wagtail__wagtail-7639\n",
      "Token count is too large: celery__celery-6516\n",
      "Token count is too large: Lightning-AI__lightning-309\n",
      "Token count is too large: numpy__numpy-11774\n",
      "Token count is too large: pyca__cryptography-2405\n",
      "Token count is too large: pandas-dev__pandas-3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3292 examples [04:05,  7.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10676\n",
      "Token count is too large: Qiskit__qiskit-10652\n",
      "Token count is too large: huggingface__transformers-10475\n",
      "Token count is too large: docker__compose-2314\n",
      "Token count is too large: pandas-dev__pandas-11191\n",
      "Token count is too large: mesonbuild__meson-10076\n",
      "Token count is too large: conan-io__conan-2941\n",
      "Token count is too large: scipy__scipy-4281\n",
      "Token count is too large: Qiskit__qiskit-2672\n",
      "Token count is too large: conan-io__conan-3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3297 examples [04:05, 10.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5247\n",
      "Token count is too large: dagster-io__dagster-6865\n",
      "Token count is too large: ray-project__ray-9142\n",
      "Token count is too large: numpy__numpy-19654\n",
      "Token count is too large: googleapis__google-cloud-python-11204\n",
      "Token count is too large: celery__celery-6635\n",
      "Token count is too large: huggingface__transformers-19707\n",
      "Token count is too large: numpy__numpy-9784\n",
      "Token count is too large: Qiskit__qiskit-6014\n",
      "Token count is too large: conan-io__conan-2459\n",
      "Token count is too large: pantsbuild__pants-5358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3307 examples [04:05, 17.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-2182\n",
      "Token count is too large: Lightning-AI__lightning-603\n",
      "Token count is too large: pandas-dev__pandas-28216\n",
      "Token count is too large: huggingface__transformers-14729\n",
      "Token count is too large: pandas-dev__pandas-30460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3312 examples [04:06, 16.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22880\n",
      "Token count is too large: conda__conda-3416\n",
      "Token count is too large: mesonbuild__meson-6421\n",
      "Token count is too large: pandas-dev__pandas-31733\n",
      "Token count is too large: ray-project__ray-10680\n",
      "Token count is too large: pandas-dev__pandas-28634\n",
      "Token count is too large: googleapis__google-cloud-python-4453\n",
      "Token count is too large: tensorflow__models-2725\n",
      "Token count is too large: numpy__numpy-14368\n",
      "Token count is too large: pandas-dev__pandas-18337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3315 examples [04:06, 15.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24430\n",
      "Token count is too large: conan-io__conan-5237\n",
      "Token count is too large: google__jax-353\n",
      "Token count is too large: pandas-dev__pandas-38406\n",
      "Token count is too large: pandas-dev__pandas-4356\n",
      "Token count is too large: conan-io__conan-6152\n",
      "Token count is too large: pandas-dev__pandas-8180\n",
      "Token count is too large: ipython__ipython-4565\n",
      "Token count is too large: apache__airflow-8265\n",
      "Token count is too large: pantsbuild__pants-15611\n",
      "Token count is too large: google__jax-1970\n",
      "Token count is too large: tensorflow__models-5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3318 examples [04:06, 14.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-8054\n",
      "Token count is too large: Qiskit__qiskit-9183\n",
      "Token count is too large: pandas-dev__pandas-5973\n",
      "Token count is too large: pandas-dev__pandas-15974\n",
      "Token count is too large: pandas-dev__pandas-8238\n",
      "Token count is too large: celery__celery-6578\n",
      "Token count is too large: docker__compose-5254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3323 examples [04:06, 17.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4190\n",
      "Token count is too large: apache__airflow-12899\n",
      "Token count is too large: google__jax-175\n",
      "Token count is too large: googleapis__google-cloud-python-7512\n",
      "Token count is too large: mesonbuild__meson-1606\n",
      "Token count is too large: ipython__ipython-1483\n",
      "Token count is too large: gitpython-developers__GitPython-955\n",
      "Token count is too large: pandas-dev__pandas-18997\n",
      "Token count is too large: conda__conda-2566\n",
      "Token count is too large: huggingface__transformers-15900\n",
      "Token count is too large: pandas-dev__pandas-22674\n",
      "Token count is too large: Qiskit__qiskit-4525\n",
      "Token count is too large: huggingface__transformers-9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3326 examples [04:07, 16.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-8340\n",
      "Token count is too large: ipython__ipython-5965\n",
      "Token count is too large: huggingface__transformers-13679\n",
      "Token count is too large: pandas-dev__pandas-3078\n",
      "Token count is too large: Lightning-AI__lightning-2160\n",
      "Token count is too large: googleapis__google-cloud-python-7692\n",
      "Token count is too large: pandas-dev__pandas-34458\n",
      "Token count is too large: wagtail__wagtail-6434\n",
      "Token count is too large: pandas-dev__pandas-19624\n",
      "Token count is too large: pandas-dev__pandas-8663\n",
      "Token count is too large: numpy__numpy-7584\n",
      "Token count is too large: pandas-dev__pandas-39807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3333 examples [04:07, 15.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10726\n",
      "Token count is too large: celery__celery-1834\n",
      "Token count is too large: huggingface__transformers-1055\n",
      "Token count is too large: ray-project__ray-10767\n",
      "Token count is too large: pandas-dev__pandas-8415\n",
      "Token count is too large: PrefectHQ__prefect-1168\n",
      "Token count is too large: huggingface__transformers-21675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3335 examples [04:07, 15.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19066\n",
      "Token count is too large: wagtail__wagtail-637\n",
      "Token count is too large: pandas-dev__pandas-37159\n",
      "Token count is too large: google__jax-201\n",
      "Token count is too large: ytdl-org__youtube-dl-16999\n",
      "Token count is too large: mesonbuild__meson-7069\n",
      "Token count is too large: pandas-dev__pandas-4106\n",
      "Token count is too large: conan-io__conan-4276\n",
      "Token count is too large: Qiskit__qiskit-1554\n",
      "Token count is too large: pandas-dev__pandas-18150\n",
      "Token count is too large: pantsbuild__pants-18787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3337 examples [04:08, 12.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5859\n",
      "Token count is too large: twisted__twisted-11752\n",
      "Token count is too large: pandas-dev__pandas-25588\n",
      "Token count is too large: mesonbuild__meson-3863\n",
      "Token count is too large: numpy__numpy-10615\n",
      "Token count is too large: apache__airflow-20486\n",
      "Token count is too large: pypa__pip-9394\n",
      "Token count is too large: pandas-dev__pandas-3502\n",
      "Token count is too large: pandas-dev__pandas-30491\n",
      "Token count is too large: pandas-dev__pandas-19231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3343 examples [04:08, 14.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-2973\n",
      "Token count is too large: huggingface__transformers-18407\n",
      "Token count is too large: pandas-dev__pandas-31842\n",
      "Token count is too large: docker__compose-4383\n",
      "Token count is too large: apache__airflow-9329\n",
      "Token count is too large: conda__conda-4818\n",
      "Token count is too large: Qiskit__qiskit-4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3350 examples [04:08, 23.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-7930\n",
      "Token count is too large: PrefectHQ__prefect-1653\n",
      "Token count is too large: pypa__pip-2799\n",
      "Token count is too large: conan-io__conan-3439\n",
      "Token count is too large: ytdl-org__youtube-dl-26301\n",
      "Token count is too large: pandas-dev__pandas-35150\n",
      "Token count is too large: mesonbuild__meson-3246\n",
      "Token count is too large: pandas-dev__pandas-35794\n",
      "Token count is too large: pantsbuild__pants-7929\n",
      "Token count is too large: numpy__numpy-6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3353 examples [04:08, 20.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15646\n",
      "Token count is too large: Qiskit__qiskit-1111\n",
      "Token count is too large: ytdl-org__youtube-dl-30713\n",
      "Token count is too large: googleapis__google-cloud-python-8667\n",
      "Token count is too large: google__jax-1525\n",
      "Token count is too large: googleapis__google-cloud-python-9796\n",
      "Token count is too large: pandas-dev__pandas-19926\n",
      "Token count is too large: pandas-dev__pandas-29943\n",
      "Token count is too large: mesonbuild__meson-2933\n",
      "Token count is too large: pandas-dev__pandas-34423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3356 examples [04:08, 20.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-6518\n",
      "Token count is too large: pandas-dev__pandas-5096\n",
      "Token count is too large: pandas-dev__pandas-27716\n",
      "Token count is too large: conan-io__conan-8704\n",
      "Token count is too large: pandas-dev__pandas-26607\n",
      "Token count is too large: pandas-dev__pandas-23036\n",
      "Token count is too large: Qiskit__qiskit-4795\n",
      "Token count is too large: pandas-dev__pandas-28367\n",
      "Token count is too large: ipython__ipython-10863\n",
      "Token count is too large: pandas-dev__pandas-30784\n",
      "Token count is too large: conan-io__conan-2930\n",
      "Token count is too large: pandas-dev__pandas-7428\n",
      "Token count is too large: pandas-dev__pandas-10593\n",
      "Token count is too large: Qiskit__qiskit-9980\n",
      "Token count is too large: Lightning-AI__lightning-1459\n",
      "Token count is too large: numpy__numpy-3626\n",
      "Token count is too large: Qiskit__qiskit-686\n",
      "Token count is too large: pandas-dev__pandas-20968\n",
      "Token count is too large: Qiskit__qiskit-9953\n",
      "Token count is too large: mesonbuild__meson-4214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3364 examples [04:09, 17.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6451\n",
      "Token count is too large: conan-io__conan-9256\n",
      "Token count is too large: ytdl-org__youtube-dl-30676\n",
      "Token count is too large: pandas-dev__pandas-19240\n",
      "Token count is too large: pantsbuild__pants-19314\n",
      "Token count is too large: mesonbuild__meson-1194\n",
      "Token count is too large: pandas-dev__pandas-9659\n",
      "Token count is too large: numpy__numpy-5383\n",
      "Token count is too large: Lightning-AI__lightning-2501\n",
      "Token count is too large: googleapis__google-cloud-python-3705\n",
      "Token count is too large: celery__celery-6452\n",
      "Token count is too large: celery__celery-6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3372 examples [04:09, 22.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6996\n",
      "Token count is too large: pandas-dev__pandas-39374\n",
      "Token count is too large: huggingface__transformers-18470\n",
      "Token count is too large: googleapis__google-cloud-python-3794\n",
      "Token count is too large: pandas-dev__pandas-10370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3375 examples [04:10, 18.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-8567\n",
      "Token count is too large: conda__conda-8611\n",
      "Token count is too large: apache__airflow-13260\n",
      "Token count is too large: ipython__ipython-1855\n",
      "Token count is too large: googleapis__google-cloud-python-3386\n",
      "Token count is too large: ytdl-org__youtube-dl-12696\n",
      "Token count is too large: pandas-dev__pandas-19734\n",
      "Token count is too large: huggingface__transformers-15940\n",
      "Token count is too large: Qiskit__qiskit-2126\n",
      "Token count is too large: PrefectHQ__prefect-1673\n",
      "Token count is too large: pandas-dev__pandas-38109\n",
      "Token count is too large: pandas-dev__pandas-34619\n",
      "Token count is too large: wagtail__wagtail-10131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3382 examples [04:10, 20.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20401\n",
      "Token count is too large: pandas-dev__pandas-8373\n",
      "Token count is too large: ytdl-org__youtube-dl-1216\n",
      "Token count is too large: ray-project__ray-4857\n",
      "Token count is too large: docker__compose-6034\n",
      "Token count is too large: scipy__scipy-5132\n",
      "Token count is too large: Lightning-AI__lightning-2957\n",
      "Token count is too large: Qiskit__qiskit-2049\n",
      "Token count is too large: googleapis__google-cloud-python-8430\n",
      "Token count is too large: pandas-dev__pandas-32700\n",
      "Token count is too large: googleapis__google-cloud-python-7219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3387 examples [04:10, 22.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29395\n",
      "Token count is too large: Qiskit__qiskit-10372\n",
      "Token count is too large: ipython__ipython-1951\n",
      "Token count is too large: numpy__numpy-23269\n",
      "Token count is too large: pandas-dev__pandas-5558\n",
      "Token count is too large: pandas-dev__pandas-18695\n",
      "Token count is too large: twisted__twisted-11720\n",
      "Token count is too large: pandas-dev__pandas-25720\n",
      "Token count is too large: pyca__cryptography-1552\n",
      "Token count is too large: conda__conda-8184\n",
      "Token count is too large: celery__celery-5091\n",
      "Token count is too large: pandas-dev__pandas-39423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3390 examples [04:10, 22.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-793\n",
      "Token count is too large: huggingface__transformers-12024\n",
      "Token count is too large: conda__conda-6585\n",
      "Token count is too large: pandas-dev__pandas-19073\n",
      "Token count is too large: Qiskit__qiskit-1481\n",
      "Token count is too large: pandas-dev__pandas-9123\n",
      "Token count is too large: pandas-dev__pandas-25769\n",
      "Token count is too large: pandas-dev__pandas-38486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3393 examples [04:10, 21.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34955\n",
      "Token count is too large: pyca__cryptography-1384\n",
      "Token count is too large: apache__airflow-17210\n",
      "Token count is too large: pandas-dev__pandas-38247\n",
      "Token count is too large: pandas-dev__pandas-11596\n",
      "Token count is too large: huggingface__transformers-17936\n",
      "Token count is too large: conda__conda-7783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3397 examples [04:11, 19.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: PrefectHQ__prefect-205\n",
      "Token count is too large: apache__airflow-9861\n",
      "Token count is too large: numpy__numpy-8827\n",
      "Token count is too large: pandas-dev__pandas-38626\n",
      "Token count is too large: pandas-dev__pandas-9257\n",
      "Token count is too large: celery__celery-6791\n",
      "Token count is too large: Lightning-AI__lightning-74\n",
      "Token count is too large: conan-io__conan-2794\n",
      "Token count is too large: ipython__ipython-1121\n",
      "Token count is too large: pantsbuild__pants-14959\n",
      "Token count is too large: googleapis__google-cloud-python-835\n",
      "Token count is too large: pantsbuild__pants-16956\n",
      "Token count is too large: google__jax-922\n",
      "Token count is too large: pandas-dev__pandas-23685\n",
      "Token count is too large: Lightning-AI__lightning-2632\n",
      "Token count is too large: scipy__scipy-3709\n",
      "Token count is too large: mesonbuild__meson-5683\n",
      "Token count is too large: docker__compose-5101\n",
      "Token count is too large: pypa__pip-7747\n",
      "Token count is too large: conan-io__conan-5064\n",
      "Token count is too large: docker__compose-3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3403 examples [04:11, 13.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25129\n",
      "Token count is too large: ray-project__ray-3872\n",
      "Token count is too large: pandas-dev__pandas-7712\n",
      "Token count is too large: pandas-dev__pandas-24467\n",
      "Token count is too large: mesonbuild__meson-6065\n",
      "Token count is too large: pandas-dev__pandas-31524\n",
      "Token count is too large: mesonbuild__meson-5905\n",
      "Token count is too large: huggingface__transformers-25735\n",
      "Token count is too large: mesonbuild__meson-11690\n",
      "Token count is too large: googleapis__google-cloud-python-7697\n",
      "Token count is too large: pandas-dev__pandas-33954\n",
      "Token count is too large: pantsbuild__pants-5150\n",
      "Token count is too large: PrefectHQ__prefect-2386\n",
      "Token count is too large: pandas-dev__pandas-21291\n",
      "Token count is too large: conan-io__conan-7309\n",
      "Token count is too large: scipy__scipy-5782\n",
      "Token count is too large: pantsbuild__pants-16499\n",
      "Token count is too large: Qiskit__qiskit-6909\n",
      "Token count is too large: pandas-dev__pandas-20999\n",
      "Token count is too large: huggingface__transformers-17064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3405 examples [04:12,  9.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-3075\n",
      "Token count is too large: pandas-dev__pandas-9793\n",
      "Token count is too large: pandas-dev__pandas-7007\n",
      "Token count is too large: pandas-dev__pandas-11809\n",
      "Token count is too large: PrefectHQ__prefect-1014\n",
      "Token count is too large: wagtail__wagtail-957\n",
      "Token count is too large: docker__compose-3598\n",
      "There was an error processing\n",
      "Token count is too large: conda__conda-5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3407 examples [04:12,  8.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-21997\n",
      "Token count is too large: pandas-dev__pandas-4838\n",
      "Token count is too large: conda__conda-11215\n",
      "Token count is too large: pandas-dev__pandas-39071\n",
      "Token count is too large: Lightning-AI__lightning-786\n",
      "Token count is too large: conda__conda-5122\n",
      "Token count is too large: tiangolo__fastapi-681\n",
      "Token count is too large: google__jax-1882\n",
      "Token count is too large: conda__conda-6652\n",
      "Token count is too large: pandas-dev__pandas-34012\n",
      "Token count is too large: PrefectHQ__prefect-2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3409 examples [04:12,  9.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11303\n",
      "Token count is too large: ipython__ipython-7006\n",
      "Token count is too large: numpy__numpy-4792\n",
      "Token count is too large: conda__conda-4370\n",
      "Token count is too large: ipython__ipython-618\n",
      "Token count is too large: apache__airflow-27828\n",
      "Token count is too large: Qiskit__qiskit-6828\n",
      "Token count is too large: google__jax-2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3411 examples [04:12,  8.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6378\n",
      "Token count is too large: pandas-dev__pandas-13767\n",
      "Token count is too large: Qiskit__qiskit-2228\n",
      "Token count is too large: pantsbuild__pants-16717\n",
      "Token count is too large: pandas-dev__pandas-10061\n",
      "Token count is too large: pandas-dev__pandas-22826\n",
      "Token count is too large: wagtail__wagtail-1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3414 examples [04:13,  8.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30584\n",
      "Token count is too large: ray-project__ray-10097\n",
      "Token count is too large: pandas-dev__pandas-17077\n",
      "Token count is too large: googleapis__google-cloud-python-5987\n",
      "Token count is too large: pandas-dev__pandas-16543\n",
      "Token count is too large: googleapis__google-cloud-python-3318\n",
      "Token count is too large: pyca__cryptography-2541\n",
      "Token count is too large: huggingface__transformers-9749\n",
      "Token count is too large: pandas-dev__pandas-4950\n",
      "Token count is too large: pandas-dev__pandas-30945\n",
      "Token count is too large: numpy__numpy-18695\n",
      "Token count is too large: jupyterlab__jupyterlab-9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3415 examples [04:13,  8.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5631\n",
      "Token count is too large: pypa__pip-10249\n",
      "Token count is too large: pandas-dev__pandas-38248\n",
      "Token count is too large: explosion__spaCy-2135\n",
      "Token count is too large: numpy__numpy-13337\n",
      "Token count is too large: Lightning-AI__lightning-2505\n",
      "Token count is too large: mesonbuild__meson-5739\n",
      "Token count is too large: celery__celery-3730\n",
      "Token count is too large: PrefectHQ__prefect-1782\n",
      "Token count is too large: apache__airflow-31415\n",
      "Token count is too large: Qiskit__qiskit-5245\n",
      "Token count is too large: docker__compose-3340\n",
      "Token count is too large: pandas-dev__pandas-30691\n",
      "Token count is too large: pandas-dev__pandas-23072\n",
      "Token count is too large: ytdl-org__youtube-dl-10524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3420 examples [04:13, 14.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: PrefectHQ__prefect-2089\n",
      "Token count is too large: gitpython-developers__GitPython-645\n",
      "Token count is too large: Qiskit__qiskit-9665\n",
      "Token count is too large: huggingface__transformers-12975\n",
      "Token count is too large: PrefectHQ__prefect-239\n",
      "Token count is too large: numpy__numpy-7659\n",
      "Token count is too large: pandas-dev__pandas-37827\n",
      "Token count is too large: pandas-dev__pandas-26466\n",
      "Token count is too large: pantsbuild__pants-18025\n",
      "Token count is too large: pandas-dev__pandas-37439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3423 examples [04:13, 12.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-20267\n",
      "Token count is too large: wagtail__wagtail-554\n",
      "Token count is too large: googleapis__google-cloud-python-11578\n",
      "Token count is too large: pantsbuild__pants-11793\n",
      "Token count is too large: ytdl-org__youtube-dl-29187\n",
      "Token count is too large: pandas-dev__pandas-3055\n",
      "Token count is too large: google__jax-516\n",
      "Token count is too large: numpy__numpy-22679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3425 examples [04:14, 12.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38405\n",
      "Token count is too large: Qiskit__qiskit-2212\n",
      "Token count is too large: google__jax-682\n",
      "Token count is too large: huggingface__transformers-15972\n",
      "Token count is too large: pandas-dev__pandas-24953\n",
      "Token count is too large: Qiskit__qiskit-7255\n",
      "Token count is too large: pandas-dev__pandas-24446\n",
      "Token count is too large: pandas-dev__pandas-27368\n",
      "Token count is too large: docker__compose-6342\n",
      "Token count is too large: docker__compose-4370\n",
      "Token count is too large: mesonbuild__meson-7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3431 examples [04:14, 16.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16478\n",
      "Token count is too large: jupyterlab__jupyterlab-2836\n",
      "Token count is too large: mesonbuild__meson-1023\n",
      "Token count is too large: huggingface__transformers-14102\n",
      "Token count is too large: wagtail__wagtail-6183\n",
      "Token count is too large: pandas-dev__pandas-36149\n",
      "Token count is too large: mesonbuild__meson-5196\n",
      "Token count is too large: docker__compose-6925\n",
      "Token count is too large: Qiskit__qiskit-1115\n",
      "Token count is too large: ipython__ipython-1717\n",
      "Token count is too large: conan-io__conan-5623\n",
      "Token count is too large: pandas-dev__pandas-29405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3436 examples [04:14, 12.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31461\n",
      "Token count is too large: googleapis__google-cloud-python-6084\n",
      "Token count is too large: ray-project__ray-8628\n",
      "Token count is too large: pandas-dev__pandas-8988\n",
      "Token count is too large: Qiskit__qiskit-5702\n",
      "Token count is too large: mesonbuild__meson-3069\n",
      "Token count is too large: ipython__ipython-13914\n",
      "Token count is too large: Lightning-AI__lightning-2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3440 examples [04:15, 13.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-4462\n",
      "Token count is too large: scipy__scipy-3927\n",
      "Token count is too large: huggingface__transformers-22078\n",
      "Token count is too large: ray-project__ray-2283\n",
      "Token count is too large: pandas-dev__pandas-38492\n",
      "Token count is too large: conan-io__conan-4313\n",
      "Token count is too large: pandas-dev__pandas-25612\n",
      "Token count is too large: googleapis__google-cloud-python-287\n",
      "Token count is too large: googleapis__google-cloud-python-5611\n",
      "Token count is too large: huggingface__transformers-15843\n",
      "Token count is too large: numpy__numpy-18070\n",
      "Token count is too large: pandas-dev__pandas-5998\n",
      "Token count is too large: ipython__ipython-1538\n",
      "Token count is too large: numpy__numpy-8988\n",
      "Token count is too large: scipy__scipy-3928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3445 examples [04:15, 14.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23208\n",
      "Token count is too large: pandas-dev__pandas-27173\n",
      "Token count is too large: huggingface__transformers-564\n",
      "Token count is too large: ipython__ipython-5221\n",
      "Token count is too large: ytdl-org__youtube-dl-2812\n",
      "Token count is too large: celery__celery-3997\n",
      "Token count is too large: numpy__numpy-11720\n",
      "Token count is too large: pandas-dev__pandas-16879\n",
      "Token count is too large: numpy__numpy-8555\n",
      "Token count is too large: pandas-dev__pandas-4456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3449 examples [04:15, 13.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27580\n",
      "Token count is too large: conda__conda-2705\n",
      "Token count is too large: apache__airflow-30432\n",
      "Token count is too large: conan-io__conan-2765\n",
      "Token count is too large: conda__conda-4637\n",
      "Token count is too large: numpy__numpy-3638\n",
      "Token count is too large: conan-io__conan-11655\n",
      "Token count is too large: pandas-dev__pandas-25914\n",
      "Token count is too large: pyca__cryptography-4819\n",
      "Token count is too large: numpy__numpy-8008\n",
      "Token count is too large: numpy__numpy-14346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3453 examples [04:15, 16.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-12906\n",
      "Token count is too large: conda__conda-8907\n",
      "Token count is too large: huggingface__transformers-17951\n",
      "Token count is too large: pandas-dev__pandas-21281\n",
      "Token count is too large: twisted__twisted-11697\n",
      "Token count is too large: ray-project__ray-9663\n",
      "Token count is too large: Qiskit__qiskit-2299\n",
      "Token count is too large: huggingface__transformers-6903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3459 examples [04:16, 18.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-5417\n",
      "Token count is too large: mesonbuild__meson-1058\n",
      "Token count is too large: pandas-dev__pandas-6078\n",
      "Token count is too large: pypa__pip-6655\n",
      "Token count is too large: pantsbuild__pants-4381\n",
      "Token count is too large: mesonbuild__meson-8812\n",
      "Token count is too large: docker__compose-5132\n",
      "Token count is too large: mesonbuild__meson-4820\n",
      "Token count is too large: open-mmlab__mmdetection-3497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3466 examples [04:16, 25.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35272\n",
      "Token count is too large: pandas-dev__pandas-22883\n",
      "Token count is too large: jupyterlab__jupyterlab-8921\n",
      "Token count is too large: pandas-dev__pandas-19481\n",
      "Token count is too large: googleapis__google-cloud-python-2682\n",
      "Token count is too large: google__jax-2804\n",
      "Token count is too large: google__jax-1378\n",
      "Token count is too large: mesonbuild__meson-1444\n",
      "Token count is too large: Qiskit__qiskit-3391\n",
      "Token count is too large: mesonbuild__meson-10540\n",
      "Token count is too large: mesonbuild__meson-3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3472 examples [04:16, 30.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22196\n",
      "Token count is too large: Qiskit__qiskit-9543\n",
      "Token count is too large: numpy__numpy-6643\n",
      "Token count is too large: PrefectHQ__prefect-1979\n",
      "Token count is too large: conan-io__conan-132\n",
      "Token count is too large: pandas-dev__pandas-27128\n",
      "Token count is too large: Lightning-AI__lightning-1729\n",
      "Token count is too large: pandas-dev__pandas-37661\n",
      "Token count is too large: conda__conda-2547\n",
      "Token count is too large: ray-project__ray-4735\n",
      "Token count is too large: ipython__ipython-11806\n",
      "Token count is too large: google__jax-82\n",
      "Token count is too large: huggingface__transformers-7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3476 examples [04:16, 25.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-6588\n",
      "Token count is too large: Qiskit__qiskit-2414\n",
      "Token count is too large: ipython__ipython-1652\n",
      "Token count is too large: explosion__spaCy-3080\n",
      "Token count is too large: Lightning-AI__lightning-1016\n",
      "Token count is too large: pypa__pip-3539\n",
      "Token count is too large: pandas-dev__pandas-20543\n",
      "Token count is too large: ipython__ipython-9617\n",
      "Token count is too large: ytdl-org__youtube-dl-13605\n",
      "Token count is too large: pandas-dev__pandas-36690\n",
      "Token count is too large: ytdl-org__youtube-dl-10382\n",
      "Token count is too large: pandas-dev__pandas-5606\n",
      "Token count is too large: jupyterlab__jupyterlab-2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3480 examples [04:16, 21.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-18118\n",
      "Token count is too large: numpy__numpy-22391\n",
      "Token count is too large: pantsbuild__pants-13653\n",
      "Token count is too large: apache__airflow-16601\n",
      "Token count is too large: Lightning-AI__lightning-3344\n",
      "Token count is too large: pandas-dev__pandas-6845\n",
      "Token count is too large: ytdl-org__youtube-dl-16707\n",
      "Token count is too large: mesonbuild__meson-3777\n",
      "Token count is too large: numpy__numpy-7879\n",
      "Token count is too large: pandas-dev__pandas-17831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3484 examples [04:17, 22.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5103\n",
      "Token count is too large: open-mmlab__mmdetection-6632\n",
      "Token count is too large: numpy__numpy-8497\n",
      "Token count is too large: DataDog__integrations-core-10093\n",
      "Token count is too large: apache__airflow-26554\n",
      "Token count is too large: open-mmlab__mmdetection-9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3488 examples [04:17, 16.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-2223\n",
      "Token count is too large: pandas-dev__pandas-39751\n",
      "Token count is too large: numpy__numpy-6347\n",
      "Token count is too large: pandas-dev__pandas-18258\n",
      "Token count is too large: pandas-dev__pandas-38120\n",
      "Token count is too large: pandas-dev__pandas-21036\n",
      "Token count is too large: pypa__pip-2169\n",
      "Token count is too large: pandas-dev__pandas-34435\n",
      "Token count is too large: open-mmlab__mmdetection-7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3490 examples [04:17, 13.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: open-mmlab__mmdetection-4378\n",
      "Token count is too large: mesonbuild__meson-2260\n",
      "Token count is too large: pandas-dev__pandas-19427\n",
      "Token count is too large: conan-io__conan-3718\n",
      "Token count is too large: pandas-dev__pandas-11248\n",
      "Token count is too large: pandas-dev__pandas-22108\n",
      "Token count is too large: docker__compose-2620\n",
      "Token count is too large: pandas-dev__pandas-23031\n",
      "Token count is too large: conda__conda-5201\n",
      "Token count is too large: googleapis__google-cloud-python-3472\n",
      "Token count is too large: pandas-dev__pandas-8410\n",
      "Token count is too large: pandas-dev__pandas-33553\n",
      "Token count is too large: pantsbuild__pants-15292\n",
      "Token count is too large: wagtail__wagtail-9946\n",
      "Token count is too large: googleapis__google-cloud-python-6706\n",
      "Token count is too large: pandas-dev__pandas-28748\n",
      "Token count is too large: huggingface__transformers-12449\n",
      "Token count is too large: huggingface__transformers-10688\n",
      "Token count is too large: huggingface__transformers-24618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3492 examples [04:18,  8.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37310\n",
      "Token count is too large: googleapis__google-cloud-python-9231\n",
      "Token count is too large: numpy__numpy-17141\n",
      "Token count is too large: Qiskit__qiskit-7477\n",
      "Token count is too large: pandas-dev__pandas-37761\n",
      "Token count is too large: DataDog__integrations-core-698\n",
      "Token count is too large: Qiskit__qiskit-6700\n",
      "Token count is too large: pandas-dev__pandas-18882\n",
      "Token count is too large: huggingface__transformers-19073\n",
      "Token count is too large: googleapis__google-cloud-python-7483\n",
      "Token count is too large: apache__airflow-12949\n",
      "Token count is too large: apache__airflow-11241\n",
      "Token count is too large: huggingface__transformers-3354\n",
      "Token count is too large: mesonbuild__meson-1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3496 examples [04:18, 11.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26063\n",
      "Token count is too large: pyca__cryptography-4504\n",
      "Token count is too large: pantsbuild__pants-13178\n",
      "Token count is too large: pandas-dev__pandas-17736\n",
      "Token count is too large: huggingface__transformers-7034\n",
      "Token count is too large: pandas-dev__pandas-23593\n",
      "Token count is too large: pandas-dev__pandas-28739\n",
      "Token count is too large: jupyterlab__jupyterlab-3781\n",
      "Token count is too large: googleapis__google-cloud-python-11203\n",
      "Token count is too large: conda__conda-11255\n",
      "Token count is too large: pandas-dev__pandas-7099\n",
      "Token count is too large: huggingface__transformers-16812\n",
      "Token count is too large: pantsbuild__pants-5033\n",
      "Token count is too large: pantsbuild__pants-5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3500 examples [04:18, 11.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-1633\n",
      "Token count is too large: numpy__numpy-22002\n",
      "Token count is too large: huggingface__transformers-18119\n",
      "Token count is too large: mesonbuild__meson-8568\n",
      "Token count is too large: pantsbuild__pants-12399\n",
      "Token count is too large: pandas-dev__pandas-32520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3502 examples [04:19,  8.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21614\n",
      "Token count is too large: ipython__ipython-9551\n",
      "Token count is too large: pandas-dev__pandas-5084\n",
      "Token count is too large: conda__conda-5252\n",
      "Token count is too large: pandas-dev__pandas-36297\n",
      "Token count is too large: googleapis__google-cloud-python-11371\n",
      "Token count is too large: pandas-dev__pandas-37129\n",
      "Token count is too large: PrefectHQ__prefect-2825\n",
      "Token count is too large: Lightning-AI__lightning-2200\n",
      "Token count is too large: docker__compose-5699\n",
      "Token count is too large: google__jax-1025\n",
      "Token count is too large: numpy__numpy-9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3507 examples [04:19, 12.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-2266\n",
      "Token count is too large: googleapis__google-cloud-python-8734\n",
      "Token count is too large: google__jax-1395\n",
      "Token count is too large: huggingface__transformers-22293\n",
      "Token count is too large: googleapis__google-cloud-python-5217\n",
      "Token count is too large: open-mmlab__mmdetection-4282\n",
      "Token count is too large: pandas-dev__pandas-6953\n",
      "Token count is too large: mesonbuild__meson-3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3510 examples [04:19, 13.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23406\n",
      "Token count is too large: huggingface__transformers-19376\n",
      "Token count is too large: PrefectHQ__prefect-1393\n",
      "Token count is too large: pandas-dev__pandas-11714\n",
      "Token count is too large: pandas-dev__pandas-5050\n",
      "Token count is too large: googleapis__google-cloud-python-9245\n",
      "Token count is too large: googleapis__google-cloud-python-8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3513 examples [04:19, 12.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2166\n",
      "Token count is too large: pandas-dev__pandas-17633\n",
      "Token count is too large: mesonbuild__meson-11183\n",
      "Token count is too large: pandas-dev__pandas-21195\n",
      "Token count is too large: conan-io__conan-4446\n",
      "Token count is too large: conan-io__conan-6042\n",
      "Token count is too large: docker__compose-5250\n",
      "Token count is too large: googleapis__google-cloud-python-1844\n",
      "Token count is too large: pandas-dev__pandas-7272\n",
      "Token count is too large: apache__airflow-18244\n",
      "Token count is too large: pypa__pip-3626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3516 examples [04:20, 14.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-6618\n",
      "Token count is too large: conda__conda-5200\n",
      "Token count is too large: Qiskit__qiskit-6541\n",
      "Token count is too large: pantsbuild__pants-13714\n",
      "Token count is too large: mesonbuild__meson-8071\n",
      "Token count is too large: pandas-dev__pandas-18293\n",
      "Token count is too large: ipython__ipython-6902\n",
      "Token count is too large: open-mmlab__mmdetection-6079\n",
      "Token count is too large: googleapis__google-cloud-python-10106\n",
      "Token count is too large: google__jax-1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3523 examples [04:20, 16.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4756\n",
      "Token count is too large: pandas-dev__pandas-26431\n",
      "Token count is too large: pandas-dev__pandas-26170\n",
      "Token count is too large: pantsbuild__pants-15686\n",
      "Token count is too large: docker__compose-5223\n",
      "Token count is too large: ytdl-org__youtube-dl-2700\n",
      "Token count is too large: ray-project__ray-9141\n",
      "Token count is too large: huggingface__transformers-23891\n",
      "Token count is too large: PrefectHQ__prefect-865\n",
      "Token count is too large: ytdl-org__youtube-dl-6731\n",
      "Token count is too large: ipython__ipython-1020\n",
      "Token count is too large: pandas-dev__pandas-27934\n",
      "Token count is too large: googleapis__google-cloud-python-5699\n",
      "Token count is too large: pantsbuild__pants-12367\n",
      "Token count is too large: Qiskit__qiskit-6008\n",
      "Token count is too large: ipython__ipython-12926\n",
      "Token count is too large: Lightning-AI__lightning-2828\n",
      "Token count is too large: numpy__numpy-15229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3529 examples [04:20, 16.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-9813\n",
      "Token count is too large: numpy__numpy-3855\n",
      "Token count is too large: pandas-dev__pandas-14211\n",
      "Token count is too large: pandas-dev__pandas-30519\n",
      "Token count is too large: pandas-dev__pandas-22543\n",
      "Token count is too large: mesonbuild__meson-7306\n",
      "Token count is too large: pandas-dev__pandas-22971\n",
      "Token count is too large: numpy__numpy-8384\n",
      "Token count is too large: pandas-dev__pandas-16247\n",
      "Token count is too large: pandas-dev__pandas-3914\n",
      "Token count is too large: googleapis__google-cloud-python-9064\n",
      "Token count is too large: numpy__numpy-19642\n",
      "Token count is too large: Qiskit__qiskit-2909\n",
      "Token count is too large: numpy__numpy-14623\n",
      "Token count is too large: conan-io__conan-13729\n",
      "Token count is too large: conan-io__conan-11348\n",
      "Token count is too large: pandas-dev__pandas-39497\n",
      "Token count is too large: numpy__numpy-19110\n",
      "Token count is too large: pantsbuild__pants-15113\n",
      "Token count is too large: pandas-dev__pandas-36790\n",
      "Token count is too large: docker__compose-3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3532 examples [04:21, 13.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7619\n",
      "Token count is too large: pypa__pip-8839\n",
      "Token count is too large: celery__celery-7373\n",
      "Token count is too large: apache__airflow-15731\n",
      "Token count is too large: dagster-io__dagster-8874\n",
      "Token count is too large: Qiskit__qiskit-7319\n",
      "Token count is too large: pandas-dev__pandas-19780\n",
      "Token count is too large: pantsbuild__pants-14961\n",
      "Token count is too large: pandas-dev__pandas-19058\n",
      "Token count is too large: pandas-dev__pandas-4926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3535 examples [04:21, 12.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-18225\n",
      "Token count is too large: celery__celery-6741\n",
      "Token count is too large: pandas-dev__pandas-34933\n",
      "Token count is too large: Qiskit__qiskit-4579\n",
      "Token count is too large: pypa__pip-7534\n",
      "Token count is too large: mesonbuild__meson-2017\n",
      "Token count is too large: ray-project__ray-10531\n",
      "Token count is too large: pandas-dev__pandas-16442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3542 examples [04:21, 18.37 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5432\n",
      "Token count is too large: googleapis__google-cloud-python-10081\n",
      "Token count is too large: mesonbuild__meson-7955\n",
      "Token count is too large: conda__conda-6671\n",
      "Token count is too large: ipython__ipython-12244\n",
      "Token count is too large: pandas-dev__pandas-3645\n",
      "Token count is too large: pandas-dev__pandas-27103\n",
      "Token count is too large: Qiskit__qiskit-3285\n",
      "Token count is too large: Qiskit__qiskit-8047\n",
      "Token count is too large: pantsbuild__pants-14352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3545 examples [04:21, 15.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15831\n",
      "Token count is too large: jupyterlab__jupyterlab-7125\n",
      "Token count is too large: pandas-dev__pandas-7525\n",
      "Token count is too large: numpy__numpy-17456\n",
      "Token count is too large: Qiskit__qiskit-308\n",
      "Token count is too large: googleapis__google-cloud-python-4127\n",
      "Token count is too large: pandas-dev__pandas-25584\n",
      "Token count is too large: pandas-dev__pandas-18401\n",
      "Token count is too large: conda__conda-6778\n",
      "Token count is too large: pandas-dev__pandas-38657\n",
      "Token count is too large: mesonbuild__meson-1011\n",
      "Token count is too large: ipython__ipython-1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3549 examples [04:22, 18.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9392\n",
      "Token count is too large: conda__conda-5103\n",
      "Token count is too large: docker__compose-4817\n",
      "Token count is too large: Lightning-AI__lightning-832\n",
      "Token count is too large: pandas-dev__pandas-34421\n",
      "Token count is too large: pandas-dev__pandas-30467\n",
      "Token count is too large: pandas-dev__pandas-24155\n",
      "Token count is too large: pandas-dev__pandas-9899\n",
      "Token count is too large: ipython__ipython-5067\n",
      "Token count is too large: PrefectHQ__prefect-225\n",
      "Token count is too large: pandas-dev__pandas-9102\n",
      "Token count is too large: pandas-dev__pandas-18591\n",
      "Token count is too large: mesonbuild__meson-4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3558 examples [04:22, 20.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24137\n",
      "Token count is too large: conan-io__conan-5423\n",
      "Token count is too large: pantsbuild__pants-15505\n",
      "Token count is too large: huggingface__transformers-4884\n",
      "Token count is too large: pandas-dev__pandas-6177\n",
      "Token count is too large: mesonbuild__meson-5173\n",
      "Token count is too large: mesonbuild__meson-3436\n",
      "Token count is too large: pypa__pip-6089\n",
      "Token count is too large: mesonbuild__meson-7484\n",
      "Token count is too large: celery__celery-5399\n",
      "Token count is too large: mesonbuild__meson-3770\n",
      "Token count is too large: pandas-dev__pandas-20860\n",
      "Token count is too large: conan-io__conan-6139\n",
      "Token count is too large: Lightning-AI__lightning-2221\n",
      "Token count is too large: huggingface__transformers-19722\n",
      "Token count is too large: pypa__pip-11949\n",
      "Token count is too large: pypa__pip-7931\n",
      "Token count is too large: pandas-dev__pandas-22304\n",
      "Token count is too large: mesonbuild__meson-5143\n",
      "Token count is too large: mesonbuild__meson-6341\n",
      "Token count is too large: mesonbuild__meson-4825\n",
      "Token count is too large: apache__airflow-24673\n",
      "Token count is too large: pandas-dev__pandas-33751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3563 examples [04:22, 14.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24635\n",
      "Token count is too large: pandas-dev__pandas-33062\n",
      "Token count is too large: ipython__ipython-3606\n",
      "Token count is too large: pandas-dev__pandas-37644\n",
      "Token count is too large: wagtail__wagtail-598\n",
      "Token count is too large: google__jax-2136\n",
      "Token count is too large: numpy__numpy-11777\n",
      "Token count is too large: pandas-dev__pandas-17310\n",
      "Token count is too large: docker__compose-7411\n",
      "Token count is too large: conda__conda-7191\n",
      "Token count is too large: ytdl-org__youtube-dl-10996\n",
      "Token count is too large: celery__celery-5168\n",
      "Token count is too large: open-mmlab__mmdetection-4939\n",
      "Token count is too large: pandas-dev__pandas-16951\n",
      "Token count is too large: google__jax-2753\n",
      "Token count is too large: celery__celery-1970\n",
      "Token count is too large: pandas-dev__pandas-19281\n",
      "Token count is too large: pantsbuild__pants-16911\n",
      "Token count is too large: PrefectHQ__prefect-1703\n",
      "Token count is too large: Qiskit__qiskit-1200\n",
      "Token count is too large: pandas-dev__pandas-18681\n",
      "Token count is too large: pandas-dev__pandas-28875\n",
      "Token count is too large: mesonbuild__meson-5997\n",
      "Token count is too large: wagtail__wagtail-6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3566 examples [04:23, 11.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1153\n",
      "Token count is too large: huggingface__transformers-7641\n",
      "Token count is too large: Qiskit__qiskit-1522\n",
      "Token count is too large: pypa__pip-3008\n",
      "Token count is too large: pantsbuild__pants-12337\n",
      "Token count is too large: huggingface__transformers-19750\n",
      "Token count is too large: conda__conda-12612\n",
      "Token count is too large: Qiskit__qiskit-3235\n",
      "Token count is too large: mesonbuild__meson-225\n",
      "Token count is too large: pyca__cryptography-2978\n",
      "Token count is too large: Lightning-AI__lightning-55\n",
      "Token count is too large: ray-project__ray-2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3570 examples [04:23, 13.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-6726\n",
      "Token count is too large: googleapis__google-cloud-python-7046\n",
      "Token count is too large: mesonbuild__meson-190\n",
      "Token count is too large: Lightning-AI__lightning-752\n",
      "Token count is too large: pandas-dev__pandas-15929\n",
      "Token count is too large: googleapis__google-cloud-python-2803\n",
      "Token count is too large: pandas-dev__pandas-3831\n",
      "Token count is too large: numpy__numpy-17955\n",
      "Token count is too large: apache__airflow-13308\n",
      "Token count is too large: pandas-dev__pandas-25503\n",
      "Token count is too large: conan-io__conan-5044\n",
      "Token count is too large: huggingface__transformers-23126\n",
      "Token count is too large: pandas-dev__pandas-27653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3572 examples [04:24,  9.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21624\n",
      "Token count is too large: numpy__numpy-8016\n",
      "Token count is too large: Lightning-AI__lightning-405\n",
      "Token count is too large: mesonbuild__meson-10092\n",
      "Token count is too large: apache__airflow-16414\n",
      "Token count is too large: conda__conda-6609\n",
      "Token count is too large: pandas-dev__pandas-37823\n",
      "Token count is too large: pandas-dev__pandas-25402\n",
      "Token count is too large: googleapis__google-cloud-python-3245\n",
      "Token count is too large: dagster-io__dagster-9666\n",
      "Token count is too large: pypa__pip-9945\n",
      "Token count is too large: pandas-dev__pandas-7565\n",
      "Token count is too large: pandas-dev__pandas-22626\n",
      "Token count is too large: Qiskit__qiskit-1857\n",
      "Token count is too large: pandas-dev__pandas-39475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3581 examples [04:24, 17.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26736\n",
      "Token count is too large: conda__conda-7067\n",
      "Token count is too large: ytdl-org__youtube-dl-30675\n",
      "Token count is too large: huggingface__transformers-7186\n",
      "Token count is too large: Qiskit__qiskit-7656\n",
      "Token count is too large: jupyterlab__jupyterlab-9051\n",
      "Token count is too large: conan-io__conan-12307\n",
      "Token count is too large: Qiskit__qiskit-1651\n",
      "Token count is too large: huggingface__transformers-19254\n",
      "Token count is too large: pandas-dev__pandas-5270\n",
      "Token count is too large: docker__compose-5679\n",
      "Token count is too large: google__jax-574\n",
      "Token count is too large: Qiskit__qiskit-9427\n",
      "Token count is too large: pandas-dev__pandas-14230\n",
      "Token count is too large: ray-project__ray-8802\n",
      "Token count is too large: conda__conda-5422\n",
      "Token count is too large: pandas-dev__pandas-34396\n",
      "Token count is too large: pandas-dev__pandas-25712\n",
      "Token count is too large: huggingface__transformers-23976\n",
      "Token count is too large: pantsbuild__pants-13403\n",
      "Token count is too large: pyca__cryptography-1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3586 examples [04:24, 15.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-21851\n",
      "Token count is too large: mesonbuild__meson-5277\n",
      "Token count is too large: pantsbuild__pants-10409\n",
      "Token count is too large: pandas-dev__pandas-27102\n",
      "Token count is too large: celery__celery-6142\n",
      "Token count is too large: numpy__numpy-12064\n",
      "Token count is too large: open-mmlab__mmdetection-6512\n",
      "Token count is too large: pandas-dev__pandas-31493\n",
      "Token count is too large: dagster-io__dagster-10446\n",
      "Token count is too large: pandas-dev__pandas-3017\n",
      "Token count is too large: googleapis__google-cloud-python-11347\n",
      "Token count is too large: pandas-dev__pandas-36290\n",
      "Token count is too large: conan-io__conan-4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3589 examples [04:25, 11.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-17546\n",
      "Token count is too large: ray-project__ray-506\n",
      "Token count is too large: pandas-dev__pandas-7924\n",
      "Token count is too large: pandas-dev__pandas-16996\n",
      "Token count is too large: pypa__pip-11052\n",
      "Token count is too large: pyca__cryptography-3329\n",
      "Token count is too large: apache__airflow-18953\n",
      "Token count is too large: pandas-dev__pandas-23384\n",
      "Token count is too large: conan-io__conan-6214\n",
      "Token count is too large: pandas-dev__pandas-39023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3596 examples [04:25, 15.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26242\n",
      "Token count is too large: pandas-dev__pandas-10527\n",
      "Token count is too large: Qiskit__qiskit-6588\n",
      "Token count is too large: pandas-dev__pandas-10386\n",
      "Token count is too large: huggingface__transformers-12938\n",
      "Token count is too large: pandas-dev__pandas-7424\n",
      "Token count is too large: docker__compose-2132\n",
      "Token count is too large: numpy__numpy-12447\n",
      "Token count is too large: pandas-dev__pandas-5321\n",
      "Token count is too large: ipython__ipython-11354\n",
      "Token count is too large: pyca__cryptography-876\n",
      "Token count is too large: ipython__ipython-5784\n",
      "Token count is too large: huggingface__transformers-8878\n",
      "Token count is too large: Qiskit__qiskit-8702\n",
      "Token count is too large: docker__compose-5910\n",
      "Token count is too large: huggingface__transformers-21847\n",
      "Token count is too large: Qiskit__qiskit-1629\n",
      "Token count is too large: Qiskit__qiskit-3873\n",
      "Token count is too large: ytdl-org__youtube-dl-29698\n",
      "Token count is too large: docker__compose-6359\n",
      "Token count is too large: pandas-dev__pandas-28102\n",
      "Token count is too large: huggingface__transformers-21701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3599 examples [04:25, 12.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8695\n",
      "Token count is too large: mesonbuild__meson-919\n",
      "Token count is too large: pandas-dev__pandas-33846\n",
      "Token count is too large: apache__airflow-9170\n",
      "Token count is too large: googleapis__google-cloud-python-7060\n",
      "Token count is too large: pandas-dev__pandas-18462\n",
      "Token count is too large: pandas-dev__pandas-22886\n",
      "Token count is too large: ytdl-org__youtube-dl-6768\n",
      "Token count is too large: pandas-dev__pandas-7457\n",
      "Token count is too large: docker__compose-5237\n",
      "Token count is too large: mesonbuild__meson-7392\n",
      "Token count is too large: huggingface__transformers-8848\n",
      "Token count is too large: wagtail__wagtail-3983\n",
      "Token count is too large: Qiskit__qiskit-2157\n",
      "Token count is too large: conda__conda-7216\n",
      "Token count is too large: mesonbuild__meson-9994\n",
      "Token count is too large: mesonbuild__meson-10289\n",
      "Token count is too large: pandas-dev__pandas-31046\n",
      "Token count is too large: mesonbuild__meson-9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3602 examples [04:25, 13.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18576\n",
      "Token count is too large: pandas-dev__pandas-31946\n",
      "Token count is too large: apache__airflow-13318\n",
      "Token count is too large: Lightning-AI__lightning-1505\n",
      "Token count is too large: pantsbuild__pants-8484\n",
      "Token count is too large: pandas-dev__pandas-30394\n",
      "Token count is too large: pandas-dev__pandas-28165\n",
      "Token count is too large: mesonbuild__meson-1002\n",
      "Token count is too large: pandas-dev__pandas-26362\n",
      "Token count is too large: pandas-dev__pandas-2950\n",
      "Token count is too large: huggingface__transformers-24259\n",
      "Token count is too large: ray-project__ray-8211\n",
      "Token count is too large: Qiskit__qiskit-7423\n",
      "Token count is too large: huggingface__transformers-11220\n",
      "Token count is too large: ytdl-org__youtube-dl-29682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3604 examples [04:26,  9.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-5498\n",
      "Token count is too large: conda__conda-6364\n",
      "Token count is too large: pandas-dev__pandas-19937\n",
      "Token count is too large: ytdl-org__youtube-dl-27937\n",
      "Token count is too large: pantsbuild__pants-15366\n",
      "Token count is too large: mesonbuild__meson-1620\n",
      "Token count is too large: pandas-dev__pandas-26255\n",
      "Token count is too large: PrefectHQ__prefect-2868\n",
      "Token count is too large: pandas-dev__pandas-18252\n",
      "Token count is too large: pyca__cryptography-3382\n",
      "Token count is too large: googleapis__google-cloud-python-3027\n",
      "Token count is too large: apache__airflow-9320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3606 examples [04:26,  7.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24016\n",
      "Token count is too large: pandas-dev__pandas-4657\n",
      "Token count is too large: docker__compose-8005\n",
      "Token count is too large: ray-project__ray-8514\n",
      "Token count is too large: pandas-dev__pandas-4228\n",
      "Token count is too large: huggingface__transformers-4533\n",
      "Token count is too large: Lightning-AI__lightning-1863\n",
      "Token count is too large: numpy__numpy-10478\n",
      "Token count is too large: pyca__cryptography-4843\n",
      "Token count is too large: Lightning-AI__lightning-3194\n",
      "Token count is too large: googleapis__google-cloud-python-6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3613 examples [04:27, 11.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-2511\n",
      "Token count is too large: conan-io__conan-3245\n",
      "Token count is too large: pandas-dev__pandas-7214\n",
      "Token count is too large: huggingface__transformers-8391\n",
      "Token count is too large: pantsbuild__pants-18327\n",
      "Token count is too large: ipython__ipython-9609\n",
      "Token count is too large: pandas-dev__pandas-10983\n",
      "Token count is too large: pandas-dev__pandas-27618\n",
      "Token count is too large: pypa__pip-8061\n",
      "Token count is too large: celery__celery-6419\n",
      "Token count is too large: huggingface__transformers-12226\n",
      "Token count is too large: jupyterlab__jupyterlab-1222\n",
      "Token count is too large: pypa__pip-11853\n",
      "Token count is too large: numpy__numpy-9941\n",
      "Token count is too large: PrefectHQ__prefect-929\n",
      "Token count is too large: numpy__numpy-13340\n",
      "Token count is too large: ipython__ipython-2233\n",
      "Token count is too large: pandas-dev__pandas-16213\n",
      "Token count is too large: ytdl-org__youtube-dl-1790\n",
      "Token count is too large: googleapis__google-cloud-python-8193\n",
      "Token count is too large: pandas-dev__pandas-35829\n",
      "Token count is too large: pandas-dev__pandas-3613\n",
      "Token count is too large: ray-project__ray-7567\n",
      "Token count is too large: huggingface__transformers-19523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3618 examples [04:27, 13.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22087\n",
      "Token count is too large: ipython__ipython-7708\n",
      "Token count is too large: pandas-dev__pandas-23655\n",
      "Token count is too large: pandas-dev__pandas-19894\n",
      "Token count is too large: pandas-dev__pandas-15623\n",
      "Token count is too large: mesonbuild__meson-910\n",
      "Token count is too large: Qiskit__qiskit-890\n",
      "Token count is too large: dagster-io__dagster-10589\n",
      "Token count is too large: googleapis__google-cloud-python-2478\n",
      "Token count is too large: ipython__ipython-2223\n",
      "Token count is too large: ytdl-org__youtube-dl-4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3621 examples [04:27, 13.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11366\n",
      "Token count is too large: numpy__numpy-23971\n",
      "Token count is too large: pandas-dev__pandas-5224\n",
      "Token count is too large: pandas-dev__pandas-15066\n",
      "Token count is too large: dagster-io__dagster-10706\n",
      "Token count is too large: conda__conda-7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3625 examples [04:27, 15.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-2054\n",
      "Token count is too large: twisted__twisted-11703\n",
      "Token count is too large: Lightning-AI__lightning-3151\n",
      "Token count is too large: pandas-dev__pandas-14060\n",
      "Token count is too large: pandas-dev__pandas-9427\n",
      "Token count is too large: ytdl-org__youtube-dl-15137\n",
      "Token count is too large: open-mmlab__mmdetection-9570\n",
      "Token count is too large: pandas-dev__pandas-38157\n",
      "Token count is too large: PrefectHQ__prefect-471\n",
      "Token count is too large: docker__compose-5940\n",
      "Token count is too large: pandas-dev__pandas-23153\n",
      "Token count is too large: googleapis__google-cloud-python-3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3627 examples [04:28, 13.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6410\n",
      "Token count is too large: pantsbuild__pants-19136\n",
      "Token count is too large: wagtail__wagtail-1529\n",
      "Token count is too large: conda__conda-7396\n",
      "Token count is too large: ipython__ipython-13021\n",
      "Token count is too large: pantsbuild__pants-12566\n",
      "Token count is too large: pandas-dev__pandas-26750\n",
      "Token count is too large: apache__airflow-23463\n",
      "Token count is too large: pandas-dev__pandas-30498\n",
      "Token count is too large: pandas-dev__pandas-3127\n",
      "Token count is too large: Qiskit__qiskit-9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3633 examples [04:28, 14.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20028\n",
      "Token count is too large: conan-io__conan-3809\n",
      "Token count is too large: googleapis__google-cloud-python-6576\n",
      "Token count is too large: pandas-dev__pandas-20885\n",
      "Token count is too large: pandas-dev__pandas-4437\n",
      "Token count is too large: googleapis__google-cloud-python-1486\n",
      "Token count is too large: pandas-dev__pandas-32539\n",
      "Token count is too large: ray-project__ray-890\n",
      "Token count is too large: docker__compose-2326\n",
      "Token count is too large: conan-io__conan-5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3636 examples [04:28, 15.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39272\n",
      "Token count is too large: pandas-dev__pandas-35231\n",
      "Token count is too large: pandas-dev__pandas-20611\n",
      "Token count is too large: conda__conda-5265\n",
      "Token count is too large: googleapis__google-cloud-python-6388\n",
      "Token count is too large: docker__compose-4267\n",
      "Token count is too large: pandas-dev__pandas-17430\n",
      "Token count is too large: numpy__numpy-24142\n",
      "Token count is too large: pypa__pip-9575\n",
      "Token count is too large: Lightning-AI__lightning-311\n",
      "Token count is too large: pandas-dev__pandas-7832\n",
      "Token count is too large: pandas-dev__pandas-28362\n",
      "Token count is too large: googleapis__google-cloud-python-3160\n",
      "Token count is too large: pandas-dev__pandas-19833\n",
      "Token count is too large: pypa__pip-2833\n",
      "Token count is too large: pandas-dev__pandas-27790\n",
      "Token count is too large: jupyterlab__jupyterlab-4920\n",
      "Token count is too large: pandas-dev__pandas-39362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3646 examples [04:29, 17.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13979\n",
      "Token count is too large: huggingface__transformers-6596\n",
      "Token count is too large: google__jax-2112\n",
      "Token count is too large: huggingface__transformers-8738\n",
      "Token count is too large: googleapis__google-cloud-python-2379\n",
      "Token count is too large: numpy__numpy-21251\n",
      "Token count is too large: ray-project__ray-3161\n",
      "Token count is too large: mesonbuild__meson-3041\n",
      "Token count is too large: googleapis__google-cloud-python-8179\n",
      "Token count is too large: numpy__numpy-13433\n",
      "Token count is too large: googleapis__google-cloud-python-2303\n",
      "Token count is too large: mesonbuild__meson-1076\n",
      "Token count is too large: pandas-dev__pandas-27664\n",
      "Token count is too large: pandas-dev__pandas-8090\n",
      "Token count is too large: wagtail__wagtail-208\n",
      "Token count is too large: pandas-dev__pandas-28029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3649 examples [04:29, 16.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5705\n",
      "Token count is too large: pandas-dev__pandas-17474\n",
      "Token count is too large: open-mmlab__mmdetection-7407\n",
      "Token count is too large: pandas-dev__pandas-22679\n",
      "Token count is too large: mesonbuild__meson-6878\n",
      "Token count is too large: wagtail__wagtail-1087\n",
      "Token count is too large: googleapis__google-cloud-python-8546\n",
      "Token count is too large: huggingface__transformers-16119\n",
      "Token count is too large: googleapis__google-cloud-python-326\n",
      "Token count is too large: pandas-dev__pandas-27129\n",
      "Token count is too large: pandas-dev__pandas-8767\n",
      "Token count is too large: pypa__pip-6522\n",
      "Token count is too large: pandas-dev__pandas-11603\n",
      "Token count is too large: docker__compose-3588\n",
      "Token count is too large: pypa__pip-1032\n",
      "Token count is too large: pypa__pip-12197\n",
      "Token count is too large: numpy__numpy-11082\n",
      "Token count is too large: Qiskit__qiskit-1172\n",
      "Token count is too large: pandas-dev__pandas-11252\n",
      "Token count is too large: pandas-dev__pandas-7979\n",
      "Token count is too large: numpy__numpy-11358\n",
      "Token count is too large: tiangolo__fastapi-2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3652 examples [04:29, 11.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1386\n",
      "Token count is too large: pandas-dev__pandas-8837\n",
      "Token count is too large: huggingface__transformers-8585\n",
      "Token count is too large: pandas-dev__pandas-16325\n",
      "Token count is too large: googleapis__google-cloud-python-2254\n",
      "Token count is too large: docker__compose-6608\n",
      "Token count is too large: conan-io__conan-5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3656 examples [04:30, 11.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-14433\n",
      "Token count is too large: pandas-dev__pandas-5844\n",
      "Token count is too large: docker__compose-2997\n",
      "Token count is too large: pandas-dev__pandas-18231\n",
      "Token count is too large: huggingface__transformers-10526\n",
      "Token count is too large: Qiskit__qiskit-5855\n",
      "Token count is too large: ray-project__ray-9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3663 examples [04:30, 13.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5681\n",
      "Token count is too large: Qiskit__qiskit-7459\n",
      "Token count is too large: pandas-dev__pandas-21794\n",
      "Token count is too large: Qiskit__qiskit-10332\n",
      "Token count is too large: huggingface__transformers-8095\n",
      "Token count is too large: mesonbuild__meson-11091\n",
      "Token count is too large: pandas-dev__pandas-33406\n",
      "Token count is too large: googleapis__google-cloud-python-20\n",
      "Token count is too large: huggingface__transformers-6908\n",
      "Token count is too large: mesonbuild__meson-6689\n",
      "Token count is too large: pandas-dev__pandas-39639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3667 examples [04:30, 17.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5472\n",
      "Token count is too large: google__jax-3350\n",
      "Token count is too large: numpy__numpy-8216\n",
      "Token count is too large: googleapis__google-cloud-python-9982\n",
      "Token count is too large: scipy__scipy-5623\n",
      "Token count is too large: ytdl-org__youtube-dl-22091\n",
      "Token count is too large: pandas-dev__pandas-8551\n",
      "Token count is too large: docker__compose-4553\n",
      "Token count is too large: pypa__pip-7072\n",
      "Token count is too large: pandas-dev__pandas-18637\n",
      "Token count is too large: pyca__cryptography-7853\n",
      "Token count is too large: docker__compose-7417\n",
      "Token count is too large: pantsbuild__pants-5201\n",
      "Token count is too large: pandas-dev__pandas-31458\n",
      "Token count is too large: pandas-dev__pandas-17984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3671 examples [04:31, 13.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-6750\n",
      "Token count is too large: pypa__pip-2049\n",
      "Token count is too large: Lightning-AI__lightning-1408\n",
      "Token count is too large: conan-io__conan-2908\n",
      "Token count is too large: numpy__numpy-5116\n",
      "Token count is too large: googleapis__google-cloud-python-9365\n",
      "Token count is too large: huggingface__transformers-17902\n",
      "Token count is too large: Lightning-AI__lightning-337\n",
      "Token count is too large: pandas-dev__pandas-18374\n",
      "Token count is too large: pandas-dev__pandas-17739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3673 examples [04:31, 12.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20901\n",
      "Token count is too large: conan-io__conan-9431\n",
      "Token count is too large: conan-io__conan-6010\n",
      "Token count is too large: huggingface__transformers-12749\n",
      "Token count is too large: huggingface__transformers-2310\n",
      "Token count is too large: conan-io__conan-2529\n",
      "Token count is too large: ytdl-org__youtube-dl-13962\n",
      "Token count is too large: apache__airflow-20870\n",
      "Token count is too large: pandas-dev__pandas-4659\n",
      "Token count is too large: ipython__ipython-1875\n",
      "Token count is too large: docker__compose-1933\n",
      "Token count is too large: ipython__ipython-12886\n",
      "Token count is too large: mesonbuild__meson-6641\n",
      "Token count is too large: googleapis__google-cloud-python-932\n",
      "Token count is too large: pandas-dev__pandas-21427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3675 examples [04:31, 12.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29583\n",
      "Token count is too large: conda__conda-7041\n",
      "Token count is too large: wagtail__wagtail-277\n",
      "Token count is too large: pandas-dev__pandas-19549\n",
      "Token count is too large: pandas-dev__pandas-3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3677 examples [04:31,  9.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31060\n",
      "Token count is too large: googleapis__google-cloud-python-2025\n",
      "Token count is too large: pantsbuild__pants-19179\n",
      "Token count is too large: pandas-dev__pandas-38420\n",
      "Token count is too large: pandas-dev__pandas-14739\n",
      "Token count is too large: pandas-dev__pandas-3219\n",
      "Token count is too large: google__jax-1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3680 examples [04:32,  9.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21566\n",
      "Token count is too large: numpy__numpy-6537\n",
      "Token count is too large: docker__compose-6115\n",
      "Token count is too large: Qiskit__qiskit-8790\n",
      "Token count is too large: pyca__cryptography-8397\n",
      "Token count is too large: ipython__ipython-6896\n",
      "Token count is too large: apache__airflow-24215\n",
      "Token count is too large: pantsbuild__pants-14549\n",
      "Token count is too large: apache__airflow-16393\n",
      "Token count is too large: pandas-dev__pandas-22737\n",
      "Token count is too large: conan-io__conan-4835\n",
      "Token count is too large: Qiskit__qiskit-8802\n",
      "Token count is too large: Qiskit__qiskit-9924\n",
      "Token count is too large: pandas-dev__pandas-34192\n",
      "Token count is too large: pandas-dev__pandas-26483\n",
      "Token count is too large: Qiskit__qiskit-4900\n",
      "Token count is too large: ipython__ipython-11353\n",
      "Token count is too large: ipython__ipython-10737\n",
      "Token count is too large: pandas-dev__pandas-7442\n",
      "Token count is too large: googleapis__google-cloud-python-8883\n",
      "Token count is too large: pandas-dev__pandas-21540\n",
      "Token count is too large: pandas-dev__pandas-17589\n",
      "Token count is too large: Lightning-AI__lightning-561\n",
      "Token count is too large: Qiskit__qiskit-8110\n",
      "Token count is too large: Lightning-AI__lightning-91\n",
      "Token count is too large: ray-project__ray-1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3683 examples [04:32,  7.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37511\n",
      "Token count is too large: pandas-dev__pandas-24021\n",
      "Token count is too large: ipython__ipython-4372\n",
      "Token count is too large: Qiskit__qiskit-5506\n",
      "Token count is too large: pandas-dev__pandas-6362\n",
      "Token count is too large: pantsbuild__pants-6205\n",
      "Token count is too large: numpy__numpy-8206\n",
      "Token count is too large: pandas-dev__pandas-31941\n",
      "Token count is too large: pandas-dev__pandas-26264\n",
      "Token count is too large: pandas-dev__pandas-9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3684 examples [04:32,  7.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-117\n",
      "Token count is too large: huggingface__transformers-24266\n",
      "Token count is too large: huggingface__transformers-9017\n",
      "Token count is too large: docker__compose-5767\n",
      "Token count is too large: conda__conda-2736\n",
      "Token count is too large: apache__airflow-9699\n",
      "Token count is too large: mesonbuild__meson-9523\n",
      "Token count is too large: apache__airflow-9497\n",
      "Token count is too large: dagster-io__dagster-6112\n",
      "Token count is too large: scipy__scipy-3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3686 examples [04:33,  8.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-4464\n",
      "Token count is too large: googleapis__google-cloud-python-11118\n",
      "Token count is too large: pandas-dev__pandas-20444\n",
      "Token count is too large: pandas-dev__pandas-15868\n",
      "Token count is too large: conan-io__conan-5481\n",
      "Token count is too large: pandas-dev__pandas-3554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3690 examples [04:33, 10.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: google__jax-1913\n",
      "Token count is too large: pandas-dev__pandas-6591\n",
      "Token count is too large: apache__airflow-22389\n",
      "Token count is too large: ytdl-org__youtube-dl-23193\n",
      "Token count is too large: apache__airflow-28799\n",
      "Token count is too large: pantsbuild__pants-10035\n",
      "Token count is too large: numpy__numpy-11813\n",
      "Token count is too large: pandas-dev__pandas-17291\n",
      "Token count is too large: pantsbuild__pants-17743\n",
      "Token count is too large: pandas-dev__pandas-37878\n",
      "Token count is too large: wagtail__wagtail-10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3692 examples [04:33,  9.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13052\n",
      "Token count is too large: pandas-dev__pandas-7350\n",
      "Token count is too large: pandas-dev__pandas-4797\n",
      "Token count is too large: PrefectHQ__prefect-2705\n",
      "Token count is too large: pandas-dev__pandas-28172\n",
      "Token count is too large: wagtail__wagtail-1026\n",
      "Token count is too large: pandas-dev__pandas-35647\n",
      "Token count is too large: pyca__cryptography-1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3695 examples [04:34,  8.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-1271\n",
      "Token count is too large: googleapis__google-cloud-python-6361\n",
      "Token count is too large: Lightning-AI__lightning-88\n",
      "Token count is too large: ytdl-org__youtube-dl-27673\n",
      "Token count is too large: mesonbuild__meson-5436\n",
      "Token count is too large: PrefectHQ__prefect-374\n",
      "Token count is too large: mesonbuild__meson-11323\n",
      "Token count is too large: numpy__numpy-17039\n",
      "Token count is too large: conan-io__conan-4941\n",
      "Token count is too large: celery__celery-7057\n",
      "Token count is too large: pandas-dev__pandas-8519\n",
      "Token count is too large: pyca__cryptography-4555\n",
      "Token count is too large: pypa__pip-9700\n",
      "Token count is too large: pandas-dev__pandas-30505\n",
      "Token count is too large: apache__airflow-9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3696 examples [04:34,  6.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-19981\n",
      "Token count is too large: apache__airflow-14869\n",
      "Token count is too large: googleapis__google-cloud-python-3069\n",
      "Token count is too large: googleapis__google-cloud-python-56\n",
      "Token count is too large: googleapis__google-cloud-python-7710\n",
      "Token count is too large: Qiskit__qiskit-4034\n",
      "Token count is too large: mesonbuild__meson-1842\n",
      "Token count is too large: pypa__pip-3715\n",
      "Token count is too large: huggingface__transformers-10183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3700 examples [04:34,  7.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20631\n",
      "Token count is too large: pandas-dev__pandas-7907\n",
      "Token count is too large: pandas-dev__pandas-38334\n",
      "Token count is too large: ray-project__ray-5971\n",
      "Token count is too large: pandas-dev__pandas-21132\n",
      "Token count is too large: numpy__numpy-23206\n",
      "Token count is too large: pandas-dev__pandas-29124\n",
      "Token count is too large: pandas-dev__pandas-37606\n",
      "Token count is too large: pantsbuild__pants-18636\n",
      "Token count is too large: pandas-dev__pandas-10096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3704 examples [04:35,  9.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-7252\n",
      "Token count is too large: docker__compose-5769\n",
      "Token count is too large: huggingface__transformers-20401\n",
      "Token count is too large: pandas-dev__pandas-18247\n",
      "Token count is too large: pandas-dev__pandas-7144\n",
      "Token count is too large: apache__airflow-8571\n",
      "Token count is too large: jupyterlab__jupyterlab-2628\n",
      "Token count is too large: apache__airflow-23071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3708 examples [04:35, 14.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-18786\n",
      "Token count is too large: ytdl-org__youtube-dl-3744\n",
      "Token count is too large: dagster-io__dagster-4528\n",
      "Token count is too large: googleapis__google-cloud-python-2743\n",
      "Token count is too large: pantsbuild__pants-6574\n",
      "Token count is too large: huggingface__transformers-11573\n",
      "Token count is too large: ray-project__ray-8012\n",
      "Token count is too large: huggingface__transformers-11569\n",
      "Token count is too large: pandas-dev__pandas-22125\n",
      "There was an error processing\n",
      "Token count is too large: numpy__numpy-5847\n",
      "Token count is too large: numpy__numpy-19244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3718 examples [04:35, 22.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: dagster-io__dagster-11982\n",
      "Token count is too large: googleapis__google-cloud-python-6630\n",
      "Token count is too large: Lightning-AI__lightning-256\n",
      "Token count is too large: ray-project__ray-1545\n",
      "Token count is too large: pandas-dev__pandas-21904\n",
      "Token count is too large: pandas-dev__pandas-18952\n",
      "Token count is too large: huggingface__transformers-18387\n",
      "Token count is too large: googleapis__google-cloud-python-11292\n",
      "Token count is too large: pandas-dev__pandas-6657\n",
      "Token count is too large: docker__compose-6352\n",
      "Token count is too large: pandas-dev__pandas-35271\n",
      "Token count is too large: ipython__ipython-1713\n",
      "Token count is too large: pandas-dev__pandas-14571\n",
      "Token count is too large: mesonbuild__meson-10976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3721 examples [04:36, 13.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6406\n",
      "Token count is too large: numpy__numpy-6674\n",
      "Token count is too large: pandas-dev__pandas-15499\n",
      "Token count is too large: celery__celery-3693\n",
      "Token count is too large: open-mmlab__mmdetection-4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3723 examples [04:36, 11.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36493\n",
      "Token count is too large: numpy__numpy-3495\n",
      "Token count is too large: docker__compose-6606\n",
      "Token count is too large: mesonbuild__meson-9926\n",
      "Token count is too large: pandas-dev__pandas-37905\n",
      "Token count is too large: apache__airflow-33404\n",
      "Token count is too large: pandas-dev__pandas-25964\n",
      "Token count is too large: Qiskit__qiskit-7302\n",
      "Token count is too large: conan-io__conan-3477\n",
      "Token count is too large: pandas-dev__pandas-14007\n",
      "Token count is too large: pandas-dev__pandas-14762\n",
      "Token count is too large: gitpython-developers__GitPython-317\n",
      "Token count is too large: pandas-dev__pandas-6142\n",
      "Token count is too large: pandas-dev__pandas-4752\n",
      "Token count is too large: pandas-dev__pandas-35532\n",
      "Token count is too large: googleapis__google-cloud-python-11325\n",
      "Token count is too large: gitpython-developers__GitPython-1190\n",
      "Token count is too large: numpy__numpy-17522\n",
      "Token count is too large: huggingface__transformers-22631\n",
      "Token count is too large: pandas-dev__pandas-37943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3730 examples [04:36, 13.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-11787\n",
      "Token count is too large: pandas-dev__pandas-6603\n",
      "Token count is too large: pandas-dev__pandas-4709\n",
      "Token count is too large: pandas-dev__pandas-11318\n",
      "Token count is too large: numpy__numpy-21991\n",
      "Token count is too large: pypa__pip-11560\n",
      "Token count is too large: ray-project__ray-8782\n",
      "Token count is too large: ytdl-org__youtube-dl-17199\n",
      "Token count is too large: Qiskit__qiskit-1564\n",
      "Token count is too large: mesonbuild__meson-1077\n",
      "Token count is too large: pandas-dev__pandas-14862\n",
      "Token count is too large: pandas-dev__pandas-6558\n",
      "Token count is too large: celery__celery-8098\n",
      "Token count is too large: pandas-dev__pandas-25992\n",
      "Token count is too large: PrefectHQ__prefect-632\n",
      "Token count is too large: docker__compose-6800\n",
      "Token count is too large: conda__conda-5192\n",
      "Token count is too large: ytdl-org__youtube-dl-401\n",
      "Token count is too large: huggingface__transformers-21191\n",
      "Token count is too large: google__jax-759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3733 examples [04:37, 11.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6859\n",
      "Token count is too large: pandas-dev__pandas-30246\n",
      "Token count is too large: Qiskit__qiskit-2493\n",
      "Token count is too large: pandas-dev__pandas-37198\n",
      "Token count is too large: Qiskit__qiskit-7860\n",
      "Token count is too large: huggingface__transformers-20864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3735 examples [04:37,  9.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24719\n",
      "Token count is too large: ytdl-org__youtube-dl-7045\n",
      "Token count is too large: PrefectHQ__prefect-924\n",
      "Token count is too large: Qiskit__qiskit-9020\n",
      "Token count is too large: pandas-dev__pandas-32214\n",
      "Token count is too large: pantsbuild__pants-14251\n",
      "Token count is too large: pandas-dev__pandas-5682\n",
      "Token count is too large: pandas-dev__pandas-10163\n",
      "Token count is too large: pypa__pip-11598\n",
      "Token count is too large: huggingface__transformers-25608\n",
      "Token count is too large: pantsbuild__pants-17505\n",
      "Token count is too large: numpy__numpy-10608\n",
      "Token count is too large: pandas-dev__pandas-36613\n",
      "Token count is too large: mesonbuild__meson-6106\n",
      "Token count is too large: pandas-dev__pandas-27119\n",
      "Token count is too large: conda__conda-872\n",
      "Token count is too large: pandas-dev__pandas-8714\n",
      "Token count is too large: googleapis__google-cloud-python-1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3739 examples [04:38,  8.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21572\n",
      "Token count is too large: mesonbuild__meson-10630\n",
      "Token count is too large: celery__celery-3892\n",
      "Token count is too large: pandas-dev__pandas-19751\n",
      "Token count is too large: pandas-dev__pandas-6365\n",
      "Token count is too large: pandas-dev__pandas-33985\n",
      "Token count is too large: googleapis__google-cloud-python-449\n",
      "Token count is too large: numpy__numpy-10621\n",
      "Token count is too large: pandas-dev__pandas-17169\n",
      "Token count is too large: google__jax-662\n",
      "Token count is too large: google__jax-2512\n",
      "Token count is too large: huggingface__transformers-9532\n",
      "Token count is too large: pandas-dev__pandas-6685\n",
      "Token count is too large: numpy__numpy-8543\n",
      "Token count is too large: celery__celery-6757\n",
      "Token count is too large: Lightning-AI__lightning-308\n",
      "Token count is too large: pantsbuild__pants-13926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3744 examples [04:38,  9.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19880\n",
      "Token count is too large: numpy__numpy-5468\n",
      "Token count is too large: jupyterlab__jupyterlab-2409\n",
      "Token count is too large: pandas-dev__pandas-37170\n",
      "Token count is too large: apache__airflow-19723\n",
      "Token count is too large: Lightning-AI__lightning-2671\n",
      "Token count is too large: huggingface__transformers-22458\n",
      "Token count is too large: Lightning-AI__lightning-1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3747 examples [04:38, 12.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-2122\n",
      "Token count is too large: pandas-dev__pandas-34201\n",
      "Token count is too large: PrefectHQ__prefect-2185\n",
      "Token count is too large: mesonbuild__meson-10824\n",
      "Token count is too large: pandas-dev__pandas-27026\n",
      "Token count is too large: pantsbuild__pants-19225\n",
      "Token count is too large: pandas-dev__pandas-3661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3750 examples [04:38, 14.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-5596\n",
      "Token count is too large: ipython__ipython-10479\n",
      "Token count is too large: conan-io__conan-227\n",
      "Token count is too large: pandas-dev__pandas-10644\n",
      "Token count is too large: google__jax-1541\n",
      "Token count is too large: conda__conda-4626\n",
      "Token count is too large: mesonbuild__meson-1652\n",
      "Token count is too large: pantsbuild__pants-18166\n",
      "Token count is too large: pandas-dev__pandas-8577\n",
      "Token count is too large: conan-io__conan-9050\n",
      "Token count is too large: pantsbuild__pants-18634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3752 examples [04:39, 10.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14576\n",
      "Token count is too large: pandas-dev__pandas-20537\n",
      "Token count is too large: huggingface__transformers-18687\n",
      "Token count is too large: googleapis__google-cloud-python-1249\n",
      "Token count is too large: apache__airflow-20542\n",
      "Token count is too large: pandas-dev__pandas-35503\n",
      "Token count is too large: mesonbuild__meson-8253\n",
      "Token count is too large: pandas-dev__pandas-5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3759 examples [04:39, 16.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23495\n",
      "Token count is too large: celery__celery-4880\n",
      "Token count is too large: huggingface__transformers-22772\n",
      "Token count is too large: apache__airflow-15302\n",
      "Token count is too large: huggingface__transformers-12134\n",
      "Token count is too large: Qiskit__qiskit-836\n",
      "Token count is too large: pandas-dev__pandas-38170\n",
      "Token count is too large: googleapis__google-cloud-python-4321\n",
      "Token count is too large: Lightning-AI__lightning-2483\n",
      "Token count is too large: conan-io__conan-3834\n",
      "Token count is too large: scipy__scipy-2806\n",
      "Token count is too large: Qiskit__qiskit-7099\n",
      "Token count is too large: pandas-dev__pandas-8622\n",
      "Token count is too large: pantsbuild__pants-13479\n",
      "Token count is too large: conan-io__conan-4923\n",
      "Token count is too large: Qiskit__qiskit-8617\n",
      "Token count is too large: numpy__numpy-10411\n",
      "Token count is too large: pandas-dev__pandas-5209\n",
      "Token count is too large: pandas-dev__pandas-5415\n",
      "Token count is too large: pypa__pip-1688\n",
      "Token count is too large: Qiskit__qiskit-4049\n",
      "Token count is too large: pandas-dev__pandas-7370\n",
      "Token count is too large: pandas-dev__pandas-25289\n",
      "Token count is too large: Qiskit__qiskit-9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3765 examples [04:39, 15.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3238\n",
      "Token count is too large: mesonbuild__meson-6197\n",
      "Token count is too large: ytdl-org__youtube-dl-20341\n",
      "Token count is too large: Qiskit__qiskit-6952\n",
      "Token count is too large: pantsbuild__pants-5400\n",
      "Token count is too large: huggingface__transformers-10236\n",
      "Token count is too large: pyca__cryptography-3680\n",
      "Token count is too large: conda__conda-10721\n",
      "Token count is too large: google__jax-832\n",
      "Token count is too large: mesonbuild__meson-5197\n",
      "Token count is too large: mesonbuild__meson-5255\n",
      "Token count is too large: conda__conda-2571\n",
      "Token count is too large: pantsbuild__pants-15265\n",
      "Token count is too large: pandas-dev__pandas-37256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3769 examples [04:40, 12.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23139\n",
      "Token count is too large: huggingface__transformers-20712\n",
      "Token count is too large: pandas-dev__pandas-38089\n",
      "Token count is too large: numpy__numpy-23604\n",
      "Token count is too large: pandas-dev__pandas-4148\n",
      "Token count is too large: pantsbuild__pants-18077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3771 examples [04:40, 13.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-16516\n",
      "Token count is too large: Lightning-AI__lightning-1327\n",
      "Token count is too large: pandas-dev__pandas-17517\n",
      "Token count is too large: pandas-dev__pandas-11301\n",
      "Token count is too large: pandas-dev__pandas-5090\n",
      "Token count is too large: wagtail__wagtail-7512\n",
      "Token count is too large: pandas-dev__pandas-4374\n",
      "Token count is too large: Qiskit__qiskit-9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3775 examples [04:40, 16.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: scipy__scipy-4648\n",
      "Token count is too large: pandas-dev__pandas-6824\n",
      "Token count is too large: apache__airflow-19375\n",
      "Token count is too large: googleapis__google-cloud-python-2776\n",
      "Token count is too large: numpy__numpy-12634\n",
      "Token count is too large: numpy__numpy-12828\n",
      "Token count is too large: googleapis__google-cloud-python-6440\n",
      "Token count is too large: Qiskit__qiskit-6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3777 examples [04:41, 11.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-28074\n",
      "Token count is too large: conda__conda-2604\n",
      "Token count is too large: pandas-dev__pandas-33373\n",
      "Token count is too large: mesonbuild__meson-10747\n",
      "Token count is too large: Qiskit__qiskit-8995\n",
      "Token count is too large: pandas-dev__pandas-27267\n",
      "Token count is too large: pypa__pip-7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3781 examples [04:41, 14.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25265\n",
      "Token count is too large: docker__compose-7543\n",
      "Token count is too large: dagster-io__dagster-2721\n",
      "Token count is too large: Qiskit__qiskit-2226\n",
      "Token count is too large: wagtail__wagtail-8786\n",
      "Token count is too large: pandas-dev__pandas-38816\n",
      "Token count is too large: pandas-dev__pandas-30838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3787 examples [04:41, 19.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-10002\n",
      "Token count is too large: pandas-dev__pandas-8218\n",
      "Token count is too large: conan-io__conan-12854\n",
      "Token count is too large: huggingface__transformers-7272\n",
      "Token count is too large: ipython__ipython-12954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3790 examples [04:41, 16.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: scipy__scipy-4756\n",
      "Token count is too large: pandas-dev__pandas-6159\n",
      "Token count is too large: mesonbuild__meson-1263\n",
      "Token count is too large: pandas-dev__pandas-23482\n",
      "Token count is too large: conda__conda-7951\n",
      "Token count is too large: pandas-dev__pandas-24337\n",
      "Token count is too large: pandas-dev__pandas-36185\n",
      "Token count is too large: pandas-dev__pandas-3647\n",
      "Token count is too large: googleapis__google-cloud-python-3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3793 examples [04:41, 14.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22066\n",
      "Token count is too large: pandas-dev__pandas-37039\n",
      "Token count is too large: pandas-dev__pandas-35578\n",
      "Token count is too large: pypa__pip-3794\n",
      "Token count is too large: pandas-dev__pandas-17587\n",
      "Token count is too large: Qiskit__qiskit-2740\n",
      "Token count is too large: conan-io__conan-2717\n",
      "Token count is too large: pandas-dev__pandas-27712\n",
      "Token count is too large: PrefectHQ__prefect-2755\n",
      "Token count is too large: pandas-dev__pandas-25525\n",
      "Token count is too large: numpy__numpy-16950\n",
      "Token count is too large: Qiskit__qiskit-8906\n",
      "Token count is too large: Lightning-AI__lightning-728\n",
      "Token count is too large: tiangolo__fastapi-1553\n",
      "Token count is too large: numpy__numpy-16300\n",
      "Token count is too large: pyca__cryptography-7132\n",
      "Token count is too large: pypa__pip-7826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3797 examples [04:42, 10.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9901\n",
      "Token count is too large: docker__compose-5938\n",
      "Token count is too large: pandas-dev__pandas-35543\n",
      "Token count is too large: pandas-dev__pandas-22163\n",
      "Token count is too large: open-mmlab__mmdetection-8273\n",
      "Token count is too large: tensorflow__models-6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3802 examples [04:42, 14.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9294\n",
      "Token count is too large: mesonbuild__meson-3101\n",
      "Token count is too large: pandas-dev__pandas-22865\n",
      "Token count is too large: numpy__numpy-21890\n",
      "Token count is too large: apache__airflow-26806\n",
      "Token count is too large: pandas-dev__pandas-4868\n",
      "Token count is too large: wagtail__wagtail-148\n",
      "Token count is too large: pantsbuild__pants-5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3804 examples [04:42, 13.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8083\n",
      "Token count is too large: googleapis__google-cloud-python-6522\n",
      "Token count is too large: mesonbuild__meson-6961\n",
      "Token count is too large: pandas-dev__pandas-38834\n",
      "Token count is too large: pandas-dev__pandas-19216\n",
      "Token count is too large: pandas-dev__pandas-8855\n",
      "Token count is too large: huggingface__transformers-13824\n",
      "Token count is too large: pantsbuild__pants-19155\n",
      "Token count is too large: mesonbuild__meson-1588\n",
      "Token count is too large: pandas-dev__pandas-28876\n",
      "Token count is too large: pandas-dev__pandas-24434\n",
      "Token count is too large: huggingface__transformers-19784\n",
      "Token count is too large: Qiskit__qiskit-7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3807 examples [04:43, 11.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17821\n",
      "Token count is too large: googleapis__google-cloud-python-3825\n",
      "Token count is too large: numpy__numpy-8762\n",
      "Token count is too large: googleapis__google-cloud-python-6079\n",
      "Token count is too large: ray-project__ray-2320\n",
      "Token count is too large: numpy__numpy-4437\n",
      "Token count is too large: mesonbuild__meson-10449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3809 examples [04:43,  9.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33863\n",
      "Token count is too large: pandas-dev__pandas-30788\n",
      "Token count is too large: pantsbuild__pants-15592\n",
      "Token count is too large: pandas-dev__pandas-34814\n",
      "Token count is too large: pandas-dev__pandas-33339\n",
      "Token count is too large: conan-io__conan-2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3812 examples [04:43, 10.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28854\n",
      "Token count is too large: docker__compose-3653\n",
      "Token count is too large: ipython__ipython-1077\n",
      "Token count is too large: mesonbuild__meson-3093\n",
      "Token count is too large: Qiskit__qiskit-908\n",
      "Token count is too large: pandas-dev__pandas-33137\n",
      "Token count is too large: ray-project__ray-10563\n",
      "Token count is too large: pandas-dev__pandas-35707\n",
      "Token count is too large: googleapis__google-cloud-python-3436\n",
      "Token count is too large: twisted__twisted-11658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3821 examples [04:44, 15.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11318\n",
      "Token count is too large: pandas-dev__pandas-28789\n",
      "Token count is too large: pantsbuild__pants-11773\n",
      "Token count is too large: huggingface__transformers-18562\n",
      "Token count is too large: apache__airflow-26103\n",
      "Token count is too large: googleapis__google-cloud-python-1779\n",
      "Token count is too large: jupyterlab__jupyterlab-7136\n",
      "Token count is too large: PrefectHQ__prefect-2743\n",
      "Token count is too large: Qiskit__qiskit-3538\n",
      "Token count is too large: Qiskit__qiskit-8852\n",
      "Token count is too large: mesonbuild__meson-6139\n",
      "Token count is too large: conan-io__conan-12578\n",
      "Token count is too large: conda__conda-3391\n",
      "Token count is too large: pandas-dev__pandas-39278\n",
      "Token count is too large: mesonbuild__meson-12053\n",
      "Token count is too large: pantsbuild__pants-12331\n",
      "Token count is too large: wagtail__wagtail-10657\n",
      "Token count is too large: numpy__numpy-19805\n",
      "Token count is too large: google__jax-326\n",
      "Token count is too large: pandas-dev__pandas-27392\n",
      "Token count is too large: google__jax-232\n",
      "Token count is too large: pantsbuild__pants-13896\n",
      "Token count is too large: conan-io__conan-4362\n",
      "Token count is too large: conan-io__conan-4683\n",
      "Token count is too large: pandas-dev__pandas-27916\n",
      "Token count is too large: Qiskit__qiskit-9789\n",
      "Token count is too large: pantsbuild__pants-12976\n",
      "Token count is too large: apache__airflow-28953\n",
      "Token count is too large: Lightning-AI__lightning-275\n",
      "Token count is too large: conan-io__conan-9118\n",
      "Token count is too large: googleapis__google-cloud-python-1232\n",
      "Token count is too large: PrefectHQ__prefect-3085\n",
      "Token count is too large: pandas-dev__pandas-37528\n",
      "Token count is too large: pantsbuild__pants-7326\n",
      "Token count is too large: Lightning-AI__lightning-2252\n",
      "Token count is too large: PrefectHQ__prefect-2840\n",
      "Token count is too large: Lightning-AI__lightning-3014\n",
      "Token count is too large: googleapis__google-cloud-python-6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3825 examples [04:44, 10.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23197\n",
      "Token count is too large: google__jax-884\n",
      "Token count is too large: pandas-dev__pandas-5790\n",
      "Token count is too large: pandas-dev__pandas-28245\n",
      "Token count is too large: huggingface__transformers-23842\n",
      "Token count is too large: Qiskit__qiskit-2769\n",
      "Token count is too large: conda__conda-6511\n",
      "Token count is too large: pandas-dev__pandas-9622\n",
      "Token count is too large: huggingface__transformers-24859\n",
      "Token count is too large: huggingface__transformers-21811\n",
      "Token count is too large: open-mmlab__mmdetection-10568\n",
      "Token count is too large: docker__compose-5490\n",
      "Token count is too large: pandas-dev__pandas-23808\n",
      "Token count is too large: pandas-dev__pandas-5474\n",
      "Token count is too large: huggingface__transformers-11582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3828 examples [04:45,  6.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17484\n",
      "Token count is too large: mesonbuild__meson-5078\n",
      "Token count is too large: pandas-dev__pandas-9078\n",
      "Token count is too large: mesonbuild__meson-1266\n",
      "There was an error processing\n",
      "Token count is too large: huggingface__transformers-17849\n",
      "Token count is too large: mesonbuild__meson-9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3831 examples [04:46,  7.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-16792\n",
      "Token count is too large: apache__airflow-19821\n",
      "Token count is too large: pandas-dev__pandas-14531\n",
      "Token count is too large: dagster-io__dagster-6348\n",
      "Token count is too large: conda__conda-7989\n",
      "Token count is too large: google__jax-410\n",
      "Token count is too large: pandas-dev__pandas-17011\n",
      "Token count is too large: celery__celery-7244\n",
      "Token count is too large: ytdl-org__youtube-dl-29236\n",
      "Token count is too large: pantsbuild__pants-4685\n",
      "Token count is too large: pantsbuild__pants-6428\n",
      "Token count is too large: huggingface__transformers-12981\n",
      "Token count is too large: pypa__pip-10577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3835 examples [04:46,  8.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25407\n",
      "Token count is too large: ipython__ipython-4452\n",
      "Token count is too large: mesonbuild__meson-1334\n",
      "Token count is too large: google__jax-643\n",
      "Token count is too large: mesonbuild__meson-5146\n",
      "Token count is too large: numpy__numpy-10324\n",
      "Token count is too large: pandas-dev__pandas-9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3840 examples [04:46, 11.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-13772\n",
      "Token count is too large: ray-project__ray-9527\n",
      "Token count is too large: pantsbuild__pants-9903\n",
      "Token count is too large: ray-project__ray-5673\n",
      "Token count is too large: PrefectHQ__prefect-2681\n",
      "Token count is too large: Lightning-AI__lightning-2166\n",
      "Token count is too large: docker__compose-6088\n",
      "Token count is too large: pantsbuild__pants-18798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3842 examples [04:47,  9.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5986\n",
      "Token count is too large: pandas-dev__pandas-5880\n",
      "Token count is too large: Qiskit__qiskit-1944\n",
      "Token count is too large: pandas-dev__pandas-6810\n",
      "Token count is too large: wagtail__wagtail-8689\n",
      "Token count is too large: googleapis__google-cloud-python-10219\n",
      "Token count is too large: pantsbuild__pants-16093\n",
      "Token count is too large: pandas-dev__pandas-13859\n",
      "Token count is too large: huggingface__transformers-7699\n",
      "Token count is too large: ipython__ipython-8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3846 examples [04:47, 10.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-4536\n",
      "Token count is too large: ytdl-org__youtube-dl-8843\n",
      "Token count is too large: googleapis__google-cloud-python-9785\n",
      "Token count is too large: Qiskit__qiskit-9725\n",
      "Token count is too large: pandas-dev__pandas-11898\n",
      "Token count is too large: ipython__ipython-11172\n",
      "Token count is too large: pantsbuild__pants-15637\n",
      "Token count is too large: pandas-dev__pandas-24628\n",
      "Token count is too large: pantsbuild__pants-6088\n",
      "Token count is too large: googleapis__google-cloud-python-4458\n",
      "Token count is too large: apache__airflow-20217\n",
      "Token count is too large: huggingface__transformers-19721\n",
      "Token count is too large: numpy__numpy-10537\n",
      "Token count is too large: pandas-dev__pandas-30578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3857 examples [04:47, 14.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3242\n",
      "Token count is too large: googleapis__google-cloud-python-11206\n",
      "Token count is too large: ytdl-org__youtube-dl-31000\n",
      "Token count is too large: Qiskit__qiskit-6463\n",
      "Token count is too large: apache__airflow-16345\n",
      "Token count is too large: apache__airflow-17980\n",
      "Token count is too large: pandas-dev__pandas-38742\n",
      "Token count is too large: numpy__numpy-14520\n",
      "Token count is too large: pandas-dev__pandas-31666\n",
      "Token count is too large: pandas-dev__pandas-21350\n",
      "Token count is too large: pandas-dev__pandas-38998\n",
      "Token count is too large: pandas-dev__pandas-3913\n",
      "Token count is too large: pandas-dev__pandas-32633\n",
      "Token count is too large: pantsbuild__pants-5414\n",
      "Token count is too large: pypa__pip-7927\n",
      "Token count is too large: pandas-dev__pandas-36923\n",
      "Token count is too large: Qiskit__qiskit-2958\n",
      "Token count is too large: pandas-dev__pandas-34394\n",
      "Token count is too large: apache__airflow-9174\n",
      "Token count is too large: mesonbuild__meson-11911\n",
      "Token count is too large: pandas-dev__pandas-14161\n",
      "Token count is too large: pandas-dev__pandas-24322\n",
      "Token count is too large: google__jax-2931\n",
      "Token count is too large: pandas-dev__pandas-39586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3862 examples [04:48, 10.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24274\n",
      "Token count is too large: numpy__numpy-8682\n",
      "Token count is too large: conan-io__conan-7585\n",
      "Token count is too large: pypa__pip-7494\n",
      "Token count is too large: mesonbuild__meson-4263\n",
      "Token count is too large: googleapis__google-cloud-python-552\n",
      "Token count is too large: pantsbuild__pants-18957\n",
      "Token count is too large: pyca__cryptography-2507\n",
      "Token count is too large: ipython__ipython-9827\n",
      "Token count is too large: conda__conda-739\n",
      "Token count is too large: googleapis__google-cloud-python-3765\n",
      "Token count is too large: docker__compose-7787\n",
      "Token count is too large: pandas-dev__pandas-28300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3872 examples [04:48, 15.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-5775\n",
      "Token count is too large: numpy__numpy-16332\n",
      "Token count is too large: ipython__ipython-13706\n",
      "Token count is too large: pandas-dev__pandas-19584\n",
      "Token count is too large: pandas-dev__pandas-19277\n",
      "Token count is too large: open-mmlab__mmdetection-7157\n",
      "Token count is too large: mesonbuild__meson-794\n",
      "Token count is too large: pandas-dev__pandas-29545\n",
      "Token count is too large: pandas-dev__pandas-15020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3878 examples [04:49, 19.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-2112\n",
      "Token count is too large: pandas-dev__pandas-35838\n",
      "Token count is too large: conda__conda-6719\n",
      "Token count is too large: pandas-dev__pandas-27650\n",
      "Token count is too large: mesonbuild__meson-5750\n",
      "Token count is too large: Qiskit__qiskit-10271\n",
      "Token count is too large: pandas-dev__pandas-17723\n",
      "Token count is too large: pantsbuild__pants-5837\n",
      "Token count is too large: googleapis__google-cloud-python-9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3881 examples [04:49, 18.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4757\n",
      "Token count is too large: numpy__numpy-10120\n",
      "Token count is too large: conan-io__conan-6433\n",
      "Token count is too large: apache__airflow-29441\n",
      "Token count is too large: docker__compose-7328\n",
      "Token count is too large: numpy__numpy-12224\n",
      "Token count is too large: googleapis__google-cloud-python-2365\n",
      "Token count is too large: pandas-dev__pandas-10960\n",
      "Token count is too large: Qiskit__qiskit-8041\n",
      "Token count is too large: Qiskit__qiskit-1454\n",
      "Token count is too large: docker__compose-6596\n",
      "Token count is too large: pantsbuild__pants-19135\n",
      "Token count is too large: apache__airflow-25821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3887 examples [04:49, 20.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39109\n",
      "Token count is too large: pandas-dev__pandas-26022\n",
      "Token count is too large: Qiskit__qiskit-2112\n",
      "Token count is too large: ray-project__ray-3270\n",
      "Token count is too large: googleapis__google-cloud-python-9162\n",
      "Token count is too large: ray-project__ray-6942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3895 examples [04:49, 21.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6083\n",
      "Token count is too large: pandas-dev__pandas-27466\n",
      "Token count is too large: huggingface__transformers-6322\n",
      "Token count is too large: docker__compose-4820\n",
      "Token count is too large: conda__conda-6347\n",
      "Token count is too large: Qiskit__qiskit-458\n",
      "Token count is too large: pantsbuild__pants-16148\n",
      "Token count is too large: Qiskit__qiskit-6111\n",
      "Token count is too large: googleapis__google-cloud-python-560\n",
      "Token count is too large: ytdl-org__youtube-dl-31235\n",
      "Token count is too large: open-mmlab__mmdetection-7685\n",
      "Token count is too large: celery__celery-3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3899 examples [04:50, 17.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-6599\n",
      "Token count is too large: ipython__ipython-4054\n",
      "Token count is too large: huggingface__transformers-25497\n",
      "Token count is too large: apache__airflow-468\n",
      "Token count is too large: pandas-dev__pandas-5387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3913 examples [04:50, 31.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-4479\n",
      "Token count is too large: pantsbuild__pants-6772\n",
      "Token count is too large: conan-io__conan-2314\n",
      "Token count is too large: Lightning-AI__lightning-1385\n",
      "Token count is too large: PrefectHQ__prefect-1069\n",
      "Token count is too large: mesonbuild__meson-3483\n",
      "Token count is too large: apache__airflow-12386\n",
      "Token count is too large: ray-project__ray-7501\n",
      "Token count is too large: pandas-dev__pandas-5188\n",
      "Token count is too large: pandas-dev__pandas-29420\n",
      "Token count is too large: huggingface__transformers-1383\n",
      "Token count is too large: pyca__cryptography-2543\n",
      "Token count is too large: jupyterlab__jupyterlab-3115\n",
      "Token count is too large: Qiskit__qiskit-3748\n",
      "Token count is too large: googleapis__google-cloud-python-1241\n",
      "Token count is too large: google__jax-2113\n",
      "Token count is too large: Qiskit__qiskit-2815\n",
      "Token count is too large: conan-io__conan-5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3920 examples [04:50, 27.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21843\n",
      "Token count is too large: Qiskit__qiskit-1532\n",
      "Token count is too large: scipy__scipy-4150\n",
      "Token count is too large: ipython__ipython-3846\n",
      "Token count is too large: google__jax-1916\n",
      "Token count is too large: pyca__cryptography-5314\n",
      "Token count is too large: pandas-dev__pandas-8586\n",
      "Token count is too large: DataDog__integrations-core-446\n",
      "Token count is too large: pandas-dev__pandas-38246\n",
      "Token count is too large: pandas-dev__pandas-16429\n",
      "Token count is too large: pantsbuild__pants-8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3925 examples [04:51, 23.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5757\n",
      "Token count is too large: pandas-dev__pandas-4602\n",
      "Token count is too large: open-mmlab__mmdetection-7585\n",
      "Token count is too large: docker__compose-5266\n",
      "Token count is too large: huggingface__transformers-15427\n",
      "Token count is too large: Qiskit__qiskit-4656\n",
      "Token count is too large: wagtail__wagtail-8008\n",
      "Token count is too large: pandas-dev__pandas-29353\n",
      "Token count is too large: numpy__numpy-19736\n",
      "Token count is too large: googleapis__google-cloud-python-4546\n",
      "Token count is too large: docker__compose-6542\n",
      "Token count is too large: numpy__numpy-3208\n",
      "Token count is too large: pandas-dev__pandas-35645\n",
      "Token count is too large: pypa__pip-12078\n",
      "Token count is too large: pandas-dev__pandas-8483\n",
      "Token count is too large: pandas-dev__pandas-32278\n",
      "Token count is too large: wagtail__wagtail-8175\n",
      "Token count is too large: pypa__pip-10502\n",
      "Token count is too large: docker__compose-6641\n",
      "Token count is too large: pandas-dev__pandas-17586\n",
      "Token count is too large: Qiskit__qiskit-1643\n",
      "Token count is too large: google__jax-3160\n",
      "Token count is too large: apache__airflow-12342\n",
      "Token count is too large: ytdl-org__youtube-dl-16038\n",
      "Token count is too large: Qiskit__qiskit-10016\n",
      "Token count is too large: Qiskit__qiskit-2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3929 examples [04:51, 15.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: open-mmlab__mmdetection-4810\n",
      "Token count is too large: Lightning-AI__lightning-1108\n",
      "Token count is too large: pandas-dev__pandas-4641\n",
      "Token count is too large: ipython__ipython-1065\n",
      "Token count is too large: mesonbuild__meson-2598\n",
      "Token count is too large: docker__compose-1889\n",
      "Token count is too large: celery__celery-5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3936 examples [04:51, 20.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-10516\n",
      "Token count is too large: numpy__numpy-8255\n",
      "Token count is too large: Qiskit__qiskit-10484\n",
      "Token count is too large: celery__celery-6223\n",
      "Token count is too large: pandas-dev__pandas-27303\n",
      "Token count is too large: pandas-dev__pandas-25142\n",
      "Token count is too large: conda__conda-10735\n",
      "Token count is too large: conda__conda-8083\n",
      "Token count is too large: numpy__numpy-7587\n",
      "Token count is too large: apache__airflow-14179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3940 examples [04:52, 16.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17367\n",
      "Token count is too large: pandas-dev__pandas-6054\n",
      "Token count is too large: pandas-dev__pandas-7544\n",
      "Token count is too large: pantsbuild__pants-15595\n",
      "Token count is too large: conan-io__conan-7353\n",
      "Token count is too large: Lightning-AI__lightning-751\n",
      "Token count is too large: conda__conda-6708\n",
      "Token count is too large: Qiskit__qiskit-5804\n",
      "Token count is too large: huggingface__transformers-357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3943 examples [04:52, 15.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10718\n",
      "Token count is too large: huggingface__transformers-20136\n",
      "Token count is too large: docker__compose-6654\n",
      "Token count is too large: apache__airflow-21307\n",
      "Token count is too large: pandas-dev__pandas-19717\n",
      "Token count is too large: pandas-dev__pandas-4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3946 examples [04:52, 17.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29212\n",
      "Token count is too large: pandas-dev__pandas-22802\n",
      "Token count is too large: pandas-dev__pandas-22811\n",
      "Token count is too large: pandas-dev__pandas-27549\n",
      "Token count is too large: huggingface__transformers-12035\n",
      "Token count is too large: mesonbuild__meson-11926\n",
      "Token count is too large: pandas-dev__pandas-18416\n",
      "Token count is too large: Qiskit__qiskit-4626\n",
      "Token count is too large: numpy__numpy-8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3949 examples [04:53, 12.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-6293\n",
      "Token count is too large: wagtail__wagtail-8895\n",
      "Token count is too large: pandas-dev__pandas-36145\n",
      "Token count is too large: numpy__numpy-10905\n",
      "Token count is too large: pandas-dev__pandas-15671\n",
      "Token count is too large: pandas-dev__pandas-34611\n",
      "Token count is too large: pandas-dev__pandas-36061\n",
      "Token count is too large: ytdl-org__youtube-dl-3534\n",
      "Token count is too large: pandas-dev__pandas-27920\n",
      "Token count is too large: pandas-dev__pandas-19561\n",
      "Token count is too large: huggingface__transformers-23122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3953 examples [04:53, 10.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-7719\n",
      "Token count is too large: apache__airflow-9730\n",
      "Token count is too large: ipython__ipython-3789\n",
      "Token count is too large: mesonbuild__meson-5717\n",
      "Token count is too large: pandas-dev__pandas-21497\n",
      "Token count is too large: mesonbuild__meson-10595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3957 examples [04:53, 11.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34069\n",
      "Token count is too large: PrefectHQ__prefect-2433\n",
      "Token count is too large: apache__airflow-12829\n",
      "Token count is too large: google__jax-234\n",
      "Token count is too large: google__jax-1055\n",
      "Token count is too large: pandas-dev__pandas-28762\n",
      "Token count is too large: wagtail__wagtail-8676\n",
      "Token count is too large: pandas-dev__pandas-24494\n",
      "Token count is too large: scipy__scipy-3270\n",
      "Token count is too large: mesonbuild__meson-1621\n",
      "Token count is too large: scipy__scipy-4611\n",
      "Token count is too large: dagster-io__dagster-14163\n",
      "Token count is too large: docker__compose-5560\n",
      "Token count is too large: Lightning-AI__lightning-2904\n",
      "Token count is too large: googleapis__google-cloud-python-2178\n",
      "Token count is too large: twisted__twisted-1650\n",
      "Token count is too large: googleapis__google-cloud-python-7797\n",
      "Token count is too large: wagtail__wagtail-10130\n",
      "Token count is too large: PrefectHQ__prefect-864\n",
      "Token count is too large: ipython__ipython-10787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3961 examples [04:54, 12.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36697\n",
      "Token count is too large: mesonbuild__meson-4001\n",
      "Token count is too large: ytdl-org__youtube-dl-613\n",
      "Token count is too large: ipython__ipython-2364\n",
      "Token count is too large: tiangolo__fastapi-1122\n",
      "Token count is too large: pandas-dev__pandas-21987\n",
      "Token count is too large: pandas-dev__pandas-24680\n",
      "Token count is too large: conda__conda-6881\n",
      "Token count is too large: pandas-dev__pandas-26537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3965 examples [04:54, 12.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33047\n",
      "Token count is too large: huggingface__transformers-15566\n",
      "Token count is too large: pandas-dev__pandas-18677\n",
      "Token count is too large: huggingface__transformers-11994\n",
      "Token count is too large: scipy__scipy-3504\n",
      "Token count is too large: apache__airflow-30856\n",
      "Token count is too large: numpy__numpy-12280\n",
      "Token count is too large: Qiskit__qiskit-8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3967 examples [04:54, 12.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-9202\n",
      "Token count is too large: Qiskit__qiskit-6926\n",
      "Token count is too large: mesonbuild__meson-5325\n",
      "Token count is too large: pandas-dev__pandas-8787\n",
      "Token count is too large: huggingface__transformers-8623\n",
      "Token count is too large: conan-io__conan-8769\n",
      "Token count is too large: Qiskit__qiskit-10376\n",
      "Token count is too large: googleapis__google-cloud-python-11350\n",
      "Token count is too large: pandas-dev__pandas-31359\n",
      "Token count is too large: ray-project__ray-10662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3972 examples [04:54, 14.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-19297\n",
      "Token count is too large: pandas-dev__pandas-35061\n",
      "Token count is too large: dagster-io__dagster-8765\n",
      "Token count is too large: PrefectHQ__prefect-963\n",
      "Token count is too large: Qiskit__qiskit-8166\n",
      "Token count is too large: apache__airflow-3828\n",
      "Token count is too large: Qiskit__qiskit-7933\n",
      "Token count is too large: pandas-dev__pandas-6338\n",
      "Token count is too large: huggingface__transformers-16906\n",
      "Token count is too large: Qiskit__qiskit-8978\n",
      "Token count is too large: pandas-dev__pandas-3635\n",
      "Token count is too large: open-mmlab__mmdetection-3634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3974 examples [04:55, 14.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-6724\n",
      "Token count is too large: mesonbuild__meson-3066\n",
      "Token count is too large: numpy__numpy-12587\n",
      "Token count is too large: pandas-dev__pandas-4478\n",
      "Token count is too large: pantsbuild__pants-6475\n",
      "Token count is too large: googleapis__google-cloud-python-733\n",
      "Token count is too large: pandas-dev__pandas-37043\n",
      "Token count is too large: conda__conda-6932\n",
      "Token count is too large: apache__airflow-15361\n",
      "Token count is too large: googleapis__google-cloud-python-7532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3976 examples [04:55, 11.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-12985\n",
      "Token count is too large: ipython__ipython-9335\n",
      "Token count is too large: pandas-dev__pandas-4627\n",
      "Token count is too large: Lightning-AI__lightning-2115\n",
      "Token count is too large: mesonbuild__meson-10050\n",
      "Token count is too large: mesonbuild__meson-6555\n",
      "Token count is too large: pandas-dev__pandas-36482\n",
      "Token count is too large: numpy__numpy-10352\n",
      "Token count is too large: pandas-dev__pandas-32166\n",
      "Token count is too large: scipy__scipy-5178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3982 examples [04:56, 10.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-10175\n",
      "Token count is too large: conan-io__conan-3615\n",
      "Token count is too large: pandas-dev__pandas-17902\n",
      "Token count is too large: googleapis__google-cloud-python-11112\n",
      "Token count is too large: mesonbuild__meson-5975\n",
      "Token count is too large: pandas-dev__pandas-22436\n",
      "Token count is too large: Qiskit__qiskit-3142\n",
      "Token count is too large: wagtail__wagtail-7738\n",
      "Token count is too large: celery__celery-6147\n",
      "Token count is too large: ray-project__ray-8324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3986 examples [04:56, 13.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-11159\n",
      "Token count is too large: mesonbuild__meson-10111\n",
      "Token count is too large: conda__conda-6794\n",
      "Token count is too large: pandas-dev__pandas-28074\n",
      "Token count is too large: mesonbuild__meson-2591\n",
      "Token count is too large: pandas-dev__pandas-23051\n",
      "Token count is too large: numpy__numpy-21253\n",
      "Token count is too large: huggingface__transformers-18832\n",
      "Token count is too large: pantsbuild__pants-11557\n",
      "Token count is too large: apache__airflow-26667\n",
      "Token count is too large: mesonbuild__meson-9696\n",
      "Token count is too large: huggingface__transformers-19773\n",
      "Token count is too large: Lightning-AI__lightning-685\n",
      "Token count is too large: huggingface__transformers-25033\n",
      "Token count is too large: numpy__numpy-5168\n",
      "Token count is too large: ytdl-org__youtube-dl-900\n",
      "Token count is too large: conda__conda-10022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3988 examples [04:56,  9.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14753\n",
      "Token count is too large: pandas-dev__pandas-35900\n",
      "Token count is too large: Qiskit__qiskit-2883\n",
      "Token count is too large: pandas-dev__pandas-35583\n",
      "Token count is too large: pandas-dev__pandas-19829\n",
      "Token count is too large: pandas-dev__pandas-6467\n",
      "Token count is too large: huggingface__transformers-19000\n",
      "Token count is too large: wagtail__wagtail-9369\n",
      "Token count is too large: ipython__ipython-2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3990 examples [04:56,  8.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-6435\n",
      "Token count is too large: pantsbuild__pants-5867\n",
      "Token count is too large: google__jax-629\n",
      "Token count is too large: mesonbuild__meson-4432\n",
      "Token count is too large: pandas-dev__pandas-17703\n",
      "Token count is too large: pandas-dev__pandas-7341\n",
      "Token count is too large: pandas-dev__pandas-8726\n",
      "Token count is too large: apache__airflow-31140\n",
      "Token count is too large: kubeflow__pipelines-1269\n",
      "Token count is too large: ipython__ipython-9418\n",
      "Token count is too large: ray-project__ray-1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3993 examples [04:57,  8.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24128\n",
      "Token count is too large: wagtail__wagtail-371\n",
      "Token count is too large: Qiskit__qiskit-5740\n",
      "Token count is too large: pandas-dev__pandas-28221\n",
      "Token count is too large: google__jax-1063\n",
      "Token count is too large: pandas-dev__pandas-5125\n",
      "Token count is too large: pandas-dev__pandas-4943\n",
      "Token count is too large: pandas-dev__pandas-7149\n",
      "Token count is too large: huggingface__transformers-5749\n",
      "Token count is too large: Qiskit__qiskit-2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3997 examples [04:57, 10.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-1229\n",
      "Token count is too large: PrefectHQ__prefect-1100\n",
      "Token count is too large: Qiskit__qiskit-10375\n",
      "Token count is too large: apache__airflow-19933\n",
      "Token count is too large: pandas-dev__pandas-7087\n",
      "Token count is too large: pandas-dev__pandas-31013\n",
      "Token count is too large: Qiskit__qiskit-3053\n",
      "Token count is too large: pantsbuild__pants-18839\n",
      "Token count is too large: numpy__numpy-9025\n",
      "Token count is too large: ytdl-org__youtube-dl-8703\n",
      "Token count is too large: ipython__ipython-13464\n",
      "Token count is too large: docker__compose-1643\n",
      "Token count is too large: numpy__numpy-9718\n",
      "Token count is too large: google__jax-699\n",
      "Token count is too large: googleapis__google-cloud-python-5343\n",
      "Token count is too large: pandas-dev__pandas-33493\n",
      "Token count is too large: pandas-dev__pandas-7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3999 examples [04:57,  9.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21968\n",
      "Token count is too large: pandas-dev__pandas-5718\n",
      "Token count is too large: Lightning-AI__lightning-128\n",
      "Token count is too large: pyca__cryptography-1048\n",
      "Token count is too large: mesonbuild__meson-8142\n",
      "Token count is too large: Qiskit__qiskit-578\n",
      "Token count is too large: pandas-dev__pandas-37499\n",
      "Token count is too large: scipy__scipy-5140\n",
      "Token count is too large: wagtail__wagtail-5138\n",
      "Token count is too large: pandas-dev__pandas-38754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4002 examples [04:58, 10.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3753\n",
      "Token count is too large: google__jax-477\n",
      "Token count is too large: wagtail__wagtail-3467\n",
      "Token count is too large: conda__conda-3390\n",
      "Token count is too large: pandas-dev__pandas-34199\n",
      "Token count is too large: pandas-dev__pandas-4440\n",
      "Token count is too large: mesonbuild__meson-10696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4013 examples [04:58, 17.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: open-mmlab__mmdetection-7559\n",
      "Token count is too large: mesonbuild__meson-3507\n",
      "Token count is too large: googleapis__google-cloud-python-9475\n",
      "Token count is too large: pandas-dev__pandas-6352\n",
      "Token count is too large: ray-project__ray-11218\n",
      "Token count is too large: pandas-dev__pandas-10107\n",
      "Token count is too large: ipython__ipython-7468\n",
      "Token count is too large: docker__compose-1963\n",
      "Token count is too large: numpy__numpy-15054\n",
      "Token count is too large: numpy__numpy-17812\n",
      "Token count is too large: ray-project__ray-8533\n",
      "Token count is too large: pandas-dev__pandas-19948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4016 examples [04:58, 16.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-4056\n",
      "Token count is too large: PrefectHQ__prefect-215\n",
      "Token count is too large: pandas-dev__pandas-7519\n",
      "Token count is too large: docker__compose-2288\n",
      "Token count is too large: pandas-dev__pandas-4515\n",
      "Token count is too large: pandas-dev__pandas-38244\n",
      "Token count is too large: apache__airflow-25661\n",
      "Token count is too large: pantsbuild__pants-4487\n",
      "Token count is too large: huggingface__transformers-24322\n",
      "Token count is too large: mesonbuild__meson-8878\n",
      "Token count is too large: pypa__pip-3542\n",
      "Token count is too large: ipython__ipython-1129\n",
      "Token count is too large: mesonbuild__meson-11706\n",
      "Token count is too large: googleapis__google-cloud-python-11577\n",
      "Token count is too large: pyca__cryptography-3725\n",
      "Token count is too large: huggingface__transformers-20713\n",
      "Token count is too large: pandas-dev__pandas-25329\n",
      "Token count is too large: ray-project__ray-2892\n",
      "Token count is too large: Qiskit__qiskit-5577\n",
      "Token count is too large: mesonbuild__meson-7841\n",
      "Token count is too large: ray-project__ray-1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4023 examples [05:00,  7.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-6835\n",
      "Token count is too large: pandas-dev__pandas-3040\n",
      "Token count is too large: pandas-dev__pandas-2231\n",
      "Token count is too large: pypa__pip-6215\n",
      "Token count is too large: pandas-dev__pandas-22809\n",
      "Token count is too large: googleapis__google-cloud-python-8979\n",
      "Token count is too large: googleapis__google-cloud-python-1924\n",
      "Token count is too large: pandas-dev__pandas-21332\n",
      "Token count is too large: pandas-dev__pandas-25625\n",
      "Token count is too large: Lightning-AI__lightning-1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4025 examples [05:00,  6.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25083\n",
      "Token count is too large: pandas-dev__pandas-25479\n",
      "Token count is too large: pypa__pip-2290\n",
      "Token count is too large: pandas-dev__pandas-10691\n",
      "Token count is too large: pandas-dev__pandas-4991\n",
      "Token count is too large: apache__airflow-23070\n",
      "Token count is too large: conan-io__conan-6021\n",
      "Token count is too large: ray-project__ray-7875\n",
      "Token count is too large: Qiskit__qiskit-2121\n",
      "Token count is too large: pandas-dev__pandas-11432\n",
      "Token count is too large: pyca__cryptography-520\n",
      "Token count is too large: googleapis__google-cloud-python-656\n",
      "Token count is too large: mesonbuild__meson-11174\n",
      "Token count is too large: huggingface__transformers-7078\n",
      "Token count is too large: huggingface__transformers-7153\n",
      "Token count is too large: pandas-dev__pandas-31788\n",
      "Token count is too large: pyca__cryptography-5879\n",
      "Token count is too large: mesonbuild__meson-4874\n",
      "Token count is too large: pandas-dev__pandas-17388\n",
      "Token count is too large: conan-io__conan-4297\n",
      "Token count is too large: Lightning-AI__lightning-2339\n",
      "Token count is too large: conan-io__conan-3560\n",
      "Token count is too large: pandas-dev__pandas-35254\n",
      "Token count is too large: pandas-dev__pandas-6853\n",
      "Token count is too large: pandas-dev__pandas-6269\n",
      "Token count is too large: huggingface__transformers-15406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4031 examples [05:01,  7.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-23767\n",
      "Token count is too large: pandas-dev__pandas-13680\n",
      "Token count is too large: googleapis__google-cloud-python-4265\n",
      "Token count is too large: conda__conda-6616\n",
      "Token count is too large: pandas-dev__pandas-37547\n",
      "Token count is too large: gitpython-developers__GitPython-818\n",
      "Token count is too large: Qiskit__qiskit-3597\n",
      "Token count is too large: pantsbuild__pants-12296\n",
      "Token count is too large: pantsbuild__pants-11656\n",
      "Token count is too large: ray-project__ray-956\n",
      "Token count is too large: PrefectHQ__prefect-1004\n",
      "Token count is too large: celery__celery-6233\n",
      "Token count is too large: pantsbuild__pants-13602\n",
      "Token count is too large: pantsbuild__pants-14962\n",
      "Token count is too large: pandas-dev__pandas-13188\n",
      "Token count is too large: pandas-dev__pandas-36763\n",
      "Token count is too large: pandas-dev__pandas-26360\n",
      "Token count is too large: Qiskit__qiskit-3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4034 examples [05:01,  7.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: jupyterlab__jupyterlab-1607\n",
      "Token count is too large: ipython__ipython-576\n",
      "Token count is too large: pandas-dev__pandas-7068\n",
      "Token count is too large: PrefectHQ__prefect-629\n",
      "Token count is too large: pandas-dev__pandas-16397\n",
      "Token count is too large: pandas-dev__pandas-7591\n",
      "Token count is too large: ray-project__ray-5382\n",
      "Token count is too large: wagtail__wagtail-7069\n",
      "Token count is too large: google__jax-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4039 examples [05:02, 11.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-12066\n",
      "Token count is too large: conda__conda-5115\n",
      "Token count is too large: numpy__numpy-10797\n",
      "Token count is too large: PrefectHQ__prefect-1572\n",
      "Token count is too large: googleapis__google-cloud-python-1367\n",
      "Token count is too large: pandas-dev__pandas-33465\n",
      "Token count is too large: pandas-dev__pandas-16449\n",
      "Token count is too large: pandas-dev__pandas-25620\n",
      "Token count is too large: pantsbuild__pants-4324\n",
      "Token count is too large: google__jax-3413\n",
      "Token count is too large: DataDog__integrations-core-8335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4042 examples [05:02, 12.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-9450\n",
      "Token count is too large: scipy__scipy-4570\n",
      "Token count is too large: ytdl-org__youtube-dl-16250\n",
      "Token count is too large: pandas-dev__pandas-3780\n",
      "Token count is too large: pandas-dev__pandas-32953\n",
      "Token count is too large: wagtail__wagtail-1120\n",
      "Token count is too large: pandas-dev__pandas-21252\n",
      "Token count is too large: mesonbuild__meson-2627\n",
      "Token count is too large: mesonbuild__meson-9989\n",
      "Token count is too large: numpy__numpy-16081\n",
      "Token count is too large: google__jax-1171\n",
      "Token count is too large: numpy__numpy-5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4045 examples [05:02, 11.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22920\n",
      "Token count is too large: PrefectHQ__prefect-2865\n",
      "Token count is too large: pypa__pip-10771\n",
      "Token count is too large: numpy__numpy-9336\n",
      "Token count is too large: Qiskit__qiskit-6567\n",
      "Token count is too large: pandas-dev__pandas-33089\n",
      "Token count is too large: conda__conda-12996\n",
      "Token count is too large: pandas-dev__pandas-22515\n",
      "Token count is too large: conan-io__conan-3661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4050 examples [05:02, 13.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27140\n",
      "Token count is too large: huggingface__transformers-9428\n",
      "Token count is too large: ray-project__ray-11041\n",
      "Token count is too large: pantsbuild__pants-15064\n",
      "Token count is too large: pypa__pip-7845\n",
      "Token count is too large: pandas-dev__pandas-5000\n",
      "Token count is too large: ray-project__ray-7065\n",
      "Token count is too large: Lightning-AI__lightning-2969\n",
      "Token count is too large: pandas-dev__pandas-14392\n",
      "Token count is too large: ipython__ipython-7099\n",
      "Token count is too large: mesonbuild__meson-3784\n",
      "Token count is too large: pandas-dev__pandas-23082\n",
      "Token count is too large: pandas-dev__pandas-38277\n",
      "Token count is too large: ytdl-org__youtube-dl-30556\n",
      "Token count is too large: Qiskit__qiskit-4810\n",
      "Token count is too large: pandas-dev__pandas-24293\n",
      "Token count is too large: pandas-dev__pandas-3762\n",
      "Token count is too large: pandas-dev__pandas-28651\n",
      "Token count is too large: Qiskit__qiskit-636\n",
      "Token count is too large: conda__conda-5091\n",
      "Token count is too large: googleapis__google-cloud-python-2594\n",
      "Token count is too large: pandas-dev__pandas-18529\n",
      "Token count is too large: ipython__ipython-8260\n",
      "Token count is too large: googleapis__google-cloud-python-9599\n",
      "Token count is too large: pandas-dev__pandas-26768\n",
      "Token count is too large: huggingface__transformers-23141\n",
      "Token count is too large: mesonbuild__meson-5584\n",
      "Token count is too large: pandas-dev__pandas-38202\n",
      "Token count is too large: pandas-dev__pandas-10879\n",
      "Token count is too large: pandas-dev__pandas-17489\n",
      "Token count is too large: numpy__numpy-7515\n",
      "Token count is too large: pandas-dev__pandas-30226\n",
      "Token count is too large: docker__compose-1515\n",
      "Token count is too large: pantsbuild__pants-17513\n",
      "Token count is too large: Qiskit__qiskit-6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4053 examples [05:03,  8.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8484\n",
      "Token count is too large: pantsbuild__pants-4747\n",
      "Token count is too large: pandas-dev__pandas-16532\n",
      "Token count is too large: Lightning-AI__lightning-2358\n",
      "Token count is too large: Qiskit__qiskit-2723\n",
      "Token count is too large: pandas-dev__pandas-38220\n",
      "Token count is too large: pandas-dev__pandas-27928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4058 examples [05:03, 10.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11651\n",
      "Token count is too large: conan-io__conan-7243\n",
      "Token count is too large: pandas-dev__pandas-37675\n",
      "Token count is too large: ytdl-org__youtube-dl-16326\n",
      "Token count is too large: pandas-dev__pandas-20939\n",
      "Token count is too large: pandas-dev__pandas-17882\n",
      "Token count is too large: mesonbuild__meson-5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4060 examples [05:04, 10.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-7013\n",
      "Token count is too large: pandas-dev__pandas-10597\n",
      "Token count is too large: ytdl-org__youtube-dl-31517\n",
      "Token count is too large: pandas-dev__pandas-21009\n",
      "Token count is too large: pandas-dev__pandas-27425\n",
      "Token count is too large: Qiskit__qiskit-6545\n",
      "Token count is too large: celery__celery-6749\n",
      "Token count is too large: conan-io__conan-301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4066 examples [05:04, 15.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-3319\n",
      "Token count is too large: Qiskit__qiskit-4887\n",
      "Token count is too large: pandas-dev__pandas-27630\n",
      "Token count is too large: pandas-dev__pandas-16123\n",
      "Token count is too large: pandas-dev__pandas-24421\n",
      "Token count is too large: pandas-dev__pandas-16786\n",
      "Token count is too large: ipython__ipython-1023\n",
      "Token count is too large: celery__celery-5700\n",
      "Token count is too large: pypa__pip-2767\n",
      "Token count is too large: conan-io__conan-2425\n",
      "Token count is too large: pandas-dev__pandas-34048\n",
      "Token count is too large: googleapis__google-cloud-python-6082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4070 examples [05:04, 18.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32490\n",
      "Token count is too large: jupyterlab__jupyterlab-7976\n",
      "Token count is too large: google__jax-633\n",
      "Token count is too large: pandas-dev__pandas-22031\n",
      "Token count is too large: Lightning-AI__lightning-2689\n",
      "Token count is too large: google__jax-3439\n",
      "Token count is too large: numpy__numpy-4300\n",
      "Token count is too large: pandas-dev__pandas-18488\n",
      "Token count is too large: pantsbuild__pants-11312\n",
      "Token count is too large: pandas-dev__pandas-18110\n",
      "Token count is too large: pypa__pip-3265\n",
      "Token count is too large: open-mmlab__mmdetection-2280\n",
      "Token count is too large: pandas-dev__pandas-36638\n",
      "Token count is too large: google__jax-981\n",
      "Token count is too large: pandas-dev__pandas-37166\n",
      "Token count is too large: huggingface__transformers-9076\n",
      "Token count is too large: pandas-dev__pandas-38759\n",
      "Token count is too large: mesonbuild__meson-8500\n",
      "Token count is too large: open-mmlab__mmdetection-6781\n",
      "Token count is too large: pandas-dev__pandas-21628\n",
      "Token count is too large: huggingface__transformers-18123\n",
      "Token count is too large: ipython__ipython-3623\n",
      "Token count is too large: pandas-dev__pandas-36564\n",
      "Token count is too large: jupyterlab__jupyterlab-6567\n",
      "Token count is too large: mesonbuild__meson-5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4077 examples [05:04, 16.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-25312\n",
      "Token count is too large: pantsbuild__pants-7116\n",
      "Token count is too large: mesonbuild__meson-1186\n",
      "Token count is too large: twisted__twisted-11909\n",
      "Token count is too large: numpy__numpy-20796\n",
      "Token count is too large: Lightning-AI__lightning-2581\n",
      "Token count is too large: conda__conda-5526\n",
      "Token count is too large: pandas-dev__pandas-13392\n",
      "Token count is too large: pandas-dev__pandas-37268\n",
      "Token count is too large: pandas-dev__pandas-38136\n",
      "Token count is too large: ray-project__ray-4868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4084 examples [05:05, 20.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24254\n",
      "Token count is too large: conda__conda-7606\n",
      "Token count is too large: docker__compose-7052\n",
      "Token count is too large: dagster-io__dagster-6920\n",
      "Token count is too large: googleapis__google-cloud-python-6648\n",
      "Token count is too large: Qiskit__qiskit-2539\n",
      "Token count is too large: pandas-dev__pandas-8832\n",
      "Token count is too large: huggingface__transformers-19798\n",
      "Token count is too large: pandas-dev__pandas-23802\n",
      "Token count is too large: pandas-dev__pandas-3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4087 examples [05:05, 16.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-11785\n",
      "Token count is too large: pandas-dev__pandas-32757\n",
      "Token count is too large: pandas-dev__pandas-14005\n",
      "Token count is too large: ipython__ipython-5047\n",
      "Token count is too large: Lightning-AI__lightning-1431\n",
      "Token count is too large: numpy__numpy-7053\n",
      "Token count is too large: pandas-dev__pandas-5134\n",
      "Token count is too large: pypa__pip-6389\n",
      "Token count is too large: conda__conda-12904\n",
      "Token count is too large: apache__airflow-24034\n",
      "Token count is too large: pandas-dev__pandas-11863\n",
      "Token count is too large: celery__celery-8312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4096 examples [05:05, 22.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-14190\n",
      "Token count is too large: googleapis__google-cloud-python-11349\n",
      "Token count is too large: googleapis__google-cloud-python-299\n",
      "Token count is too large: googleapis__google-cloud-python-5655\n",
      "Token count is too large: pandas-dev__pandas-9289\n",
      "Token count is too large: googleapis__google-cloud-python-941\n",
      "Token count is too large: dagster-io__dagster-1217\n",
      "Token count is too large: Qiskit__qiskit-10377\n",
      "Token count is too large: Qiskit__qiskit-4243\n",
      "Token count is too large: ipython__ipython-10434\n",
      "Token count is too large: conan-io__conan-13041\n",
      "Token count is too large: pyca__cryptography-849\n",
      "Token count is too large: gitpython-developers__GitPython-1102\n",
      "Token count is too large: wagtail__wagtail-4514\n",
      "Token count is too large: googleapis__google-cloud-python-11373\n",
      "Token count is too large: pandas-dev__pandas-16790\n",
      "Token count is too large: ipython__ipython-1008\n",
      "Token count is too large: conan-io__conan-2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4099 examples [05:06, 18.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21347\n",
      "Token count is too large: ipython__ipython-11698\n",
      "Token count is too large: twisted__twisted-11718\n",
      "Token count is too large: open-mmlab__mmdetection-7386\n",
      "Token count is too large: conan-io__conan-187\n",
      "Token count is too large: Qiskit__qiskit-1009\n",
      "Token count is too large: Qiskit__qiskit-7613\n",
      "Token count is too large: Qiskit__qiskit-4932\n",
      "Token count is too large: huggingface__transformers-3833\n",
      "Token count is too large: conan-io__conan-6739\n",
      "Token count is too large: pypa__pip-9123\n",
      "Token count is too large: Qiskit__qiskit-2058\n",
      "Token count is too large: ytdl-org__youtube-dl-889\n",
      "Token count is too large: Lightning-AI__lightning-2428\n",
      "Token count is too large: Qiskit__qiskit-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4106 examples [05:06, 22.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-3630\n",
      "Token count is too large: Qiskit__qiskit-9961\n",
      "Token count is too large: Lightning-AI__lightning-1145\n",
      "Token count is too large: pandas-dev__pandas-39547\n",
      "Token count is too large: pandas-dev__pandas-16108\n",
      "Token count is too large: pandas-dev__pandas-17691\n",
      "Token count is too large: pandas-dev__pandas-16683\n",
      "Token count is too large: huggingface__transformers-9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4109 examples [05:06, 17.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-13132\n",
      "Token count is too large: ipython__ipython-10795\n",
      "Token count is too large: wagtail__wagtail-9814\n",
      "Token count is too large: pandas-dev__pandas-21573\n",
      "Token count is too large: pantsbuild__pants-16226\n",
      "Token count is too large: celery__celery-6869\n",
      "Token count is too large: pandas-dev__pandas-6983\n",
      "Token count is too large: PrefectHQ__prefect-84\n",
      "Token count is too large: ray-project__ray-6485\n",
      "Token count is too large: pandas-dev__pandas-6089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4111 examples [05:06, 16.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-9779\n",
      "Token count is too large: huggingface__transformers-12441\n",
      "Token count is too large: mesonbuild__meson-4051\n",
      "Token count is too large: ipython__ipython-3180\n",
      "Token count is too large: huggingface__transformers-16492\n",
      "Token count is too large: dagster-io__dagster-13240\n",
      "Token count is too large: wagtail__wagtail-9147\n",
      "Token count is too large: pandas-dev__pandas-24187\n",
      "Token count is too large: conda__conda-8160\n",
      "Token count is too large: mesonbuild__meson-6457\n",
      "Token count is too large: pandas-dev__pandas-24217\n",
      "Token count is too large: pyca__cryptography-6599\n",
      "Token count is too large: wagtail__wagtail-7082\n",
      "Token count is too large: numpy__numpy-10635\n",
      "Token count is too large: ray-project__ray-1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4118 examples [05:07, 15.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32544\n",
      "Token count is too large: pyca__cryptography-4811\n",
      "Token count is too large: wagtail__wagtail-5510\n",
      "Token count is too large: mesonbuild__meson-1356\n",
      "Token count is too large: Qiskit__qiskit-6713\n",
      "Token count is too large: huggingface__transformers-13919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4121 examples [05:07, 14.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-9106\n",
      "Token count is too large: conan-io__conan-3186\n",
      "Token count is too large: pantsbuild__pants-19076\n",
      "Token count is too large: pandas-dev__pandas-6475\n",
      "Token count is too large: pandas-dev__pandas-25745\n",
      "Token count is too large: Lightning-AI__lightning-955\n",
      "Token count is too large: numpy__numpy-8750\n",
      "Token count is too large: pandas-dev__pandas-18670\n",
      "Token count is too large: jupyterlab__jupyterlab-9390\n",
      "Token count is too large: pandas-dev__pandas-20240\n",
      "Token count is too large: pandas-dev__pandas-21263\n",
      "Token count is too large: googleapis__google-cloud-python-3514\n",
      "Token count is too large: pandas-dev__pandas-15161\n",
      "Token count is too large: ipython__ipython-2036\n",
      "Token count is too large: celery__celery-3867\n",
      "Token count is too large: pandas-dev__pandas-27243\n",
      "Token count is too large: pandas-dev__pandas-21482\n",
      "Token count is too large: pandas-dev__pandas-4073\n",
      "Token count is too large: pantsbuild__pants-15032\n",
      "Token count is too large: numpy__numpy-13498\n",
      "Token count is too large: mesonbuild__meson-5673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4125 examples [05:07, 13.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-10086\n",
      "Token count is too large: conan-io__conan-2448\n",
      "Token count is too large: ipython__ipython-1906\n",
      "Token count is too large: pandas-dev__pandas-9264\n",
      "Token count is too large: conda__conda-8819\n",
      "Token count is too large: conda__conda-5414\n",
      "Token count is too large: googleapis__google-cloud-python-9294\n",
      "Token count is too large: mesonbuild__meson-2837\n",
      "Token count is too large: huggingface__transformers-11387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4128 examples [05:08, 13.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3559\n",
      "Token count is too large: mesonbuild__meson-9983\n",
      "Token count is too large: PrefectHQ__prefect-2391\n",
      "Token count is too large: pandas-dev__pandas-32546\n",
      "Token count is too large: pyca__cryptography-2180\n",
      "Token count is too large: apache__airflow-13822\n",
      "Token count is too large: Qiskit__qiskit-1406\n",
      "Token count is too large: Qiskit__qiskit-1962\n",
      "Token count is too large: googleapis__google-cloud-python-9949\n",
      "Token count is too large: googleapis__google-cloud-python-6442\n",
      "Token count is too large: gitpython-developers__GitPython-780\n",
      "Token count is too large: googleapis__google-cloud-python-2978\n",
      "Token count is too large: apache__airflow-17539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4131 examples [05:08, 13.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-1976\n",
      "Token count is too large: numpy__numpy-22725\n",
      "Token count is too large: pandas-dev__pandas-33646\n",
      "Token count is too large: ray-project__ray-10706\n",
      "Token count is too large: pandas-dev__pandas-22785\n",
      "Token count is too large: pantsbuild__pants-12504\n",
      "Token count is too large: mesonbuild__meson-795\n",
      "Token count is too large: Lightning-AI__lightning-3004\n",
      "Token count is too large: pandas-dev__pandas-17841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4133 examples [05:08, 10.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11306\n",
      "Token count is too large: pandas-dev__pandas-16433\n",
      "Token count is too large: wagtail__wagtail-7253\n",
      "Token count is too large: docker__compose-4860\n",
      "Token count is too large: pandas-dev__pandas-23715\n",
      "Token count is too large: pantsbuild__pants-15588\n",
      "Token count is too large: pandas-dev__pandas-16486\n",
      "Token count is too large: pandas-dev__pandas-29700\n",
      "Token count is too large: pyca__cryptography-1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4136 examples [05:09,  9.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4220\n",
      "Token count is too large: celery__celery-6394\n",
      "Token count is too large: Qiskit__qiskit-3468\n",
      "Token count is too large: apache__airflow-23030\n",
      "Token count is too large: pandas-dev__pandas-18015\n",
      "Token count is too large: ytdl-org__youtube-dl-9195\n",
      "Token count is too large: huggingface__transformers-24980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4138 examples [05:09,  9.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-26634\n",
      "Token count is too large: mesonbuild__meson-577\n",
      "Token count is too large: pantsbuild__pants-13856\n",
      "Token count is too large: huggingface__transformers-7291\n",
      "Token count is too large: pandas-dev__pandas-3845\n",
      "Token count is too large: wagtail__wagtail-8310\n",
      "Token count is too large: mesonbuild__meson-2376\n",
      "Token count is too large: apache__airflow-22872\n",
      "Token count is too large: pypa__pip-6972\n",
      "Token count is too large: ipython__ipython-448\n",
      "Token count is too large: googleapis__google-cloud-python-7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4140 examples [05:09,  9.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24581\n",
      "Token count is too large: pandas-dev__pandas-28689\n",
      "Token count is too large: ray-project__ray-11181\n",
      "Token count is too large: huggingface__transformers-19464\n",
      "Token count is too large: celery__celery-4736\n",
      "Token count is too large: pandas-dev__pandas-11153\n",
      "Token count is too large: pandas-dev__pandas-4783\n",
      "Token count is too large: conan-io__conan-3383\n",
      "Token count is too large: pandas-dev__pandas-22869\n",
      "Token count is too large: mesonbuild__meson-8921\n",
      "Token count is too large: Qiskit__qiskit-9792\n",
      "Token count is too large: ipython__ipython-12443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4148 examples [05:09, 13.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12049\n",
      "Token count is too large: conan-io__conan-7322\n",
      "Token count is too large: pandas-dev__pandas-11607\n",
      "Token count is too large: pandas-dev__pandas-10419\n",
      "Token count is too large: ipython__ipython-10931\n",
      "Token count is too large: ipython__ipython-7762\n",
      "Token count is too large: pandas-dev__pandas-29260\n",
      "Token count is too large: conan-io__conan-6184\n",
      "Token count is too large: pandas-dev__pandas-4299\n",
      "Token count is too large: celery__celery-7680\n",
      "Token count is too large: pandas-dev__pandas-18309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4150 examples [05:10, 14.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-29317\n",
      "Token count is too large: Lightning-AI__lightning-1996\n",
      "Token count is too large: Qiskit__qiskit-5442\n",
      "Token count is too large: pantsbuild__pants-17205\n",
      "Token count is too large: numpy__numpy-6761\n",
      "Token count is too large: pandas-dev__pandas-34059\n",
      "Token count is too large: googleapis__google-cloud-python-914\n",
      "Token count is too large: pypa__pip-9331\n",
      "Token count is too large: ipython__ipython-7191\n",
      "Token count is too large: pandas-dev__pandas-37750\n",
      "Token count is too large: Qiskit__qiskit-6072\n",
      "Token count is too large: pantsbuild__pants-17013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4158 examples [05:10, 16.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22062\n",
      "Token count is too large: google__jax-737\n",
      "Token count is too large: pandas-dev__pandas-10158\n",
      "Token count is too large: mesonbuild__meson-5294\n",
      "Token count is too large: mesonbuild__meson-297\n",
      "Token count is too large: Qiskit__qiskit-8440\n",
      "Token count is too large: ytdl-org__youtube-dl-717\n",
      "Token count is too large: apache__airflow-19443\n",
      "Token count is too large: apache__airflow-17281\n",
      "Token count is too large: google__jax-1099\n",
      "Token count is too large: numpy__numpy-7618\n",
      "Token count is too large: numpy__numpy-6355\n",
      "Token count is too large: conda__conda-11889\n",
      "Token count is too large: ytdl-org__youtube-dl-2173\n",
      "Token count is too large: apache__airflow-15130\n",
      "Token count is too large: numpy__numpy-14145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4170 examples [05:10, 21.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21934\n",
      "Token count is too large: conan-io__conan-6465\n",
      "Token count is too large: pantsbuild__pants-15087\n",
      "Token count is too large: docker__compose-6017\n",
      "Token count is too large: pandas-dev__pandas-30339\n",
      "Token count is too large: scipy__scipy-4583\n",
      "Token count is too large: twisted__twisted-11578\n",
      "Token count is too large: mesonbuild__meson-866\n",
      "Token count is too large: numpy__numpy-10367\n",
      "Token count is too large: numpy__numpy-20325\n",
      "Token count is too large: pandas-dev__pandas-7921\n",
      "Token count is too large: pandas-dev__pandas-34294\n",
      "Token count is too large: mesonbuild__meson-10008\n",
      "Token count is too large: ytdl-org__youtube-dl-14279\n",
      "Token count is too large: pandas-dev__pandas-37145\n",
      "Token count is too large: pandas-dev__pandas-35964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4173 examples [05:11, 18.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-28397\n",
      "Token count is too large: huggingface__transformers-8860\n",
      "Token count is too large: wagtail__wagtail-10320\n",
      "Token count is too large: Qiskit__qiskit-4410\n",
      "Token count is too large: celery__celery-5820\n",
      "Token count is too large: huggingface__transformers-24301\n",
      "Token count is too large: Lightning-AI__lightning-1396\n",
      "Token count is too large: pandas-dev__pandas-7402\n",
      "Token count is too large: pandas-dev__pandas-6672\n",
      "Token count is too large: ray-project__ray-5060\n",
      "Token count is too large: pandas-dev__pandas-31159\n",
      "Token count is too large: celery__celery-4369\n",
      "Token count is too large: conan-io__conan-4958\n",
      "Token count is too large: pandas-dev__pandas-5004\n",
      "Token count is too large: jupyterlab__jupyterlab-9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4176 examples [05:11, 11.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21513\n",
      "Token count is too large: pandas-dev__pandas-4904\n",
      "Token count is too large: numpy__numpy-10046\n",
      "Token count is too large: pantsbuild__pants-5420\n",
      "Token count is too large: pandas-dev__pandas-35029\n",
      "Token count is too large: pandas-dev__pandas-21775\n",
      "Token count is too large: ray-project__ray-6886\n",
      "Token count is too large: ray-project__ray-5599\n",
      "Token count is too large: celery__celery-4432\n",
      "Token count is too large: mesonbuild__meson-7816\n",
      "Token count is too large: scipy__scipy-3060\n",
      "Token count is too large: conda__conda-7223\n",
      "Token count is too large: pandas-dev__pandas-27832\n",
      "Token count is too large: pandas-dev__pandas-8904\n",
      "Token count is too large: pantsbuild__pants-8881\n",
      "Token count is too large: pandas-dev__pandas-37207\n",
      "Token count is too large: numpy__numpy-21999\n",
      "Token count is too large: numpy__numpy-12962\n",
      "Token count is too large: PrefectHQ__prefect-2814\n",
      "Token count is too large: huggingface__transformers-16700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4180 examples [05:12, 11.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-6450\n",
      "Token count is too large: pandas-dev__pandas-10202\n",
      "Token count is too large: pandas-dev__pandas-18653\n",
      "Token count is too large: numpy__numpy-5324\n",
      "Token count is too large: ipython__ipython-10546\n",
      "Token count is too large: pandas-dev__pandas-35214\n",
      "Token count is too large: numpy__numpy-7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4183 examples [05:12, 12.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: PrefectHQ__prefect-555\n",
      "Token count is too large: conda__conda-5815\n",
      "Token count is too large: pandas-dev__pandas-6778\n",
      "Token count is too large: conan-io__conan-2788\n",
      "Token count is too large: numpy__numpy-13948\n",
      "Token count is too large: Qiskit__qiskit-1398\n",
      "Token count is too large: mesonbuild__meson-1624\n",
      "Token count is too large: huggingface__transformers-21849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4190 examples [05:12, 14.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-6241\n",
      "Token count is too large: pandas-dev__pandas-20840\n",
      "Token count is too large: pandas-dev__pandas-7479\n",
      "Token count is too large: pandas-dev__pandas-35212\n",
      "Token count is too large: pyca__cryptography-2761\n",
      "Token count is too large: numpy__numpy-7332\n",
      "Token count is too large: conda__conda-10542\n",
      "Token count is too large: Qiskit__qiskit-8889\n",
      "Token count is too large: dagster-io__dagster-14956\n",
      "Token count is too large: ipython__ipython-10959\n",
      "Token count is too large: mesonbuild__meson-10703\n",
      "Token count is too large: pandas-dev__pandas-4676\n",
      "Token count is too large: conda__conda-125\n",
      "Token count is too large: pandas-dev__pandas-11484\n",
      "Token count is too large: Qiskit__qiskit-10537\n",
      "Token count is too large: google__jax-792\n",
      "Token count is too large: pantsbuild__pants-13910\n",
      "Token count is too large: Qiskit__qiskit-5212\n",
      "Token count is too large: celery__celery-2782\n",
      "Token count is too large: google__jax-92\n",
      "Token count is too large: pandas-dev__pandas-35444\n",
      "Token count is too large: mesonbuild__meson-5147\n",
      "Token count is too large: google__jax-1246\n",
      "Token count is too large: numpy__numpy-8010\n",
      "Token count is too large: pandas-dev__pandas-4933\n",
      "Token count is too large: Lightning-AI__lightning-2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4192 examples [05:13, 11.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-10085\n",
      "Token count is too large: conda__conda-7076\n",
      "Token count is too large: mesonbuild__meson-10013\n",
      "Token count is too large: pandas-dev__pandas-18117\n",
      "Token count is too large: mesonbuild__meson-2551\n",
      "Token count is too large: gitpython-developers__GitPython-700\n",
      "Token count is too large: mesonbuild__meson-157\n",
      "Token count is too large: pandas-dev__pandas-25219\n",
      "Token count is too large: pantsbuild__pants-13817\n",
      "Token count is too large: huggingface__transformers-9829\n",
      "Token count is too large: huggingface__transformers-12889\n",
      "Token count is too large: pypa__pip-8062\n",
      "Token count is too large: pandas-dev__pandas-35946\n",
      "Token count is too large: pantsbuild__pants-11204\n",
      "Token count is too large: pandas-dev__pandas-31991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4194 examples [05:13, 11.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5089\n",
      "Token count is too large: conda__conda-8154\n",
      "Token count is too large: huggingface__transformers-12630\n",
      "Token count is too large: pandas-dev__pandas-27615\n",
      "Token count is too large: pantsbuild__pants-15086\n",
      "Token count is too large: conan-io__conan-7376\n",
      "Token count is too large: pandas-dev__pandas-35003\n",
      "Token count is too large: pantsbuild__pants-18974\n",
      "Token count is too large: pandas-dev__pandas-38148\n",
      "Token count is too large: pandas-dev__pandas-39564\n",
      "Token count is too large: pandas-dev__pandas-35848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4198 examples [05:13, 12.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25553\n",
      "Token count is too large: celery__celery-4456\n",
      "Token count is too large: pandas-dev__pandas-19510\n",
      "Token count is too large: mesonbuild__meson-8166\n",
      "Token count is too large: ipython__ipython-8124\n",
      "Token count is too large: mesonbuild__meson-318\n",
      "Token count is too large: conan-io__conan-5763\n",
      "Token count is too large: pandas-dev__pandas-8682\n",
      "Token count is too large: pypa__pip-599\n",
      "Token count is too large: pandas-dev__pandas-23152\n",
      "Token count is too large: conda__conda-7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4200 examples [05:13, 11.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24984\n",
      "Token count is too large: pandas-dev__pandas-20941\n",
      "Token count is too large: numpy__numpy-23747\n",
      "Token count is too large: pandas-dev__pandas-30937\n",
      "Token count is too large: pandas-dev__pandas-34908\n",
      "Token count is too large: google__jax-2903\n",
      "Token count is too large: google__jax-1790\n",
      "Token count is too large: apache__airflow-22886\n",
      "Token count is too large: pandas-dev__pandas-23829\n",
      "Token count is too large: pypa__pip-5190\n",
      "Token count is too large: pandas-dev__pandas-26440\n",
      "Token count is too large: ray-project__ray-3020\n",
      "Token count is too large: pandas-dev__pandas-36808\n",
      "Token count is too large: pandas-dev__pandas-39800\n",
      "Token count is too large: docker__compose-2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4203 examples [05:14,  7.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23127\n",
      "Token count is too large: pyca__cryptography-1072\n",
      "Token count is too large: pantsbuild__pants-13715\n",
      "Token count is too large: pandas-dev__pandas-28622\n",
      "Token count is too large: open-mmlab__mmdetection-9694\n",
      "Token count is too large: Qiskit__qiskit-7213\n",
      "Token count is too large: googleapis__google-cloud-python-2334\n",
      "Token count is too large: huggingface__transformers-7289\n",
      "Token count is too large: pandas-dev__pandas-38262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4208 examples [05:14, 10.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-17236\n",
      "Token count is too large: docker__compose-5291\n",
      "Token count is too large: Qiskit__qiskit-1700\n",
      "Token count is too large: google__jax-3016\n",
      "Token count is too large: ytdl-org__youtube-dl-26100\n",
      "Token count is too large: pantsbuild__pants-11483\n",
      "Token count is too large: pandas-dev__pandas-33080\n",
      "Token count is too large: pyca__cryptography-5318\n",
      "Token count is too large: pandas-dev__pandas-10263\n",
      "Token count is too large: pandas-dev__pandas-30675\n",
      "Token count is too large: mesonbuild__meson-9430\n",
      "Token count is too large: googleapis__google-cloud-python-4209\n",
      "Token count is too large: dagster-io__dagster-12799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4212 examples [05:14, 12.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-1414\n",
      "Token count is too large: huggingface__transformers-22537\n",
      "Token count is too large: pandas-dev__pandas-35507\n",
      "Token count is too large: docker__compose-4604\n",
      "Token count is too large: huggingface__transformers-21150\n",
      "Token count is too large: pandas-dev__pandas-3244\n",
      "Token count is too large: conda__conda-5991\n",
      "Token count is too large: pandas-dev__pandas-39216\n",
      "Token count is too large: dagster-io__dagster-10150\n",
      "Token count is too large: numpy__numpy-19388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4214 examples [05:15,  9.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36303\n",
      "Token count is too large: pandas-dev__pandas-6459\n",
      "Token count is too large: Lightning-AI__lightning-1576\n",
      "Token count is too large: Qiskit__qiskit-2316\n",
      "Token count is too large: pandas-dev__pandas-10808\n",
      "Token count is too large: mesonbuild__meson-10679\n",
      "Token count is too large: pandas-dev__pandas-34493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4216 examples [05:15,  9.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7077\n",
      "Token count is too large: pandas-dev__pandas-30679\n",
      "Token count is too large: numpy__numpy-12428\n",
      "Token count is too large: conda__conda-667\n",
      "Token count is too large: pandas-dev__pandas-16725\n",
      "Token count is too large: ytdl-org__youtube-dl-14548\n",
      "Token count is too large: mesonbuild__meson-11039\n",
      "Token count is too large: dagster-io__dagster-6446\n",
      "Token count is too large: Lightning-AI__lightning-492\n",
      "Token count is too large: pypa__pip-3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4220 examples [05:15, 11.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20002\n",
      "Token count is too large: pandas-dev__pandas-7279\n",
      "Token count is too large: pandas-dev__pandas-10064\n",
      "Token count is too large: Lightning-AI__lightning-233\n",
      "Token count is too large: pypa__pip-2137\n",
      "Token count is too large: pandas-dev__pandas-39006\n",
      "Token count is too large: wagtail__wagtail-8574\n",
      "Token count is too large: pandas-dev__pandas-24973\n",
      "Token count is too large: explosion__spaCy-3075\n",
      "Token count is too large: pandas-dev__pandas-25058\n",
      "Token count is too large: googleapis__google-cloud-python-9894\n",
      "Token count is too large: pandas-dev__pandas-7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4223 examples [05:15, 10.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: twisted__twisted-11732\n",
      "Token count is too large: pandas-dev__pandas-6736\n",
      "Token count is too large: huggingface__transformers-16990\n",
      "Token count is too large: pandas-dev__pandas-9182\n",
      "Token count is too large: ray-project__ray-7851\n",
      "Token count is too large: pandas-dev__pandas-28248\n",
      "Token count is too large: googleapis__google-cloud-python-8882\n",
      "Token count is too large: docker__compose-3095\n",
      "Token count is too large: pandas-dev__pandas-23112\n",
      "Token count is too large: pyca__cryptography-2582\n",
      "Token count is too large: open-mmlab__mmdetection-5370\n",
      "Token count is too large: Qiskit__qiskit-3788\n",
      "Token count is too large: numpy__numpy-10622\n",
      "Token count is too large: pandas-dev__pandas-31515\n",
      "Token count is too large: pandas-dev__pandas-10185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4229 examples [05:16, 12.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25234\n",
      "Token count is too large: googleapis__google-cloud-python-11291\n",
      "Token count is too large: pandas-dev__pandas-19594\n",
      "Token count is too large: apache__airflow-28730\n",
      "Token count is too large: pandas-dev__pandas-8179\n",
      "Token count is too large: pandas-dev__pandas-10183\n",
      "Token count is too large: PrefectHQ__prefect-221\n",
      "Token count is too large: numpy__numpy-22254\n",
      "Token count is too large: pandas-dev__pandas-16462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4234 examples [05:16, 15.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: gitpython-developers__GitPython-948\n",
      "Token count is too large: pandas-dev__pandas-18076\n",
      "Token count is too large: pandas-dev__pandas-7085\n",
      "Token count is too large: docker__compose-2728\n",
      "Token count is too large: google__jax-2503\n",
      "Token count is too large: pandas-dev__pandas-34488\n",
      "Token count is too large: pandas-dev__pandas-16834\n",
      "Token count is too large: dagster-io__dagster-12356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4236 examples [05:16, 13.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11316\n",
      "Token count is too large: huggingface__transformers-14000\n",
      "Token count is too large: conan-io__conan-9752\n",
      "Token count is too large: pandas-dev__pandas-24185\n",
      "Token count is too large: pandas-dev__pandas-22229\n",
      "Token count is too large: huggingface__transformers-12303\n",
      "Token count is too large: conan-io__conan-7890\n",
      "Token count is too large: ipython__ipython-3328\n",
      "Token count is too large: ipython__ipython-5418\n",
      "Token count is too large: conda__conda-4518\n",
      "Token count is too large: pantsbuild__pants-6022\n",
      "Token count is too large: googleapis__google-cloud-python-6770\n",
      "Token count is too large: pandas-dev__pandas-27520\n",
      "Token count is too large: apache__airflow-23180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4239 examples [05:17, 11.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36950\n",
      "Token count is too large: huggingface__transformers-10033\n",
      "Token count is too large: pandas-dev__pandas-30842\n",
      "Token count is too large: conda__conda-5429\n",
      "Token count is too large: pandas-dev__pandas-33140\n",
      "Token count is too large: open-mmlab__mmdetection-2156\n",
      "Token count is too large: numpy__numpy-8665\n",
      "Token count is too large: ipython__ipython-10279\n",
      "Token count is too large: numpy__numpy-10034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4241 examples [05:17, 11.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-10304\n",
      "Token count is too large: pandas-dev__pandas-14236\n",
      "Token count is too large: conda__conda-12233\n",
      "Token count is too large: googleapis__google-cloud-python-4343\n",
      "Token count is too large: google__jax-1720\n",
      "Token count is too large: googleapis__google-cloud-python-4784\n",
      "Token count is too large: twisted__twisted-11878\n",
      "Token count is too large: mesonbuild__meson-10365\n",
      "Token count is too large: pandas-dev__pandas-6114\n",
      "Token count is too large: pyca__cryptography-7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4248 examples [05:17, 16.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Lightning-AI__lightning-3321\n",
      "Token count is too large: pandas-dev__pandas-24837\n",
      "Token count is too large: pypa__pip-2227\n",
      "Token count is too large: pantsbuild__pants-16478\n",
      "Token count is too large: Qiskit__qiskit-6228\n",
      "Token count is too large: mesonbuild__meson-10837\n",
      "Token count is too large: pandas-dev__pandas-32107\n",
      "Token count is too large: numpy__numpy-12923\n",
      "Token count is too large: pandas-dev__pandas-37202\n",
      "Token count is too large: docker__compose-255\n",
      "Token count is too large: pandas-dev__pandas-31005\n",
      "Token count is too large: ray-project__ray-3458\n",
      "Token count is too large: numpy__numpy-18184\n",
      "Token count is too large: wagtail__wagtail-8006\n",
      "Token count is too large: numpy__numpy-5638\n",
      "Token count is too large: conan-io__conan-2416\n",
      "Token count is too large: mesonbuild__meson-3818\n",
      "Token count is too large: pandas-dev__pandas-29387\n",
      "Token count is too large: mesonbuild__meson-1924\n",
      "Token count is too large: apache__airflow-24496\n",
      "Token count is too large: pandas-dev__pandas-23460\n",
      "Token count is too large: ipython__ipython-5568\n",
      "Token count is too large: pandas-dev__pandas-30229\n",
      "Token count is too large: pandas-dev__pandas-32126\n",
      "Token count is too large: googleapis__google-cloud-python-3605\n",
      "Token count is too large: pandas-dev__pandas-6123\n",
      "Token count is too large: huggingface__transformers-9673\n",
      "Token count is too large: pandas-dev__pandas-8809\n",
      "Token count is too large: pandas-dev__pandas-37764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4254 examples [05:18, 15.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-25624\n",
      "Token count is too large: apache__airflow-25305\n",
      "Token count is too large: docker__compose-2708\n",
      "Token count is too large: pandas-dev__pandas-18632\n",
      "Token count is too large: pandas-dev__pandas-16166\n",
      "Token count is too large: Lightning-AI__lightning-1495\n",
      "Token count is too large: pandas-dev__pandas-10625\n",
      "Token count is too large: huggingface__transformers-14441\n",
      "Token count is too large: pandas-dev__pandas-5847\n",
      "Token count is too large: PrefectHQ__prefect-2005\n",
      "Token count is too large: conan-io__conan-6993\n",
      "Token count is too large: Qiskit__qiskit-7606\n",
      "Token count is too large: jupyterlab__jupyterlab-1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4260 examples [05:18, 17.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-221\n",
      "Token count is too large: pantsbuild__pants-18948\n",
      "Token count is too large: numpy__numpy-3131\n",
      "Token count is too large: pypa__pip-1984\n",
      "Token count is too large: pandas-dev__pandas-24601\n",
      "Token count is too large: pandas-dev__pandas-6339\n",
      "Token count is too large: pypa__pip-7704\n",
      "Token count is too large: pantsbuild__pants-11815\n",
      "Token count is too large: ipython__ipython-13612\n",
      "Token count is too large: pandas-dev__pandas-7161\n",
      "Token count is too large: googleapis__google-cloud-python-9237\n",
      "Token count is too large: Qiskit__qiskit-2249\n",
      "Token count is too large: numpy__numpy-8122\n",
      "Token count is too large: pandas-dev__pandas-33767\n",
      "Token count is too large: PrefectHQ__prefect-496\n",
      "Token count is too large: pandas-dev__pandas-24572\n",
      "Token count is too large: ipython__ipython-6010\n",
      "Token count is too large: pandas-dev__pandas-6548\n",
      "Token count is too large: pandas-dev__pandas-17793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4263 examples [05:18, 10.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-342\n",
      "Token count is too large: DataDog__integrations-core-2360\n",
      "Token count is too large: celery__celery-6589\n",
      "Token count is too large: pandas-dev__pandas-36385\n",
      "Token count is too large: pandas-dev__pandas-25585\n",
      "Token count is too large: pandas-dev__pandas-27300\n",
      "Token count is too large: ipython__ipython-11358\n",
      "Token count is too large: huggingface__transformers-10554\n",
      "Token count is too large: pandas-dev__pandas-34461\n",
      "Token count is too large: Qiskit__qiskit-2104\n",
      "Token count is too large: conan-io__conan-6559\n",
      "Token count is too large: docker__compose-6548\n",
      "Token count is too large: twisted__twisted-11739\n",
      "Token count is too large: ytdl-org__youtube-dl-22954\n",
      "Token count is too large: ytdl-org__youtube-dl-9465\n",
      "Token count is too large: pyca__cryptography-5307\n",
      "Token count is too large: ipython__ipython-3854\n",
      "Token count is too large: pandas-dev__pandas-15570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4270 examples [05:19, 14.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-12518\n",
      "Token count is too large: pandas-dev__pandas-4924\n",
      "Token count is too large: pypa__pip-3198\n",
      "Token count is too large: googleapis__google-cloud-python-2362\n",
      "Token count is too large: pandas-dev__pandas-7941\n",
      "Token count is too large: pandas-dev__pandas-5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4272 examples [05:19, 14.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22776\n",
      "Token count is too large: pandas-dev__pandas-4696\n",
      "Token count is too large: mesonbuild__meson-3687\n",
      "Token count is too large: pandas-dev__pandas-37056\n",
      "Token count is too large: Qiskit__qiskit-4662\n",
      "Token count is too large: pandas-dev__pandas-4100\n",
      "Token count is too large: pandas-dev__pandas-17670\n",
      "Token count is too large: pypa__pip-1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4278 examples [05:19, 14.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1025\n",
      "Token count is too large: huggingface__transformers-13693\n",
      "Token count is too large: pypa__pip-11269\n",
      "Token count is too large: googleapis__google-cloud-python-542\n",
      "Token count is too large: mesonbuild__meson-4652\n",
      "Token count is too large: dagster-io__dagster-9407\n",
      "Token count is too large: pypa__pip-9428\n",
      "Token count is too large: pandas-dev__pandas-33279\n",
      "Token count is too large: Qiskit__qiskit-9818\n",
      "Token count is too large: pandas-dev__pandas-6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4281 examples [05:20, 12.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-23966\n",
      "Token count is too large: ipython__ipython-8030\n",
      "Token count is too large: Qiskit__qiskit-8656\n",
      "Token count is too large: pandas-dev__pandas-4995\n",
      "Token count is too large: Lightning-AI__lightning-1842\n",
      "Token count is too large: huggingface__transformers-378\n",
      "Token count is too large: pandas-dev__pandas-6593\n",
      "Token count is too large: mesonbuild__meson-4847\n",
      "Token count is too large: Qiskit__qiskit-1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4283 examples [05:20, 11.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-16131\n",
      "Token count is too large: pandas-dev__pandas-28078\n",
      "Token count is too large: pandas-dev__pandas-5373\n",
      "Token count is too large: pandas-dev__pandas-39065\n",
      "Token count is too large: ytdl-org__youtube-dl-24642\n",
      "Token count is too large: huggingface__transformers-14790\n",
      "There was an error processing\n",
      "Token count is too large: PrefectHQ__prefect-529\n",
      "Token count is too large: docker__compose-5706\n",
      "Token count is too large: pantsbuild__pants-16531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4285 examples [05:20, 11.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-5283\n",
      "Token count is too large: pandas-dev__pandas-38097\n",
      "Token count is too large: pandas-dev__pandas-19425\n",
      "Token count is too large: pandas-dev__pandas-37072\n",
      "Token count is too large: conda__conda-8248\n",
      "Token count is too large: huggingface__transformers-9488\n",
      "Token count is too large: Qiskit__qiskit-3394\n",
      "Token count is too large: conan-io__conan-4260\n",
      "Token count is too large: pypa__pip-7354\n",
      "Token count is too large: Qiskit__qiskit-7666\n",
      "Token count is too large: conan-io__conan-6298\n",
      "Token count is too large: conda__conda-5249\n",
      "Token count is too large: conda__conda-6741\n",
      "Token count is too large: jupyterlab__jupyterlab-7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4287 examples [05:20,  9.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4498\n",
      "Token count is too large: pandas-dev__pandas-21933\n",
      "Token count is too large: Lightning-AI__lightning-689\n",
      "Token count is too large: pantsbuild__pants-6940\n",
      "Token count is too large: pandas-dev__pandas-24549\n",
      "Token count is too large: googleapis__google-cloud-python-11355\n",
      "Token count is too large: Qiskit__qiskit-8570\n",
      "Token count is too large: pandas-dev__pandas-37873\n",
      "Token count is too large: docker__compose-6609\n",
      "Token count is too large: googleapis__google-cloud-python-3270\n",
      "Token count is too large: pandas-dev__pandas-18524\n",
      "Token count is too large: pandas-dev__pandas-36223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4290 examples [05:20, 11.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-4207\n",
      "Token count is too large: conda__conda-9614\n",
      "Token count is too large: googleapis__google-cloud-python-8806\n",
      "Token count is too large: ytdl-org__youtube-dl-2948\n",
      "Token count is too large: pandas-dev__pandas-11212\n",
      "Token count is too large: ipython__ipython-8587\n",
      "Token count is too large: google__jax-1240\n",
      "Token count is too large: jupyterlab__jupyterlab-3567\n",
      "Token count is too large: pandas-dev__pandas-9245\n",
      "Token count is too large: pantsbuild__pants-7603\n",
      "Token count is too large: pandas-dev__pandas-8320\n",
      "Token count is too large: pantsbuild__pants-16254\n",
      "Token count is too large: ray-project__ray-7250\n",
      "Token count is too large: pandas-dev__pandas-23731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4301 examples [05:21, 22.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-28899\n",
      "Token count is too large: mesonbuild__meson-7117\n",
      "Token count is too large: numpy__numpy-11691\n",
      "Token count is too large: ray-project__ray-9521\n",
      "Token count is too large: pandas-dev__pandas-5064\n",
      "Token count is too large: pandas-dev__pandas-2349\n",
      "Token count is too large: conan-io__conan-5725\n",
      "Token count is too large: ipython__ipython-1306\n",
      "Token count is too large: numpy__numpy-3642\n",
      "Token count is too large: googleapis__google-cloud-python-7491\n",
      "Token count is too large: numpy__numpy-18176\n",
      "Token count is too large: conan-io__conan-11505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4305 examples [05:21, 25.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8478\n",
      "Token count is too large: pandas-dev__pandas-37148\n",
      "Token count is too large: pandas-dev__pandas-16303\n",
      "Token count is too large: pandas-dev__pandas-8523\n",
      "Token count is too large: pandas-dev__pandas-32074\n",
      "Token count is too large: pandas-dev__pandas-30961\n",
      "Token count is too large: conda__conda-8198\n",
      "Token count is too large: ipython__ipython-4187\n",
      "Token count is too large: docker__compose-2894\n",
      "Token count is too large: pandas-dev__pandas-17926\n",
      "Token count is too large: ytdl-org__youtube-dl-3430\n",
      "Token count is too large: numpy__numpy-6628\n",
      "Token count is too large: dagster-io__dagster-2803\n",
      "Token count is too large: pandas-dev__pandas-7219\n",
      "Token count is too large: apache__airflow-16931\n",
      "Token count is too large: conan-io__conan-3086\n",
      "Token count is too large: mesonbuild__meson-7149\n",
      "Token count is too large: mesonbuild__meson-9665\n",
      "Token count is too large: huggingface__transformers-8880\n",
      "Token count is too large: pandas-dev__pandas-23183\n",
      "Token count is too large: huggingface__transformers-22447\n",
      "Token count is too large: pantsbuild__pants-13723\n",
      "Token count is too large: celery__celery-4744\n",
      "Token count is too large: huggingface__transformers-18856\n",
      "Token count is too large: googleapis__google-cloud-python-6575\n",
      "Token count is too large: huggingface__transformers-7569\n",
      "Token count is too large: pandas-dev__pandas-7379\n",
      "Token count is too large: pandas-dev__pandas-38452\n",
      "Token count is too large: huggingface__transformers-14658\n",
      "Token count is too large: google__jax-703\n",
      "Token count is too large: pandas-dev__pandas-22161\n",
      "Token count is too large: google__jax-897\n",
      "Token count is too large: pypa__pip-7996\n",
      "Token count is too large: google__jax-141\n",
      "Token count is too large: ray-project__ray-10499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4308 examples [05:22, 10.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-8624\n",
      "Token count is too large: pandas-dev__pandas-16949\n",
      "Token count is too large: pandas-dev__pandas-33336\n",
      "Token count is too large: huggingface__transformers-2051\n",
      "Token count is too large: pantsbuild__pants-15605\n",
      "Token count is too large: pandas-dev__pandas-9321\n",
      "Token count is too large: conan-io__conan-4660\n",
      "Token count is too large: Qiskit__qiskit-3079\n",
      "Token count is too large: pyca__cryptography-4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4314 examples [05:22, 12.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-12759\n",
      "Token count is too large: ytdl-org__youtube-dl-3644\n",
      "Token count is too large: pandas-dev__pandas-3245\n",
      "Token count is too large: conan-io__conan-3941\n",
      "Token count is too large: pandas-dev__pandas-8925\n",
      "Token count is too large: huggingface__transformers-6744\n",
      "Token count is too large: celery__celery-5795\n",
      "Token count is too large: pandas-dev__pandas-28197\n",
      "Token count is too large: numpy__numpy-14209\n",
      "Token count is too large: pandas-dev__pandas-35287\n",
      "Token count is too large: apache__airflow-11395\n",
      "Token count is too large: googleapis__google-cloud-python-1717\n",
      "Token count is too large: celery__celery-4205\n",
      "Token count is too large: celery__celery-6614\n",
      "Token count is too large: numpy__numpy-8131\n",
      "Token count is too large: Lightning-AI__lightning-1891\n",
      "Token count is too large: Qiskit__qiskit-9623\n",
      "Token count is too large: mesonbuild__meson-5830\n",
      "Token count is too large: huggingface__transformers-7087\n",
      "Token count is too large: gitpython-developers__GitPython-475\n",
      "Token count is too large: numpy__numpy-16907\n",
      "Token count is too large: pandas-dev__pandas-39396\n",
      "Token count is too large: pandas-dev__pandas-26608\n",
      "Token count is too large: jupyterlab__jupyterlab-11067\n",
      "Token count is too large: pantsbuild__pants-7289\n",
      "Token count is too large: pandas-dev__pandas-32541\n",
      "Token count is too large: Lightning-AI__lightning-1426\n",
      "Token count is too large: conda__conda-6929\n",
      "Token count is too large: ipython__ipython-7471\n",
      "Token count is too large: Qiskit__qiskit-5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4322 examples [05:22, 16.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-5382\n",
      "Token count is too large: mesonbuild__meson-7562\n",
      "Token count is too large: pypa__pip-4483\n",
      "Token count is too large: Qiskit__qiskit-517\n",
      "Token count is too large: apache__airflow-21852\n",
      "Token count is too large: mesonbuild__meson-5397\n",
      "Token count is too large: pandas-dev__pandas-30446\n",
      "Token count is too large: conan-io__conan-9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4329 examples [05:23, 18.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-6501\n",
      "Token count is too large: dagster-io__dagster-14055\n",
      "Token count is too large: pandas-dev__pandas-11622\n",
      "Token count is too large: huggingface__transformers-12113\n",
      "Token count is too large: googleapis__google-cloud-python-6199\n",
      "Token count is too large: pandas-dev__pandas-34208\n",
      "Token count is too large: mesonbuild__meson-9751\n",
      "Token count is too large: conan-io__conan-3025\n",
      "Token count is too large: apache__airflow-26223\n",
      "Token count is too large: PrefectHQ__prefect-732\n",
      "Token count is too large: pandas-dev__pandas-6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4332 examples [05:23, 16.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-5390\n",
      "Token count is too large: pandas-dev__pandas-35633\n",
      "There was an error processing\n",
      "Token count is too large: Qiskit__qiskit-3120\n",
      "Token count is too large: pandas-dev__pandas-27999\n",
      "Token count is too large: pypa__pip-11634\n",
      "Token count is too large: mesonbuild__meson-10728\n",
      "Token count is too large: Qiskit__qiskit-3004\n",
      "Token count is too large: huggingface__transformers-11819\n",
      "Token count is too large: Qiskit__qiskit-4734\n",
      "Token count is too large: huggingface__transformers-18134\n",
      "Token count is too large: pandas-dev__pandas-7851\n",
      "Token count is too large: pandas-dev__pandas-3615\n",
      "Token count is too large: huggingface__transformers-18602\n",
      "Token count is too large: pandas-dev__pandas-7572\n",
      "Token count is too large: ipython__ipython-11350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4336 examples [05:23, 16.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4435\n",
      "Token count is too large: pandas-dev__pandas-18604\n",
      "Token count is too large: pandas-dev__pandas-9022\n",
      "Token count is too large: scipy__scipy-150\n",
      "Token count is too large: numpy__numpy-18181\n",
      "Token count is too large: mesonbuild__meson-703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4339 examples [05:24, 12.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-5707\n",
      "Token count is too large: open-mmlab__mmdetection-3836\n",
      "Token count is too large: huggingface__transformers-25042\n",
      "Token count is too large: googleapis__google-cloud-python-9634\n",
      "Token count is too large: pandas-dev__pandas-23575\n",
      "Token count is too large: Qiskit__qiskit-7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4342 examples [05:24, 13.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-8067\n",
      "Token count is too large: docker__compose-2126\n",
      "Token count is too large: numpy__numpy-5666\n",
      "Token count is too large: mesonbuild__meson-2258\n",
      "Token count is too large: huggingface__transformers-16771\n",
      "Token count is too large: googleapis__google-cloud-python-5712\n",
      "Token count is too large: numpy__numpy-16919\n",
      "Token count is too large: numpy__numpy-3236\n",
      "Token count is too large: ipython__ipython-10244\n",
      "Token count is too large: pandas-dev__pandas-20708\n",
      "Token count is too large: google__jax-3485\n",
      "Token count is too large: jupyterlab__jupyterlab-3356\n",
      "Token count is too large: ytdl-org__youtube-dl-18425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4345 examples [05:24, 13.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-6052\n",
      "Token count is too large: Qiskit__qiskit-6962\n",
      "Token count is too large: google__jax-2288\n",
      "Token count is too large: pandas-dev__pandas-25586\n",
      "Token count is too large: pandas-dev__pandas-3840\n",
      "Token count is too large: googleapis__google-cloud-python-11328\n",
      "Token count is too large: pandas-dev__pandas-21116\n",
      "Token count is too large: pandas-dev__pandas-36457\n",
      "Token count is too large: pandas-dev__pandas-19109\n",
      "Token count is too large: ray-project__ray-4504\n",
      "Token count is too large: pandas-dev__pandas-11806\n",
      "Token count is too large: pandas-dev__pandas-7245\n",
      "Token count is too large: apache__airflow-11509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4348 examples [05:24, 10.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11690\n",
      "Token count is too large: pandas-dev__pandas-34296\n",
      "Token count is too large: celery__celery-6849\n",
      "Token count is too large: dagster-io__dagster-2517\n",
      "Token count is too large: conan-io__conan-4309\n",
      "Token count is too large: mesonbuild__meson-2826\n",
      "Token count is too large: mesonbuild__meson-3057\n",
      "Token count is too large: open-mmlab__mmdetection-2671\n",
      "Token count is too large: pandas-dev__pandas-6068\n",
      "Token count is too large: google__jax-778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4350 examples [05:25, 11.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3879\n",
      "Token count is too large: conda__conda-11398\n",
      "Token count is too large: Qiskit__qiskit-691\n",
      "Token count is too large: pandas-dev__pandas-32079\n",
      "Token count is too large: pypa__pip-5280\n",
      "Token count is too large: pandas-dev__pandas-25949\n",
      "Token count is too large: pandas-dev__pandas-35668\n",
      "Token count is too large: numpy__numpy-22721\n",
      "Token count is too large: tiangolo__fastapi-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4352 examples [05:25,  9.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4953\n",
      "Token count is too large: ytdl-org__youtube-dl-854\n",
      "Token count is too large: pandas-dev__pandas-26677\n",
      "Token count is too large: pandas-dev__pandas-39442\n",
      "Token count is too large: jupyterlab__jupyterlab-6194\n",
      "Token count is too large: ray-project__ray-3593\n",
      "Token count is too large: pypa__pip-6267\n",
      "Token count is too large: pyca__cryptography-2126\n",
      "Token count is too large: Qiskit__qiskit-3573\n",
      "Token count is too large: numpy__numpy-13560\n",
      "Token count is too large: conda__conda-6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4356 examples [05:25, 10.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22498\n",
      "Token count is too large: Qiskit__qiskit-1134\n",
      "Token count is too large: google__jax-2026\n",
      "Token count is too large: pantsbuild__pants-12505\n",
      "Token count is too large: conda__conda-3143\n",
      "Token count is too large: mesonbuild__meson-3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4362 examples [05:25, 15.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-15247\n",
      "Token count is too large: pantsbuild__pants-5352\n",
      "Token count is too large: PrefectHQ__prefect-95\n",
      "Token count is too large: conda__conda-5531\n",
      "Token count is too large: pandas-dev__pandas-8763\n",
      "Token count is too large: pandas-dev__pandas-6443\n",
      "Token count is too large: PrefectHQ__prefect-1963\n",
      "Token count is too large: ytdl-org__youtube-dl-3789\n",
      "Token count is too large: pantsbuild__pants-16219\n",
      "Token count is too large: apache__airflow-16805\n",
      "Token count is too large: pypa__pip-4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4366 examples [05:26, 16.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33771\n",
      "Token count is too large: huggingface__transformers-15456\n",
      "Token count is too large: Qiskit__qiskit-9000\n",
      "Token count is too large: pandas-dev__pandas-3939\n",
      "Token count is too large: pandas-dev__pandas-17982\n",
      "Token count is too large: conan-io__conan-2639\n",
      "Token count is too large: pandas-dev__pandas-28838\n",
      "Token count is too large: pandas-dev__pandas-20412\n",
      "Token count is too large: google__jax-1309\n",
      "Token count is too large: pandas-dev__pandas-24355\n",
      "Token count is too large: Qiskit__qiskit-3772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4369 examples [05:26, 17.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8990\n",
      "Token count is too large: jupyterlab__jupyterlab-8961\n",
      "Token count is too large: googleapis__google-cloud-python-5405\n",
      "Token count is too large: huggingface__transformers-8621\n",
      "Token count is too large: docker__compose-6377\n",
      "Token count is too large: ipython__ipython-3561\n",
      "Token count is too large: conan-io__conan-6169\n",
      "Token count is too large: Qiskit__qiskit-8977\n",
      "Token count is too large: huggingface__transformers-21630\n",
      "Token count is too large: ipython__ipython-4106\n",
      "Token count is too large: mesonbuild__meson-2413\n",
      "Token count is too large: conda__conda-6446\n",
      "Token count is too large: docker__compose-6368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4374 examples [05:26, 16.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-2666\n",
      "Token count is too large: pandas-dev__pandas-36365\n",
      "Token count is too large: pyca__cryptography-5831\n",
      "Token count is too large: pantsbuild__pants-18840\n",
      "Token count is too large: pandas-dev__pandas-28257\n",
      "Token count is too large: pandas-dev__pandas-36022\n",
      "Token count is too large: Qiskit__qiskit-1317\n",
      "Token count is too large: open-mmlab__mmdetection-5820\n",
      "Token count is too large: celery__celery-7077\n",
      "Token count is too large: pypa__pip-4496\n",
      "Token count is too large: mesonbuild__meson-2310\n",
      "Token count is too large: pandas-dev__pandas-18753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4379 examples [05:26, 18.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-9635\n",
      "Token count is too large: pantsbuild__pants-4578\n",
      "Token count is too large: conan-io__conan-10178\n",
      "Token count is too large: pantsbuild__pants-13540\n",
      "Token count is too large: pandas-dev__pandas-32903\n",
      "Token count is too large: pandas-dev__pandas-32836\n",
      "Token count is too large: conan-io__conan-2682\n",
      "Token count is too large: dagster-io__dagster-1199\n",
      "Token count is too large: Lightning-AI__lightning-2853\n",
      "Token count is too large: pandas-dev__pandas-7688\n",
      "Token count is too large: wagtail__wagtail-5559\n",
      "Token count is too large: pandas-dev__pandas-23471\n",
      "Token count is too large: huggingface__transformers-11596\n",
      "Token count is too large: apache__airflow-33706\n",
      "Token count is too large: Lightning-AI__lightning-1191\n",
      "Token count is too large: wagtail__wagtail-10623\n",
      "Token count is too large: pandas-dev__pandas-36464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4381 examples [05:27, 12.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-33218\n",
      "Token count is too large: Lightning-AI__lightning-2755\n",
      "Token count is too large: pandas-dev__pandas-6646\n",
      "Token count is too large: docker__compose-6425\n",
      "Token count is too large: huggingface__transformers-16198\n",
      "Token count is too large: Qiskit__qiskit-7614\n",
      "Token count is too large: apache__airflow-14810\n",
      "Token count is too large: Lightning-AI__lightning-2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4386 examples [05:27, 14.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39258\n",
      "Token count is too large: pandas-dev__pandas-3145\n",
      "Token count is too large: pandas-dev__pandas-18407\n",
      "Token count is too large: PrefectHQ__prefect-679\n",
      "Token count is too large: pypa__pip-4144\n",
      "Token count is too large: ytdl-org__youtube-dl-32138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4390 examples [05:27, 16.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ray-project__ray-6376\n",
      "Token count is too large: pandas-dev__pandas-37727\n",
      "Token count is too large: pandas-dev__pandas-5334\n",
      "Token count is too large: Lightning-AI__lightning-2202\n",
      "Token count is too large: Lightning-AI__lightning-2624\n",
      "Token count is too large: pandas-dev__pandas-25338\n",
      "Token count is too large: Qiskit__qiskit-6018\n",
      "Token count is too large: ray-project__ray-2754\n",
      "Token count is too large: Qiskit__qiskit-8847\n",
      "Token count is too large: pandas-dev__pandas-29792\n",
      "Token count is too large: apache__airflow-12916\n",
      "Token count is too large: jupyterlab__jupyterlab-3140\n",
      "Token count is too large: wagtail__wagtail-942\n",
      "Token count is too large: conda__conda-4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4392 examples [05:27, 12.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23010\n",
      "There was an error processing\n",
      "Token count is too large: Lightning-AI__lightning-2293\n",
      "Token count is too large: mesonbuild__meson-7735\n",
      "Token count is too large: googleapis__google-cloud-python-11416\n",
      "Token count is too large: pandas-dev__pandas-16549\n",
      "Token count is too large: googleapis__google-cloud-python-7061\n",
      "Token count is too large: conda__conda-7064\n",
      "Token count is too large: pandas-dev__pandas-35187\n",
      "Token count is too large: google__jax-3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4396 examples [05:28, 13.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-17063\n",
      "Token count is too large: pandas-dev__pandas-14536\n",
      "Token count is too large: huggingface__transformers-17710\n",
      "Token count is too large: explosion__spaCy-866\n",
      "Token count is too large: mesonbuild__meson-8464\n",
      "Token count is too large: pandas-dev__pandas-37736\n",
      "Token count is too large: huggingface__transformers-22684\n",
      "Token count is too large: pandas-dev__pandas-9914\n",
      "Token count is too large: huggingface__transformers-23173\n",
      "Token count is too large: pandas-dev__pandas-32723\n",
      "Token count is too large: Qiskit__qiskit-1479\n",
      "Token count is too large: pandas-dev__pandas-19324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4398 examples [05:28, 11.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-5423\n",
      "Token count is too large: mesonbuild__meson-4689\n",
      "Token count is too large: pandas-dev__pandas-7923\n",
      "Token count is too large: ipython__ipython-10809\n",
      "Token count is too large: pantsbuild__pants-17473\n",
      "Token count is too large: googleapis__google-cloud-python-9143\n",
      "Token count is too large: pandas-dev__pandas-25531\n",
      "Token count is too large: ytdl-org__youtube-dl-16157\n",
      "Token count is too large: huggingface__transformers-17423\n",
      "Token count is too large: pandas-dev__pandas-5111\n",
      "Token count is too large: pypa__pip-11872\n",
      "Token count is too large: pandas-dev__pandas-7973\n",
      "Token count is too large: huggingface__transformers-23235\n",
      "Token count is too large: huggingface__transformers-9382\n",
      "Token count is too large: Qiskit__qiskit-3441\n",
      "Token count is too large: pandas-dev__pandas-10570\n",
      "Token count is too large: googleapis__google-cloud-python-1664\n",
      "Token count is too large: numpy__numpy-16022\n",
      "Token count is too large: pandas-dev__pandas-7963\n",
      "Token count is too large: Qiskit__qiskit-3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4402 examples [05:29,  8.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-1022\n",
      "Token count is too large: pandas-dev__pandas-34344\n",
      "Token count is too large: ipython__ipython-13928\n",
      "Token count is too large: pandas-dev__pandas-4806\n",
      "Token count is too large: mesonbuild__meson-11746\n",
      "Token count is too large: Qiskit__qiskit-740\n",
      "Token count is too large: pandas-dev__pandas-7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4404 examples [05:29,  8.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22966\n",
      "Token count is too large: googleapis__google-cloud-python-2052\n",
      "Token count is too large: pypa__pip-3003\n",
      "Token count is too large: googleapis__google-cloud-python-8701\n",
      "Token count is too large: apache__airflow-13640\n",
      "Token count is too large: pandas-dev__pandas-6390\n",
      "Token count is too large: huggingface__transformers-10184\n",
      "Token count is too large: numpy__numpy-4758\n",
      "Token count is too large: pandas-dev__pandas-9473\n",
      "Token count is too large: pandas-dev__pandas-28743\n",
      "Token count is too large: ipython__ipython-11812\n",
      "Token count is too large: mesonbuild__meson-4604\n",
      "Token count is too large: googleapis__google-cloud-python-897\n",
      "Token count is too large: huggingface__transformers-7672\n",
      "Token count is too large: google__jax-1335\n",
      "Token count is too large: docker__compose-6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4409 examples [05:29, 11.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6743\n",
      "Token count is too large: pandas-dev__pandas-3451\n",
      "Token count is too large: ray-project__ray-7347\n",
      "Token count is too large: pandas-dev__pandas-10502\n",
      "Token count is too large: pandas-dev__pandas-8834\n",
      "Token count is too large: pandas-dev__pandas-5220\n",
      "Token count is too large: ytdl-org__youtube-dl-11929\n",
      "Token count is too large: googleapis__google-cloud-python-3713\n",
      "Token count is too large: ipython__ipython-6769\n",
      "Token count is too large: ipython__ipython-7278\n",
      "Token count is too large: Qiskit__qiskit-10244\n",
      "Token count is too large: huggingface__transformers-10034\n",
      "Token count is too large: pandas-dev__pandas-10508\n",
      "Token count is too large: pandas-dev__pandas-25789\n",
      "Token count is too large: ray-project__ray-10594\n",
      "Token count is too large: googleapis__google-cloud-python-9973\n",
      "Token count is too large: huggingface__transformers-19657\n",
      "Token count is too large: ipython__ipython-1988\n",
      "Token count is too large: huggingface__transformers-15394\n",
      "Token count is too large: mesonbuild__meson-5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4411 examples [05:30,  8.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39341\n",
      "Token count is too large: Qiskit__qiskit-6065\n",
      "Token count is too large: Qiskit__qiskit-7789\n",
      "Token count is too large: huggingface__transformers-9271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4421 examples [05:30, 15.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-3450\n",
      "Token count is too large: pandas-dev__pandas-37102\n",
      "Token count is too large: wagtail__wagtail-3423\n",
      "Token count is too large: conan-io__conan-4083\n",
      "Token count is too large: pandas-dev__pandas-11023\n",
      "Token count is too large: mesonbuild__meson-4157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4424 examples [05:30, 14.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-7284\n",
      "Token count is too large: numpy__numpy-9965\n",
      "Token count is too large: pandas-dev__pandas-9028\n",
      "Token count is too large: docker__compose-2361\n",
      "Token count is too large: pyca__cryptography-5533\n",
      "Token count is too large: pandas-dev__pandas-21029\n",
      "Token count is too large: pypa__pip-3289\n",
      "Token count is too large: docker__compose-171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4426 examples [05:30, 14.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6820\n",
      "Token count is too large: mesonbuild__meson-3573\n",
      "Token count is too large: twisted__twisted-11693\n",
      "Token count is too large: PrefectHQ__prefect-991\n",
      "Token count is too large: huggingface__transformers-19655\n",
      "Token count is too large: pandas-dev__pandas-32040\n",
      "Token count is too large: pandas-dev__pandas-33769\n",
      "Token count is too large: Qiskit__qiskit-937\n",
      "Token count is too large: pypa__pip-5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4435 examples [05:30, 22.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-15890\n",
      "Token count is too large: mesonbuild__meson-2800\n",
      "Token count is too large: pandas-dev__pandas-21924\n",
      "Token count is too large: google__jax-1903\n",
      "Token count is too large: pandas-dev__pandas-9014\n",
      "Token count is too large: conan-io__conan-5321\n",
      "Token count is too large: Lightning-AI__lightning-2375\n",
      "Token count is too large: Lightning-AI__lightning-607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4439 examples [05:31, 22.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24458\n",
      "Token count is too large: celery__celery-6872\n",
      "Token count is too large: conda__conda-11302\n",
      "Token count is too large: google__jax-2532\n",
      "Token count is too large: pandas-dev__pandas-11628\n",
      "Token count is too large: pandas-dev__pandas-24490\n",
      "Token count is too large: pandas-dev__pandas-19330\n",
      "Token count is too large: pandas-dev__pandas-7450\n",
      "Token count is too large: googleapis__google-cloud-python-6229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4445 examples [05:31, 27.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36606\n",
      "Token count is too large: Lightning-AI__lightning-610\n",
      "Token count is too large: google__jax-2610\n",
      "Token count is too large: pandas-dev__pandas-8715\n",
      "Token count is too large: ray-project__ray-7719\n",
      "Token count is too large: googleapis__google-cloud-python-4349\n",
      "Token count is too large: pandas-dev__pandas-33664\n",
      "Token count is too large: huggingface__transformers-20146\n",
      "Token count is too large: apache__airflow-26702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4450 examples [05:31, 20.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-9597\n",
      "Token count is too large: mesonbuild__meson-9215\n",
      "Token count is too large: huggingface__transformers-13334\n",
      "Token count is too large: conda__conda-10864\n",
      "Token count is too large: Lightning-AI__lightning-303\n",
      "Token count is too large: huggingface__transformers-18815\n",
      "Token count is too large: pantsbuild__pants-13972\n",
      "Token count is too large: googleapis__google-cloud-python-5825\n",
      "Token count is too large: pandas-dev__pandas-5906\n",
      "Token count is too large: pandas-dev__pandas-35098\n",
      "Token count is too large: PrefectHQ__prefect-416\n",
      "Token count is too large: pandas-dev__pandas-9802\n",
      "Token count is too large: Qiskit__qiskit-7952\n",
      "Token count is too large: pandas-dev__pandas-36431\n",
      "Token count is too large: pypa__pip-6268\n",
      "Token count is too large: conda__conda-682\n",
      "Token count is too large: conan-io__conan-3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4456 examples [05:32, 18.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27201\n",
      "Token count is too large: huggingface__transformers-14857\n",
      "Token count is too large: pandas-dev__pandas-23345\n",
      "Token count is too large: apache__airflow-28753\n",
      "Token count is too large: Qiskit__qiskit-230\n",
      "Token count is too large: pyca__cryptography-7520\n",
      "Token count is too large: googleapis__google-cloud-python-904\n",
      "Token count is too large: Qiskit__qiskit-9018\n",
      "Token count is too large: Qiskit__qiskit-105\n",
      "Token count is too large: ray-project__ray-3704\n",
      "Token count is too large: pandas-dev__pandas-20347\n",
      "Token count is too large: ipython__ipython-4895\n",
      "Token count is too large: celery__celery-4251\n",
      "Token count is too large: pandas-dev__pandas-10507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4459 examples [05:32, 18.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: twisted__twisted-778\n",
      "Token count is too large: numpy__numpy-10670\n",
      "Token count is too large: pandas-dev__pandas-19013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4463 examples [05:32, 16.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8184\n",
      "Token count is too large: Qiskit__qiskit-4392\n",
      "Token count is too large: pandas-dev__pandas-39000\n",
      "Token count is too large: pandas-dev__pandas-24441\n",
      "Token count is too large: conda__conda-5098\n",
      "Token count is too large: Qiskit__qiskit-9777\n",
      "Token count is too large: apache__airflow-25086\n",
      "Token count is too large: Lightning-AI__lightning-203\n",
      "Token count is too large: Lightning-AI__lightning-2062\n",
      "Token count is too large: ytdl-org__youtube-dl-12268\n",
      "Token count is too large: pantsbuild__pants-18814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4473 examples [05:32, 25.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15327\n",
      "Token count is too large: pandas-dev__pandas-16616\n",
      "Token count is too large: googleapis__google-cloud-python-9178\n",
      "Token count is too large: pypa__pip-5180\n",
      "Token count is too large: conda__conda-6766\n",
      "Token count is too large: pandas-dev__pandas-12065\n",
      "Token count is too large: conda__conda-5010\n",
      "Token count is too large: Qiskit__qiskit-10291\n",
      "Token count is too large: pandas-dev__pandas-31563\n",
      "Token count is too large: google__jax-2966\n",
      "Token count is too large: pandas-dev__pandas-30350\n",
      "Token count is too large: pandas-dev__pandas-7202\n",
      "Token count is too large: docker__compose-2130\n",
      "Token count is too large: apache__airflow-8512\n",
      "Token count is too large: conan-io__conan-14378\n",
      "Token count is too large: pandas-dev__pandas-21363\n",
      "Token count is too large: pandas-dev__pandas-15548\n",
      "Token count is too large: numpy__numpy-22009\n",
      "Token count is too large: huggingface__transformers-19206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4477 examples [05:33, 16.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: docker__compose-5939\n",
      "Token count is too large: celery__celery-7555\n",
      "Token count is too large: Qiskit__qiskit-1184\n",
      "Token count is too large: google__jax-2789\n",
      "Token count is too large: pypa__pip-3153\n",
      "Token count is too large: conan-io__conan-5206\n",
      "Token count is too large: pandas-dev__pandas-6137\n",
      "Token count is too large: Qiskit__qiskit-8900\n",
      "Token count is too large: googleapis__google-cloud-python-4757\n",
      "Token count is too large: pypa__pip-8562\n",
      "Token count is too large: apache__airflow-23177\n",
      "Token count is too large: Qiskit__qiskit-5063\n",
      "Token count is too large: conan-io__conan-3091\n",
      "Token count is too large: pandas-dev__pandas-21683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4480 examples [05:33, 13.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16970\n",
      "Token count is too large: docker__compose-7031\n",
      "Token count is too large: pandas-dev__pandas-30311\n",
      "Token count is too large: huggingface__transformers-15068\n",
      "Token count is too large: pantsbuild__pants-14957\n",
      "Token count is too large: conda__conda-8219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4488 examples [05:34, 17.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10967\n",
      "Token count is too large: pandas-dev__pandas-34183\n",
      "Token count is too large: ray-project__ray-1668\n",
      "Token count is too large: Qiskit__qiskit-5759\n",
      "Token count is too large: pandas-dev__pandas-9226\n",
      "Token count is too large: pandas-dev__pandas-16434\n",
      "Token count is too large: mesonbuild__meson-9473\n",
      "Token count is too large: conda__conda-6550\n",
      "Token count is too large: pypa__pip-3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4491 examples [05:34, 17.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-20166\n",
      "Token count is too large: ytdl-org__youtube-dl-31675\n",
      "Token count is too large: ipython__ipython-11419\n",
      "Token count is too large: Lightning-AI__lightning-706\n",
      "Token count is too large: docker__compose-5415\n",
      "Token count is too large: pandas-dev__pandas-19626\n",
      "Token count is too large: PrefectHQ__prefect-311\n",
      "Token count is too large: pandas-dev__pandas-24273\n",
      "Token count is too large: conan-io__conan-2510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4494 examples [05:34, 18.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-18369\n",
      "Token count is too large: ipython__ipython-13436\n",
      "Token count is too large: pandas-dev__pandas-8460\n",
      "Token count is too large: apache__airflow-12072\n",
      "Token count is too large: Qiskit__qiskit-8151\n",
      "Token count is too large: pandas-dev__pandas-18929\n",
      "Token count is too large: ray-project__ray-4676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4500 examples [05:34, 17.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-6552\n",
      "Token count is too large: googleapis__google-cloud-python-9436\n",
      "Token count is too large: pypa__pip-3225\n",
      "Token count is too large: googleapis__google-cloud-python-11321\n",
      "Token count is too large: celery__celery-6462\n",
      "Token count is too large: Lightning-AI__lightning-1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4502 examples [05:34, 16.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4349\n",
      "Token count is too large: celery__celery-6733\n",
      "Token count is too large: pandas-dev__pandas-26106\n",
      "Token count is too large: numpy__numpy-5733\n",
      "Token count is too large: pandas-dev__pandas-10810\n",
      "Token count is too large: googleapis__google-cloud-python-2589\n",
      "Token count is too large: numpy__numpy-16349\n",
      "Token count is too large: pypa__pip-6928\n",
      "Token count is too large: ytdl-org__youtube-dl-4248\n",
      "Token count is too large: Lightning-AI__lightning-2930\n",
      "Token count is too large: pandas-dev__pandas-37613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4504 examples [05:34, 16.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-2029\n",
      "Token count is too large: ray-project__ray-9516\n",
      "Token count is too large: conan-io__conan-1039\n",
      "Token count is too large: wagtail__wagtail-116\n",
      "Token count is too large: conda__conda-7603\n",
      "Token count is too large: Lightning-AI__lightning-2640\n",
      "Token count is too large: Qiskit__qiskit-7175\n",
      "Token count is too large: numpy__numpy-19566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4509 examples [05:35, 18.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23862\n",
      "Token count is too large: googleapis__google-cloud-python-3195\n",
      "Token count is too large: PrefectHQ__prefect-2155\n",
      "Token count is too large: pandas-dev__pandas-22482\n",
      "Token count is too large: apache__airflow-26239\n",
      "Token count is too large: pandas-dev__pandas-5003\n",
      "Token count is too large: Qiskit__qiskit-10521\n",
      "Token count is too large: PrefectHQ__prefect-186\n",
      "Token count is too large: pandas-dev__pandas-17279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4511 examples [05:35, 14.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18852\n",
      "Token count is too large: pandas-dev__pandas-32842\n",
      "Token count is too large: conan-io__conan-3101\n",
      "Token count is too large: googleapis__google-cloud-python-1932\n",
      "Token count is too large: mesonbuild__meson-10656\n",
      "Token count is too large: numpy__numpy-10111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4513 examples [05:35, 10.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-7181\n",
      "Token count is too large: pandas-dev__pandas-25394\n",
      "Token count is too large: conda__conda-795\n",
      "Token count is too large: mesonbuild__meson-3783\n",
      "Token count is too large: Qiskit__qiskit-1344\n",
      "Token count is too large: pandas-dev__pandas-24993\n",
      "Token count is too large: pandas-dev__pandas-5227\n",
      "Token count is too large: huggingface__transformers-12116\n",
      "Token count is too large: pandas-dev__pandas-28099\n",
      "Token count is too large: pandas-dev__pandas-19723\n",
      "Token count is too large: pandas-dev__pandas-24407\n",
      "Token count is too large: Qiskit__qiskit-303\n",
      "Token count is too large: conan-io__conan-5215\n",
      "Token count is too large: mesonbuild__meson-3885\n",
      "Token count is too large: numpy__numpy-6541\n",
      "Token count is too large: docker__compose-7653\n",
      "Token count is too large: huggingface__transformers-22158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4518 examples [05:36, 10.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-639\n",
      "Token count is too large: docker__compose-4716\n",
      "Token count is too large: mesonbuild__meson-1594\n",
      "Token count is too large: wagtail__wagtail-3973\n",
      "Token count is too large: Lightning-AI__lightning-3045\n",
      "Token count is too large: huggingface__transformers-18010\n",
      "Token count is too large: apache__airflow-29445\n",
      "Token count is too large: pandas-dev__pandas-5680\n",
      "Token count is too large: googleapis__google-cloud-python-11304\n",
      "Token count is too large: googleapis__google-cloud-python-2798\n",
      "Token count is too large: pypa__pip-10625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4520 examples [05:36, 11.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36822\n",
      "Token count is too large: pandas-dev__pandas-22490\n",
      "Token count is too large: pypa__pip-6603\n",
      "Token count is too large: googleapis__google-cloud-python-6202\n",
      "Token count is too large: pypa__pip-5726\n",
      "Token count is too large: pantsbuild__pants-18446\n",
      "Token count is too large: pandas-dev__pandas-32737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4523 examples [05:36, 12.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23856\n",
      "Token count is too large: pandas-dev__pandas-24005\n",
      "Token count is too large: numpy__numpy-9063\n",
      "Token count is too large: pandas-dev__pandas-26295\n",
      "Token count is too large: google__jax-460\n",
      "Token count is too large: Qiskit__qiskit-9955\n",
      "Token count is too large: pyca__cryptography-5976\n",
      "Token count is too large: Qiskit__qiskit-2569\n",
      "Token count is too large: ipython__ipython-6006\n",
      "Token count is too large: google__jax-2536\n",
      "Token count is too large: jupyterlab__jupyterlab-5462\n",
      "Token count is too large: conan-io__conan-5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4528 examples [05:36, 18.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18440\n",
      "Token count is too large: mesonbuild__meson-1943\n",
      "Token count is too large: pandas-dev__pandas-24186\n",
      "Token count is too large: Qiskit__qiskit-5562\n",
      "Token count is too large: conda__conda-6855\n",
      "Token count is too large: docker__compose-1787\n",
      "Token count is too large: mesonbuild__meson-1651\n",
      "Token count is too large: conan-io__conan-2705\n",
      "Token count is too large: docker__compose-2393\n",
      "Token count is too large: mesonbuild__meson-2918\n",
      "Token count is too large: pandas-dev__pandas-18710\n",
      "Token count is too large: pantsbuild__pants-14550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4535 examples [05:37, 20.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: open-mmlab__mmdetection-3695\n",
      "Token count is too large: numpy__numpy-8816\n",
      "Token count is too large: ipython__ipython-1089\n",
      "Token count is too large: pandas-dev__pandas-7741\n",
      "Token count is too large: googleapis__google-cloud-python-9642\n",
      "Token count is too large: ipython__ipython-1178\n",
      "Token count is too large: huggingface__transformers-17326\n",
      "Token count is too large: ytdl-org__youtube-dl-9324\n",
      "Token count is too large: huggingface__transformers-14276\n",
      "Token count is too large: pantsbuild__pants-18311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4541 examples [05:37, 24.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pantsbuild__pants-9852\n",
      "Token count is too large: conan-io__conan-10917\n",
      "Token count is too large: Qiskit__qiskit-7551\n",
      "Token count is too large: pandas-dev__pandas-24642\n",
      "Token count is too large: mesonbuild__meson-11760\n",
      "Token count is too large: Qiskit__qiskit-6483\n",
      "Token count is too large: Lightning-AI__lightning-530\n",
      "Token count is too large: apache__airflow-25793\n",
      "Token count is too large: ray-project__ray-1152\n",
      "Token count is too large: mesonbuild__meson-2313\n",
      "Token count is too large: pyca__cryptography-4619\n",
      "Token count is too large: docker__compose-2351\n",
      "Token count is too large: pypa__pip-9669\n",
      "Token count is too large: jupyterlab__jupyterlab-3149\n",
      "Token count is too large: ipython__ipython-5818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4547 examples [05:37, 30.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-13365\n",
      "Token count is too large: googleapis__google-cloud-python-6365\n",
      "Token count is too large: numpy__numpy-17492\n",
      "Token count is too large: huggingface__transformers-24941\n",
      "Token count is too large: docker__compose-2384\n",
      "Token count is too large: google__jax-1245\n",
      "Token count is too large: pandas-dev__pandas-19000\n",
      "Token count is too large: twisted__twisted-11831\n",
      "Token count is too large: pypa__pip-3416\n",
      "Token count is too large: google__jax-690\n",
      "Token count is too large: pandas-dev__pandas-7371\n",
      "Token count is too large: numpy__numpy-10547\n",
      "Token count is too large: pandas-dev__pandas-7909\n",
      "Token count is too large: Qiskit__qiskit-5248\n",
      "Token count is too large: mesonbuild__meson-4551\n",
      "Token count is too large: huggingface__transformers-25514\n",
      "Token count is too large: huggingface__transformers-1434\n",
      "Token count is too large: pypa__pip-2538\n",
      "Token count is too large: Qiskit__qiskit-3361\n",
      "Token count is too large: huggingface__transformers-12371\n",
      "Token count is too large: pandas-dev__pandas-23614\n",
      "Token count is too large: pandas-dev__pandas-11356\n",
      "Token count is too large: pandas-dev__pandas-38789\n",
      "Token count is too large: celery__celery-4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4558 examples [05:38, 19.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-8208\n",
      "Token count is too large: jupyterlab__jupyterlab-8212\n",
      "Token count is too large: pandas-dev__pandas-24956\n",
      "Token count is too large: pandas-dev__pandas-10922\n",
      "Token count is too large: conan-io__conan-3292\n",
      "Token count is too large: pandas-dev__pandas-20984\n",
      "Token count is too large: conan-io__conan-11803\n",
      "Token count is too large: pandas-dev__pandas-7336\n",
      "Token count is too large: pantsbuild__pants-8374\n",
      "Token count is too large: pantsbuild__pants-5374\n",
      "Token count is too large: pandas-dev__pandas-11874\n",
      "Token count is too large: mesonbuild__meson-4514\n",
      "Token count is too large: pandas-dev__pandas-39161\n",
      "Token count is too large: apache__airflow-23119\n",
      "Token count is too large: pandas-dev__pandas-30478\n",
      "Token count is too large: numpy__numpy-10653\n",
      "Token count is too large: ray-project__ray-6253\n",
      "Token count is too large: pandas-dev__pandas-28671\n",
      "Token count is too large: huggingface__transformers-8554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4561 examples [05:38, 16.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11342\n",
      "Token count is too large: ray-project__ray-3676\n",
      "Token count is too large: huggingface__transformers-24988\n",
      "Token count is too large: googleapis__google-cloud-python-8039\n",
      "Token count is too large: pandas-dev__pandas-33446\n",
      "Token count is too large: conda__conda-8444\n",
      "Token count is too large: apache__airflow-24117\n",
      "Token count is too large: Qiskit__qiskit-3093\n",
      "Token count is too large: pandas-dev__pandas-34954\n",
      "Token count is too large: PrefectHQ__prefect-2167\n",
      "Token count is too large: pyca__cryptography-2202\n",
      "Token count is too large: open-mmlab__mmdetection-5221\n",
      "Token count is too large: pandas-dev__pandas-23205\n",
      "Token count is too large: pypa__pip-6656\n",
      "Token count is too large: conan-io__conan-4918\n",
      "Token count is too large: mesonbuild__meson-4460\n",
      "Token count is too large: googleapis__google-cloud-python-4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4568 examples [05:38, 15.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-13498\n",
      "Token count is too large: Qiskit__qiskit-5648\n",
      "Token count is too large: numpy__numpy-16273\n",
      "Token count is too large: numpy__numpy-18361\n",
      "Token count is too large: googleapis__google-cloud-python-811\n",
      "Token count is too large: twisted__twisted-11756\n",
      "Token count is too large: pandas-dev__pandas-22750\n",
      "Token count is too large: pandas-dev__pandas-20933\n",
      "Token count is too large: ipython__ipython-11608\n",
      "Token count is too large: twisted__twisted-11615\n",
      "Token count is too large: pandas-dev__pandas-27584\n",
      "Token count is too large: conan-io__conan-5261\n",
      "Token count is too large: mesonbuild__meson-5638\n",
      "Token count is too large: pandas-dev__pandas-6163\n",
      "Token count is too large: PrefectHQ__prefect-300\n",
      "Token count is too large: pandas-dev__pandas-26359\n",
      "Token count is too large: pandas-dev__pandas-27893\n",
      "Token count is too large: pandas-dev__pandas-8044\n",
      "Token count is too large: wagtail__wagtail-497\n",
      "Token count is too large: docker__compose-6297\n",
      "Token count is too large: googleapis__google-cloud-python-3478\n",
      "Token count is too large: ipython__ipython-14029\n",
      "Token count is too large: numpy__numpy-20795\n",
      "Token count is too large: pandas-dev__pandas-8045\n",
      "Token count is too large: huggingface__transformers-24317\n",
      "Token count is too large: Lightning-AI__lightning-1423\n",
      "Token count is too large: Lightning-AI__lightning-355\n",
      "Token count is too large: apache__airflow-26389\n",
      "Token count is too large: mesonbuild__meson-8603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4573 examples [05:39, 10.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-19090\n",
      "Token count is too large: Qiskit__qiskit-5910\n",
      "Token count is too large: gitpython-developers__GitPython-316\n",
      "Token count is too large: googleapis__google-cloud-python-2109\n",
      "Token count is too large: googleapis__google-cloud-python-5429\n",
      "Token count is too large: numpy__numpy-12713\n",
      "Token count is too large: pandas-dev__pandas-28399\n",
      "Token count is too large: mesonbuild__meson-2912\n",
      "Token count is too large: googleapis__google-cloud-python-1377\n",
      "Token count is too large: celery__celery-6624\n",
      "Token count is too large: PrefectHQ__prefect-1341\n",
      "Token count is too large: huggingface__transformers-18435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4577 examples [05:40, 11.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8131\n",
      "Token count is too large: pandas-dev__pandas-5911\n",
      "Token count is too large: pandas-dev__pandas-39188\n",
      "Token count is too large: conda__conda-6573\n",
      "Token count is too large: Qiskit__qiskit-7361\n",
      "Token count is too large: wagtail__wagtail-10596\n",
      "Token count is too large: google__jax-2800\n",
      "Token count is too large: numpy__numpy-19087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4579 examples [05:40, 11.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-24154\n",
      "Token count is too large: huggingface__transformers-10338\n",
      "Token count is too large: pandas-dev__pandas-14026\n",
      "Token count is too large: apache__airflow-28776\n",
      "Token count is too large: pandas-dev__pandas-29159\n",
      "Token count is too large: ipython__ipython-13730\n",
      "Token count is too large: pandas-dev__pandas-18436\n",
      "Token count is too large: pandas-dev__pandas-3749\n",
      "Token count is too large: pypa__pip-7118\n",
      "Token count is too large: Qiskit__qiskit-8220\n",
      "Token count is too large: numpy__numpy-7738\n",
      "Token count is too large: pandas-dev__pandas-17002\n",
      "Token count is too large: Qiskit__qiskit-10366\n",
      "Token count is too large: numpy__numpy-12971\n",
      "Token count is too large: conda__conda-12315\n",
      "Token count is too large: numpy__numpy-24549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4584 examples [05:40,  9.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-8520\n",
      "Token count is too large: pandas-dev__pandas-21394\n",
      "Token count is too large: Qiskit__qiskit-10140\n",
      "Token count is too large: pandas-dev__pandas-4938\n",
      "Token count is too large: pandas-dev__pandas-31596\n",
      "Token count is too large: googleapis__google-cloud-python-3101\n",
      "Token count is too large: conan-io__conan-5176\n",
      "Token count is too large: pandas-dev__pandas-26794\n",
      "Token count is too large: jupyterlab__jupyterlab-7463\n",
      "Token count is too large: celery__celery-7470\n",
      "Token count is too large: pantsbuild__pants-18799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4587 examples [05:41, 11.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-27239\n",
      "Token count is too large: pandas-dev__pandas-32499\n",
      "Token count is too large: docker__compose-5096\n",
      "Token count is too large: huggingface__transformers-16222\n",
      "Token count is too large: pandas-dev__pandas-29796\n",
      "Token count is too large: pandas-dev__pandas-20923\n",
      "Token count is too large: huggingface__transformers-17289\n",
      "Token count is too large: pandas-dev__pandas-18643\n",
      "Token count is too large: pandas-dev__pandas-4871\n",
      "Token count is too large: ytdl-org__youtube-dl-25980\n",
      "Token count is too large: huggingface__transformers-21833\n",
      "Token count is too large: huggingface__transformers-16536\n",
      "Token count is too large: pandas-dev__pandas-25118\n",
      "Token count is too large: Qiskit__qiskit-3181\n",
      "Token count is too large: pypa__pip-9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4591 examples [05:41, 10.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-18732\n",
      "Token count is too large: pandas-dev__pandas-36239\n",
      "Token count is too large: numpy__numpy-12560\n",
      "Token count is too large: Qiskit__qiskit-8947\n",
      "Token count is too large: pantsbuild__pants-17299\n",
      "Token count is too large: pandas-dev__pandas-27382\n",
      "Token count is too large: googleapis__google-cloud-python-2984\n",
      "Token count is too large: pandas-dev__pandas-23032\n",
      "Token count is too large: apache__airflow-24847\n",
      "Token count is too large: PrefectHQ__prefect-1382\n",
      "Token count is too large: docker__compose-4004\n",
      "Token count is too large: pandas-dev__pandas-17843\n",
      "Token count is too large: googleapis__google-cloud-python-9450\n",
      "Token count is too large: numpy__numpy-10822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4596 examples [05:41, 13.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: celery__celery-7951\n",
      "Token count is too large: pandas-dev__pandas-19913\n",
      "Token count is too large: google__jax-2907\n",
      "Token count is too large: PrefectHQ__prefect-1071\n",
      "Token count is too large: pandas-dev__pandas-7373\n",
      "Token count is too large: ipython__ipython-1893\n",
      "Token count is too large: numpy__numpy-15991\n",
      "Token count is too large: conda__conda-11349\n",
      "Token count is too large: pandas-dev__pandas-36760\n",
      "Token count is too large: pandas-dev__pandas-35411\n",
      "Token count is too large: ipython__ipython-10719\n",
      "Token count is too large: pandas-dev__pandas-22325\n",
      "Token count is too large: mesonbuild__meson-1657\n",
      "Token count is too large: pandas-dev__pandas-35750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4598 examples [05:42,  9.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-20732\n",
      "Token count is too large: googleapis__google-cloud-python-8023\n",
      "Token count is too large: scipy__scipy-3253\n",
      "Token count is too large: ipython__ipython-11393\n",
      "Token count is too large: pandas-dev__pandas-20884\n",
      "Token count is too large: Qiskit__qiskit-9587\n",
      "Token count is too large: pantsbuild__pants-4332\n",
      "Token count is too large: conan-io__conan-2287\n",
      "Token count is too large: pandas-dev__pandas-29940\n",
      "Token count is too large: pandas-dev__pandas-31203\n",
      "Token count is too large: pandas-dev__pandas-8146\n",
      "Token count is too large: ipython__ipython-7770\n",
      "Token count is too large: pandas-dev__pandas-7843\n",
      "Token count is too large: pantsbuild__pants-11092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4601 examples [05:42, 11.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-19661\n",
      "Token count is too large: ray-project__ray-7021\n",
      "Token count is too large: pandas-dev__pandas-6575\n",
      "Token count is too large: pandas-dev__pandas-9715\n",
      "Token count is too large: huggingface__transformers-14016\n",
      "Token count is too large: pandas-dev__pandas-5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4606 examples [05:42, 13.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-11564\n",
      "Token count is too large: pypa__pip-6191\n",
      "Token count is too large: pandas-dev__pandas-9138\n",
      "Token count is too large: pandas-dev__pandas-27717\n",
      "Token count is too large: numpy__numpy-16356\n",
      "Token count is too large: ipython__ipython-1782\n",
      "Token count is too large: ray-project__ray-6395\n",
      "Token count is too large: pandas-dev__pandas-20779\n",
      "Token count is too large: conan-io__conan-2634\n",
      "Token count is too large: pandas-dev__pandas-37425\n",
      "Token count is too large: conan-io__conan-2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4609 examples [05:42, 14.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-35506\n",
      "Token count is too large: pandas-dev__pandas-20729\n",
      "Token count is too large: pypa__pip-3203\n",
      "Token count is too large: pandas-dev__pandas-6592\n",
      "Token count is too large: apache__airflow-11372\n",
      "Token count is too large: Qiskit__qiskit-4095\n",
      "Token count is too large: Qiskit__qiskit-9084\n",
      "Token count is too large: pandas-dev__pandas-20593\n",
      "Token count is too large: apache__airflow-855\n",
      "Token count is too large: pandas-dev__pandas-3164\n",
      "Token count is too large: numpy__numpy-4297\n",
      "Token count is too large: pyca__cryptography-7591\n",
      "Token count is too large: Qiskit__qiskit-8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4614 examples [05:43, 14.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-21769\n",
      "Token count is too large: huggingface__transformers-7305\n",
      "Token count is too large: mesonbuild__meson-1095\n",
      "Token count is too large: pantsbuild__pants-16185\n",
      "Token count is too large: ytdl-org__youtube-dl-6679\n",
      "Token count is too large: pandas-dev__pandas-7803\n",
      "Token count is too large: open-mmlab__mmdetection-2269\n",
      "Token count is too large: pandas-dev__pandas-26356\n",
      "Token count is too large: pandas-dev__pandas-25360\n",
      "Token count is too large: mesonbuild__meson-4000\n",
      "Token count is too large: Qiskit__qiskit-4561\n",
      "Token count is too large: celery__celery-6899\n",
      "Token count is too large: docker__compose-2662\n",
      "Token count is too large: conda__conda-9045\n",
      "Token count is too large: wagtail__wagtail-8155\n",
      "Token count is too large: numpy__numpy-11746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4616 examples [05:43, 12.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3131\n",
      "Token count is too large: docker__compose-6454\n",
      "Token count is too large: googleapis__google-cloud-python-559\n",
      "Token count is too large: google__jax-767\n",
      "Token count is too large: pandas-dev__pandas-39394\n",
      "Token count is too large: googleapis__google-cloud-python-6540\n",
      "Token count is too large: mesonbuild__meson-6013\n",
      "Token count is too large: numpy__numpy-4498\n",
      "Token count is too large: googleapis__google-cloud-python-10807\n",
      "Token count is too large: jupyterlab__jupyterlab-9021\n",
      "Token count is too large: pandas-dev__pandas-6861\n",
      "Token count is too large: Qiskit__qiskit-6965\n",
      "Token count is too large: pandas-dev__pandas-14788\n",
      "Token count is too large: Qiskit__qiskit-9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4623 examples [05:43, 17.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-5108\n",
      "Token count is too large: googleapis__google-cloud-python-8650\n",
      "Token count is too large: mesonbuild__meson-6800\n",
      "Token count is too large: numpy__numpy-12892\n",
      "Token count is too large: huggingface__transformers-6437\n",
      "Token count is too large: scipy__scipy-4958\n",
      "Token count is too large: huggingface__transformers-13336\n",
      "Token count is too large: huggingface__transformers-17212\n",
      "Token count is too large: conda__conda-6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4625 examples [05:43, 15.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4862\n",
      "Token count is too large: pandas-dev__pandas-6429\n",
      "Token count is too large: huggingface__transformers-11718\n",
      "Token count is too large: huggingface__transformers-14879\n",
      "Token count is too large: wagtail__wagtail-842\n",
      "Token count is too large: pandas-dev__pandas-3999\n",
      "Token count is too large: huggingface__transformers-17053\n",
      "Token count is too large: PrefectHQ__prefect-1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4627 examples [05:44, 11.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-25736\n",
      "Token count is too large: apache__airflow-33279\n",
      "Token count is too large: pandas-dev__pandas-34067\n",
      "Token count is too large: mesonbuild__meson-2673\n",
      "Token count is too large: Qiskit__qiskit-6925\n",
      "Token count is too large: ipython__ipython-3181\n",
      "Token count is too large: PrefectHQ__prefect-466\n",
      "Token count is too large: pandas-dev__pandas-4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4635 examples [05:44, 18.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37986\n",
      "Token count is too large: pantsbuild__pants-11396\n",
      "Token count is too large: jupyterlab__jupyterlab-9709\n",
      "Token count is too large: pantsbuild__pants-13519\n",
      "Token count is too large: pandas-dev__pandas-36125\n",
      "Token count is too large: pandas-dev__pandas-25103\n",
      "Token count is too large: PrefectHQ__prefect-863\n",
      "Token count is too large: pandas-dev__pandas-18131\n",
      "Token count is too large: conan-io__conan-3387\n",
      "Token count is too large: docker__compose-2363\n",
      "Token count is too large: pandas-dev__pandas-33659\n",
      "Token count is too large: ray-project__ray-1307\n",
      "Token count is too large: pandas-dev__pandas-23607\n",
      "Token count is too large: pandas-dev__pandas-4740\n",
      "Token count is too large: ytdl-org__youtube-dl-15066\n",
      "Token count is too large: docker__compose-2808\n",
      "Token count is too large: twisted__twisted-11691\n",
      "Token count is too large: pantsbuild__pants-13046\n",
      "Token count is too large: pandas-dev__pandas-22209\n",
      "Token count is too large: Qiskit__qiskit-9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4638 examples [05:44, 12.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4745\n",
      "Token count is too large: ytdl-org__youtube-dl-30614\n",
      "Token count is too large: pandas-dev__pandas-10290\n",
      "Token count is too large: pandas-dev__pandas-7026\n",
      "Token count is too large: pandas-dev__pandas-11581\n",
      "Token count is too large: Qiskit__qiskit-1218\n",
      "Token count is too large: ipython__ipython-1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4646 examples [05:45, 20.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-36106\n",
      "Token count is too large: celery__celery-6863\n",
      "Token count is too large: ipython__ipython-13625\n",
      "Token count is too large: googleapis__google-cloud-python-5011\n",
      "Token count is too large: conda__conda-6451\n",
      "Token count is too large: pandas-dev__pandas-14432\n",
      "Token count is too large: numpy__numpy-4304\n",
      "Token count is too large: pandas-dev__pandas-32764\n",
      "Token count is too large: apache__airflow-22008\n",
      "Token count is too large: open-mmlab__mmdetection-4928\n",
      "Token count is too large: pandas-dev__pandas-25928\n",
      "Token count is too large: Lightning-AI__lightning-2190\n",
      "Token count is too large: wagtail__wagtail-10010\n",
      "Token count is too large: pandas-dev__pandas-7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4650 examples [05:45, 21.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22990\n",
      "Token count is too large: Lightning-AI__lightning-549\n",
      "Token count is too large: pantsbuild__pants-7120\n",
      "Token count is too large: pandas-dev__pandas-16512\n",
      "Token count is too large: dagster-io__dagster-15810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4654 examples [05:45, 17.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-4812\n",
      "Token count is too large: google__jax-1020\n",
      "Token count is too large: pandas-dev__pandas-30943\n",
      "Token count is too large: mesonbuild__meson-11631\n",
      "Token count is too large: ytdl-org__youtube-dl-24512\n",
      "Token count is too large: pandas-dev__pandas-9806\n",
      "Token count is too large: mesonbuild__meson-4030\n",
      "Token count is too large: Qiskit__qiskit-4277\n",
      "Token count is too large: pandas-dev__pandas-5210\n",
      "Token count is too large: huggingface__transformers-6847\n",
      "Token count is too large: numpy__numpy-9343\n",
      "Token count is too large: open-mmlab__mmdetection-2891\n",
      "Token count is too large: Qiskit__qiskit-6856\n",
      "Token count is too large: pandas-dev__pandas-22602\n",
      "Token count is too large: conan-io__conan-4033\n",
      "Token count is too large: googleapis__google-cloud-python-10356\n",
      "Token count is too large: numpy__numpy-4588\n",
      "Token count is too large: pandas-dev__pandas-23858\n",
      "Token count is too large: ytdl-org__youtube-dl-29303\n",
      "Token count is too large: apache__airflow-15132\n",
      "Token count is too large: pandas-dev__pandas-24584\n",
      "Token count is too large: Qiskit__qiskit-4178\n",
      "Token count is too large: mesonbuild__meson-6178\n",
      "Token count is too large: wagtail__wagtail-9348\n",
      "Token count is too large: mesonbuild__meson-11064\n",
      "Token count is too large: conan-io__conan-8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4658 examples [05:46, 12.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-21580\n",
      "Token count is too large: ray-project__ray-5754\n",
      "Token count is too large: mesonbuild__meson-8087\n",
      "Token count is too large: conda__conda-5159\n",
      "Token count is too large: conda__conda-5261\n",
      "Token count is too large: pandas-dev__pandas-23235\n",
      "Token count is too large: docker__compose-5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4662 examples [05:46, 12.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-39451\n",
      "Token count is too large: numpy__numpy-3780\n",
      "Token count is too large: pandas-dev__pandas-3228\n",
      "Token count is too large: PrefectHQ__prefect-226\n",
      "Token count is too large: pandas-dev__pandas-17815\n",
      "Token count is too large: apache__airflow-28243\n",
      "Token count is too large: pandas-dev__pandas-32538\n",
      "Token count is too large: DataDog__integrations-core-2361\n",
      "Token count is too large: Lightning-AI__lightning-769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4664 examples [05:46, 10.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-22343\n",
      "Token count is too large: googleapis__google-cloud-python-11356\n",
      "Token count is too large: Qiskit__qiskit-6023\n",
      "Token count is too large: pandas-dev__pandas-8827\n",
      "Token count is too large: Qiskit__qiskit-3869\n",
      "Token count is too large: pandas-dev__pandas-20956\n",
      "Token count is too large: conda__conda-7598\n",
      "Token count is too large: pandas-dev__pandas-3459\n",
      "Token count is too large: pandas-dev__pandas-7770\n",
      "Token count is too large: google__jax-846\n",
      "Token count is too large: huggingface__transformers-19403\n",
      "Token count is too large: Qiskit__qiskit-3541\n",
      "Token count is too large: conda__conda-4963\n",
      "Token count is too large: googleapis__google-cloud-python-11353\n",
      "Token count is too large: mesonbuild__meson-1505\n",
      "Token count is too large: numpy__numpy-3232\n",
      "Token count is too large: conda__conda-8564\n",
      "Token count is too large: jupyterlab__jupyterlab-10063\n",
      "Token count is too large: PrefectHQ__prefect-2387\n",
      "Token count is too large: googleapis__google-cloud-python-1336\n",
      "Token count is too large: pandas-dev__pandas-25629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4669 examples [05:47,  9.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-5229\n",
      "Token count is too large: huggingface__transformers-18110\n",
      "Token count is too large: pandas-dev__pandas-6172\n",
      "Token count is too large: numpy__numpy-18960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4674 examples [05:47, 11.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-23429\n",
      "Token count is too large: docker__compose-4621\n",
      "Token count is too large: gitpython-developers__GitPython-1214\n",
      "Token count is too large: pandas-dev__pandas-36444\n",
      "Token count is too large: conda__conda-5988\n",
      "Token count is too large: pandas-dev__pandas-29281\n",
      "Token count is too large: pandas-dev__pandas-35510\n",
      "Token count is too large: pandas-dev__pandas-6776\n",
      "Token count is too large: numpy__numpy-12658\n",
      "Token count is too large: pyca__cryptography-4128\n",
      "Token count is too large: pandas-dev__pandas-9754\n",
      "Token count is too large: numpy__numpy-9070\n",
      "Token count is too large: pandas-dev__pandas-32566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4680 examples [05:47, 15.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-15232\n",
      "Token count is too large: JohnSnowLabs__spark-nlp-13798\n",
      "Token count is too large: DataDog__integrations-core-503\n",
      "Token count is too large: pandas-dev__pandas-11237\n",
      "Token count is too large: ray-project__ray-10519\n",
      "Token count is too large: pandas-dev__pandas-10705\n",
      "Token count is too large: pantsbuild__pants-19191\n",
      "Token count is too large: numpy__numpy-12493\n",
      "Token count is too large: PrefectHQ__prefect-1239\n",
      "Token count is too large: conan-io__conan-10941\n",
      "Token count is too large: docker__compose-6864\n",
      "Token count is too large: pandas-dev__pandas-18094\n",
      "Token count is too large: huggingface__transformers-9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4689 examples [05:47, 23.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: scipy__scipy-5384\n",
      "Token count is too large: mesonbuild__meson-8396\n",
      "Token count is too large: pandas-dev__pandas-38272\n",
      "Token count is too large: pandas-dev__pandas-34606\n",
      "Token count is too large: pandas-dev__pandas-23703\n",
      "Token count is too large: pandas-dev__pandas-26765\n",
      "Token count is too large: pandas-dev__pandas-26994\n",
      "Token count is too large: mesonbuild__meson-11619\n",
      "Token count is too large: numpy__numpy-20243\n",
      "Token count is too large: numpy__numpy-18759\n",
      "Token count is too large: huggingface__transformers-2134\n",
      "Token count is too large: pandas-dev__pandas-37778\n",
      "Token count is too large: pandas-dev__pandas-24069\n",
      "Token count is too large: pandas-dev__pandas-12043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4693 examples [05:48, 15.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-34887\n",
      "Token count is too large: pandas-dev__pandas-34942\n",
      "Token count is too large: huggingface__transformers-6999\n",
      "Token count is too large: apache__airflow-11325\n",
      "Token count is too large: Qiskit__qiskit-9913\n",
      "Token count is too large: pandas-dev__pandas-32320\n",
      "Token count is too large: PrefectHQ__prefect-2202\n",
      "Token count is too large: ytdl-org__youtube-dl-8611\n",
      "Token count is too large: pandas-dev__pandas-35995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4696 examples [05:48, 15.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11336\n",
      "Token count is too large: huggingface__transformers-6098\n",
      "Token count is too large: dagster-io__dagster-7086\n",
      "Token count is too large: open-mmlab__mmdetection-2492\n",
      "Token count is too large: mesonbuild__meson-3277\n",
      "Token count is too large: pandas-dev__pandas-21481\n",
      "Token count is too large: docker__compose-4713\n",
      "Token count is too large: pandas-dev__pandas-4857\n",
      "Token count is too large: ray-project__ray-9497\n",
      "Token count is too large: googleapis__google-cloud-python-7311\n",
      "Token count is too large: docker__compose-5596\n",
      "Token count is too large: pandas-dev__pandas-17201\n",
      "Token count is too large: pandas-dev__pandas-37394\n",
      "Token count is too large: mesonbuild__meson-10668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4701 examples [05:49, 12.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: numpy__numpy-3205\n",
      "Token count is too large: pandas-dev__pandas-22083\n",
      "Token count is too large: celery__celery-7544\n",
      "Token count is too large: mesonbuild__meson-11259\n",
      "Token count is too large: pandas-dev__pandas-14055\n",
      "Token count is too large: pandas-dev__pandas-10429\n",
      "Token count is too large: mesonbuild__meson-4698\n",
      "Token count is too large: Qiskit__qiskit-4670\n",
      "Token count is too large: PrefectHQ__prefect-457\n",
      "Token count is too large: googleapis__google-cloud-python-9889\n",
      "Token count is too large: Qiskit__qiskit-764\n",
      "Token count is too large: mesonbuild__meson-605\n",
      "Token count is too large: Qiskit__qiskit-6546\n",
      "Token count is too large: pandas-dev__pandas-6941\n",
      "Token count is too large: pandas-dev__pandas-36208\n",
      "Token count is too large: ipython__ipython-13825\n",
      "Token count is too large: pandas-dev__pandas-38431\n",
      "Token count is too large: celery__celery-6746\n",
      "Token count is too large: gitpython-developers__GitPython-922\n",
      "Token count is too large: apache__airflow-24378\n",
      "Token count is too large: conda__conda-6526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4703 examples [05:49, 11.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conan-io__conan-5236\n",
      "Token count is too large: pandas-dev__pandas-14085\n",
      "Token count is too large: numpy__numpy-19151\n",
      "Token count is too large: numpy__numpy-4309\n",
      "Token count is too large: pandas-dev__pandas-38026\n",
      "Token count is too large: pandas-dev__pandas-29712\n",
      "Token count is too large: pandas-dev__pandas-23999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4706 examples [05:49, 10.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28024\n",
      "Token count is too large: huggingface__transformers-23663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4710 examples [05:50, 11.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-10265\n",
      "Token count is too large: huggingface__transformers-11300\n",
      "Token count is too large: dagster-io__dagster-14773\n",
      "Token count is too large: pandas-dev__pandas-37989\n",
      "Token count is too large: docker__compose-5455\n",
      "Token count is too large: scipy__scipy-4849\n",
      "Token count is too large: docker__compose-5657\n",
      "Token count is too large: pypa__pip-2294\n",
      "Token count is too large: huggingface__transformers-13829\n",
      "Token count is too large: ytdl-org__youtube-dl-14369\n",
      "Token count is too large: pandas-dev__pandas-16907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4712 examples [05:50,  9.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-7798\n",
      "Token count is too large: mesonbuild__meson-5911\n",
      "Token count is too large: pypa__pip-3522\n",
      "Token count is too large: conan-io__conan-5005\n",
      "Token count is too large: huggingface__transformers-12562\n",
      "Token count is too large: pandas-dev__pandas-30145\n",
      "Token count is too large: wagtail__wagtail-4704\n",
      "Token count is too large: mesonbuild__meson-579\n",
      "Token count is too large: conan-io__conan-8567\n",
      "Token count is too large: huggingface__transformers-14779\n",
      "Token count is too large: ipython__ipython-13902\n",
      "Token count is too large: conan-io__conan-9267\n",
      "Token count is too large: huggingface__transformers-7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4715 examples [05:50,  9.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ytdl-org__youtube-dl-30527\n",
      "Token count is too large: pandas-dev__pandas-10090\n",
      "Token count is too large: pantsbuild__pants-5231\n",
      "Token count is too large: dagster-io__dagster-14784\n",
      "There was an error processing\n",
      "Token count is too large: pandas-dev__pandas-28215\n",
      "Token count is too large: googleapis__google-cloud-python-1128\n",
      "Token count is too large: pandas-dev__pandas-21212\n",
      "Token count is too large: pyca__cryptography-4534\n",
      "Token count is too large: conan-io__conan-7108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4719 examples [05:51, 11.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15438\n",
      "Token count is too large: huggingface__transformers-24298\n",
      "Token count is too large: pandas-dev__pandas-34661\n",
      "Token count is too large: conan-io__conan-4787\n",
      "Token count is too large: conan-io__conan-2723\n",
      "Token count is too large: Qiskit__qiskit-9843\n",
      "Token count is too large: Qiskit__qiskit-5474\n",
      "Token count is too large: Qiskit__qiskit-3314\n",
      "Token count is too large: pandas-dev__pandas-39644\n",
      "Token count is too large: conan-io__conan-7507\n",
      "Token count is too large: mesonbuild__meson-1221\n",
      "Token count is too large: pandas-dev__pandas-6421\n",
      "Token count is too large: googleapis__google-cloud-python-5097\n",
      "Token count is too large: celery__celery-6699\n",
      "Token count is too large: googleapis__google-cloud-python-3443\n",
      "Token count is too large: Qiskit__qiskit-6151\n",
      "Token count is too large: conan-io__conan-2458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4721 examples [05:51,  8.37 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: DataDog__integrations-core-998\n",
      "Token count is too large: huggingface__transformers-14055\n",
      "Token count is too large: mesonbuild__meson-4617\n",
      "Token count is too large: pandas-dev__pandas-35513\n",
      "Token count is too large: pandas-dev__pandas-27317\n",
      "Token count is too large: Lightning-AI__lightning-1513\n",
      "Token count is too large: conan-io__conan-2412\n",
      "Token count is too large: Qiskit__qiskit-7515\n",
      "Token count is too large: pandas-dev__pandas-17621\n",
      "Token count is too large: tiangolo__fastapi-3372\n",
      "Token count is too large: apache__airflow-26081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4724 examples [05:51, 10.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-18210\n",
      "Token count is too large: pandas-dev__pandas-23000\n",
      "Token count is too large: pandas-dev__pandas-38331\n",
      "Token count is too large: googleapis__google-cloud-python-7545\n",
      "Token count is too large: ipython__ipython-5077\n",
      "Token count is too large: Qiskit__qiskit-3137\n",
      "Token count is too large: pandas-dev__pandas-6990\n",
      "Token count is too large: pandas-dev__pandas-30234\n",
      "Token count is too large: pandas-dev__pandas-9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4726 examples [05:52,  8.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: ipython__ipython-6045\n",
      "Token count is too large: pandas-dev__pandas-11127\n",
      "Token count is too large: pandas-dev__pandas-33651\n",
      "Token count is too large: explosion__spaCy-3393\n",
      "Token count is too large: numpy__numpy-6653\n",
      "Token count is too large: Lightning-AI__lightning-2425\n",
      "Token count is too large: pandas-dev__pandas-10346\n",
      "Token count is too large: mesonbuild__meson-3064\n",
      "Token count is too large: mesonbuild__meson-3432\n",
      "Token count is too large: mesonbuild__meson-6941\n",
      "Token count is too large: pandas-dev__pandas-25568\n",
      "Token count is too large: conda__conda-5107\n",
      "Token count is too large: conda__conda-4647\n",
      "Token count is too large: pantsbuild__pants-17051\n",
      "Token count is too large: google__jax-3150\n",
      "Token count is too large: huggingface__transformers-13321\n",
      "Token count is too large: huggingface__transformers-12654\n",
      "Token count is too large: pandas-dev__pandas-38427\n",
      "Token count is too large: ytdl-org__youtube-dl-27234\n",
      "Token count is too large: numpy__numpy-7417\n",
      "Token count is too large: pandas-dev__pandas-19783\n",
      "Token count is too large: Lightning-AI__lightning-2974\n",
      "Token count is too large: numpy__numpy-18405\n",
      "Token count is too large: pandas-dev__pandas-7593\n",
      "Token count is too large: apache__airflow-8787\n",
      "Token count is too large: numpy__numpy-21256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4730 examples [05:52, 10.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-8024\n",
      "Token count is too large: huggingface__transformers-11631\n",
      "Token count is too large: googleapis__google-cloud-python-9077\n",
      "Token count is too large: ray-project__ray-7758\n",
      "Token count is too large: google__jax-1352\n",
      "Token count is too large: pandas-dev__pandas-27594\n",
      "Token count is too large: numpy__numpy-8508\n",
      "Token count is too large: pypa__pip-9124\n",
      "Token count is too large: pantsbuild__pants-4521\n",
      "Token count is too large: googleapis__google-cloud-python-6078\n",
      "Token count is too large: conda__conda-7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4735 examples [05:52, 11.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-12090\n",
      "Token count is too large: google__jax-3436\n",
      "Token count is too large: conan-io__conan-2991\n",
      "Token count is too large: conda__conda-9841\n",
      "Token count is too large: pandas-dev__pandas-19707\n",
      "Token count is too large: scipy__scipy-4145\n",
      "Token count is too large: numpy__numpy-9408\n",
      "Token count is too large: Qiskit__qiskit-1158\n",
      "Token count is too large: google__jax-1613\n",
      "Token count is too large: pandas-dev__pandas-16339\n",
      "Token count is too large: pandas-dev__pandas-36610\n",
      "Token count is too large: apache__airflow-15794\n",
      "Token count is too large: pandas-dev__pandas-9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4738 examples [05:52, 12.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4386\n",
      "Token count is too large: Qiskit__qiskit-1281\n",
      "Token count is too large: pandas-dev__pandas-6021\n",
      "Token count is too large: ipython__ipython-1693\n",
      "Token count is too large: numpy__numpy-18375\n",
      "Token count is too large: docker__compose-2882\n",
      "Token count is too large: pandas-dev__pandas-27375\n",
      "Token count is too large: ray-project__ray-8521\n",
      "Token count is too large: ytdl-org__youtube-dl-8354\n",
      "Token count is too large: pypa__pip-3382\n",
      "Token count is too large: pandas-dev__pandas-9522\n",
      "Token count is too large: pantsbuild__pants-19253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4744 examples [05:53, 19.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-1478\n",
      "Token count is too large: pantsbuild__pants-15299\n",
      "Token count is too large: pandas-dev__pandas-28733\n",
      "Token count is too large: pandas-dev__pandas-3533\n",
      "Token count is too large: googleapis__google-cloud-python-5377\n",
      "Token count is too large: mesonbuild__meson-4236\n",
      "Token count is too large: conda__conda-4628\n",
      "Token count is too large: pandas-dev__pandas-5022\n",
      "Token count is too large: ytdl-org__youtube-dl-31060\n",
      "Token count is too large: conan-io__conan-9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4752 examples [05:53, 15.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-11340\n",
      "Token count is too large: PrefectHQ__prefect-2886\n",
      "Token count is too large: conan-io__conan-13788\n",
      "Token count is too large: pandas-dev__pandas-7113\n",
      "Token count is too large: pandas-dev__pandas-8557\n",
      "Token count is too large: pantsbuild__pants-18930\n",
      "Token count is too large: googleapis__google-cloud-python-1862\n",
      "Token count is too large: ytdl-org__youtube-dl-14555\n",
      "Token count is too large: ipython__ipython-11307\n",
      "Token count is too large: googleapis__google-cloud-python-961\n",
      "Token count is too large: pandas-dev__pandas-28802\n",
      "Token count is too large: pandas-dev__pandas-25644\n",
      "Token count is too large: pandas-dev__pandas-39012\n",
      "Token count is too large: conda__conda-2529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4755 examples [05:53, 16.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-10117\n",
      "Token count is too large: pyca__cryptography-3794\n",
      "Token count is too large: Qiskit__qiskit-1748\n",
      "Token count is too large: Lightning-AI__lightning-2216\n",
      "Token count is too large: wagtail__wagtail-9240\n",
      "Token count is too large: Qiskit__qiskit-5396\n",
      "Token count is too large: pandas-dev__pandas-8946\n",
      "Token count is too large: pandas-dev__pandas-36516\n",
      "Token count is too large: pandas-dev__pandas-5426\n",
      "Token count is too large: pantsbuild__pants-7781\n",
      "Token count is too large: celery__celery-6838\n",
      "Token count is too large: DataDog__integrations-core-2937\n",
      "Token count is too large: pandas-dev__pandas-37479\n",
      "Token count is too large: conda__conda-3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4763 examples [05:53, 25.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1227\n",
      "Token count is too large: numpy__numpy-19131\n",
      "Token count is too large: pandas-dev__pandas-28680\n",
      "Token count is too large: Lightning-AI__lightning-3098\n",
      "Token count is too large: PrefectHQ__prefect-2877\n",
      "Token count is too large: Qiskit__qiskit-7407\n",
      "Token count is too large: pandas-dev__pandas-34654\n",
      "Token count is too large: pantsbuild__pants-14788\n",
      "Token count is too large: pandas-dev__pandas-10250\n",
      "Token count is too large: mesonbuild__meson-11328\n",
      "Token count is too large: pandas-dev__pandas-6691\n",
      "Token count is too large: pandas-dev__pandas-7736\n",
      "Token count is too large: celery__celery-4611\n",
      "Token count is too large: Lightning-AI__lightning-1152\n",
      "Token count is too large: google__jax-2812\n",
      "Token count is too large: ytdl-org__youtube-dl-5669\n",
      "Token count is too large: pandas-dev__pandas-36557\n",
      "Token count is too large: pandas-dev__pandas-4092\n",
      "Token count is too large: ipython__ipython-1207\n",
      "Token count is too large: pandas-dev__pandas-26852\n",
      "Token count is too large: pandas-dev__pandas-36403\n",
      "Token count is too large: pypa__pip-6260\n",
      "Token count is too large: conan-io__conan-2844\n",
      "Token count is too large: wagtail__wagtail-10248\n",
      "Token count is too large: ray-project__ray-10449\n",
      "Token count is too large: pantsbuild__pants-13561\n",
      "Token count is too large: ipython__ipython-12130\n",
      "Token count is too large: google__jax-3453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4768 examples [05:54, 11.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-38517\n",
      "Token count is too large: mesonbuild__meson-5560\n",
      "Token count is too large: apache__airflow-18733\n",
      "Token count is too large: huggingface__transformers-19538\n",
      "Token count is too large: pandas-dev__pandas-33487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4773 examples [05:55, 13.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pyca__cryptography-1476\n",
      "Token count is too large: pandas-dev__pandas-33284\n",
      "Token count is too large: numpy__numpy-19902\n",
      "Token count is too large: huggingface__transformers-16065\n",
      "Token count is too large: tiangolo__fastapi-4871\n",
      "Token count is too large: pypa__pip-7341\n",
      "Token count is too large: google__jax-3097\n",
      "Token count is too large: pandas-dev__pandas-27846\n",
      "Token count is too large: huggingface__transformers-25358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4781 examples [05:55, 16.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: googleapis__google-cloud-python-9426\n",
      "Token count is too large: jupyterlab__jupyterlab-8956\n",
      "Token count is too large: pandas-dev__pandas-28463\n",
      "Token count is too large: google__jax-188\n",
      "Token count is too large: google__jax-942\n",
      "Token count is too large: pandas-dev__pandas-21321\n",
      "Token count is too large: pandas-dev__pandas-32894\n",
      "Token count is too large: ray-project__ray-4421\n",
      "Token count is too large: pandas-dev__pandas-11114\n",
      "Token count is too large: pandas-dev__pandas-33805\n",
      "Token count is too large: Lightning-AI__lightning-2674\n",
      "Token count is too large: mesonbuild__meson-5894\n",
      "Token count is too large: ytdl-org__youtube-dl-14406\n",
      "Token count is too large: numpy__numpy-16690\n",
      "Token count is too large: mesonbuild__meson-8507\n",
      "Token count is too large: pandas-dev__pandas-39592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4787 examples [05:55, 14.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-28447\n",
      "Token count is too large: Qiskit__qiskit-3848\n",
      "Token count is too large: pandas-dev__pandas-38140\n",
      "Token count is too large: ray-project__ray-7863\n",
      "Token count is too large: pandas-dev__pandas-25765\n",
      "Token count is too large: ray-project__ray-5426\n",
      "Token count is too large: googleapis__google-cloud-python-6367\n",
      "Token count is too large: apache__airflow-21551\n",
      "Token count is too large: pandas-dev__pandas-34354\n",
      "Token count is too large: huggingface__transformers-16819\n",
      "Token count is too large: pandas-dev__pandas-38325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4789 examples [05:56,  9.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31156\n",
      "Token count is too large: pandas-dev__pandas-14786\n",
      "Token count is too large: tiangolo__fastapi-2606\n",
      "Token count is too large: googleapis__google-cloud-python-4667\n",
      "Token count is too large: pandas-dev__pandas-19914\n",
      "Token count is too large: pandas-dev__pandas-17580\n",
      "Token count is too large: huggingface__transformers-18069\n",
      "Token count is too large: pandas-dev__pandas-11590\n",
      "Token count is too large: googleapis__google-cloud-python-2284\n",
      "Token count is too large: pantsbuild__pants-15606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4792 examples [05:56, 10.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-7795\n",
      "Token count is too large: ipython__ipython-10549\n",
      "Token count is too large: pandas-dev__pandas-18812\n",
      "Token count is too large: pandas-dev__pandas-36393\n",
      "Token count is too large: pandas-dev__pandas-18065\n",
      "Token count is too large: apache__airflow-10612\n",
      "Token count is too large: pandas-dev__pandas-3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4794 examples [05:56, 10.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-6153\n",
      "Token count is too large: ytdl-org__youtube-dl-30266\n",
      "Token count is too large: mesonbuild__meson-2824\n",
      "Token count is too large: mesonbuild__meson-4868\n",
      "Token count is too large: googleapis__google-cloud-python-9649\n",
      "Token count is too large: pypa__pip-8144\n",
      "Token count is too large: pandas-dev__pandas-8977\n",
      "Token count is too large: pandas-dev__pandas-20152\n",
      "Token count is too large: numpy__numpy-15468\n",
      "Token count is too large: apache__airflow-15942\n",
      "Token count is too large: pandas-dev__pandas-28662\n",
      "Token count is too large: mesonbuild__meson-5224\n",
      "Token count is too large: conda__conda-5703\n",
      "Token count is too large: docker__compose-6592\n",
      "Token count is too large: conda__conda-7773\n",
      "Token count is too large: pandas-dev__pandas-24772\n",
      "Token count is too large: pandas-dev__pandas-7421\n",
      "Token count is too large: googleapis__google-cloud-python-11341\n",
      "Token count is too large: pandas-dev__pandas-11531\n",
      "Token count is too large: pantsbuild__pants-14185\n",
      "Token count is too large: scipy__scipy-3497\n",
      "Token count is too large: mesonbuild__meson-6915\n",
      "Token count is too large: apache__airflow-25500\n",
      "Token count is too large: ipython__ipython-1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4798 examples [05:57, 10.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: apache__airflow-26617\n",
      "Token count is too large: pandas-dev__pandas-4502\n",
      "Token count is too large: numpy__numpy-5616\n",
      "Token count is too large: Qiskit__qiskit-3978\n",
      "Token count is too large: Qiskit__qiskit-3174\n",
      "Token count is too large: huggingface__transformers-13542\n",
      "Token count is too large: pandas-dev__pandas-38710\n",
      "Token count is too large: pandas-dev__pandas-39064\n",
      "Token count is too large: docker__compose-5436\n",
      "Token count is too large: pandas-dev__pandas-34343\n",
      "Token count is too large: pandas-dev__pandas-8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4803 examples [05:57, 14.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-811\n",
      "Token count is too large: Lightning-AI__lightning-223\n",
      "Token count is too large: PrefectHQ__prefect-248\n",
      "Token count is too large: google__jax-828\n",
      "Token count is too large: ray-project__ray-873\n",
      "Token count is too large: conan-io__conan-5014\n",
      "Token count is too large: pandas-dev__pandas-2005\n",
      "Token count is too large: conda__conda-6655\n",
      "Token count is too large: ipython__ipython-1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4805 examples [05:57, 12.67 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-14002\n",
      "Token count is too large: ytdl-org__youtube-dl-30582\n",
      "Token count is too large: apache__airflow-27961\n",
      "Token count is too large: pandas-dev__pandas-24856\n",
      "Token count is too large: googleapis__google-cloud-python-7684\n",
      "Token count is too large: wagtail__wagtail-6275\n",
      "Token count is too large: apache__airflow-19747\n",
      "Token count is too large: pandas-dev__pandas-24520\n",
      "Token count is too large: pandas-dev__pandas-23264\n",
      "Token count is too large: wagtail__wagtail-7077\n",
      "Token count is too large: numpy__numpy-6487\n",
      "Token count is too large: pyca__cryptography-3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4811 examples [05:57, 17.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-14419\n",
      "Token count is too large: numpy__numpy-4316\n",
      "Token count is too large: Qiskit__qiskit-7191\n",
      "Token count is too large: pandas-dev__pandas-6388\n",
      "Token count is too large: ytdl-org__youtube-dl-18343\n",
      "Token count is too large: huggingface__transformers-6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4816 examples [05:58, 18.56 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-18057\n",
      "Token count is too large: mesonbuild__meson-7118\n",
      "Token count is too large: pandas-dev__pandas-33304\n",
      "Token count is too large: ytdl-org__youtube-dl-6828\n",
      "Token count is too large: pandas-dev__pandas-29427\n",
      "Token count is too large: numpy__numpy-23854\n",
      "Token count is too large: huggingface__transformers-193\n",
      "Token count is too large: ipython__ipython-7872\n",
      "Token count is too large: apache__airflow-24079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4821 examples [05:58, 20.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4972\n",
      "Token count is too large: numpy__numpy-12399\n",
      "Token count is too large: huggingface__transformers-11380\n",
      "Token count is too large: numpy__numpy-20666\n",
      "Token count is too large: huggingface__transformers-5125\n",
      "Token count is too large: pandas-dev__pandas-32890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4829 examples [05:58, 20.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24952\n",
      "Token count is too large: pandas-dev__pandas-30508\n",
      "Token count is too large: pantsbuild__pants-17518\n",
      "Token count is too large: googleapis__google-cloud-python-11287\n",
      "Token count is too large: Qiskit__qiskit-7157\n",
      "Token count is too large: PrefectHQ__prefect-70\n",
      "Token count is too large: pypa__pip-3466\n",
      "Token count is too large: google__jax-1238\n",
      "Token count is too large: PrefectHQ__prefect-446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4832 examples [05:58, 19.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-7047\n",
      "Token count is too large: ipython__ipython-3859\n",
      "Token count is too large: googleapis__google-cloud-python-4388\n",
      "Token count is too large: ray-project__ray-7670\n",
      "Token count is too large: pandas-dev__pandas-16428\n",
      "Token count is too large: pypa__pip-5875\n",
      "Token count is too large: pandas-dev__pandas-39139\n",
      "Token count is too large: huggingface__transformers-19640\n",
      "Token count is too large: pantsbuild__pants-6671\n",
      "Token count is too large: pandas-dev__pandas-10009\n",
      "Token count is too large: pyca__cryptography-4331\n",
      "Token count is too large: Qiskit__qiskit-4224\n",
      "Token count is too large: pandas-dev__pandas-19135\n",
      "Token count is too large: huggingface__transformers-6093\n",
      "Token count is too large: pandas-dev__pandas-23271\n",
      "Token count is too large: numpy__numpy-12297\n",
      "Token count is too large: PrefectHQ__prefect-1996\n",
      "Token count is too large: PrefectHQ__prefect-430\n",
      "Token count is too large: docker__compose-5435\n",
      "Token count is too large: ray-project__ray-8279\n",
      "Token count is too large: docker__compose-4737\n",
      "Token count is too large: huggingface__transformers-16543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4838 examples [05:59, 12.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24993\n",
      "Token count is too large: Qiskit__qiskit-9085\n",
      "Token count is too large: mesonbuild__meson-11585\n",
      "Token count is too large: PrefectHQ__prefect-206\n",
      "Token count is too large: huggingface__transformers-13857\n",
      "Token count is too large: googleapis__google-cloud-python-5492\n",
      "Token count is too large: ray-project__ray-7985\n",
      "Token count is too large: pandas-dev__pandas-21407\n",
      "Token count is too large: pantsbuild__pants-17652\n",
      "Token count is too large: pandas-dev__pandas-6849\n",
      "Token count is too large: conan-io__conan-8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4840 examples [05:59, 12.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-15473\n",
      "Token count is too large: pandas-dev__pandas-8208\n",
      "Token count is too large: mesonbuild__meson-3491\n",
      "Token count is too large: pandas-dev__pandas-23698\n",
      "Token count is too large: pandas-dev__pandas-6126\n",
      "Token count is too large: twisted__twisted-11576\n",
      "Token count is too large: pandas-dev__pandas-5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4847 examples [06:00, 12.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-1600\n",
      "Token count is too large: pandas-dev__pandas-5101\n",
      "Token count is too large: pandas-dev__pandas-35914\n",
      "Token count is too large: pandas-dev__pandas-27284\n",
      "Token count is too large: huggingface__transformers-13725\n",
      "Token count is too large: ytdl-org__youtube-dl-6061\n",
      "Token count is too large: apache__airflow-1290\n",
      "Token count is too large: googleapis__google-cloud-python-498\n",
      "Token count is too large: pandas-dev__pandas-3587\n",
      "Token count is too large: numpy__numpy-12920\n",
      "Token count is too large: mesonbuild__meson-9131\n",
      "Token count is too large: huggingface__transformers-10071\n",
      "Token count is too large: conan-io__conan-4771\n",
      "Token count is too large: pandas-dev__pandas-5733\n",
      "Token count is too large: celery__celery-5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4854 examples [06:00, 13.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-25402\n",
      "Token count is too large: pantsbuild__pants-15390\n",
      "Token count is too large: Lightning-AI__lightning-332\n",
      "Token count is too large: pandas-dev__pandas-18373\n",
      "Token count is too large: Qiskit__qiskit-7460\n",
      "Token count is too large: pandas-dev__pandas-11486\n",
      "Token count is too large: pandas-dev__pandas-725\n",
      "Token count is too large: pandas-dev__pandas-4922\n",
      "Token count is too large: pandas-dev__pandas-26685\n",
      "Token count is too large: numpy__numpy-4949\n",
      "Token count is too large: google__jax-437\n",
      "Token count is too large: googleapis__google-cloud-python-2553\n",
      "Token count is too large: numpy__numpy-5489\n",
      "Token count is too large: pandas-dev__pandas-30386\n",
      "Token count is too large: ipython__ipython-3525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4856 examples [06:00, 14.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1238\n",
      "Token count is too large: pandas-dev__pandas-21400\n",
      "Token count is too large: pyca__cryptography-1346\n",
      "Token count is too large: ytdl-org__youtube-dl-31305\n",
      "Token count is too large: pandas-dev__pandas-8232\n",
      "Token count is too large: pandas-dev__pandas-8372\n",
      "Token count is too large: wagtail__wagtail-8268\n",
      "Token count is too large: googleapis__google-cloud-python-6631\n",
      "Token count is too large: conan-io__conan-8821\n",
      "Token count is too large: pandas-dev__pandas-34985\n",
      "Token count is too large: pantsbuild__pants-9826\n",
      "Token count is too large: pandas-dev__pandas-26112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4860 examples [06:01, 16.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-30813\n",
      "Token count is too large: pypa__pip-1745\n",
      "Token count is too large: pandas-dev__pandas-10866\n",
      "Token count is too large: apache__airflow-8256\n",
      "Token count is too large: pandas-dev__pandas-4063\n",
      "Token count is too large: pyca__cryptography-4889\n",
      "Token count is too large: pandas-dev__pandas-5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4863 examples [06:01, 16.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-22279\n",
      "Token count is too large: googleapis__google-cloud-python-5935\n",
      "Token count is too large: Qiskit__qiskit-10362\n",
      "Token count is too large: wagtail__wagtail-8571\n",
      "Token count is too large: pandas-dev__pandas-7578\n",
      "Token count is too large: conda__conda-9730\n",
      "Token count is too large: mesonbuild__meson-7179\n",
      "Token count is too large: mesonbuild__meson-9027\n",
      "Token count is too large: scipy__scipy-5205\n",
      "Token count is too large: Qiskit__qiskit-6782\n",
      "Token count is too large: pandas-dev__pandas-3797\n",
      "Token count is too large: ipython__ipython-11953\n",
      "Token count is too large: apache__airflow-27944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4866 examples [06:01, 12.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-15782\n",
      "Token count is too large: apache__airflow-17501\n",
      "Token count is too large: pandas-dev__pandas-17419\n",
      "Token count is too large: pandas-dev__pandas-18508\n",
      "Token count is too large: pandas-dev__pandas-4664\n",
      "Token count is too large: pandas-dev__pandas-17823\n",
      "Token count is too large: pandas-dev__pandas-38780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4870 examples [06:01, 14.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3890\n",
      "Token count is too large: pandas-dev__pandas-21038\n",
      "Token count is too large: pypa__pip-2214\n",
      "Token count is too large: pandas-dev__pandas-25482\n",
      "Token count is too large: google__jax-976\n",
      "Token count is too large: conan-io__conan-2533\n",
      "Token count is too large: wagtail__wagtail-9153\n",
      "Token count is too large: pandas-dev__pandas-29529\n",
      "Token count is too large: Qiskit__qiskit-7039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4876 examples [06:02, 20.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3299\n",
      "Token count is too large: pandas-dev__pandas-31312\n",
      "Token count is too large: pandas-dev__pandas-25619\n",
      "Token count is too large: numpy__numpy-8038\n",
      "Token count is too large: huggingface__transformers-2192\n",
      "Token count is too large: pandas-dev__pandas-25268\n",
      "Token count is too large: Lightning-AI__lightning-1176\n",
      "Token count is too large: pandas-dev__pandas-10023\n",
      "Token count is too large: Lightning-AI__lightning-2786\n",
      "Token count is too large: pandas-dev__pandas-28268\n",
      "Token count is too large: google__jax-911\n",
      "Token count is too large: huggingface__transformers-20301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4879 examples [06:02, 17.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: wagtail__wagtail-9709\n",
      "Token count is too large: Qiskit__qiskit-5623\n",
      "Token count is too large: pandas-dev__pandas-5977\n",
      "Token count is too large: mesonbuild__meson-4616\n",
      "Token count is too large: pandas-dev__pandas-22423\n",
      "Token count is too large: Qiskit__qiskit-1771\n",
      "Token count is too large: Qiskit__qiskit-6587\n",
      "Token count is too large: pandas-dev__pandas-19831\n",
      "Token count is too large: pandas-dev__pandas-3135\n",
      "Token count is too large: jupyterlab__jupyterlab-6265\n",
      "Token count is too large: pyca__cryptography-4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4883 examples [06:02, 16.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: conda__conda-4392\n",
      "Token count is too large: googleapis__google-cloud-python-6842\n",
      "Token count is too large: huggingface__transformers-22040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4890 examples [06:02, 21.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-32702\n",
      "Token count is too large: pandas-dev__pandas-16936\n",
      "Token count is too large: pandas-dev__pandas-25904\n",
      "Token count is too large: pandas-dev__pandas-25308\n",
      "Token count is too large: pantsbuild__pants-15300\n",
      "Token count is too large: pandas-dev__pandas-29858\n",
      "Token count is too large: apache__airflow-28476\n",
      "Token count is too large: pantsbuild__pants-16126\n",
      "Token count is too large: huggingface__transformers-15437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4895 examples [06:03, 19.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-31809\n",
      "Token count is too large: pandas-dev__pandas-22264\n",
      "Token count is too large: conan-io__conan-5946\n",
      "Token count is too large: ytdl-org__youtube-dl-2113\n",
      "Token count is too large: huggingface__transformers-15875\n",
      "Token count is too large: pandas-dev__pandas-32984\n",
      "Token count is too large: pandas-dev__pandas-21543\n",
      "Token count is too large: pandas-dev__pandas-6132\n",
      "Token count is too large: pandas-dev__pandas-26456\n",
      "Token count is too large: apache__airflow-24530\n",
      "Token count is too large: huggingface__transformers-10685\n",
      "Token count is too large: apache__airflow-9217\n",
      "Token count is too large: pandas-dev__pandas-8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4901 examples [06:03, 21.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2473\n",
      "Token count is too large: apache__airflow-12320\n",
      "Token count is too large: docker__compose-4113\n",
      "Token count is too large: google__jax-1880\n",
      "Token count is too large: Lightning-AI__lightning-2405\n",
      "Token count is too large: pantsbuild__pants-9084\n",
      "Token count is too large: celery__celery-3934\n",
      "Token count is too large: Qiskit__qiskit-6662\n",
      "Token count is too large: mesonbuild__meson-5152\n",
      "Token count is too large: celery__celery-4565\n",
      "Token count is too large: pantsbuild__pants-17457\n",
      "Token count is too large: Qiskit__qiskit-7251\n",
      "Token count is too large: huggingface__transformers-25447\n",
      "Token count is too large: huggingface__transformers-14487\n",
      "Token count is too large: Qiskit__qiskit-910\n",
      "Token count is too large: pandas-dev__pandas-17266\n",
      "Token count is too large: huggingface__transformers-18358\n",
      "Token count is too large: ytdl-org__youtube-dl-3790\n",
      "Token count is too large: pandas-dev__pandas-4507\n",
      "Token count is too large: ipython__ipython-1831\n",
      "Token count is too large: apache__airflow-31998\n",
      "Token count is too large: scipy__scipy-194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4912 examples [06:04, 19.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: huggingface__transformers-24334\n",
      "Token count is too large: Qiskit__qiskit-369\n",
      "Token count is too large: Qiskit__qiskit-4621\n",
      "Token count is too large: pypa__pip-2237\n",
      "Token count is too large: ytdl-org__youtube-dl-2725\n",
      "Token count is too large: pandas-dev__pandas-36176\n",
      "Token count is too large: numpy__numpy-5636\n",
      "Token count is too large: Qiskit__qiskit-1141\n",
      "Token count is too large: conan-io__conan-4667\n",
      "Token count is too large: huggingface__transformers-10334\n",
      "Token count is too large: pandas-dev__pandas-9525\n",
      "Token count is too large: pypa__pip-2699\n",
      "Token count is too large: pantsbuild__pants-6170\n",
      "Token count is too large: pandas-dev__pandas-6569\n",
      "Token count is too large: conan-io__conan-2611\n",
      "Token count is too large: google__jax-151\n",
      "Token count is too large: numpy__numpy-3645\n",
      "Token count is too large: celery__celery-5074\n",
      "Token count is too large: pantsbuild__pants-17385\n",
      "Token count is too large: ipython__ipython-13745\n",
      "Token count is too large: pandas-dev__pandas-30175\n",
      "Token count is too large: pandas-dev__pandas-36654\n",
      "Token count is too large: Qiskit__qiskit-2512\n",
      "Token count is too large: Lightning-AI__lightning-1271\n",
      "Token count is too large: celery__celery-6357\n",
      "Token count is too large: ytdl-org__youtube-dl-18228\n",
      "Token count is too large: pandas-dev__pandas-31910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4917 examples [06:04, 15.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: Qiskit__qiskit-2167\n",
      "Token count is too large: pandas-dev__pandas-32068\n",
      "Token count is too large: huggingface__transformers-11406\n",
      "Token count is too large: pypa__pip-9775\n",
      "Token count is too large: apache__airflow-19854\n",
      "Token count is too large: mesonbuild__meson-4789\n",
      "Token count is too large: pandas-dev__pandas-8680\n",
      "Token count is too large: mesonbuild__meson-1966\n",
      "Token count is too large: googleapis__google-cloud-python-4439\n",
      "Token count is too large: pandas-dev__pandas-8488\n",
      "Token count is too large: numpy__numpy-12251\n",
      "Token count is too large: googleapis__google-cloud-python-3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4920 examples [06:04, 14.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-16860\n",
      "Token count is too large: ipython__ipython-10338\n",
      "Token count is too large: apache__airflow-19048\n",
      "Token count is too large: Qiskit__qiskit-2833\n",
      "Token count is too large: wagtail__wagtail-9090\n",
      "Token count is too large: pandas-dev__pandas-21300\n",
      "Token count is too large: pandas-dev__pandas-4670\n",
      "Token count is too large: pandas-dev__pandas-8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4923 examples [06:05, 14.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3949\n",
      "Token count is too large: pandas-dev__pandas-18481\n",
      "Token count is too large: ytdl-org__youtube-dl-588\n",
      "Token count is too large: open-mmlab__mmdetection-4467\n",
      "Token count is too large: huggingface__transformers-8245\n",
      "Token count is too large: pandas-dev__pandas-7019\n",
      "Token count is too large: pandas-dev__pandas-17455\n",
      "Token count is too large: google__jax-735\n",
      "Token count is too large: pyca__cryptography-1865\n",
      "Token count is too large: mesonbuild__meson-9390\n",
      "Token count is too large: ipython__ipython-3558\n",
      "Token count is too large: huggingface__transformers-8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4927 examples [06:05, 14.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-37672\n",
      "Token count is too large: apache__airflow-9531\n",
      "Token count is too large: conan-io__conan-4991\n",
      "Token count is too large: Lightning-AI__lightning-964\n",
      "Token count is too large: ipython__ipython-356\n",
      "Token count is too large: Qiskit__qiskit-3843\n",
      "Token count is too large: mesonbuild__meson-1156\n",
      "Token count is too large: pandas-dev__pandas-4015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4930 examples [06:05, 13.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-4113\n",
      "Token count is too large: pandas-dev__pandas-29173\n",
      "Token count is too large: Lightning-AI__lightning-919\n",
      "Token count is too large: ytdl-org__youtube-dl-14716\n",
      "Token count is too large: huggingface__transformers-18648\n",
      "Token count is too large: mesonbuild__meson-1541\n",
      "Token count is too large: mesonbuild__meson-5974\n",
      "Token count is too large: huggingface__transformers-18907\n",
      "Token count is too large: mesonbuild__meson-9484\n",
      "Token count is too large: google__jax-958\n",
      "Token count is too large: docker__compose-1356\n",
      "Token count is too large: celery__celery-4240\n",
      "Token count is too large: numpy__numpy-8423\n",
      "Token count is too large: ipython__ipython-4303\n",
      "Token count is too large: pandas-dev__pandas-8330\n",
      "Token count is too large: pandas-dev__pandas-26371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4933 examples [06:05, 11.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-4489\n",
      "Token count is too large: conan-io__conan-4663\n",
      "Token count is too large: pandas-dev__pandas-26916\n",
      "Token count is too large: numpy__numpy-7016\n",
      "Token count is too large: pantsbuild__pants-19224\n",
      "Token count is too large: pantsbuild__pants-15224\n",
      "Token count is too large: mesonbuild__meson-3209\n",
      "Token count is too large: ipython__ipython-415\n",
      "Token count is too large: Qiskit__qiskit-377\n",
      "Token count is too large: pantsbuild__pants-13813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4935 examples [06:06, 10.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-3464\n",
      "Token count is too large: pandas-dev__pandas-3312\n",
      "Token count is too large: pandas-dev__pandas-19039\n",
      "Token count is too large: huggingface__transformers-18716\n",
      "Token count is too large: Qiskit__qiskit-609\n",
      "Token count is too large: Qiskit__qiskit-4762\n",
      "Token count is too large: numpy__numpy-13097\n",
      "Token count is too large: Qiskit__qiskit-1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4945 examples [06:06, 18.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pandas-dev__pandas-7842\n",
      "Token count is too large: Qiskit__qiskit-4558\n",
      "Token count is too large: Lightning-AI__lightning-2789\n",
      "Token count is too large: pandas-dev__pandas-37270\n",
      "Token count is too large: ipython__ipython-4521\n",
      "Token count is too large: ytdl-org__youtube-dl-7514\n",
      "Token count is too large: pandas-dev__pandas-22054\n",
      "Token count is too large: pandas-dev__pandas-7581\n",
      "Token count is too large: Qiskit__qiskit-5588\n",
      "Token count is too large: numpy__numpy-6660\n",
      "Token count is too large: wagtail__wagtail-738\n",
      "Token count is too large: apache__airflow-18119\n",
      "Token count is too large: pypa__pip-10846\n",
      "Token count is too large: pandas-dev__pandas-6883\n",
      "Token count is too large: pandas-dev__pandas-6112\n",
      "Token count is too large: apache__airflow-15277\n",
      "Token count is too large: apache__airflow-1431\n",
      "Token count is too large: ray-project__ray-6941\n",
      "Token count is too large: pandas-dev__pandas-4770\n",
      "Token count is too large: pandas-dev__pandas-25462\n",
      "Token count is too large: pandas-dev__pandas-37149\n",
      "Token count is too large: pandas-dev__pandas-6650\n",
      "Token count is too large: wagtail__wagtail-9133\n",
      "Token count is too large: Qiskit__qiskit-1880\n",
      "Token count is too large: pandas-dev__pandas-39239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4950 examples [06:06, 14.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: pypa__pip-6429\n",
      "Token count is too large: pypa__pip-9993\n",
      "Token count is too large: mesonbuild__meson-5116\n",
      "Token count is too large: googleapis__google-cloud-python-9991\n",
      "Token count is too large: google__jax-818\n",
      "Token count is too large: pandas-dev__pandas-11294\n",
      "Token count is too large: pandas-dev__pandas-31569\n",
      "Token count is too large: pandas-dev__pandas-35852\n",
      "Token count is too large: apache__airflow-22506\n",
      "Token count is too large: pandas-dev__pandas-39118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4954 examples [06:07, 18.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count is too large: mesonbuild__meson-1914\n",
      "Token count is too large: pantsbuild__pants-18447\n",
      "Token count is too large: pypa__pip-8678\n",
      "Token count is too large: pandas-dev__pandas-37676\n",
      "Token count is too large: pantsbuild__pants-13402\n",
      "Token count is too large: Lightning-AI__lightning-3188\n",
      "Token count is too large: docker__compose-2878\n",
      "Token count is too large: ipython__ipython-13417\n",
      "Token count is too large: pandas-dev__pandas-9743\n",
      "Token count is too large: PrefectHQ__prefect-2646\n",
      "Token count is too large: Lightning-AI__lightning-941\n",
      "Token count is too large: pandas-dev__pandas-34877\n",
      "Token count is too large: Qiskit__qiskit-9386\n",
      "Token count is too large: docker__compose-3056\n",
      "Token count is too large: googleapis__google-cloud-python-10162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4959 examples [06:07, 13.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4959/4959 [00:00<00:00, 18409.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_next_row():\n",
    "    for row in dataset:\n",
    "        try:\n",
    "            input_text = row[\"text\"]\n",
    "            input_text = input_text.replace(PATCH_FORMATTING_INST, SEARCH_REPLACE_INST)\n",
    "            row_id = row[\"instance_id\"]\n",
    "\n",
    "            input_text += f\"\\n\\n{DELIM}\\n\\n\"\n",
    "\n",
    "            diff_string_trimmed = row[\"patch\"].replace(\"<patch>\", \"\").replace(\"</patch>\", \"\")\n",
    "            # Maybe clean up some more strings at the top\n",
    "            parsed_diff = parse_diff(diff_string_trimmed)\n",
    "            fmtd_search_replaces = \"\"\n",
    "            # Need to remove the a/ and the b/ at the start\n",
    "            for block in parsed_diff:\n",
    "                if len(block.search_block.strip()) == 0 and len(block.replace_block.strip()) == 0:\n",
    "                    continue\n",
    "\n",
    "                if \"dev/null\" in block.previous_filepath:\n",
    "                    fmtd_search_replaces += f\"\\n<newfile>\\n<filepath>{block.filepath[2:]}</filepath>\\n<content>{block.contents}</content>\\n</newfile>\"\n",
    "                else:\n",
    "                    fmtd_search_replaces += f\"\\n<edit>\\n<filepath>{block.filepath[2:]}</filepath>\\n<search>{block.search_block}</search>\\n<replace>{block.replace_block}</replace>\\n</edit>\\n\"\n",
    "\n",
    "            token_count = len(encoding.encode(input_text)) + len(encoding.encode(fmtd_search_replaces))\n",
    "            # print(f\"Was able to calculate token count\")\n",
    "            if token_count > 8000:\n",
    "                print(f\"Token count is too large: {row_id}\")\n",
    "            else:\n",
    "                yield {\"input\": input_text, \"output\": fmtd_search_replaces}\n",
    "        except Exception as e:\n",
    "            print(\"There was an error processing\")\n",
    "\n",
    "ds = Dataset.from_generator(process_next_row)\n",
    "ds.save_to_disk(\"./search_replace_dataset/\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 11.65ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/vdaita/swe-bench-search-replace/commit/bce2418428cb1e0e93b19f92c8b47d99690e65db', commit_message='Upload dataset', commit_description='', oid='bce2418428cb1e0e93b19f92c8b47d99690e65db', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"vdaita/swe-bench-search-replace\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 4959/4959 [00:00<00:00, 205921.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def process_next_row_with_insertions():\n",
    "    for row in dataset:\n",
    "        try:\n",
    "            input_text = row[\"text\"]\n",
    "            input_text = input_text.replace(PATCH_FORMATTING_INST, SEARCH_REPLACE_INST)\n",
    "            row_id = row[\"instance_id\"]\n",
    "\n",
    "            input_text += f\"\\n\\n{DELIM}\\n\\n\"\n",
    "\n",
    "            diff_string_trimmed = row[\"patch\"].replace(\"<patch>\", \"\").replace(\"</patch>\", \"\")\n",
    "            # Maybe clean up some more strings at the top\n",
    "            parsed_diff = parse_diff(diff_string_trimmed)\n",
    "            fmtd_search_replaces = \"\"\n",
    "            # Need to remove the a/ and the b/ at the start\n",
    "            for block in parsed_diff:\n",
    "                if \"dev/null\" in block.previous_filepath:\n",
    "                    fmtd_search_replaces += f\"\\n<newfile>\\n<filepath>{block.filepath[2:]}</filepath>\\n<content>{block.contents}</content>\\n</newfile>\"\n",
    "                else:\n",
    "                    fmtd_search_replaces += f\"\\n<edit>\\n<filepath>{block.filepath[2:]}</filepath>\\n<search>{block.search_block}</search>\\n<replace>{block.replace_block}</replace>\\n</edit>\\n\"\n",
    "\n",
    "            token_count = len(encoding.encode(input_text)) + len(encoding.encode(fmtd_search_replaces))\n",
    "            print(f\"Was able to calculate token count\")\n",
    "            if token_count > 14000:\n",
    "                print(f\"Token count is too large: {row_id}\")\n",
    "            else:\n",
    "                yield {\"input\": input_text, \"output\": fmtd_search_replaces}\n",
    "        except Exception as e:\n",
    "            print(\"There was an error processing\")\n",
    "\n",
    "ds = Dataset.from_generator(process_next_row)\n",
    "ds.save_to_disk(\"./search_replace_dataset/\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superdocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
